{
        "posts": [
          {
            "id": "6416878f23ad590d103c02cd",
            "uuid": "7e663bf2-5a7a-457b-ae1b-27a84d17e3eb",
            "title": "About This Site",
            "slug": "about",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"hr\",{}],[\"hr\",{}],[\"markdown\",{\"markdown\":\"### Credits - Thank You!\\n\\n- The site's banner image is courtesy of my brother and amature photographer, Ron McFate.\\n- To-Do List banner image is from <a href=\\\"https://unsplash.com/@jessicalewiscreative?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\\\">Jessica Lewis</a> on <a href=\\\"https://unsplash.com/photos/fJXv46LT7Xk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\\\">Unsplash</a>.  \\n- Unless noted otherwise, all other images were tagged by the built-in _Upslash_ feature.\"}],[\"markdown\",{\"markdown\":\"# Rebuild Me\\nClick [here](https://blog.SummittDweller.com/rebuild.html) if you know the magic word.  ðŸ™ƒ\"}]],\"markups\":[[\"a\",[\"href\",\"https://gohugo.io\"]],[\"a\",[\"href\",\"https://drupal.org\"]],[\"code\"],[\"a\",[\"href\",\"https://github.com/TryGhost/eleventy-starter-ghost?ref=blog-ghost.summittservices.com\"]],[\"a\",[\"href\",\"https://hooshmand.net/host-a-second-or-multiple-ghost-blogs-on-one-server/?ref=blog-ghost.summittservices.com\"]],[\"a\",[\"href\",\"https://ghost.org\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Summitt Dweller's Blog is an independent publication launched in March 2023 by Mark McFate, aka \\\"Summitt Dweller\\\".  It replaces an old \"],[0,[0],1,\"Hugo\"],[0,[],0,\" site which replaced an old \"],[0,[1],1,\"Drupal\"],[0,[],0,\" site many years ago.\"]]],[1,\"h3\",[[0,[],0,\"Eleventy (11ty) + Ghost\"]]],[1,\"p\",[[0,[],0,\"This past weekend my daughter, Mackenzie, made the decision to move her portfolio page into a configuration that features Eleventy (11ty) on the frontend with content managed in Ghost on the backend.  I like that combination very much so to help support her move, and learn a little something along the way, we've setup a new Ghost server in a DigitalOcean droplet, namely \"],[0,[2],1,\"ghostonubuntu2204-s-1vcpu-1gb-intel-nyc1-01\"],[0,[],0,\" , and I've decided to make the same move myself.\"]]],[1,\"p\",[[0,[],0,\"This post is intended to track my blog's journey from a \"],[0,[2],1,\"git\"],[0,[],0,\" workflow (for both structure and content) in Hugo, to Eleventy + Ghost, and it begins with the guidance provided in \"],[0,[3],1,\"https://github.com/TryGhost/eleventy-starter-ghost\"],[0,[],0,\". I already have a working Ghost server as mentioned above, the one that we setup for Mackenzie's portfolio, and we've already followed \"],[0,[4],1,\"Install and host Multiple Ghost blog Servers on One Server\"],[0,[],0,\" to create the Ghost backend for this blog on the same DO droplet that host's Mackenzie's portfolio content.\"]]],[10,0],[1,\"h3\",[[0,[],0,\"Start Your Own Thing\"]]],[1,\"p\",[[0,[],0,\"Enjoying the experience? Get started for free and set up your very own subscription business using \"],[0,[5],1,\"Ghost\"],[0,[],0,\", the same platform that powers the CMS backend of this website.\"]]],[10,1],[10,2],[10,3],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Summitt Dweller's Blog is an independent publication launched in March 2023 by Mark McFate, aka \"Summitt Dweller\". Â It replaces an old <a href=\"https://gohugo.io\">Hugo</a> site which replaced an old <a href=\"https://drupal.org\">Drupal</a> site many years ago.</p><h3 id=\"eleventy-11ty-ghost\">Eleventy (11ty) + Ghost</h3><p>This past weekend my daughter, Mackenzie, made the decision to move her portfolio page into a configuration that features Eleventy (11ty) on the frontend with content managed in Ghost on the backend. Â I like that combination very much so to help support her move, and learn a little something along the way, we've setup a new Ghost server in a DigitalOcean droplet, namely <code>ghostonubuntu2204-s-1vcpu-1gb-intel-nyc1-01</code> , and I've decided to make the same move myself.</p><p>This post is intended to track my blog's journey from a <code>git</code> workflow (for both structure and content) in Hugo, to Eleventy + Ghost, and it begins with the guidance provided in <a href=\"https://github.com/TryGhost/eleventy-starter-ghost?ref=blog-ghost.summittservices.com\">https://github.com/TryGhost/eleventy-starter-ghost</a>. I already have a working Ghost server as mentioned above, the one that we setup for Mackenzie's portfolio, and we've already followed <a href=\"https://hooshmand.net/host-a-second-or-multiple-ghost-blogs-on-one-server/?ref=blog-ghost.summittservices.com\">Install and host Multiple Ghost blog Servers on One Server</a> to create the Ghost backend for this blog on the same DO droplet that host's Mackenzie's portfolio content.</p><hr><h3 id=\"start-your-own-thing\">Start Your Own Thing</h3><p>Enjoying the experience? Get started for free and set up your very own subscription business using <a href=\"https://ghost.org\">Ghost</a>, the same platform that powers the CMS backend of this website.</p><hr><!--kg-card-begin: markdown--><h3 id=\"creditsthank-you\">Credits - Thank You!</h3>\n<ul>\n<li>The site's banner image is courtesy of my brother and amature photographer, Ron McFate.</li>\n<li>To-Do List banner image is from <a href=\"https://unsplash.com/@jessicalewiscreative?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Jessica Lewis</a> on <a href=\"https://unsplash.com/photos/fJXv46LT7Xk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText\">Unsplash</a>.</li>\n<li>Unless noted otherwise, all other images were tagged by the built-in <em>Upslash</em> feature.</li>\n</ul>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h1 id=\"rebuild-me\">Rebuild Me</h1>\n<p>Click <a href=\"https://blog.SummittDweller.com/rebuild.html\">here</a> if you know the magic word.  ðŸ™ƒ</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "6416878f23ad590d103c02cd",
            "plaintext": "Summitt Dweller's Blog is an independent publication launched in March 2023 by Mark McFate, aka \"Summitt Dweller\". Â It replaces an old Hugo site which replaced an old Drupal site many years ago.\n\n\nEleventy (11ty) + Ghost\n\nThis past weekend my daughter, Mackenzie, made the decision to move her portfolio page into a configuration that features Eleventy (11ty) on the frontend with content managed in Ghost on the backend. Â I like that combination very much so to help support her move, and learn a little something along the way, we've setup a new Ghost server in a DigitalOcean droplet, namely ghostonubuntu2204-s-1vcpu-1gb-intel-nyc1-01 , and I've decided to make the same move myself.\n\nThis post is intended to track my blog's journey from a git workflow (for both structure and content) in Hugo, to Eleventy + Ghost, and it begins with the guidance provided in https://github.com/TryGhost/eleventy-starter-ghost. I already have a working Ghost server as mentioned above, the one that we setup for Mackenzie's portfolio, and we've already followed Install and host Multiple Ghost blog Servers on One Server to create the Ghost backend for this blog on the same DO droplet that host's Mackenzie's portfolio content.\n\n\nStart Your Own Thing\n\nEnjoying the experience? Get started for free and set up your very own subscription business using Ghost, the same platform that powers the CMS backend of this website.\n\n\nCredits - Thank You!\n\n\n * The site's banner image is courtesy of my brother and amature photographer, Ron McFate.\n * To-Do List banner image is from Jessica Lewis on Unsplash.\n * Unless noted otherwise, all other images were tagged by the built-in Upslash feature.\n\n\n\nRebuild Me\n\n\nClick here if you know the magic word. ðŸ™ƒ\n",
            "feature_image": null,
            "featured": 0,
            "type": "page",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-03-19T03:54:55.000Z",
            "updated_at": "2023-04-06T15:25:50.000Z",
            "published_at": "2023-03-19T03:54:55.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "641851af23ad590d103c0468",
            "uuid": "158bd4ec-53ac-455d-b90f-aae67d322d11",
            "title": "This Blog in Eleventy + Ghost",
            "slug": "this-blog-in-eleventy-ghost",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"bookmark\",{\"version\":\"1.0\",\"type\":\"bookmark\",\"url\":\"__GHOST_URL__/ghost/#/posts\",\"metadata\":{\"url\":\"__GHOST_URL__/ghost/#/posts\",\"title\":\"Ghost Admin\",\"description\":null,\"author\":null,\"publisher\":\"Ghost\",\"thumbnail\":null,\"icon\":\"__GHOST_URL__/ghost/assets/img/apple-touch-icon-74680e326a7e87b159d366c7d4fb3d4b.png\"},\"caption\":\"The backend: My <code>blog-ghost.summittservices.com</code> admin interface.\"}],[\"code\",{\"code\":\"cd ~/GitHub\\ngit clone https://github.com/TryGhost/eleventy-starter-ghost.git blog-eleventy-ghost\\ncd blog-eleventy-ghost\\nyarn\\nyarn start\\n^C\"}],[\"code\",{\"code\":\"rm -fr .git\\ngit init\\ngit add .\\ngit commit -m \\\"First commit\\\"\\ngit branch -M main\\ngit remote add origin https://github.com/SummittDweller/blog-eleventy-ghost.git\\ngit push -u origin main\"}],[\"code\",{\"language\":\"env\",\"code\":\"# GHOST_API_URL=https://eleventy.ghost.io\\n# GHOST_CONTENT_API_KEY=5a562eebab8528c44e856a3e0a\\nGHOST_API_URL=https://blog-ghost.summittservices.com\\nGHOST_CONTENT_API_KEY=***********hidden****************\\nSITE_URL=http://localhost:8080\"}],[\"code\",{\"code\":\"yarn start\\n\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2023/03/Screenshot-2023-03-20-at-08.40.32.png\",\"width\":452,\"height\":641,\"caption\":\"My new blog connected to <code>blog-ghost.summittservices.com</code>.\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2023/03/Screenshot-2023-03-20-at-08.45.11.png\",\"width\":457,\"height\":780,\"caption\":\"New blog updated with an initial copy of this post.\"}],[\"markdown\",{\"markdown\":\"## Migrating Content\\nNow that we have a working local site, it's time to copy some content (posts and microposts) that I wish to keep from my old blog at https://github.com/SummittDweller/blogs-SummittDweller into `blog-ghost.summittservices.com`.  For now I'm doing that \\\"manually\\\" by opening a new post and copying content from old .md files into them one-at-a-time.  Using that tedious process I managed to copy 8 posts forward into this blog.\\n\\nAlong the way I also did some quick investigation of [post2ghost](https://github.com/dumrauf/post2ghost), a utility aimed at helping populate Ghost posts from .md files.  Great idea!  Unfortunately, it looks like that work relies on an ancient version of the Ghost API, and I don't think it will work at all with the latest due to extensive changes in the API.\\n\\nStill, I very much like the idea behind `post2ghost` and I also like the name.  Maybe I'll reach out and see if I can borrow the name and leverage the new Ghost API along with my [Hugo Front Matter Tools](https://github.com/Digital-Grinnell/hugo-front-matter-tools) project to create a Python script that will read .md files with front matter and turn them into API-compatible JSON for bulk creation of new Ghost posts.  More on that effort later...\\n\\n## Next Step - Deploy and Assign an Address\\nCurrently this new blog is only available locally as https://localhost:8080 because it does not yet deploy to any internet host.  The [Eleventy Starter Ghost](https://github.com/TryGhost/eleventy-starter-ghost) project that I'm following is equiped to deploy a site to [Netlify](https://www.netlify.com) and use deploy hooks from Ghost to trigger Netlify rebuilds. \\n\\nNetlify is fine, but I only use them as a last resort, and thus far that's only for the [Wieting Theatre](https://Wieting.TamaToledo.com) where I rely on NetlifyCMS to manage backend content.  Ironically, NetlifyCMS was just rebranded as `Decap CMS`.  See https://www.netlify.com/blog/netlify-cms-to-become-decap-cms/ for details.\\n\\nSo, I'm going to try and reproduce the triggers, hooks and actions intended for Netlify with my own GitHub Action (plus whatever it takes) to deploy this blog as https://blog.SummittDweller.com.  That URL currently delivers a Hugo static site hosted on DigitalOcean (DO).  Since my Ghost instance is also on DO I think I'll take a crack at deploying this blog to DO App Platform as a Starter App.  I hope that the guidance provided in [Step 11 â€” Deploying to DigitalOcean with App Platform](https://www.digitalocean.com/community/tutorials/how-to-create-and-deploy-your-first-eleventy-website#step-11-deploying-to-digitalocean-with-app-platform) proves helpful.\\n\\n### Step 11 â€” Deploying to DigitalOcean with App Platform - My Specifics\\n\\nThe aforementioned guidance did indeed prove helpful, although it is a little out-dated compared to my acutal experience, which is detailed below in up-to-date (as of March 2023) words and pictures, of course.\\n\\nFirst I visited my DigitalOcean account and clicked the `Create` button as directed.  \\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 0001.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0001.png\\\" />\\n  <figcaption class=\\\"figure\\\"> \\n    Figure 1. Replacing the `blogs-summitt-dweller` app in DigitalOcean. Click `Create`.\\n  </figcaption>\\n</figure>    \\n\\nNext, I selected `Apps` as directed in order to initiate the creation of a new `App`. \\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 0011.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0011.png\\\" />\\n  <figcaption class=\\\"figure\\\">Figure 2. Select 'Apps'.<figcaption>\\n</figure>    \\n\\nThis app is to be built from a GitHub repo so I chose `GitHub`, allowed the system to lookup all the GitHub repositories I've given DigitalOcean permisison to \\\"see\\\". \\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 0027.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0027.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 3. Select `GitHub` and then the new site project repo.<figcaption>\\n</figure>    \\n\\nI choose the my `SummittDweller/blog-eleventy-ghost` repo. \\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 0045.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0045.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 4. Choose the repo.<figcaption>\\n</figure>  \\n\\nThen accepted all the defaults for the `main` branch, the `/` root directory (of the project repo), the default for `Auto Deploy`, and clicked `Next` to proceed. \\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 0065.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0065.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 5. Accept defaults and click `Next`.<figcaption>\\n</figure>    \\n\\nUnfortunately, when I initiated the process DigitalOcean detected the repo as a \\\"Web Service\\\", perhaps because of the `netlify.toml` file?  I don't want to create a \\\"Web Service\\\" since those are more complex and expensive than a simple static 11ty site.  So, I choose to edit the `Resource Type` to change that.\\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 0861.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0861.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 6. Edit the `Resource Type`...<figcaption>\\n</figure>    \\n\\nI subsequently choose a `Static Site` and clicked to `Save` the change.\\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 0916.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0916.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 7. Choose `Static Site` and click `Save`.<figcaption>\\n</figure>\\n\\nMy 11ty project generates static content into the project's `/dist` directory so I edited the `Output Directory` setting, set it to `dist` and clicked to `Save` that change.\\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 0954.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0954.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 8. Edit the `Output Directory`...<figcaption>\\n</figure>    \\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 0970.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0970.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 9. Set to `dist` and click `Save`.<figcaption>\\n</figure>    \\n\\nNext I clicked `Back` to find the \\\"Billing\\\" section, review the new deployment fees (should be $3/month or less), and click `Create Resources` to begin the first build and deployment.\\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 1003.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/1003.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 10. Click `Back`...<figcaption>\\n</figure>    \\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 1114.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/1114.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 11. Review fees and click `Create Resources`.<figcaption>\\n</figure>    \\n\\nIt took a few minutes, but once the app is complete you should see a screen like that shown in Figure 12 below.  Another unfortunate stumble... I forgot to change my App name up front so it carries a meaningless, random name of `coral-app`.  Let's change that now.\\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 1139.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/1139.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 12. App was created, but with a meaningless  name.<figcaption>\\n</figure>    \\n\\nI clicked `Edit` in the \\\"App Settings / Info\\\" section and changed the name to better represent the project and site that's been created.\\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 1258.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/1258.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 13. Edit the App Settings Info to change the name.<figcaption>\\n</figure>    \\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 1461.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/1461.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 14. Specify a better name and click `Save`.<figcaption>\\n</figure>    \\n\\nNote that the unique URL generated for the app did NOT change.  I fear we are stuck with that name, but it won't be a concern for very long.  Once the deployment is done you should see a `Live App` link/button.  Click it!\\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 1494.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/1494.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 15. Wait for the app to deploy and click `Live App`.<figcaption>\\n</figure>    \\n\\nEureka!  We should have a new site deployed to DigitalOcean.\\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 1513.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/1513.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 16. Eureka, we have an app!<figcaption>\\n</figure>    \\n\\nOne more thing to do, give this new site a meaningful URL.  Open the `Manage` screen and our new app, the click the `Settings` tab. \\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 2014.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/2014.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 17. Manage the app and click `Settings`.<figcaption>\\n</figure> \\n\\nClick `Add Domain` and enter the \\\"correct\\\" URL.  In this case the app needs to respond at https://blog.SummittDweller.com.  \\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 2024.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/2024.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 18. Click `Add Domain`.<figcaption>\\n</figure>    \\n\\nMy registar already points the `summittdweller.com` domain at the DigitalOcean DNS servers, so I choose `DigitalOcean DNS` as the keeper of the domain's records.  \\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 2062.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/2062.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 19. Enter the new domain name and choose DigitalOcean DNS.<figcaption>\\n</figure>    \\n\\nAfter the domain is added I needed great patience since I could visit the site, but no valid certificates had been generated yet.  I was able to check my DigitalOcean `Network` screen to see that a new CNAME record has been added for the site, and after about 30 minutes I was finally able to open the \\\"secure\\\" site at https://blog.SummittDweller.com.  \\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 2165.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/2165.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 20. Be patient, the site is not instantly secure.<figcaption>\\n</figure>    \\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Image file is 2450.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/2450.png\\\" /> \\n  <figcaption class=\\\"figure\\\">Figure 21. Visit `Networking` and observe a new CNAME record.<figcaption>\\n</figure>    \\n\\n## Customization: Formatting Figures and Matomo\\n\\nOk, now that the domain is added I wanted to introduce my first bonafide customizations, namely \\n\\n  - Better formatting of figures like you see in the previous section and below, and  \\n  - Introduction of my [Matomo](https://analytics.summittservices.com) tracking code.\\n\\n### Using Code Injection\\n\\nGhost has a nice feature called `Code Injection` that allows me to inject snippets of Javascript and CSS into every page's header and footer.  Not sure I'm \\\"sold\\\" on the use of `Code Injection` since it puts \\\"code\\\" into a database, and that's something I don't care to do.  However, as a short-term \\\"test\\\" it's a wonderful feature.\\n\\nTo engage it I visited my blog's [Ghost admin page](__GHOST_URL__/ghost) and clicked on the `gear icon` (lower-left red box in Figure 22 below) then selected the `Code Injection` as shown below.  The code injection screen that opens provides both header and footer editing spaces where Javascript and/or CSS can be added. \\n\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Ghost-Code-Injection-01.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/Ghost-Code-Injection-01.png\\\" />\\n  <figcaption class=\\\"figure\\\">Figure 22. Opening Ghost Code Injection.</figcaption>\\n</figure>  \\n\\nThe CSS that I added in the header was:\\n\\n```js\\n<style>\\n  p > figure > figcaption {\\n    font-weight: 400;\\n    font-style: italic;\\n    font-size: 16px;\\n    color: black;\\n    outline: 0;\\n    z-index: 300;\\n    padding: 2px 5px;\\n    text-align: left;\\n  }\\n    \\n  p > figure > img {\\n    border: 1px solid black;\\n  }    \\n</style>  \\n```\\n\\nThe Javascript code injected into the footer was:\\n\\n```js\\n<script>\\n  // Creates Captions from img Title attributes\\n  $(\\\"img\\\").each(\\n    function() {\\n      // Let's make the title a caption\\n      if ($(this).attr(\\\"title\\\")) {\\n        $(this).wrap(\\n          '<figure class=\\\"figure\\\"></figure>'\\n        ).after(\\n          '<figcaption class=\\\"figure\\\">' +\\n             $(this).attr(\\\"title\\\") +\\n          '</figcaption>'\\n      );\\n    }\\n  });\\n</script>\\n```\\n\\nBoth of the above code snippets were inspired by blogger [Kevin Chung](https://blog.kchung.co/author/kchung/) and his [Adding image captions to Ghost](https://blog.kchung.co/adding-image-captions-to-ghost/) post.  Kevin's code looked for any `![alt](src)` image references in the content and reformatted them into HTML that looked something like this:\\n\\n```html\\n<figure class=\\\"figure\\\">\\n  <img src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0011.png\\\" alt=\\\"Image file is 0011.png\\\" title=\\\"Figure 2. Select 'Apps'.\\\" loading=\\\"lazy\\\"/>\\n  <figcaption class=\\\"figure\\\">Figure 2. Select 'Apps'.</figcaption>\\n</figure>    \\n```\\n\\nKevin's original code modified ALL of the images, the `<img>` tags, in the post if they had `alt` attributes, and in my case that's ALL images.  That's not what I wanted to happen, so I reworked the logic so that only images (`<img>`) with `title` attributes would get captured and reformatted.  That worked nicely, but my results were inconsistent.  The behavior I saw in localhost rendering was different than in my Ghost site, and sometimes differnt than in my Elevent site.  Not good.\\n\\nAll of the Markdown for the figures, like those in this section and above, that I wanted to control is generated using my [Convert Videos to Frames](https://github.com/SummittDweller/convert_videos_to_frames) utility, I chose to take the bull by the horns and just have it generate exactly the `<figure>` and `<figcaption>` HTML that I wanted to see.  So, the raw Markdown for the figure you see above is simply:\\n\\n```html\\n<figure>\\n  <img class=\\\"figure\\\" alt=\\\"Ghost-Code-Injection-01.png\\\" src=\\\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/Ghost-Code-Injection-01.png\\\" />\\n  <figcaption class=\\\"figure\\\"> \\n    Figure 22. Opening Ghost Code Injection.\\n  </figcaption>\\n</figure> \\n```\\n\\nThe images in this instance are housed as BLOBs in _Azure Storage_ and served directly from there. \\n\\nThe simple/raw approach that I ultimately arrived at is consistent and to-the-point, and it doesn't need any Ghost code injection so I removed all of the \\\"injected\\\" code from __GHOST_URL__/ghost/#/settings/code-injection.  I also found that I could achieve better, more consistent CSS control by adding custom code to the end of the project's `src/_includes/css/styles.css` file like so:\\n      \\n```css\\n/* Summitt Dweller styles\\n/* ---------------------------------------------------------- */\\n\\nfigure img.figure.lazyloaded {\\n  border: 1px solid black;\\n}\\n\\nfigure {\\n  text-align: center;\\n}\\n\\n.post-full-content figcaption {\\n  margin: 0.2em 3em 0;\\n  font-size: 55%;\\n  line-height: 1.6em;\\n  text-align: center;\\n  font-weight: 400;\\n}\\n\\ncode {\\n  font-family: monospace,monospace;\\n  font-size: .75em;\\n  background: #eceebd;\\n  padding: 2px 5px;\\n  border-radius: 5px;\\n}\\n\\npre > code {\\n  background: none;\\n  padding: 0;\\n}\\n```      \\n\\nThe intent is to wrap the images with a `class=\\\"figure\\\"` attribute in a nice little black border, and more! \\n      \\n      \\n### Matomo\\n\\nWhile Ghost code injection didn't behave well for reformatting figures, it does work nicely, and consistently, for Matomo tracking!  However, I'd still prefer to put as much as possible into code, not into a database, so I grabbed a copy of my Matomo code that's specifically for [this blog](https://blog.SummittDweller.com) and applied it like so in the project's `src/_includes/layouts/default.njk` file: \\n\\n```js\\n<!-- Matomo -->\\n<script>\\n  var _paq = window._paq = window._paq || [];\\n  /* tracker methods like \\\"setCustomDimension\\\" should be called before \\\"trackPageView\\\" */\\n  _paq.push(['trackPageView']);\\n  _paq.push(['enableLinkTracking']);\\n  (function() {\\n    var u=\\\"https://analytics.summittservices.com/\\\";\\n    _paq.push(['setTrackerUrl', u+'matomo.php']);\\n    _paq.push(['setSiteId', '10']);\\n    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];\\n    g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);\\n  })();\\n</script>\\n<!-- End Matomo Code -->\\n```\\n\\nBeautimous. It just works!\\n\\n\"}]],\"markups\":[[\"code\"],[\"a\",[\"href\",\"https://github.com/TryGhost/eleventy-starter-ghost\"]],[\"a\",[\"href\",\"https://hooshmand.net/host-a-second-or-multiple-ghost-blogs-on-one-server/\"]],[\"em\"],[\"a\",[\"href\",\"https://gist.github.com/SummittDweller/1af7ecbb9051ee04d0a9dbad7f74c1e7\"]],[\"a\",[\"href\",\"https://eleventy.ghost.io/\"]],[\"a\",[\"href\",\"__GHOST_URL__/ghost/#/settings/integrations/64185c1723ad590d103c051a\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"This past weekend my daughter, Mackenzie, made the decision to move her portfolio page into a configuration that features Eleventy (11ty) on the frontend with content managed in Ghost on the backend.  I like that combination very much so to help support her move, and learn a little something along the way, we've setup a new Ghost server in a DigitalOcean droplet, namely \"],[0,[0],1,\"ghostonubuntu2204-s-1vcpu-1gb-intel-nyc1-01\"],[0,[],0,\" , and I've decided to make the same move myself.  \"]]],[1,\"p\",[[0,[],0,\"This post is intended to track my blog's journey from a \"],[0,[0],1,\"git\"],[0,[],0,\" workflow (for both structure and content) in Hugo, to Eleventy + Ghost, and it begins with the guidance provided in \"],[0,[1],1,\"https://github.com/TryGhost/eleventy-starter-ghost\"],[0,[],0,\".  I already have a working Ghost server as mentioned above, the one that we setup for Mackenzie's portfolio, and we've already followed \"],[0,[2],1,\"Install and host Multiple Ghost blog Servers on One Server\"],[0,[],0,\" to create the Ghost backend for this blog on the same DO droplet that host's Mackenzie's portfolio content.  The admin interface for my blog instance of Ghost is shown below.  \"]]],[10,0],[1,\"h2\",[[0,[],0,\"Creating the 11ty Frontend\"]]],[1,\"p\",[[0,[],0,\"Working locally on my Mac Mini this is the input I captured...\"]]],[10,1],[1,\"p\",[[0,[3],0,\"Note that complete input and output from all commands is available in \"],[0,[4],1,\"https://gist.github.com/SummittDweller/1af7ecbb9051ee04d0a9dbad7f74c1e7\"],[0,[],1,\".\"]]],[1,\"p\",[[0,[],0,\"That worked flawlessly and it's quick too!  \"]]],[1,\"h2\",[[0,[],0,\"Saving This Work in GitHub\"]]],[1,\"p\",[[0,[],0,\"Time to save what's been done here before our progress is lost, and I didn't fork the \"],[0,[1,0],2,\"TryGhost/eleventy-starter-ghost\"],[0,[],0,\" project because I don't intend to try and improve it, so my project needs a new GitHub home.  My typical process for doing that looks something like this...\"]]],[10,2],[1,\"h2\",[[0,[],0,\"Replacing the Ghost Backend\"]]],[1,\"p\",[[0,[],0,\"By default the project I'm using connects its 11ty frontend to a Ghost backend at \"],[0,[5],1,\"https://eleventy.ghost.io/\"],[0,[],0,\".  Fortunately, my project's \"],[0,[0],1,\"README.md\"],[0,[],0,\" file, an ammended copy from the original \"],[0,[0],1,\"TryGhost\"],[0,[],0,\" project, also provides the simple guidance required to change that, like so...\"]]],[1,\"p\",[[0,[],0,\"First, I visited \"],[0,[6],1,\"https://blog-ghost.summittservices.com/ghost/#/settings/integrations/\"],[0,[],0,\" to create new API keys, and saved them in my password vault.  Next, I needed to edit the project's \"],[0,[0],1,\".env\"],[0,[],0,\" file to read like this:\"]]],[10,3],[1,\"p\",[[0,[],0,\"Done.  When the \"],[0,[0],1,\"blog-ghost.summittservices.com\"],[0,[],0,\" instance of Ghost was created I took steps to \\\"make it private\\\", so it should function as a backend only.   So, running \"],[0,[0],1,\"yarn start\"],[0,[],0,\" with the new \"],[0,[0],1,\".env\"],[0,[],0,\" configuration should give me a stripped-down \"],[0,[0],1,\"localhost:8080\"],[0,[],0,\" edition of the blog pulling content from the intended Ghost backend, like so:\"]]],[10,4],[1,\"p\",[[0,[],0,\"Yup, that works!  I get something that looks like this now:\"]]],[10,5],[1,\"p\",[[0,[],0,\"Even better, when I save and \"],[0,[0],1,\"Publish\"],[0,[],0,\" my work on this post, effectively removing its \\\"Draft\\\" status in \"],[0,[0],1,\"blog-ghost.summittservices.com\"],[0,[],0,\", I should see an instantaneous update in my \"],[0,[0],1,\"https://localhost:8080\"],[0,[],0,\" instance of the blog.  Wish me luck...  \"]]],[1,\"p\",[[0,[],0,\"Beautimous!  Well, almost.  The change to the site was not \\\"instantaneous\\\", but after a quick \"],[0,[0],1,\"ctrl-c\"],[0,[],0,\" and a new \"],[0,[0],1,\"yarn start\"],[0,[],0,\" we have this:\"]]],[10,6],[10,7],[1,\"p\",[]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>This past weekend my daughter, Mackenzie, made the decision to move her portfolio page into a configuration that features Eleventy (11ty) on the frontend with content managed in Ghost on the backend. Â I like that combination very much so to help support her move, and learn a little something along the way, we've setup a new Ghost server in a DigitalOcean droplet, namely <code>ghostonubuntu2204-s-1vcpu-1gb-intel-nyc1-01</code> , and I've decided to make the same move myself. Â </p><p>This post is intended to track my blog's journey from a <code>git</code> workflow (for both structure and content) in Hugo, to Eleventy + Ghost, and it begins with the guidance provided in <a href=\"https://github.com/TryGhost/eleventy-starter-ghost\">https://github.com/TryGhost/eleventy-starter-ghost</a>. Â I already have a working Ghost server as mentioned above, the one that we setup for Mackenzie's portfolio, and we've already followed <a href=\"https://hooshmand.net/host-a-second-or-multiple-ghost-blogs-on-one-server/\">Install and host Multiple Ghost blog Servers on One Server</a> to create the Ghost backend for this blog on the same DO droplet that host's Mackenzie's portfolio content. Â The admin interface for my blog instance of Ghost is shown below. Â </p><figure class=\"kg-card kg-bookmark-card kg-card-hascaption\"><a class=\"kg-bookmark-container\" href=\"__GHOST_URL__/ghost/#/posts\"><div class=\"kg-bookmark-content\"><div class=\"kg-bookmark-title\">Ghost Admin</div><div class=\"kg-bookmark-description\"></div><div class=\"kg-bookmark-metadata\"><img class=\"kg-bookmark-icon\" src=\"__GHOST_URL__/ghost/assets/img/apple-touch-icon-74680e326a7e87b159d366c7d4fb3d4b.png\" alt=\"\"><span class=\"kg-bookmark-author\">Ghost</span></div></div></a><figcaption>The backend: My <code>blog-ghost.summittservices.com</code> admin interface.</figcaption></figure><h2 id=\"creating-the-11ty-frontend\">Creating the 11ty Frontend</h2><p>Working locally on my Mac Mini this is the input I captured...</p><pre><code>cd ~/GitHub\ngit clone https://github.com/TryGhost/eleventy-starter-ghost.git blog-eleventy-ghost\ncd blog-eleventy-ghost\nyarn\nyarn start\n^C</code></pre><p><em>Note that complete input and output from all commands is available in <a href=\"https://gist.github.com/SummittDweller/1af7ecbb9051ee04d0a9dbad7f74c1e7\">https://gist.github.com/SummittDweller/1af7ecbb9051ee04d0a9dbad7f74c1e7</a>.</em></p><p>That worked flawlessly and it's quick too! Â </p><h2 id=\"saving-this-work-in-github\">Saving This Work in GitHub</h2><p>Time to save what's been done here before our progress is lost, and I didn't fork the <a href=\"https://github.com/TryGhost/eleventy-starter-ghost\"><code>TryGhost/eleventy-starter-ghost</code></a> project because I don't intend to try and improve it, so my project needs a new GitHub home. Â My typical process for doing that looks something like this...</p><pre><code>rm -fr .git\ngit init\ngit add .\ngit commit -m \"First commit\"\ngit branch -M main\ngit remote add origin https://github.com/SummittDweller/blog-eleventy-ghost.git\ngit push -u origin main</code></pre><h2 id=\"replacing-the-ghost-backend\">Replacing the Ghost Backend</h2><p>By default the project I'm using connects its 11ty frontend to a Ghost backend at <a href=\"https://eleventy.ghost.io/\">https://eleventy.ghost.io/</a>. Â Fortunately, my project's <code>README.md</code> file, an ammended copy from the original <code>TryGhost</code> project, also provides the simple guidance required to change that, like so...</p><p>First, I visited <a href=\"__GHOST_URL__/ghost/#/settings/integrations/64185c1723ad590d103c051a\">https://blog-ghost.summittservices.com/ghost/#/settings/integrations/</a> to create new API keys, and saved them in my password vault. Â Next, I needed to edit the project's <code>.env</code> file to read like this:</p><pre><code class=\"language-env\"># GHOST_API_URL=https://eleventy.ghost.io\n# GHOST_CONTENT_API_KEY=5a562eebab8528c44e856a3e0a\nGHOST_API_URL=https://blog-ghost.summittservices.com\nGHOST_CONTENT_API_KEY=***********hidden****************\nSITE_URL=http://localhost:8080</code></pre><p>Done. Â When the <code>blog-ghost.summittservices.com</code> instance of Ghost was created I took steps to \"make it private\", so it should function as a backend only. Â  So, running <code>yarn start</code> with the new <code>.env</code> configuration should give me a stripped-down <code>localhost:8080</code> edition of the blog pulling content from the intended Ghost backend, like so:</p><pre><code>yarn start\n</code></pre><p>Yup, that works! Â I get something that looks like this now:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2023/03/Screenshot-2023-03-20-at-08.40.32.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"452\" height=\"641\"><figcaption>My new blog connected to <code>blog-ghost.summittservices.com</code>.</figcaption></figure><p>Even better, when I save and <code>Publish</code> my work on this post, effectively removing its \"Draft\" status in <code>blog-ghost.summittservices.com</code>, I should see an instantaneous update in my <code>https://localhost:8080</code> instance of the blog. Â Wish me luck... Â </p><p>Beautimous! Â Well, almost. Â The change to the site was not \"instantaneous\", but after a quick <code>ctrl-c</code> and a new <code>yarn start</code> we have this:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2023/03/Screenshot-2023-03-20-at-08.45.11.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"457\" height=\"780\"><figcaption>New blog updated with an initial copy of this post.</figcaption></figure><!--kg-card-begin: markdown--><h2 id=\"migrating-content\">Migrating Content</h2>\n<p>Now that we have a working local site, it's time to copy some content (posts and microposts) that I wish to keep from my old blog at <a href=\"https://github.com/SummittDweller/blogs-SummittDweller\">https://github.com/SummittDweller/blogs-SummittDweller</a> into <code>blog-ghost.summittservices.com</code>.  For now I'm doing that &quot;manually&quot; by opening a new post and copying content from old .md files into them one-at-a-time.  Using that tedious process I managed to copy 8 posts forward into this blog.</p>\n<p>Along the way I also did some quick investigation of <a href=\"https://github.com/dumrauf/post2ghost\">post2ghost</a>, a utility aimed at helping populate Ghost posts from .md files.  Great idea!  Unfortunately, it looks like that work relies on an ancient version of the Ghost API, and I don't think it will work at all with the latest due to extensive changes in the API.</p>\n<p>Still, I very much like the idea behind <code>post2ghost</code> and I also like the name.  Maybe I'll reach out and see if I can borrow the name and leverage the new Ghost API along with my <a href=\"https://github.com/Digital-Grinnell/hugo-front-matter-tools\">Hugo Front Matter Tools</a> project to create a Python script that will read .md files with front matter and turn them into API-compatible JSON for bulk creation of new Ghost posts.  More on that effort later...</p>\n<h2 id=\"next-stepdeploy-and-assign-an-address\">Next Step - Deploy and Assign an Address</h2>\n<p>Currently this new blog is only available locally as <a href=\"https://localhost:8080\">https://localhost:8080</a> because it does not yet deploy to any internet host.  The <a href=\"https://github.com/TryGhost/eleventy-starter-ghost\">Eleventy Starter Ghost</a> project that I'm following is equiped to deploy a site to <a href=\"https://www.netlify.com\">Netlify</a> and use deploy hooks from Ghost to trigger Netlify rebuilds.</p>\n<p>Netlify is fine, but I only use them as a last resort, and thus far that's only for the <a href=\"https://Wieting.TamaToledo.com\">Wieting Theatre</a> where I rely on NetlifyCMS to manage backend content.  Ironically, NetlifyCMS was just rebranded as <code>Decap CMS</code>.  See <a href=\"https://www.netlify.com/blog/netlify-cms-to-become-decap-cms/\">https://www.netlify.com/blog/netlify-cms-to-become-decap-cms/</a> for details.</p>\n<p>So, I'm going to try and reproduce the triggers, hooks and actions intended for Netlify with my own GitHub Action (plus whatever it takes) to deploy this blog as <a href=\"https://blog.SummittDweller.com\">https://blog.SummittDweller.com</a>.  That URL currently delivers a Hugo static site hosted on DigitalOcean (DO).  Since my Ghost instance is also on DO I think I'll take a crack at deploying this blog to DO App Platform as a Starter App.  I hope that the guidance provided in <a href=\"https://www.digitalocean.com/community/tutorials/how-to-create-and-deploy-your-first-eleventy-website#step-11-deploying-to-digitalocean-with-app-platform\">Step 11 â€” Deploying to DigitalOcean with App Platform</a> proves helpful.</p>\n<h3 id=\"step-11-%E2%80%94-deploying-to-digitalocean-with-app-platformmy-specifics\">Step 11 â€” Deploying to DigitalOcean with App Platform - My Specifics</h3>\n<p>The aforementioned guidance did indeed prove helpful, although it is a little out-dated compared to my acutal experience, which is detailed below in up-to-date (as of March 2023) words and pictures, of course.</p>\n<p>First I visited my DigitalOcean account and clicked the <code>Create</code> button as directed.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 0001.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0001.png\" />\n  <figcaption class=\"figure\"> \n    Figure 1. Replacing the `blogs-summitt-dweller` app in DigitalOcean. Click `Create`.\n  </figcaption>\n</figure>    \n<p>Next, I selected <code>Apps</code> as directed in order to initiate the creation of a new <code>App</code>.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 0011.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0011.png\" />\n  <figcaption class=\"figure\">Figure 2. Select 'Apps'.<figcaption>\n</figure>    \n<p>This app is to be built from a GitHub repo so I chose <code>GitHub</code>, allowed the system to lookup all the GitHub repositories I've given DigitalOcean permisison to &quot;see&quot;.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 0027.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0027.png\" /> \n  <figcaption class=\"figure\">Figure 3. Select `GitHub` and then the new site project repo.<figcaption>\n</figure>    \n<p>I choose the my <code>SummittDweller/blog-eleventy-ghost</code> repo.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 0045.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0045.png\" /> \n  <figcaption class=\"figure\">Figure 4. Choose the repo.<figcaption>\n</figure>  \n<p>Then accepted all the defaults for the <code>main</code> branch, the <code>/</code> root directory (of the project repo), the default for <code>Auto Deploy</code>, and clicked <code>Next</code> to proceed.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 0065.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0065.png\" /> \n  <figcaption class=\"figure\">Figure 5. Accept defaults and click `Next`.<figcaption>\n</figure>    \n<p>Unfortunately, when I initiated the process DigitalOcean detected the repo as a &quot;Web Service&quot;, perhaps because of the <code>netlify.toml</code> file?  I don't want to create a &quot;Web Service&quot; since those are more complex and expensive than a simple static 11ty site.  So, I choose to edit the <code>Resource Type</code> to change that.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 0861.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0861.png\" /> \n  <figcaption class=\"figure\">Figure 6. Edit the `Resource Type`...<figcaption>\n</figure>    \n<p>I subsequently choose a <code>Static Site</code> and clicked to <code>Save</code> the change.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 0916.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0916.png\" /> \n  <figcaption class=\"figure\">Figure 7. Choose `Static Site` and click `Save`.<figcaption>\n</figure>\n<p>My 11ty project generates static content into the project's <code>/dist</code> directory so I edited the <code>Output Directory</code> setting, set it to <code>dist</code> and clicked to <code>Save</code> that change.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 0954.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0954.png\" /> \n  <figcaption class=\"figure\">Figure 8. Edit the `Output Directory`...<figcaption>\n</figure>    \n<figure>\n  <img class=\"figure\" alt=\"Image file is 0970.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0970.png\" /> \n  <figcaption class=\"figure\">Figure 9. Set to `dist` and click `Save`.<figcaption>\n</figure>    \n<p>Next I clicked <code>Back</code> to find the &quot;Billing&quot; section, review the new deployment fees (should be $3/month or less), and click <code>Create Resources</code> to begin the first build and deployment.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 1003.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/1003.png\" /> \n  <figcaption class=\"figure\">Figure 10. Click `Back`...<figcaption>\n</figure>    \n<figure>\n  <img class=\"figure\" alt=\"Image file is 1114.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/1114.png\" /> \n  <figcaption class=\"figure\">Figure 11. Review fees and click `Create Resources`.<figcaption>\n</figure>    \n<p>It took a few minutes, but once the app is complete you should see a screen like that shown in Figure 12 below.  Another unfortunate stumble... I forgot to change my App name up front so it carries a meaningless, random name of <code>coral-app</code>.  Let's change that now.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 1139.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/1139.png\" /> \n  <figcaption class=\"figure\">Figure 12. App was created, but with a meaningless  name.<figcaption>\n</figure>    \n<p>I clicked <code>Edit</code> in the &quot;App Settings / Info&quot; section and changed the name to better represent the project and site that's been created.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 1258.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/1258.png\" /> \n  <figcaption class=\"figure\">Figure 13. Edit the App Settings Info to change the name.<figcaption>\n</figure>    \n<figure>\n  <img class=\"figure\" alt=\"Image file is 1461.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/1461.png\" /> \n  <figcaption class=\"figure\">Figure 14. Specify a better name and click `Save`.<figcaption>\n</figure>    \n<p>Note that the unique URL generated for the app did NOT change.  I fear we are stuck with that name, but it won't be a concern for very long.  Once the deployment is done you should see a <code>Live App</code> link/button.  Click it!</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 1494.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/1494.png\" /> \n  <figcaption class=\"figure\">Figure 15. Wait for the app to deploy and click `Live App`.<figcaption>\n</figure>    \n<p>Eureka!  We should have a new site deployed to DigitalOcean.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 1513.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/1513.png\" /> \n  <figcaption class=\"figure\">Figure 16. Eureka, we have an app!<figcaption>\n</figure>    \n<p>One more thing to do, give this new site a meaningful URL.  Open the <code>Manage</code> screen and our new app, the click the <code>Settings</code> tab.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 2014.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/2014.png\" /> \n  <figcaption class=\"figure\">Figure 17. Manage the app and click `Settings`.<figcaption>\n</figure> \n<p>Click <code>Add Domain</code> and enter the &quot;correct&quot; URL.  In this case the app needs to respond at <a href=\"https://blog.SummittDweller.com\">https://blog.SummittDweller.com</a>.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 2024.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/2024.png\" /> \n  <figcaption class=\"figure\">Figure 18. Click `Add Domain`.<figcaption>\n</figure>    \n<p>My registar already points the <code>summittdweller.com</code> domain at the DigitalOcean DNS servers, so I choose <code>DigitalOcean DNS</code> as the keeper of the domain's records.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 2062.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/2062.png\" /> \n  <figcaption class=\"figure\">Figure 19. Enter the new domain name and choose DigitalOcean DNS.<figcaption>\n</figure>    \n<p>After the domain is added I needed great patience since I could visit the site, but no valid certificates had been generated yet.  I was able to check my DigitalOcean <code>Network</code> screen to see that a new CNAME record has been added for the site, and after about 30 minutes I was finally able to open the &quot;secure&quot; site at <a href=\"https://blog.SummittDweller.com\">https://blog.SummittDweller.com</a>.</p>\n<figure>\n  <img class=\"figure\" alt=\"Image file is 2165.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/2165.png\" /> \n  <figcaption class=\"figure\">Figure 20. Be patient, the site is not instantly secure.<figcaption>\n</figure>    \n<figure>\n  <img class=\"figure\" alt=\"Image file is 2450.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/2450.png\" /> \n  <figcaption class=\"figure\">Figure 21. Visit `Networking` and observe a new CNAME record.<figcaption>\n</figure>    \n<h2 id=\"customization-formatting-figures-and-matomo\">Customization: Formatting Figures and Matomo</h2>\n<p>Ok, now that the domain is added I wanted to introduce my first bonafide customizations, namely</p>\n<ul>\n<li>Better formatting of figures like you see in the previous section and below, and</li>\n<li>Introduction of my <a href=\"https://analytics.summittservices.com\">Matomo</a> tracking code.</li>\n</ul>\n<h3 id=\"using-code-injection\">Using Code Injection</h3>\n<p>Ghost has a nice feature called <code>Code Injection</code> that allows me to inject snippets of Javascript and CSS into every page's header and footer.  Not sure I'm &quot;sold&quot; on the use of <code>Code Injection</code> since it puts &quot;code&quot; into a database, and that's something I don't care to do.  However, as a short-term &quot;test&quot; it's a wonderful feature.</p>\n<p>To engage it I visited my blog's <a href=\"__GHOST_URL__/ghost\">Ghost admin page</a> and clicked on the <code>gear icon</code> (lower-left red box in Figure 22 below) then selected the <code>Code Injection</code> as shown below.  The code injection screen that opens provides both header and footer editing spaces where Javascript and/or CSS can be added.</p>\n<figure>\n  <img class=\"figure\" alt=\"Ghost-Code-Injection-01.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/Ghost-Code-Injection-01.png\" />\n  <figcaption class=\"figure\">Figure 22. Opening Ghost Code Injection.</figcaption>\n</figure>  \n<p>The CSS that I added in the header was:</p>\n<pre><code class=\"language-js\">&lt;style&gt;\n  p &gt; figure &gt; figcaption {\n    font-weight: 400;\n    font-style: italic;\n    font-size: 16px;\n    color: black;\n    outline: 0;\n    z-index: 300;\n    padding: 2px 5px;\n    text-align: left;\n  }\n    \n  p &gt; figure &gt; img {\n    border: 1px solid black;\n  }    \n&lt;/style&gt;  \n</code></pre>\n<p>The Javascript code injected into the footer was:</p>\n<pre><code class=\"language-js\">&lt;script&gt;\n  // Creates Captions from img Title attributes\n  $(&quot;img&quot;).each(\n    function() {\n      // Let's make the title a caption\n      if ($(this).attr(&quot;title&quot;)) {\n        $(this).wrap(\n          '&lt;figure class=&quot;figure&quot;&gt;&lt;/figure&gt;'\n        ).after(\n          '&lt;figcaption class=&quot;figure&quot;&gt;' +\n             $(this).attr(&quot;title&quot;) +\n          '&lt;/figcaption&gt;'\n      );\n    }\n  });\n&lt;/script&gt;\n</code></pre>\n<p>Both of the above code snippets were inspired by blogger <a href=\"https://blog.kchung.co/author/kchung/\">Kevin Chung</a> and his <a href=\"https://blog.kchung.co/adding-image-captions-to-ghost/\">Adding image captions to Ghost</a> post.  Kevin's code looked for any <code>![alt](src)</code> image references in the content and reformatted them into HTML that looked something like this:</p>\n<pre><code class=\"language-html\">&lt;figure class=&quot;figure&quot;&gt;\n  &lt;img src=&quot;https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0011.png&quot; alt=&quot;Image file is 0011.png&quot; title=&quot;Figure 2. Select 'Apps'.&quot; loading=&quot;lazy&quot;/&gt;\n  &lt;figcaption class=&quot;figure&quot;&gt;Figure 2. Select 'Apps'.&lt;/figcaption&gt;\n&lt;/figure&gt;    \n</code></pre>\n<p>Kevin's original code modified ALL of the images, the <code>&lt;img&gt;</code> tags, in the post if they had <code>alt</code> attributes, and in my case that's ALL images.  That's not what I wanted to happen, so I reworked the logic so that only images (<code>&lt;img&gt;</code>) with <code>title</code> attributes would get captured and reformatted.  That worked nicely, but my results were inconsistent.  The behavior I saw in localhost rendering was different than in my Ghost site, and sometimes differnt than in my Elevent site.  Not good.</p>\n<p>All of the Markdown for the figures, like those in this section and above, that I wanted to control is generated using my <a href=\"https://github.com/SummittDweller/convert_videos_to_frames\">Convert Videos to Frames</a> utility, I chose to take the bull by the horns and just have it generate exactly the <code>&lt;figure&gt;</code> and <code>&lt;figcaption&gt;</code> HTML that I wanted to see.  So, the raw Markdown for the figure you see above is simply:</p>\n<pre><code class=\"language-html\">&lt;figure&gt;\n  &lt;img class=&quot;figure&quot; alt=&quot;Ghost-Code-Injection-01.png&quot; src=&quot;https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/Ghost-Code-Injection-01.png&quot; /&gt;\n  &lt;figcaption class=&quot;figure&quot;&gt; \n    Figure 22. Opening Ghost Code Injection.\n  &lt;/figcaption&gt;\n&lt;/figure&gt; \n</code></pre>\n<p>The images in this instance are housed as BLOBs in <em>Azure Storage</em> and served directly from there.</p>\n<p>The simple/raw approach that I ultimately arrived at is consistent and to-the-point, and it doesn't need any Ghost code injection so I removed all of the &quot;injected&quot; code from <a href=\"__GHOST_URL__/ghost/#/settings/code-injection\">https://blog-ghost.summittservices.com/ghost/#/settings/code-injection</a>.  I also found that I could achieve better, more consistent CSS control by adding custom code to the end of the project's <code>src/_includes/css/styles.css</code> file like so:</p>\n<pre><code class=\"language-css\">/* Summitt Dweller styles\n/* ---------------------------------------------------------- */\n\nfigure img.figure.lazyloaded {\n  border: 1px solid black;\n}\n\nfigure {\n  text-align: center;\n}\n\n.post-full-content figcaption {\n  margin: 0.2em 3em 0;\n  font-size: 55%;\n  line-height: 1.6em;\n  text-align: center;\n  font-weight: 400;\n}\n\ncode {\n  font-family: monospace,monospace;\n  font-size: .75em;\n  background: #eceebd;\n  padding: 2px 5px;\n  border-radius: 5px;\n}\n\npre &gt; code {\n  background: none;\n  padding: 0;\n}\n</code></pre>\n<p>The intent is to wrap the images with a <code>class=&quot;figure&quot;</code> attribute in a nice little black border, and more!</p>\n<h3 id=\"matomo\">Matomo</h3>\n<p>While Ghost code injection didn't behave well for reformatting figures, it does work nicely, and consistently, for Matomo tracking!  However, I'd still prefer to put as much as possible into code, not into a database, so I grabbed a copy of my Matomo code that's specifically for <a href=\"https://blog.SummittDweller.com\">this blog</a> and applied it like so in the project's <code>src/_includes/layouts/default.njk</code> file:</p>\n<pre><code class=\"language-js\">&lt;!-- Matomo --&gt;\n&lt;script&gt;\n  var _paq = window._paq = window._paq || [];\n  /* tracker methods like &quot;setCustomDimension&quot; should be called before &quot;trackPageView&quot; */\n  _paq.push(['trackPageView']);\n  _paq.push(['enableLinkTracking']);\n  (function() {\n    var u=&quot;https://analytics.summittservices.com/&quot;;\n    _paq.push(['setTrackerUrl', u+'matomo.php']);\n    _paq.push(['setSiteId', '10']);\n    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];\n    g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);\n  })();\n&lt;/script&gt;\n&lt;!-- End Matomo Code --&gt;\n</code></pre>\n<p>Beautimous. It just works!</p>\n<!--kg-card-end: markdown--><p></p>",
            "comment_id": "641851af23ad590d103c0468",
            "plaintext": "This past weekend my daughter, Mackenzie, made the decision to move her portfolio page into a configuration that features Eleventy (11ty) on the frontend with content managed in Ghost on the backend. Â I like that combination very much so to help support her move, and learn a little something along the way, we've setup a new Ghost server in a DigitalOcean droplet, namely ghostonubuntu2204-s-1vcpu-1gb-intel-nyc1-01 , and I've decided to make the same move myself. Â \n\nThis post is intended to track my blog's journey from a git workflow (for both structure and content) in Hugo, to Eleventy + Ghost, and it begins with the guidance provided in https://github.com/TryGhost/eleventy-starter-ghost. Â I already have a working Ghost server as mentioned above, the one that we setup for Mackenzie's portfolio, and we've already followed Install and host Multiple Ghost blog Servers on One Server to create the Ghost backend for this blog on the same DO droplet that host's Mackenzie's portfolio content. Â The admin interface for my blog instance of Ghost is shown below. Â \n\nGhost AdminGhost\n\n\nCreating the 11ty Frontend\n\nWorking locally on my Mac Mini this is the input I captured...\n\ncd ~/GitHub\ngit clone https://github.com/TryGhost/eleventy-starter-ghost.git blog-eleventy-ghost\ncd blog-eleventy-ghost\nyarn\nyarn start\n^C\n\nNote that complete input and output from all commands is available in https://gist.github.com/SummittDweller/1af7ecbb9051ee04d0a9dbad7f74c1e7.\n\nThat worked flawlessly and it's quick too! Â \n\n\nSaving This Work in GitHub\n\nTime to save what's been done here before our progress is lost, and I didn't fork the TryGhost/eleventy-starter-ghost project because I don't intend to try and improve it, so my project needs a new GitHub home. Â My typical process for doing that looks something like this...\n\nrm -fr .git\ngit init\ngit add .\ngit commit -m \"First commit\"\ngit branch -M main\ngit remote add origin https://github.com/SummittDweller/blog-eleventy-ghost.git\ngit push -u origin main\n\n\nReplacing the Ghost Backend\n\nBy default the project I'm using connects its 11ty frontend to a Ghost backend at https://eleventy.ghost.io/. Â Fortunately, my project's README.md file, an ammended copy from the original TryGhost project, also provides the simple guidance required to change that, like so...\n\nFirst, I visited https://blog-ghost.summittservices.com/ghost/#/settings/integrations/ to create new API keys, and saved them in my password vault. Â Next, I needed to edit the project's .env file to read like this:\n\n# GHOST_API_URL=https://eleventy.ghost.io\n# GHOST_CONTENT_API_KEY=5a562eebab8528c44e856a3e0a\nGHOST_API_URL=https://blog-ghost.summittservices.com\nGHOST_CONTENT_API_KEY=***********hidden****************\nSITE_URL=http://localhost:8080\n\nDone. Â When the blog-ghost.summittservices.com instance of Ghost was created I took steps to \"make it private\", so it should function as a backend only. Â  So, running yarn start with the new .env configuration should give me a stripped-down localhost:8080 edition of the blog pulling content from the intended Ghost backend, like so:\n\nyarn start\n\n\nYup, that works! Â I get something that looks like this now:\n\nEven better, when I save and Publish my work on this post, effectively removing its \"Draft\" status in blog-ghost.summittservices.com, I should see an instantaneous update in my https://localhost:8080 instance of the blog. Â Wish me luck... Â \n\nBeautimous! Â Well, almost. Â The change to the site was not \"instantaneous\", but after a quick ctrl-c and a new yarn start we have this:\n\n\nMigrating Content\n\n\nNow that we have a working local site, it's time to copy some content (posts and microposts) that I wish to keep from my old blog at https://github.com/SummittDweller/blogs-SummittDweller into blog-ghost.summittservices.com. For now I'm doing that \"manually\" by opening a new post and copying content from old .md files into them one-at-a-time. Using that tedious process I managed to copy 8 posts forward into this blog.\n\n\nAlong the way I also did some quick investigation of post2ghost, a utility aimed at helping populate Ghost posts from .md files. Great idea! Unfortunately, it looks like that work relies on an ancient version of the Ghost API, and I don't think it will work at all with the latest due to extensive changes in the API.\n\n\nStill, I very much like the idea behind post2ghost and I also like the name. Maybe I'll reach out and see if I can borrow the name and leverage the new Ghost API along with my Hugo Front Matter Tools project to create a Python script that will read .md files with front matter and turn them into API-compatible JSON for bulk creation of new Ghost posts. More on that effort later...\n\n\n\nNext Step - Deploy and Assign an Address\n\n\nCurrently this new blog is only available locally as https://localhost:8080 because it does not yet deploy to any internet host. The Eleventy Starter Ghost project that I'm following is equiped to deploy a site to Netlify and use deploy hooks from Ghost to trigger Netlify rebuilds.\n\n\nNetlify is fine, but I only use them as a last resort, and thus far that's only for the Wieting Theatre where I rely on NetlifyCMS to manage backend content. Ironically, NetlifyCMS was just rebranded as Decap CMS. See https://www.netlify.com/blog/netlify-cms-to-become-decap-cms/ for details.\n\n\nSo, I'm going to try and reproduce the triggers, hooks and actions intended for Netlify with my own GitHub Action (plus whatever it takes) to deploy this blog as https://blog.SummittDweller.com. That URL currently delivers a Hugo static site hosted on DigitalOcean (DO). Since my Ghost instance is also on DO I think I'll take a crack at deploying this blog to DO App Platform as a Starter App. I hope that the guidance provided in Step 11 â€” Deploying to DigitalOcean with App Platform proves helpful.\n\n\n\nStep 11 â€” Deploying to DigitalOcean with App Platform - My Specifics\n\n\nThe aforementioned guidance did indeed prove helpful, although it is a little out-dated compared to my acutal experience, which is detailed below in up-to-date (as of March 2023) words and pictures, of course.\n\n\nFirst I visited my DigitalOcean account and clicked the Create button as directed.\n\n\n\n\n\n\nNext, I selected Apps as directed in order to initiate the creation of a new App.\n\n\n\n\n\nThis app is to be built from a GitHub repo so I chose GitHub, allowed the system to lookup all the GitHub repositories I've given DigitalOcean permisison to \"see\".\n\n\n\n\n\nI choose the my SummittDweller/blog-eleventy-ghost repo.\n\n\n\n\n\nThen accepted all the defaults for the main branch, the / root directory (of the project repo), the default for Auto Deploy, and clicked Next to proceed.\n\n\n\n\n\nUnfortunately, when I initiated the process DigitalOcean detected the repo as a \"Web Service\", perhaps because of the netlify.toml file? I don't want to create a \"Web Service\" since those are more complex and expensive than a simple static 11ty site. So, I choose to edit the Resource Type to change that.\n\n\n\n\n\nI subsequently choose a Static Site and clicked to Save the change.\n\n\n\n\n\nMy 11ty project generates static content into the project's /dist directory so I edited the Output Directory setting, set it to dist and clicked to Save that change.\n\n\n\n\n\n\n\n\nNext I clicked Back to find the \"Billing\" section, review the new deployment fees (should be $3/month or less), and click Create Resources to begin the first build and deployment.\n\n\n\n\n\n\n\n\nIt took a few minutes, but once the app is complete you should see a screen like that shown in Figure 12 below. Another unfortunate stumble... I forgot to change my App name up front so it carries a meaningless, random name of coral-app. Let's change that now.\n\n\n\n\n\nI clicked Edit in the \"App Settings / Info\" section and changed the name to better represent the project and site that's been created.\n\n\n\n\n\n\n\n\nNote that the unique URL generated for the app did NOT change. I fear we are stuck with that name, but it won't be a concern for very long. Once the deployment is done you should see a Live App link/button. Click it!\n\n\n\n\n\nEureka! We should have a new site deployed to DigitalOcean.\n\n\n\n\n\nOne more thing to do, give this new site a meaningful URL. Open the Manage screen and our new app, the click the Settings tab.\n\n\n\n\n\nClick Add Domain and enter the \"correct\" URL. In this case the app needs to respond at https://blog.SummittDweller.com.\n\n\n\n\n\nMy registar already points the summittdweller.com domain at the DigitalOcean DNS servers, so I choose DigitalOcean DNS as the keeper of the domain's records.\n\n\n\n\n\nAfter the domain is added I needed great patience since I could visit the site, but no valid certificates had been generated yet. I was able to check my DigitalOcean Network screen to see that a new CNAME record has been added for the site, and after about 30 minutes I was finally able to open the \"secure\" site at https://blog.SummittDweller.com.\n\n\n\n\n\n\n\n\n\nCustomization: Formatting Figures and Matomo\n\n\nOk, now that the domain is added I wanted to introduce my first bonafide customizations, namely\n\n\n * Better formatting of figures like you see in the previous section and below, and\n * Introduction of my Matomo tracking code.\n\n\n\nUsing Code Injection\n\n\nGhost has a nice feature called Code Injection that allows me to inject snippets of Javascript and CSS into every page's header and footer. Not sure I'm \"sold\" on the use of Code Injection since it puts \"code\" into a database, and that's something I don't care to do. However, as a short-term \"test\" it's a wonderful feature.\n\n\nTo engage it I visited my blog's Ghost admin page and clicked on the gear icon (lower-left red box in Figure 22 below) then selected the Code Injection as shown below. The code injection screen that opens provides both header and footer editing spaces where Javascript and/or CSS can be added.\n\n\n\n\n\n\nThe CSS that I added in the header was:\n\n\n<style>\n  p > figure > figcaption {\n    font-weight: 400;\n    font-style: italic;\n    font-size: 16px;\n    color: black;\n    outline: 0;\n    z-index: 300;\n    padding: 2px 5px;\n    text-align: left;\n  }\n    \n  p > figure > img {\n    border: 1px solid black;\n  }    \n</style>  \n\n\n\nThe Javascript code injected into the footer was:\n\n\n<script>\n  // Creates Captions from img Title attributes\n  $(\"img\").each(\n    function() {\n      // Let's make the title a caption\n      if ($(this).attr(\"title\")) {\n        $(this).wrap(\n          '<figure class=\"figure\"></figure>'\n        ).after(\n          '<figcaption class=\"figure\">' +\n             $(this).attr(\"title\") +\n          '</figcaption>'\n      );\n    }\n  });\n</script>\n\n\n\nBoth of the above code snippets were inspired by blogger Kevin Chung and his Adding image captions to Ghost post. Kevin's code looked for any ![alt](src) image references in the content and reformatted them into HTML that looked something like this:\n\n\n<figure class=\"figure\">\n  <img src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/0011.png\" alt=\"Image file is 0011.png\" title=\"Figure 2. Select 'Apps'.\" loading=\"lazy\"/>\n  <figcaption class=\"figure\">Figure 2. Select 'Apps'.</figcaption>\n</figure>    \n\n\n\nKevin's original code modified ALL of the images, the <img> tags, in the post if they had alt attributes, and in my case that's ALL images. That's not what I wanted to happen, so I reworked the logic so that only images (<img>) with title attributes would get captured and reformatted. That worked nicely, but my results were inconsistent. The behavior I saw in localhost rendering was different than in my Ghost site, and sometimes differnt than in my Elevent site. Not good.\n\n\nAll of the Markdown for the figures, like those in this section and above, that I wanted to control is generated using my Convert Videos to Frames utility, I chose to take the bull by the horns and just have it generate exactly the <figure> and <figcaption> HTML that I wanted to see. So, the raw Markdown for the figure you see above is simply:\n\n\n<figure>\n  <img class=\"figure\" alt=\"Ghost-Code-Injection-01.png\" src=\"https://sddocs.blob.core.windows.net/documentation/Eleventy-Ghost/Ghost-Code-Injection-01.png\" />\n  <figcaption class=\"figure\"> \n    Figure 22. Opening Ghost Code Injection.\n  </figcaption>\n</figure> \n\n\n\nThe images in this instance are housed as BLOBs in Azure Storage and served directly from there.\n\n\nThe simple/raw approach that I ultimately arrived at is consistent and to-the-point, and it doesn't need any Ghost code injection so I removed all of the \"injected\" code from https://blog-ghost.summittservices.com/ghost/#/settings/code-injection. I also found that I could achieve better, more consistent CSS control by adding custom code to the end of the project's src/_includes/css/styles.css file like so:\n\n\n/* Summitt Dweller styles\n/* ---------------------------------------------------------- */\n\nfigure img.figure.lazyloaded {\n  border: 1px solid black;\n}\n\nfigure {\n  text-align: center;\n}\n\n.post-full-content figcaption {\n  margin: 0.2em 3em 0;\n  font-size: 55%;\n  line-height: 1.6em;\n  text-align: center;\n  font-weight: 400;\n}\n\ncode {\n  font-family: monospace,monospace;\n  font-size: .75em;\n  background: #eceebd;\n  padding: 2px 5px;\n  border-radius: 5px;\n}\n\npre > code {\n  background: none;\n  padding: 0;\n}\n\n\n\nThe intent is to wrap the images with a class=\"figure\" attribute in a nice little black border, and more!\n\n\n\nMatomo\n\n\nWhile Ghost code injection didn't behave well for reformatting figures, it does work nicely, and consistently, for Matomo tracking! However, I'd still prefer to put as much as possible into code, not into a database, so I grabbed a copy of my Matomo code that's specifically for this blog and applied it like so in the project's src/_includes/layouts/default.njk file:\n\n\n<!-- Matomo -->\n<script>\n  var _paq = window._paq = window._paq || [];\n  /* tracker methods like \"setCustomDimension\" should be called before \"trackPageView\" */\n  _paq.push(['trackPageView']);\n  _paq.push(['enableLinkTracking']);\n  (function() {\n    var u=\"https://analytics.summittservices.com/\";\n    _paq.push(['setTrackerUrl', u+'matomo.php']);\n    _paq.push(['setSiteId', '10']);\n    var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];\n    g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);\n  })();\n</script>\n<!-- End Matomo Code -->\n\n\n\nBeautimous. It just works!\n\n\n",
            "feature_image": "__GHOST_URL__/content/images/2023/03/Screenshot-2023-03-20-at-09.32.12.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-03-20T12:29:35.000Z",
            "updated_at": "2023-03-22T15:29:48.000Z",
            "published_at": "2023-03-20T13:44:12.000Z",
            "custom_excerpt": "Mackenzie's moving her portfolio page into an Eleventy (11ty) on frontend with content managed in Ghost on the backend.  I like that combination very much so to help support her move I'm doing the same. ",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "641899d923ad590d103c057a",
            "uuid": "91754e0e-4751-455e-825d-3ff1a9e80073",
            "title": "Microposts",
            "slug": "microposts",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[[\"a\",[\"href\",\"https://blog.summittdweller.com/microposts/\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Everything that used to live in \"],[0,[0],1,\"https://blog.summittdweller.com/microposts/\"],[0,[],0,\".   Just one BIG list of LITTLE things.\"]]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Everything that used to live in <a href=\"https://blog.summittdweller.com/microposts/\">https://blog.summittdweller.com/microposts/</a>. Â  Just one BIG list of LITTLE things.</p>",
            "comment_id": "641899d923ad590d103c057a",
            "plaintext": "Everything that used to live in https://blog.summittdweller.com/microposts/. Â  Just one BIG list of LITTLE things.",
            "feature_image": null,
            "featured": 0,
            "type": "page",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-03-20T17:37:29.000Z",
            "updated_at": "2023-04-02T18:25:19.000Z",
            "published_at": "2023-03-20T17:38:50.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6418da4223ad590d103c0590",
            "uuid": "f872adf8-5b96-4f4c-8dc0-7082175a41e7",
            "title": "Finale Workflow Documentation",
            "slug": "finale-workflow-documentation",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"hr\",{}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0010.png\",\"alt\":\"Launch the Canon MF Scan Utility\",\"title\":\"Launch the Canon MF Scan Utility\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0015.png\",\"alt\":\"Select Custom scanning\",\"title\":\"Select Custom scanning\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0020.png\",\"alt\":\"Waiting for the scanner to warm up\",\"title\":\"Waiting for the scanner to warm up\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0028.png\",\"alt\":\"Scanning in progress\",\"title\":\"Scanning in progress\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0046.png\",\"alt\":\"Save scan settings\",\"title\":\"Save scan settings\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0064.png\",\"alt\":\"SmartScore Pro launches automatically\",\"title\":\"SmartScore Pro launches automatically but needs to be closed\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0078.png\",\"alt\":\"Properly launching SmartScore\",\"title\":\"Properly launching SmartScore\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0089.png\",\"alt\":\"Starting the SmartScore recognition process\",\"title\":\"Starting the SmartScore recognition process\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0094.png\",\"alt\":\"Add scans to SmartScore recognition\",\"title\":\"Add scans to SmartScore recognition\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0105.png\",\"alt\":\"Navigate to the scan files and select them\",\"title\":\"Navigate to the scan files and select them\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0134.png\",\"alt\":\"Order the TIFFs and begin recognition\",\"title\":\"Order the TIFFs and begin recognition\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0151.png\",\"alt\":\"Recognition in progress\",\"title\":\"Recognition in progress\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0155.png\",\"alt\":\"SmartScore system report\",\"title\":\"SmartScore system report\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0157.png\",\"alt\":\"Unify score pop-up\",\"title\":\"Unify score pop-up\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0168.png\",\"alt\":\"Saving as XML\",\"title\":\"Saving as XML\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0189.png\",\"alt\":\"Confirm save and close SmartScore\",\"title\":\"Confirm save and close SmartScore\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0199.png\",\"alt\":\"Open Finale\",\"title\":\"Open Finale\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0209.png\",\"alt\":\"Selecting IMPORT MUSICXML\",\"title\":\"Selecting IMPORT MUSICXML\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0224.png\",\"alt\":\"Opening the saved MusicXML file\",\"title\":\"Opening the saved MusicXML file\"}],[\"image\",{\"src\":\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0237.png\",\"alt\":\"Save your Finale work\",\"title\":\"Save your Finale work\"}]],\"markups\":[[\"a\",[\"href\",\"https://www.finalemusic.com/\"]],[\"a\",[\"href\",\"https://static.grinnell.edu/dlad-blog/posts/138-creating-better-documentation/\"]],[\"em\"],[\"code\"],[\"strong\"]],\"sections\":[[10,0],[1,\"p\",[[0,[],0,\"Mackenzie, my daughter, and I created this post documenting my wife's \"],[0,[0],1,\"Finale\"],[0,[],0,\" workflow for scanning and editing music on her Mac.  We did this for my wife to celebrate her birthday preserve her sanity.  Well, it was worth a shot.  The birthday idea seemed more romantic, but mental health comes first.\"]]],[1,\"p\",[[0,[],0,\"The document was created using a process we recently built and documented in \"],[0,[1],1,\"Creating Better Documentation\"],[0,[],0,\".  In this instance of the process we tried to annotate in yellow screen capture elements that need attention, and used red annotation to indicate things that require input or action of some kind.  In some of the later images we failed and things that should be red were left highlighted in yellow.  Sorry.\"]]],[1,\"h1\",[[0,[],0,\"Begin by Scanning\"]]],[1,\"p\",[[0,[],0,\"The first step involved launching the \"],[0,[2],1,\"Canon MF Scan Utility\"],[0,[],0,\" as you see below.  This is the software she uses to scan music pages on the multi-function scanner attached to her Mac.\"]]],[10,1],[1,\"p\",[[0,[],0,\"We verified that the correct scanner is selected, loaded the score into the scanner*, and clicked \"],[0,[3],1,\"Custom\"],[0,[],0,\" to begin the scan.  Then, wait for the scanner to warm up, if necessary.\"]]],[1,\"p\",[[0,[],0,\"*Note that the sheet music can be placed on the scanner glass one-sheet-at-a-time, or if the pages are 8.5x11, one-sided, and in good condition, they may be loaded in the document feeder to scan continuously.  In this particular case we were able to use the document feeder.\"]]],[10,2],[10,3],[1,\"p\",[[0,[],0,\"Once the scanner is ready the mechanical process of scanning should begin.  When scanning one-page-at-a-time some user intervention will be required.\"]]],[10,4],[1,\"p\",[[0,[],0,\"When the scan is complete a \"],[0,[3],1,\"Save Settings\"],[0,[],0,\" window should pop-up.  We reviewed the information and made appropriate selections where noted below, then clicked \"],[0,[3],1,\"OK\"],[0,[],0,\" to continue.  \"],[0,[4],0,\"Be sure to set and take note of the \"],[0,[3],1,\"File Name:\"],[0,[],0,\" and \"],[0,[3],1,\"Save in:\"],[0,[],0,\" fields!  Also, it's probably wise to ensure that the \"],[0,[3],1,\"Data Format:\"],[0,[],0,\" is \\\"TIFF\\\" and the \"],[0,[3],1,\"Save to a subfolder with current date\"],[0,[],1,\" control is checked.\"]]],[10,5],[1,\"h1\",[[0,[],0,\"SmartScore 64 Pro\"]]],[1,\"p\",[[0,[],0,\"A \"],[0,[2],1,\"SmartScore 64 Pro\"],[0,[],0,\" window will automatically open, \"],[0,[4],0,\"but don't be confused, we don't want to run this application yet!  Click the \"],[0,[3],1,\"Cancel\"],[0,[],0,\" button to close \"],[0,[2],2,\"SmartScore 64 Pro\"],[0,[],0,\".\"]]],[10,6],[1,\"p\",[[0,[],0,\"Once \"],[0,[2],1,\"SmartScore 64 Pro\"],[0,[],0,\" is closed, we need to open it properly by clicking its icon in the dock.  :frowning:\"]]],[10,7],[1,\"p\",[[0,[],0,\"Now \"],[0,[2],1,\"SmartScore\"],[0,[],0,\" is open to the \"],[0,[3],1,\"Task Window\"],[0,[],0,\" where we selected \"],[0,[3],1,\"Recognition\"],[0,[],0,\" to convert the scanned images to music XML.\"]]],[10,8],[1,\"p\",[[0,[],0,\"Next, we add the files of our scanned pages to the recognition processing list.\"]]],[10,9],[1,\"p\",[[0,[],0,\"In the file dialog we navigate to the scanned page TIFFs and select them all.  The order of files in the selection is NOT critical.  With all files selected click \"],[0,[3],1,\"Open\"],[0,[],0,\".\"]]],[10,10],[1,\"p\",[[0,[],0,\"The next \"],[0,[3],1,\"Begin Recognition\"],[0,[],0,\" screen offers controls to change the file order if necessary.  Once the files are in the proper order click \"],[0,[3],1,\"Begin Recognition\"],[0,[],0,\" button to proceed.\"]]],[10,11],[1,\"p\",[[0,[],0,\"Be patient, the recognition process may take a few minutes.\"]]],[10,12],[1,\"p\",[[0,[],0,\"When the recognition is complete a \"],[0,[3],1,\"System Report\"],[0,[],0,\" appeared prompting us to \"],[0,[3],1,\"Open SmartScore file\"],[0,[],0,\".  We did.\"]]],[10,13],[1,\"p\",[[0,[],0,\"Next, the \"],[0,[3],1,\"Unify Score\"],[0,[],0,\" window popped up and we verified the default selections shown below before clicking \"],[0,[3],1,\"OK\"],[0,[],0,\".\"]]],[10,14],[1,\"p\",[[0,[],0,\"When prompted to save the score be sure to select \"],[0,[3],1,\"Music XML (*.xml)\"],[0,[],0,\" and take note of where the file will be saved.\"]]],[10,15],[1,\"p\",[[0,[],0,\"You may be prompted to save each scan/file individually.  Once the file save is confirmed you can close \"],[0,[2],1,\"SmartScore 64 Pro\"],[0,[],0,\".\"]]],[10,16],[1,\"h1\",[[0,[],0,\"Finale\"]]],[1,\"p\",[[0,[],0,\"Next, open \"],[0,[2],1,\"Finale\"],[0,[],0,\" from the dock as shown below.\"]]],[10,17],[1,\"p\",[[0,[],0,\"After a minute or more the \"],[0,[2],1,\"Finale\"],[0,[],0,\" \"],[0,[3],1,\"Launch Window\"],[0,[],0,\" should appear, and we selected \"],[0,[3],1,\"IMPORT MUSICXML\"],[0,[],0,\" as shown below.\"]]],[10,18],[1,\"p\",[[0,[],0,\"We navigated to the XML file that was saved in \"],[0,[2],1,\"SmartScore\"],[0,[],0,\" and clicked \"],[0,[3],1,\"Open\"],[0,[],0,\" to load it in \"],[0,[2],1,\"Finale\"],[0,[],0,\".\"]]],[10,19],[1,\"p\",[[0,[],0,\"That's it, the scanned score is now loaded in \"],[0,[2],1,\"Finale\"],[0,[],0,\" where it is ready to be edited!  It's a good idea to click \"],[0,[3],1,\"Save As...\"],[0,[],0,\" routinely to save your changes as you proceed.\"]]],[10,20]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<hr><p>Mackenzie, my daughter, and I created this post documenting my wife's <a href=\"https://www.finalemusic.com/\">Finale</a> workflow for scanning and editing music on her Mac. Â We did this for my wife to celebrate her birthday preserve her sanity. Â Well, it was worth a shot. Â The birthday idea seemed more romantic, but mental health comes first.</p><p>The document was created using a process we recently built and documented in <a href=\"https://static.grinnell.edu/dlad-blog/posts/138-creating-better-documentation/\">Creating Better Documentation</a>. Â In this instance of the process we tried to annotate in yellow screen capture elements that need attention, and used red annotation to indicate things that require input or action of some kind. Â In some of the later images we failed and things that should be red were left highlighted in yellow. Â Sorry.</p><h1 id=\"begin-by-scanning\">Begin by Scanning</h1><p>The first step involved launching the <em>Canon MF Scan Utility</em> as you see below. Â This is the software she uses to scan music pages on the multi-function scanner attached to her Mac.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0010.png\" class=\"kg-image\" alt=\"Launch the Canon MF Scan Utility\" loading=\"lazy\" title=\"Launch the Canon MF Scan Utility\"></figure><p>We verified that the correct scanner is selected, loaded the score into the scanner*, and clicked <code>Custom</code> to begin the scan. Â Then, wait for the scanner to warm up, if necessary.</p><p>*Note that the sheet music can be placed on the scanner glass one-sheet-at-a-time, or if the pages are 8.5x11, one-sided, and in good condition, they may be loaded in the document feeder to scan continuously. Â In this particular case we were able to use the document feeder.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0015.png\" class=\"kg-image\" alt=\"Select Custom scanning\" loading=\"lazy\" title=\"Select Custom scanning\"></figure><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0020.png\" class=\"kg-image\" alt=\"Waiting for the scanner to warm up\" loading=\"lazy\" title=\"Waiting for the scanner to warm up\"></figure><p>Once the scanner is ready the mechanical process of scanning should begin. Â When scanning one-page-at-a-time some user intervention will be required.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0028.png\" class=\"kg-image\" alt=\"Scanning in progress\" loading=\"lazy\" title=\"Scanning in progress\"></figure><p>When the scan is complete a <code>Save Settings</code> window should pop-up. Â We reviewed the information and made appropriate selections where noted below, then clicked <code>OK</code> to continue. Â <strong>Be sure to set and take note of the <code>File Name:</code> and <code>Save in:</code> fields! Â Also, it's probably wise to ensure that the <code>Data Format:</code> is \"TIFF\" and the <code>Save to a subfolder with current date</code> control is checked.</strong></p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0046.png\" class=\"kg-image\" alt=\"Save scan settings\" loading=\"lazy\" title=\"Save scan settings\"></figure><h1 id=\"smartscore-64-pro\">SmartScore 64 Pro</h1><p>A <em>SmartScore 64 Pro</em> window will automatically open, <strong>but don't be confused, we don't want to run this application yet! Â Click the <code>Cancel</code> button to close <em>SmartScore 64 Pro</em></strong>.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0064.png\" class=\"kg-image\" alt=\"SmartScore Pro launches automatically\" loading=\"lazy\" title=\"SmartScore Pro launches automatically but needs to be closed\"></figure><p>Once <em>SmartScore 64 Pro</em> is closed, we need to open it properly by clicking its icon in the dock. Â :frowning:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0078.png\" class=\"kg-image\" alt=\"Properly launching SmartScore\" loading=\"lazy\" title=\"Properly launching SmartScore\"></figure><p>Now <em>SmartScore</em> is open to the <code>Task Window</code> where we selected <code>Recognition</code> to convert the scanned images to music XML.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0089.png\" class=\"kg-image\" alt=\"Starting the SmartScore recognition process\" loading=\"lazy\" title=\"Starting the SmartScore recognition process\"></figure><p>Next, we add the files of our scanned pages to the recognition processing list.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0094.png\" class=\"kg-image\" alt=\"Add scans to SmartScore recognition\" loading=\"lazy\" title=\"Add scans to SmartScore recognition\"></figure><p>In the file dialog we navigate to the scanned page TIFFs and select them all. Â The order of files in the selection is NOT critical. Â With all files selected click <code>Open</code>.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0105.png\" class=\"kg-image\" alt=\"Navigate to the scan files and select them\" loading=\"lazy\" title=\"Navigate to the scan files and select them\"></figure><p>The next <code>Begin Recognition</code> screen offers controls to change the file order if necessary. Â Once the files are in the proper order click <code>Begin Recognition</code> button to proceed.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0134.png\" class=\"kg-image\" alt=\"Order the TIFFs and begin recognition\" loading=\"lazy\" title=\"Order the TIFFs and begin recognition\"></figure><p>Be patient, the recognition process may take a few minutes.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0151.png\" class=\"kg-image\" alt=\"Recognition in progress\" loading=\"lazy\" title=\"Recognition in progress\"></figure><p>When the recognition is complete a <code>System Report</code> appeared prompting us to <code>Open SmartScore file</code>. Â We did.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0155.png\" class=\"kg-image\" alt=\"SmartScore system report\" loading=\"lazy\" title=\"SmartScore system report\"></figure><p>Next, the <code>Unify Score</code> window popped up and we verified the default selections shown below before clicking <code>OK</code>.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0157.png\" class=\"kg-image\" alt=\"Unify score pop-up\" loading=\"lazy\" title=\"Unify score pop-up\"></figure><p>When prompted to save the score be sure to select <code>Music XML (*.xml)</code> and take note of where the file will be saved.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0168.png\" class=\"kg-image\" alt=\"Saving as XML\" loading=\"lazy\" title=\"Saving as XML\"></figure><p>You may be prompted to save each scan/file individually. Â Once the file save is confirmed you can close <em>SmartScore 64 Pro</em>.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0189.png\" class=\"kg-image\" alt=\"Confirm save and close SmartScore\" loading=\"lazy\" title=\"Confirm save and close SmartScore\"></figure><h1 id=\"finale\">Finale</h1><p>Next, open <em>Finale</em> from the dock as shown below.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0199.png\" class=\"kg-image\" alt=\"Open Finale\" loading=\"lazy\" title=\"Open Finale\"></figure><p>After a minute or more the <em>Finale</em> <code>Launch Window</code> should appear, and we selected <code>IMPORT MUSICXML</code> as shown below.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0209.png\" class=\"kg-image\" alt=\"Selecting IMPORT MUSICXML\" loading=\"lazy\" title=\"Selecting IMPORT MUSICXML\"></figure><p>We navigated to the XML file that was saved in <em>SmartScore</em> and clicked <code>Open</code> to load it in <em>Finale</em>.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0224.png\" class=\"kg-image\" alt=\"Opening the saved MusicXML file\" loading=\"lazy\" title=\"Opening the saved MusicXML file\"></figure><p>That's it, the scanned score is now loaded in <em>Finale</em> where it is ready to be edited! Â It's a good idea to click <code>Save As...</code> routinely to save your changes as you proceed.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sddocs.blob.core.windows.net/documentation/Finale-Workflow-Documentation/0237.png\" class=\"kg-image\" alt=\"Save your Finale work\" loading=\"lazy\" title=\"Save your Finale work\"></figure>",
            "comment_id": "6418da4223ad590d103c0590",
            "plaintext": "Mackenzie, my daughter, and I created this post documenting my wife's Finale workflow for scanning and editing music on her Mac. Â We did this for my wife to celebrate her birthday preserve her sanity. Â Well, it was worth a shot. Â The birthday idea seemed more romantic, but mental health comes first.\n\nThe document was created using a process we recently built and documented in Creating Better Documentation. Â In this instance of the process we tried to annotate in yellow screen capture elements that need attention, and used red annotation to indicate things that require input or action of some kind. Â In some of the later images we failed and things that should be red were left highlighted in yellow. Â Sorry.\n\n\nBegin by Scanning\n\nThe first step involved launching the Canon MF Scan Utility as you see below. Â This is the software she uses to scan music pages on the multi-function scanner attached to her Mac.\n\nWe verified that the correct scanner is selected, loaded the score into the scanner*, and clicked Custom to begin the scan. Â Then, wait for the scanner to warm up, if necessary.\n\n*Note that the sheet music can be placed on the scanner glass one-sheet-at-a-time, or if the pages are 8.5x11, one-sided, and in good condition, they may be loaded in the document feeder to scan continuously. Â In this particular case we were able to use the document feeder.\n\nOnce the scanner is ready the mechanical process of scanning should begin. Â When scanning one-page-at-a-time some user intervention will be required.\n\nWhen the scan is complete a Save Settings window should pop-up. Â We reviewed the information and made appropriate selections where noted below, then clicked OK to continue. Â Be sure to set and take note of the File Name: and Save in: fields! Â Also, it's probably wise to ensure that the Data Format: is \"TIFF\" and the Save to a subfolder with current date control is checked.\n\n\nSmartScore 64 Pro\n\nA SmartScore 64 Pro window will automatically open, but don't be confused, we don't want to run this application yet! Â Click the Cancel button to close SmartScore 64 Pro.\n\nOnce SmartScore 64 Pro is closed, we need to open it properly by clicking its icon in the dock. Â :frowning:\n\nNow SmartScore is open to the Task Window where we selected Recognition to convert the scanned images to music XML.\n\nNext, we add the files of our scanned pages to the recognition processing list.\n\nIn the file dialog we navigate to the scanned page TIFFs and select them all. Â The order of files in the selection is NOT critical. Â With all files selected click Open.\n\nThe next Begin Recognition screen offers controls to change the file order if necessary. Â Once the files are in the proper order click Begin Recognition button to proceed.\n\nBe patient, the recognition process may take a few minutes.\n\nWhen the recognition is complete a System Report appeared prompting us to Open SmartScore file. Â We did.\n\nNext, the Unify Score window popped up and we verified the default selections shown below before clicking OK.\n\nWhen prompted to save the score be sure to select Music XML (*.xml) and take note of where the file will be saved.\n\nYou may be prompted to save each scan/file individually. Â Once the file save is confirmed you can close SmartScore 64 Pro.\n\n\nFinale\n\nNext, open Finale from the dock as shown below.\n\nAfter a minute or more the Finale Launch Window should appear, and we selected IMPORT MUSICXML as shown below.\n\nWe navigated to the XML file that was saved in SmartScore and clicked Open to load it in Finale.\n\nThat's it, the scanned score is now loaded in Finale where it is ready to be edited! Â It's a good idea to click Save As... routinely to save your changes as you proceed.",
            "feature_image": "__GHOST_URL__/content/images/2023/03/Finale-0209.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-03-20T22:12:18.000Z",
            "updated_at": "2023-03-20T22:18:07.000Z",
            "published_at": "2023-02-08T18:00:00.000Z",
            "custom_excerpt": "\nChristine's Finale workflow captured using my new documentation approach",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6419163823ad590d103c05a0",
            "uuid": "6c641556-02b6-48e1-a86d-edf9a2960fc5",
            "title": "Gating My Content",
            "slug": "gating-my-content",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"hr\",{}]],\"markups\":[[\"a\",[\"href\",\"https://www.stackbit.com/\"]],[\"a\",[\"href\",\"https://www.stackbit.com/blog/gating-content-jamstack\"]],[\"a\",[\"href\",\"https://wieting.tamatoledo.com/\"]],[\"em\"],[\"a\",[\"href\",\"https://www.npmjs.com/package/staticrypt\"]],[\"a\",[\"href\",\"https://www.11ty.dev/\"]],[\"a\",[\"href\",\"mailto:summitt.dweller@gmail.com\"]],[\"a\",[\"href\",\"https://file+.vscode-resource.vscode-cdn.net/Users/mark/GitHub/blogs-SummittDweller/content/posts/2023/01/gating-content.md\"]],[\"a\",[\"href\",\"https://dev.azure.com/summittdweller\"]]],\"sections\":[[1,\"p\",[]],[1,\"h1\",[[0,[],0,\"Gating Content in JAMstack Sites\"]]],[1,\"p\",[[0,[],0,\"This section's title was borrowed from a \"],[0,[0],1,\"Stackbit\"],[0,[],0,\" article with the same title, \"],[0,[1],1,\"Gating Content in JAMstack Sites\"],[0,[],0,\". Working through that article to password protect some of the content at \"],[0,[2],1,\"https://Wieting.TamaToledo.com\"],[0,[],0,\" is my tech pursit today.\"]]],[1,\"h1\",[[0,[],0,\"Nope, Not on Netlify\"]]],[1,\"p\",[[0,[],0,\"Last evening I took a shot at implementing the \"],[0,[3],1,\"Netlify Identity\"],[0,[],0,\" tricks from the aforementioned article, but could not easily get it to work. The problem, I think, is that the \"],[0,[2],1,\"https://Wieting.TamaToledo.com\"],[0,[],0,\" on \"],[0,[3],1,\"Netlify\"],[0,[],0,\" already uses \"],[0,[3],1,\"Netlify Identity\"],[0,[],0,\" for authentication of my \"],[0,[3],1,\"Netlify CMS\"],[0,[],0,\" forms, and adding a second, separate instance of that service isn't trivial and perhaps isn't even feasible. I also tried implementing some quick \"],[0,[4],1,\"StatiCrypt\"],[0,[],0,\" CLI protection but that also failed. \"],[0,[3],1,\"Netlify\"],[0,[],0,\" does provide a really quick and painless solution, but it costs $20/month, at a minimum, to enable it.\"]]],[1,\"h1\",[[0,[],0,\"New StatiCrypt Strategy?\"]]],[1,\"p\",[[0,[],0,\"So, my next shot at this will involve creating a new \"],[0,[5],1,\"Eleventy\"],[0,[],0,\" site just for the Wieting's protected content. Wish me luck and follow along here if you like.\"]]],[1,\"h1\",[[0,[],0,\"Trying Azure DevOps\"]]],[1,\"p\",[[0,[],0,\"I recently created a personal Azure account, registered to \"],[0,[3,6],2,\"summitt.dweller@gmail.com\"],[0,[],0,\", and last evening (January 31, 2023) I took a dive into \"],[0,[7],1,\"Azure DevOps\"],[0,[],0,\" under that account. The \\\"welcome\\\" email that I received says I now have an \\\"organization\\\" URL at \"],[0,[8],1,\"https://dev.azure.com/summittdweller\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"I jumped into Azure DevOps because it looks like within that environment I can establish a Content Management System (CMS) not unlike the \"],[0,[3],1,\"NetlifyCMS\"],[0,[],0,\" (or perhaps it IS NCMS) that I run for the Wieting Theatre, hosted with Netlify.com. I really like \"],[0,[3],1,\"NetlifyCMS\"],[0,[],0,\", but thus far I've had limited success with it, and ONLY at Netlify.com where the user authentication process is nicely streamlined. I hope that Azure DevOps has user authentication that's just as easy to manage, and at less cost.\"]]],[1,\"p\",[[0,[],0,\"So, I guess the strategy now is to see what Azure DevOps has to offer, rather than venturing further with \"],[0,[4],1,\"StatiCrypt\"],[0,[],0,\".\"]]],[10,0],[1,\"p\",[[0,[],0,\"That's a TEMPORAY wrap, this post isn't finished just yet.\"]]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p></p><h1 id=\"gating-content-in-jamstack-sites\">Gating Content in JAMstack Sites</h1><p>This section's title was borrowed from a <a href=\"https://www.stackbit.com/\">Stackbit</a> article with the same title, <a href=\"https://www.stackbit.com/blog/gating-content-jamstack\">Gating Content in JAMstack Sites</a>. Working through that article to password protect some of the content at <a href=\"https://wieting.tamatoledo.com/\">https://Wieting.TamaToledo.com</a> is my tech pursit today.</p><h1 id=\"nope-not-on-netlify\">Nope, Not on Netlify</h1><p>Last evening I took a shot at implementing the <em>Netlify Identity</em> tricks from the aforementioned article, but could not easily get it to work. The problem, I think, is that the <a href=\"https://wieting.tamatoledo.com/\">https://Wieting.TamaToledo.com</a> on <em>Netlify</em> already uses <em>Netlify Identity</em> for authentication of my <em>Netlify CMS</em> forms, and adding a second, separate instance of that service isn't trivial and perhaps isn't even feasible. I also tried implementing some quick <a href=\"https://www.npmjs.com/package/staticrypt\">StatiCrypt</a> CLI protection but that also failed. <em>Netlify</em> does provide a really quick and painless solution, but it costs $20/month, at a minimum, to enable it.</p><h1 id=\"new-staticrypt-strategy\">New StatiCrypt Strategy?</h1><p>So, my next shot at this will involve creating a new <a href=\"https://www.11ty.dev/\">Eleventy</a> site just for the Wieting's protected content. Wish me luck and follow along here if you like.</p><h1 id=\"trying-azure-devops\">Trying Azure DevOps</h1><p>I recently created a personal Azure account, registered to <em><a href=\"mailto:summitt.dweller@gmail.com\">summitt.dweller@gmail.com</a></em>, and last evening (January 31, 2023) I took a dive into <a href=\"https://file+.vscode-resource.vscode-cdn.net/Users/mark/GitHub/blogs-SummittDweller/content/posts/2023/01/gating-content.md\">Azure DevOps</a> under that account. The \"welcome\" email that I received says I now have an \"organization\" URL at <a href=\"https://dev.azure.com/summittdweller\">https://dev.azure.com/summittdweller</a>.</p><p>I jumped into Azure DevOps because it looks like within that environment I can establish a Content Management System (CMS) not unlike the <em>NetlifyCMS</em> (or perhaps it IS NCMS) that I run for the Wieting Theatre, hosted with Netlify.com. I really like <em>NetlifyCMS</em>, but thus far I've had limited success with it, and ONLY at Netlify.com where the user authentication process is nicely streamlined. I hope that Azure DevOps has user authentication that's just as easy to manage, and at less cost.</p><p>So, I guess the strategy now is to see what Azure DevOps has to offer, rather than venturing further with <a href=\"https://www.npmjs.com/package/staticrypt\">StatiCrypt</a>.</p><hr><p>That's a TEMPORAY wrap, this post isn't finished just yet.</p>",
            "comment_id": "6419163823ad590d103c05a0",
            "plaintext": "Gating Content in JAMstack Sites\n\nThis section's title was borrowed from a Stackbit article with the same title, Gating Content in JAMstack Sites. Working through that article to password protect some of the content at https://Wieting.TamaToledo.com is my tech pursit today.\n\n\nNope, Not on Netlify\n\nLast evening I took a shot at implementing the Netlify Identity tricks from the aforementioned article, but could not easily get it to work. The problem, I think, is that the https://Wieting.TamaToledo.com on Netlify already uses Netlify Identity for authentication of my Netlify CMS forms, and adding a second, separate instance of that service isn't trivial and perhaps isn't even feasible. I also tried implementing some quick StatiCrypt CLI protection but that also failed. Netlify does provide a really quick and painless solution, but it costs $20/month, at a minimum, to enable it.\n\n\nNew StatiCrypt Strategy?\n\nSo, my next shot at this will involve creating a new Eleventy site just for the Wieting's protected content. Wish me luck and follow along here if you like.\n\n\nTrying Azure DevOps\n\nI recently created a personal Azure account, registered to summitt.dweller@gmail.com, and last evening (January 31, 2023) I took a dive into Azure DevOps under that account. The \"welcome\" email that I received says I now have an \"organization\" URL at https://dev.azure.com/summittdweller.\n\nI jumped into Azure DevOps because it looks like within that environment I can establish a Content Management System (CMS) not unlike the NetlifyCMS (or perhaps it IS NCMS) that I run for the Wieting Theatre, hosted with Netlify.com. I really like NetlifyCMS, but thus far I've had limited success with it, and ONLY at Netlify.com where the user authentication process is nicely streamlined. I hope that Azure DevOps has user authentication that's just as easy to manage, and at less cost.\n\nSo, I guess the strategy now is to see what Azure DevOps has to offer, rather than venturing further with StatiCrypt.\n\nThat's a TEMPORAY wrap, this post isn't finished just yet.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-03-21T02:28:08.000Z",
            "updated_at": "2023-03-21T02:37:52.000Z",
            "published_at": "2023-01-30T18:00:00.000Z",
            "custom_excerpt": "Working through https://www.stackbit.com/blog/gating-content-jamstack to password protect some of the content at https://Wieting.TamaToledo.com is my tech pursuit today.   ",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6419189e23ad590d103c05e5",
            "uuid": "7ab7847c-d9d3-483f-9f86-d099cd51ebbc",
            "title": "Fixing a Broken GitHub Repo",
            "slug": "fixing-a-broken-github-repo",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"hr\",{}]],\"markups\":[[\"em\"],[\"a\",[\"href\",\"https://cv.tamatoledo.org/\"]],[\"code\"],[\"a\",[\"href\",\"https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/removing-sensitive-data-from-a-repository#using-git-filter-repo\"]],[\"strong\"],[\"a\",[\"href\",\"https://github.com/Tama-Toledo/community-visioning\"]],[\"a\",[\"href\",\"https://github.com/Tama-Toledo/community-visioning/blob/main/README.md\"]]],\"sections\":[[1,\"h3\",[[0,[0],1,\"Don't Push Enormous Files to GitHub!\"]]],[1,\"p\",[[0,[],0,\"Pay close attention to the statement above!  A couple of days ago I was working on content for \"],[0,[1],1,\"Tama-Toledo Community Visioning\"],[0,[],0,\" and I added a large \"],[0,[2],1,\"socialmedia.zip\"],[0,[],0,\" file to the source repo, and then very stupidly pushed it to GitHub and the repo's \"],[0,[2],1,\"main\"],[0,[],0,\" branch. Naturally, the push didn't finish so I removed the file and pushed a new commit to \\\"remove it permanently\\\". Well, that ain't how \"],[0,[2],1,\"git\"],[0,[],0,\" works!\"]]],[1,\"p\",[[0,[],0,\"The \\\"remove\\\" commit appeared to have worked, but now the TTCV site wouldn't deploy since the build time had gone from less than 2 minutes, to more than 10 minutes. I immediately became suspicious of that pesky, large, \"],[0,[2],1,\"socialmedia.zip\"],[0,[],0,\" file, but how could I properly get rid of it?\"]]],[1,\"h1\",[[0,[],0,\"Using \"],[0,[2],1,\"git filter-repo\"]]],[1,\"p\",[[0,[],0,\"Fortunately, I found and followed the GitHub docs guidance in \"],[0,[3],1,\"Using git filter-repo\"],[0,[],0,\" to remove the troublesome large file, namely \"],[0,[2],1,\"socialmedia.zip\"],[0,[],0,\", from the repo. The commands I used to do this included...\"]]],[3,\"ul\",[[[0,[4],1,\"brew install git-filter-repo\"]],[[0,[4],1,\"git clone\"],[0,[],0,\" \"],[0,[5],1,\"https://github.com/Tama-Toledo/community-visioning\"]]]],[1,\"p\",[[0,[],0,\"The above command was necessary because the next command expects a \\\"clean\\\", recently compressed local repository.\"]]],[3,\"ul\",[[[0,[4],1,\"git filter-repo\"],[0,[],0,\" --invert-paths --path socialmedia.zip\"]],[[0,[4],1,\"git remote add origin\"],[0,[],0,\" \"],[0,[5],1,\"https://github.com/Tama-Toledo/community-visioning\"]],[[0,[4],1,\"git push origin --force --all\"]],[[0,[4],1,\"git branch --set-upstream-to=origin/main\"],[0,[],0,\" main\"]]]],[1,\"h1\",[[0,[],0,\"It Worked!\"]]],[1,\"p\",[[0,[],0,\"The good news, this worked, and I now have my repo back in shape such that I can successfully deploy it again.\"]]],[10,0],[1,\"p\",[[0,[],0,\"That's a wrap. Oh, in case you want to know what happened to \"],[0,[2],1,\"socialmedia.zip\"],[0,[],0,\", check out that project's \"],[0,[6],1,\"README.md\"],[0,[],0,\" file.\"]]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<h3 id=\"dont-push-enormous-files-to-github\"><em>Don't Push Enormous Files to GitHub!</em></h3><p>Pay close attention to the statement above! Â A couple of days ago I was working on content for <a href=\"https://cv.tamatoledo.org/\">Tama-Toledo Community Visioning</a> and I added a large <code>socialmedia.zip</code> file to the source repo, and then very stupidly pushed it to GitHub and the repo's <code>main</code> branch. Naturally, the push didn't finish so I removed the file and pushed a new commit to \"remove it permanently\". Well, that ain't how <code>git</code> works!</p><p>The \"remove\" commit appeared to have worked, but now the TTCV site wouldn't deploy since the build time had gone from less than 2 minutes, to more than 10 minutes. I immediately became suspicious of that pesky, large, <code>socialmedia.zip</code> file, but how could I properly get rid of it?</p><h1 id=\"using-git-filter-repo\">Using <code>git filter-repo</code></h1><p>Fortunately, I found and followed the GitHub docs guidance in <a href=\"https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/removing-sensitive-data-from-a-repository#using-git-filter-repo\">Using git filter-repo</a> to remove the troublesome large file, namely <code>socialmedia.zip</code>, from the repo. The commands I used to do this included...</p><ul><li><strong>brew install git-filter-repo</strong></li><li><strong>git clone</strong> <a href=\"https://github.com/Tama-Toledo/community-visioning\">https://github.com/Tama-Toledo/community-visioning</a></li></ul><p>The above command was necessary because the next command expects a \"clean\", recently compressed local repository.</p><ul><li><strong>git filter-repo</strong> --invert-paths --path socialmedia.zip</li><li><strong>git remote add origin</strong> <a href=\"https://github.com/Tama-Toledo/community-visioning\">https://github.com/Tama-Toledo/community-visioning</a></li><li><strong>git push origin --force --all</strong></li><li><strong>git branch --set-upstream-to=origin/main</strong> main</li></ul><h1 id=\"it-worked\">It Worked!</h1><p>The good news, this worked, and I now have my repo back in shape such that I can successfully deploy it again.</p><hr><p>That's a wrap. Oh, in case you want to know what happened to <code>socialmedia.zip</code>, check out that project's <a href=\"https://github.com/Tama-Toledo/community-visioning/blob/main/README.md\">README.md</a> file.</p>",
            "comment_id": "6419189e23ad590d103c05e5",
            "plaintext": "Don't Push Enormous Files to GitHub!\n\nPay close attention to the statement above! Â A couple of days ago I was working on content for Tama-Toledo Community Visioning and I added a large socialmedia.zip file to the source repo, and then very stupidly pushed it to GitHub and the repo's main branch. Naturally, the push didn't finish so I removed the file and pushed a new commit to \"remove it permanently\". Well, that ain't how git works!\n\nThe \"remove\" commit appeared to have worked, but now the TTCV site wouldn't deploy since the build time had gone from less than 2 minutes, to more than 10 minutes. I immediately became suspicious of that pesky, large, socialmedia.zip file, but how could I properly get rid of it?\n\n\nUsing git filter-repo\n\nFortunately, I found and followed the GitHub docs guidance in Using git filter-repo to remove the troublesome large file, namely socialmedia.zip, from the repo. The commands I used to do this included...\n\n * brew install git-filter-repo\n * git clone https://github.com/Tama-Toledo/community-visioning\n\nThe above command was necessary because the next command expects a \"clean\", recently compressed local repository.\n\n * git filter-repo --invert-paths --path socialmedia.zip\n * git remote add origin https://github.com/Tama-Toledo/community-visioning\n * git push origin --force --all\n * git branch --set-upstream-to=origin/main main\n\n\nIt Worked!\n\nThe good news, this worked, and I now have my repo back in shape such that I can successfully deploy it again.\n\nThat's a wrap. Oh, in case you want to know what happened to socialmedia.zip, check out that project's README.md file.",
            "feature_image": "https://images.unsplash.com/photo-1654277041218-84424c78f0ae?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDE2fHxnaXRodWJ8ZW58MHx8fHwxNjgwNzAwMjkw&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-03-21T02:38:22.000Z",
            "updated_at": "2023-04-05T13:12:00.000Z",
            "published_at": "2023-01-19T18:00:00.000Z",
            "custom_excerpt": "\n",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64191af123ad590d103c061b",
            "uuid": "dd35b5a4-f9a8-4b39-b285-a8b3555c2f9e",
            "title": "My Hugo Timeline",
            "slug": "my-hugo-timeline",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹mainâ€º \\nâ•°â”€$ brew install go\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹mainâ€º \\nâ•°â”€$ brew upgrade   # This is not \\\"required\\\", but probably overdue.\\n\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \\nâ•°â”€$ mkdir content/timeline/.out-of-the-way      # vvv Moving existing local stuff out of the way vvv\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \\nâ•°â”€$ mv -f layouts/partials/hugo-timeline* content/timeline/.out-of-the-way/.   \\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \\nâ•°â”€$ mv -f layouts/shortcodes/hugo-timeline* content/timeline/.out-of-the-way/.\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \\nâ•°â”€$ mv -f static/css/hugo-timeline* content/timeline/.out-of-the-way/.        \\n\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \\nâ•°â”€$ hugo mod init github.com/SummittDweller/blogs-SummittDweller        \\ngo: creating new go.mod: module github.com/SummittDweller/blogs-SummittDweller\\ngo: to add module requirements and sums:\\n        go mod tidy\\n\"}],[\"code\",{\"code\":\"module:\\n  imports:\\n    - path: github.com/SummittDweller/hugo-timeline\\n      mounts:\\n      - source: layouts\\n        target: layouts\\n      - source: static\\n        target: static\\n\",\"language\":\"yml\"}],[\"code\",{\"code\":\"â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \\nâ•°â”€$ hugo mod get -u github.com/SummittDweller/hugo-timeline\\ngo: downloading github.com/SummittDweller/hugo-timeline v0.0.0-20221206191252-cd7178e7e43b\\ngo: upgraded github.com/SummittDweller/hugo-timeline v0.0.0-20221206043330-5f1ecbad913f => v0.0.0-20221206191252-cd7178e7e43b\\n\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \\nâ•°â”€$ hugo server\\nport 1313 already in use, attempting to use an available port\\nStart building sites â€¦ \\nhugo v0.107.0+extended darwin/amd64 BuildDate=unknown\\n\\n                   | EN   \\n-------------------+------\\n  Pages            | 288  \\n  Paginator pages  |   9  \\n  Non-page files   |   0  \\n  Static files     |  38  \\n  Processed images |   0  \\n  Aliases          |  79  \\n  Sitemaps         |   1  \\n  Cleaned          |   0  \\n\\nBuilt in 90 ms\\nWatching for changes in /Users/mark/GitHub/blogs-SummittDweller/{archetypes,content,layouts,static,themes}\\nWatching for config changes in /Users/mark/GitHub/blogs-SummittDweller/config.yaml, /Users/mark/GitHub/blogs-SummittDweller/go.mod\\nEnvironment: \\\"development\\\"\\nServing pages from memory\\nRunning in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender\\nWeb Server is available at //localhost:62846/ (bind address 127.0.0.1)\\nPress Ctrl+C to stop\\n\"}],[\"hr\",{}]],\"markups\":[[\"code\"],[\"a\",[\"href\",\"https://github.com/SummittDweller/hugo-timeline\"]],[\"a\",[\"href\",\"https://gohugo.io/hugo-modules/\"]],[\"a\",[\"href\",\"https://scripter.co/hugo-modules-getting-started/\"]],[\"a\",[\"href\",\"https://www.thenewdynamic.com/article/hugo-modules-everything-from-imports-to-create/\"]],[\"a\",[\"href\",\"https://www.thenewdynamic.com/article/hugo-modules-everything-from-imports-to-create/#upgrading\"]],[\"strong\"]],\"sections\":[[1,\"p\",[[0,[],0,\"What follows is an excerpt from this blog's \"],[0,[0],1,\"README.md\"],[0,[],0,\" file.\"]]],[1,\"p\",[[0,[],0,\"I've successfully added the code to drive a new \"],[0,[0],1,\"/timeline\"],[0,[],0,\" page as part of this blog, but I did so \\\"locally\\\", and now I'd like to repeat the process but using the aforementioned \"],[0,[1],1,\"SummittDweller/hugo-timeline\"],[0,[],0,\" \"],[0,[2],1,\"module\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"I used guidance found in \"],[0,[3],1,\"Hugo Modules: Getting Started\"],[0,[],0,\" to make this happen, like so:\"]]],[10,0],[1,\"p\",[[0,[],0,\"Next, to pull in \"],[0,[1],1,\"SummittDweller/hugo-timeline\"],[0,[],0,\" as a module I turned to the \"],[0,[0],1,\"config.yml\"],[0,[],0,\" file and guidance found in \"],[0,[4],1,\"Hugo Modules: everything you need to know!\"],[0,[],0,\". Additions to \"],[0,[0],1,\"config.yml\"],[0,[],0,\" are:\"]]],[10,1],[1,\"h3\",[[0,[],0,\"Updating the Module\"]]],[1,\"p\",[[0,[],0,\"So, all of the above moves appeared to work correctly, at least locally, but I wanted to be sure I can successfully update the \"],[0,[0],1,\"hugo-timeline\"],[0,[],0,\" module and get updated behavior in this project. The command required to make that happen per \"],[0,[5],1,\"Hugo Modules: everything you need to know!\"],[0,[],0,\" is:\"]]],[10,2],[1,\"p\",[[0,[],0,\"Eureka! The page rendered at \"],[0,[0],1,\"http://localhost:1313/timeline/\"],[0,[],0,\" after the above \"],[0,[0],1,\"hugo mod get -u...\"],[0,[],0,\" command is displaying the latest changes I made to \"],[0,[0],1,\"hugo-timeline\"],[0,[],0,\"! Perfect!\"]]],[10,3],[1,\"p\",[[0,[6],1,\"My work here is done, well, for now anyway.\"],[0,[],0,\" \"]]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>What follows is an excerpt from this blog's <code>README.md</code> file.</p><p>I've successfully added the code to drive a new <code>/timeline</code> page as part of this blog, but I did so \"locally\", and now I'd like to repeat the process but using the aforementioned <a href=\"https://github.com/SummittDweller/hugo-timeline\">SummittDweller/hugo-timeline</a> <a href=\"https://gohugo.io/hugo-modules/\">module</a>.</p><p>I used guidance found in <a href=\"https://scripter.co/hugo-modules-getting-started/\">Hugo Modules: Getting Started</a> to make this happen, like so:</p><pre><code>â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹mainâ€º \nâ•°â”€$ brew install go\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹mainâ€º \nâ•°â”€$ brew upgrade   # This is not \"required\", but probably overdue.\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \nâ•°â”€$ mkdir content/timeline/.out-of-the-way      # vvv Moving existing local stuff out of the way vvv\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \nâ•°â”€$ mv -f layouts/partials/hugo-timeline* content/timeline/.out-of-the-way/.   \nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \nâ•°â”€$ mv -f layouts/shortcodes/hugo-timeline* content/timeline/.out-of-the-way/.\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \nâ•°â”€$ mv -f static/css/hugo-timeline* content/timeline/.out-of-the-way/.        \n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \nâ•°â”€$ hugo mod init github.com/SummittDweller/blogs-SummittDweller        \ngo: creating new go.mod: module github.com/SummittDweller/blogs-SummittDweller\ngo: to add module requirements and sums:\n        go mod tidy\n</code></pre><p>Next, to pull in <a href=\"https://github.com/SummittDweller/hugo-timeline\">SummittDweller/hugo-timeline</a> as a module I turned to the <code>config.yml</code> file and guidance found in <a href=\"https://www.thenewdynamic.com/article/hugo-modules-everything-from-imports-to-create/\">Hugo Modules: everything you need to know!</a>. Additions to <code>config.yml</code> are:</p><pre><code class=\"language-yml\">module:\n  imports:\n    - path: github.com/SummittDweller/hugo-timeline\n      mounts:\n      - source: layouts\n        target: layouts\n      - source: static\n        target: static\n</code></pre><h3 id=\"updating-the-module\">Updating the Module</h3><p>So, all of the above moves appeared to work correctly, at least locally, but I wanted to be sure I can successfully update the <code>hugo-timeline</code> module and get updated behavior in this project. The command required to make that happen per <a href=\"https://www.thenewdynamic.com/article/hugo-modules-everything-from-imports-to-create/#upgrading\">Hugo Modules: everything you need to know!</a> is:</p><pre><code>â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \nâ•°â”€$ hugo mod get -u github.com/SummittDweller/hugo-timeline\ngo: downloading github.com/SummittDweller/hugo-timeline v0.0.0-20221206191252-cd7178e7e43b\ngo: upgraded github.com/SummittDweller/hugo-timeline v0.0.0-20221206043330-5f1ecbad913f =&gt; v0.0.0-20221206191252-cd7178e7e43b\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \nâ•°â”€$ hugo server\nport 1313 already in use, attempting to use an available port\nStart building sites â€¦ \nhugo v0.107.0+extended darwin/amd64 BuildDate=unknown\n\n                   | EN   \n-------------------+------\n  Pages            | 288  \n  Paginator pages  |   9  \n  Non-page files   |   0  \n  Static files     |  38  \n  Processed images |   0  \n  Aliases          |  79  \n  Sitemaps         |   1  \n  Cleaned          |   0  \n\nBuilt in 90 ms\nWatching for changes in /Users/mark/GitHub/blogs-SummittDweller/{archetypes,content,layouts,static,themes}\nWatching for config changes in /Users/mark/GitHub/blogs-SummittDweller/config.yaml, /Users/mark/GitHub/blogs-SummittDweller/go.mod\nEnvironment: \"development\"\nServing pages from memory\nRunning in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender\nWeb Server is available at //localhost:62846/ (bind address 127.0.0.1)\nPress Ctrl+C to stop\n</code></pre><p>Eureka! The page rendered at <code>http://localhost:1313/timeline/</code> after the above <code>hugo mod get -u...</code> command is displaying the latest changes I made to <code>hugo-timeline</code>! Perfect!</p><hr><p><strong>My work here is done, well, for now anyway.</strong> </p>",
            "comment_id": "64191af123ad590d103c061b",
            "plaintext": "What follows is an excerpt from this blog's README.md file.\n\nI've successfully added the code to drive a new /timeline page as part of this blog, but I did so \"locally\", and now I'd like to repeat the process but using the aforementioned SummittDweller/hugo-timeline module.\n\nI used guidance found in Hugo Modules: Getting Started to make this happen, like so:\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹mainâ€º \nâ•°â”€$ brew install go\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹mainâ€º \nâ•°â”€$ brew upgrade   # This is not \"required\", but probably overdue.\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \nâ•°â”€$ mkdir content/timeline/.out-of-the-way      # vvv Moving existing local stuff out of the way vvv\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \nâ•°â”€$ mv -f layouts/partials/hugo-timeline* content/timeline/.out-of-the-way/.   \nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \nâ•°â”€$ mv -f layouts/shortcodes/hugo-timeline* content/timeline/.out-of-the-way/.\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \nâ•°â”€$ mv -f static/css/hugo-timeline* content/timeline/.out-of-the-way/.        \n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \nâ•°â”€$ hugo mod init github.com/SummittDweller/blogs-SummittDweller        \ngo: creating new go.mod: module github.com/SummittDweller/blogs-SummittDweller\ngo: to add module requirements and sums:\n        go mod tidy\n\n\nNext, to pull in SummittDweller/hugo-timeline as a module I turned to the config.yml file and guidance found in Hugo Modules: everything you need to know!. Additions to config.yml are:\n\nmodule:\n  imports:\n    - path: github.com/SummittDweller/hugo-timeline\n      mounts:\n      - source: layouts\n        target: layouts\n      - source: static\n        target: static\n\n\n\nUpdating the Module\n\nSo, all of the above moves appeared to work correctly, at least locally, but I wanted to be sure I can successfully update the hugo-timeline module and get updated behavior in this project. The command required to make that happen per Hugo Modules: everything you need to know! is:\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \nâ•°â”€$ hugo mod get -u github.com/SummittDweller/hugo-timeline\ngo: downloading github.com/SummittDweller/hugo-timeline v0.0.0-20221206191252-cd7178e7e43b\ngo: upgraded github.com/SummittDweller/hugo-timeline v0.0.0-20221206043330-5f1ecbad913f => v0.0.0-20221206191252-cd7178e7e43b\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º \nâ•°â”€$ hugo server\nport 1313 already in use, attempting to use an available port\nStart building sites â€¦ \nhugo v0.107.0+extended darwin/amd64 BuildDate=unknown\n\n                   | EN   \n-------------------+------\n  Pages            | 288  \n  Paginator pages  |   9  \n  Non-page files   |   0  \n  Static files     |  38  \n  Processed images |   0  \n  Aliases          |  79  \n  Sitemaps         |   1  \n  Cleaned          |   0  \n\nBuilt in 90 ms\nWatching for changes in /Users/mark/GitHub/blogs-SummittDweller/{archetypes,content,layouts,static,themes}\nWatching for config changes in /Users/mark/GitHub/blogs-SummittDweller/config.yaml, /Users/mark/GitHub/blogs-SummittDweller/go.mod\nEnvironment: \"development\"\nServing pages from memory\nRunning in Fast Render Mode. For full rebuilds on change: hugo server --disableFastRender\nWeb Server is available at //localhost:62846/ (bind address 127.0.0.1)\nPress Ctrl+C to stop\n\n\nEureka! The page rendered at http://localhost:1313/timeline/ after the above hugo mod get -u... command is displaying the latest changes I made to hugo-timeline! Perfect!\n\nMy work here is done, well, for now anyway.",
            "feature_image": "__GHOST_URL__/content/images/2023/04/Rootstalk-Timeline.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-03-21T02:48:17.000Z",
            "updated_at": "2023-04-05T13:05:24.000Z",
            "published_at": "2022-12-06T18:00:00.000Z",
            "custom_excerpt": "I've successfully added the code to drive a new `/timeline` page as part of this blog, but I did so \"locally\", and now I'd like to repeat the process but using the https://github.com/SummittDweller/hugo-timeline module per https://gohugo.io/hugo-modules/.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64191c6e23ad590d103c063c",
            "uuid": "7bda4cdf-2c86-48c7-9739-083b439f3e0b",
            "title": "Proper Python",
            "slug": "proper-python",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"code\",{\"code\":\"â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º\\nâ•°â”€$ python3 -m venv .venv\\n\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º\\nâ•°â”€$ source .venv/bin/activate\\n\"}],[\"code\",{\"code\":\"(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º\\nâ•°â”€$ pip3 install python-frontmatter\\n\\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummitDweller â€¹main*â€º\\nâ•°â”€$ pip3 install datetime\"}],[\"code\",{\"code\":\"(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹mainâ€º \\nâ•°â”€$ pip3 freeze > python-requirements.txt\\n\"}],[\"code\",{\"code\":\"(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º\\nâ•°â”€$ pip3 install -r python-requirements.txt\\n\"}],[\"code\",{\"code\":\"(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummitDweller â€¹main*â€º\\nâ•°â”€$ python3 consolidate.py --start 20220806 --end 20220825\\n\\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummitDweller â€¹main*â€º\\nâ•°â”€$ hugo server\\n\"}],[\"code\",{\"code\":\"source .venv/bin/activate && pip3 install -r python-requirements.txt\\n\"}]],\"markups\":[[\"code\"],[\"em\"],[\"a\",[\"href\",\"https://blog.summittdweller.com/\"]],[\"a\",[\"href\",\"https://github.com/SummittDweller/hikes\"]],[\"a\",[\"href\",\"https://predictivehacks.com/how-to-work-with-vs-code-and-virtual-environments-in-python/\"]],[\"a\",[\"href\",\"https://stackoverflow.com/questions/6590688/is-it-bad-to-have-my-virtualenv-directory-inside-my-git-repository\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"What follows is the \"],[0,[0],1,\"README.md\"],[0,[],0,\" file from my \"],[0,[1],1,\"GitHub\"],[0,[],0,\" repo where \"],[0,[2],1,\"https://blog.summittdweller.com\"],[0,[],0,\" is built. It outlines how to \\\"properly\\\" add Python to a project such that we can create an easily reproducible \\\"virtual environment\\\" without storing the necessary Python libraries in \"],[0,[1],1,\"GitHub\"],[0,[],0,\".\"]]],[1,\"p\",[[0,[],0,\"From the \"],[0,[0],1,\"README.md\"],[0,[],0,\"...\"]]],[1,\"h1\",[[0,[],0,\"blogs-SummittDweller\"]]],[1,\"p\",[[0,[],0,\"The Python portions of this repo were gleaned from \"],[0,[3],1,\"https://github.com/SummittDweller/hikes\"],[0,[],0,\". This was the repo for my \"],[0,[2],1,\"https://blog.SummittDweller.com/\"],[0,[],0,\" static website before I moved the blog to \"],[0,[1],1,\"Ghost\"],[0,[],0,\" in 2023. \"]]],[1,\"h2\",[[0,[],0,\"Latest Python Improvements\"]]],[1,\"p\",[[0,[],0,\"Using guidance at \"],[0,[4],1,\"https://predictivehacks.com/how-to-work-with-vs-code-and-virtual-environments-in-python/\"],[0,[],0,\" I successfully created a new \"],[0,[0],1,\".venv\"],[0,[],0,\" virtual environment. The commands I used to do this were...\"]]],[10,0],[1,\"p\",[[0,[],0,\"Now the \"],[0,[0],1,\".venv\"],[0,[],0,\" is engaged and ready for some code so I added my Python code and turned my attention to each of the \"],[0,[0],1,\"import\"],[0,[],0,\" statements within.  Most of these \"],[0,[0],1,\"import\"],[0,[],0,\" statements will require the installation of a module or package.  For example, statements like \"],[0,[0],1,\"import frontmatter\"],[0,[],0,\" and \"],[0,[0],1,\"from datetime import datetime\"],[0,[],0,\" suggested that I needed to install the following:\"]]],[10,1],[1,\"p\",[[0,[],0,\"Now, in order to \\\"freeze\\\" a copy of this module/package configuration to use later...  \"]]],[10,2],[1,\"p\",[[0,[],0,\"Whenever I want to re-install all of the modules/packages captured by the \\\"freeze\\\" command I do this:\"]]],[10,3],[1,\"p\",[[0,[],0,\"To finish my setup in \"],[0,[1],1,\"VSCode\"],[0,[],0,\" I used \"],[0,[0],1,\"COMMAND-SHIFT-P\"],[0,[],0,\" to select and \"],[0,[0],1,\"Python: Select interpreter\"],[0,[],0,\" to choose the new \"],[0,[0],1,\".venv\"],[0,[],0,\" Python.  After that...\"]]],[10,4],[1,\"h2\",[[0,[],0,\"Rebuilding a Local Environment\"]]],[1,\"p\",[[0,[],0,\"Based on guideance from \"],[0,[5],1,\"https://stackoverflow.com/questions/6590688/is-it-bad-to-have-my-virtualenv-directory-inside-my-git-repository\"],[0,[],0,\" I've reconstructed this project such that Python artifacts do NOT propogate into Github.\"]]],[1,\"p\",[[0,[],0,\"The project should automatically \\\"rebuild\\\" as necessary when opened in VSCode, but if the Python virtual environment needs to be recreated use...\"]]],[10,5],[1,\"h2\",[[0,[],0,\"Deployment via DigitalOcean\"]]],[1,\"p\",[[0,[],0,\"In order to deploy this \"],[0,[0],1,\"starter\"],[0,[],0,\" static app on \"],[0,[1],1,\"DigitalOcean\"],[0,[],0,\" I had to PERMANENTLY move all of my Python components (\"],[0,[0],1,\".py\"],[0,[],0,\" scripts and \"],[0,[0],1,\"requirements.txt\"],[0,[],0,\") to a \"],[0,[0],1,\".python\"],[0,[],0,\" directory to hide it from view during app creation. Before moving these elements \"],[0,[1],1,\"DigitalOcean\"],[0,[],0,\" would consistently try to deploy my app as Python, and that's not right.\"]]],[1,\"p\",[[0,[],0,\"See \"],[0,[1],1,\"DigitalOcean\"],[0,[],0,\" ticket [#06849069] \"],[0,[0],1,\"Hugo static site with Python components builds fail\"],[0,[],0,\" for details.\"]]],[1,\"p\",[[0,[],0,\"The response I received from \"],[0,[1],1,\"DigitalOcean\"],[0,[],0,\"...\"]]],[1,\"blockquote\",[[0,[],0,\"Hello,\"]]],[1,\"blockquote\",[[0,[],0,\"Thanks for contacting DigitalOcean.\"]]],[1,\"blockquote\",[[0,[],0,\"We appreciate you reaching out to us about your Hugo static site. From what you mentioned it does sound like your app is getting detected as a python webservice rather then a static site due to the requirements.txt file you had in the root of your repo.\"]]],[1,\"blockquote\",[[0,[],0,\"Unfortunately this is currently what App platform uses to detect applications as python apps. Either having a requirements.txt file or a setup.py file will cause that detection. Our engineers are looking into options to specify the build pack used rather then relying upon the auto detection, which would address this issue in your case, but don't have a timeline yet for implementing it.\"]]],[1,\"blockquote\",[[0,[],0,\"In the mean time the work around that you have specified here should work fine for this. It should cause the app to be detected as a static site rather then python. Hopefully it isn't impacting anything else in your app's build process.\"]]],[1,\"blockquote\",[[0,[],0,\"If you have any questions, please let us know.\"]]],[1,\"blockquote\",[[0,[],0,\"Regards, Nate Senior Cloud Support Engineer Check out our community for great tutorials, articles and FAQs! digitalocean.com/community\"]]],[1,\"blockquote\",[[0,[],0,\"ref:_00Df218t5m._5004P21l4JM:ref \"]]],[1,\"h3\",[[0,[],0,\"Remedy\"]]],[1,\"p\",[[0,[],0,\"Based on the response above I'm making final changes to eliminate the \"],[0,[0],1,\".python\"],[0,[],0,\" folder, renaming \"],[0,[0],1,\".python/requirements.txt\"],[0,[],0,\" as \"],[0,[0],1,\"python-requirements.txt\"],[0,[],0,\", and pulling all other contents of \"],[0,[0],1,\".python\"],[0,[],0,\" into the root of the project.\"]]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>What follows is the <code>README.md</code> file from my <em>GitHub</em> repo where <a href=\"https://blog.summittdweller.com/\">https://blog.summittdweller.com</a> is built. It outlines how to \"properly\" add Python to a project such that we can create an easily reproducible \"virtual environment\" without storing the necessary Python libraries in <em>GitHub</em>.</p><p>From the <code>README.md</code>...</p><h1 id=\"blogs-summittdweller\">blogs-SummittDweller</h1><p>The Python portions of this repo were gleaned from <a href=\"https://github.com/SummittDweller/hikes\">https://github.com/SummittDweller/hikes</a>. This was the repo for my <a href=\"https://blog.summittdweller.com/\">https://blog.SummittDweller.com/</a> static website before I moved the blog to <em>Ghost</em> in 2023. </p><h2 id=\"latest-python-improvements\">Latest Python Improvements</h2><p>Using guidance at <a href=\"https://predictivehacks.com/how-to-work-with-vs-code-and-virtual-environments-in-python/\">https://predictivehacks.com/how-to-work-with-vs-code-and-virtual-environments-in-python/</a> I successfully created a new <code>.venv</code> virtual environment. The commands I used to do this were...</p><pre><code>â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º\nâ•°â”€$ python3 -m venv .venv\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º\nâ•°â”€$ source .venv/bin/activate\n</code></pre><p>Now the <code>.venv</code> is engaged and ready for some code so I added my Python code and turned my attention to each of the <code>import</code> statements within. Â Most of these <code>import</code> statements will require the installation of a module or package. Â For example, statements like <code>import frontmatter</code> and <code>from datetime import datetime</code> suggested that I needed to install the following:</p><pre><code>(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º\nâ•°â”€$ pip3 install python-frontmatter\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummitDweller â€¹main*â€º\nâ•°â”€$ pip3 install datetime</code></pre><p>Now, in order to \"freeze\" a copy of this module/package configuration to use later... Â </p><pre><code>(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹mainâ€º \nâ•°â”€$ pip3 freeze &gt; python-requirements.txt\n</code></pre><p>Whenever I want to re-install all of the modules/packages captured by the \"freeze\" command I do this:</p><pre><code>(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º\nâ•°â”€$ pip3 install -r python-requirements.txt\n</code></pre><p>To finish my setup in <em>VSCode</em> I used <code>COMMAND-SHIFT-P</code> to select and <code>Python: Select interpreter</code> to choose the new <code>.venv</code> Python. Â After that...</p><pre><code>(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummitDweller â€¹main*â€º\nâ•°â”€$ python3 consolidate.py --start 20220806 --end 20220825\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummitDweller â€¹main*â€º\nâ•°â”€$ hugo server\n</code></pre><h2 id=\"rebuilding-a-local-environment\">Rebuilding a Local Environment</h2><p>Based on guideance from <a href=\"https://stackoverflow.com/questions/6590688/is-it-bad-to-have-my-virtualenv-directory-inside-my-git-repository\">https://stackoverflow.com/questions/6590688/is-it-bad-to-have-my-virtualenv-directory-inside-my-git-repository</a> I've reconstructed this project such that Python artifacts do NOT propogate into Github.</p><p>The project should automatically \"rebuild\" as necessary when opened in VSCode, but if the Python virtual environment needs to be recreated use...</p><pre><code>source .venv/bin/activate &amp;&amp; pip3 install -r python-requirements.txt\n</code></pre><h2 id=\"deployment-via-digitalocean\">Deployment via DigitalOcean</h2><p>In order to deploy this <code>starter</code> static app on <em>DigitalOcean</em> I had to PERMANENTLY move all of my Python components (<code>.py</code> scripts and <code>requirements.txt</code>) to a <code>.python</code> directory to hide it from view during app creation. Before moving these elements <em>DigitalOcean</em> would consistently try to deploy my app as Python, and that's not right.</p><p>See <em>DigitalOcean</em> ticket [#06849069] <code>Hugo static site with Python components builds fail</code> for details.</p><p>The response I received from <em>DigitalOcean</em>...</p><blockquote>Hello,</blockquote><blockquote>Thanks for contacting DigitalOcean.</blockquote><blockquote>We appreciate you reaching out to us about your Hugo static site. From what you mentioned it does sound like your app is getting detected as a python webservice rather then a static site due to the requirements.txt file you had in the root of your repo.</blockquote><blockquote>Unfortunately this is currently what App platform uses to detect applications as python apps. Either having a requirements.txt file or a setup.py file will cause that detection. Our engineers are looking into options to specify the build pack used rather then relying upon the auto detection, which would address this issue in your case, but don't have a timeline yet for implementing it.</blockquote><blockquote>In the mean time the work around that you have specified here should work fine for this. It should cause the app to be detected as a static site rather then python. Hopefully it isn't impacting anything else in your app's build process.</blockquote><blockquote>If you have any questions, please let us know.</blockquote><blockquote>Regards, Nate Senior Cloud Support Engineer Check out our community for great tutorials, articles and FAQs! digitalocean.com/community</blockquote><blockquote>ref:_00Df218t5m._5004P21l4JM:ref </blockquote><h3 id=\"remedy\">Remedy</h3><p>Based on the response above I'm making final changes to eliminate the <code>.python</code> folder, renaming <code>.python/requirements.txt</code> as <code>python-requirements.txt</code>, and pulling all other contents of <code>.python</code> into the root of the project.</p>",
            "comment_id": "64191c6e23ad590d103c063c",
            "plaintext": "What follows is the README.md file from my GitHub repo where https://blog.summittdweller.com is built. It outlines how to \"properly\" add Python to a project such that we can create an easily reproducible \"virtual environment\" without storing the necessary Python libraries in GitHub.\n\nFrom the README.md...\n\n\nblogs-SummittDweller\n\nThe Python portions of this repo were gleaned from https://github.com/SummittDweller/hikes. This was the repo for my https://blog.SummittDweller.com/ static website before I moved the blog to Ghost in 2023.\n\n\nLatest Python Improvements\n\nUsing guidance at https://predictivehacks.com/how-to-work-with-vs-code-and-virtual-environments-in-python/ I successfully created a new .venv virtual environment. The commands I used to do this were...\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º\nâ•°â”€$ python3 -m venv .venv\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º\nâ•°â”€$ source .venv/bin/activate\n\n\nNow the .venv is engaged and ready for some code so I added my Python code and turned my attention to each of the import statements within. Â Most of these import statements will require the installation of a module or package. Â For example, statements like import frontmatter and from datetime import datetime suggested that I needed to install the following:\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º\nâ•°â”€$ pip3 install python-frontmatter\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummitDweller â€¹main*â€º\nâ•°â”€$ pip3 install datetime\n\nNow, in order to \"freeze\" a copy of this module/package configuration to use later... Â \n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹mainâ€º \nâ•°â”€$ pip3 freeze > python-requirements.txt\n\n\nWhenever I want to re-install all of the modules/packages captured by the \"freeze\" command I do this:\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummittDweller â€¹main*â€º\nâ•°â”€$ pip3 install -r python-requirements.txt\n\n\nTo finish my setup in VSCode I used COMMAND-SHIFT-P to select and Python: Select interpreter to choose the new .venv Python. Â After that...\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummitDweller â€¹main*â€º\nâ•°â”€$ python3 consolidate.py --start 20220806 --end 20220825\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/blogs-SummitDweller â€¹main*â€º\nâ•°â”€$ hugo server\n\n\n\nRebuilding a Local Environment\n\nBased on guideance from https://stackoverflow.com/questions/6590688/is-it-bad-to-have-my-virtualenv-directory-inside-my-git-repository I've reconstructed this project such that Python artifacts do NOT propogate into Github.\n\nThe project should automatically \"rebuild\" as necessary when opened in VSCode, but if the Python virtual environment needs to be recreated use...\n\nsource .venv/bin/activate && pip3 install -r python-requirements.txt\n\n\n\nDeployment via DigitalOcean\n\nIn order to deploy this starter static app on DigitalOcean I had to PERMANENTLY move all of my Python components (.py scripts and requirements.txt) to a .python directory to hide it from view during app creation. Before moving these elements DigitalOcean would consistently try to deploy my app as Python, and that's not right.\n\nSee DigitalOcean ticket [#06849069] Hugo static site with Python components builds fail for details.\n\nThe response I received from DigitalOcean...\n\nHello,\n\nThanks for contacting DigitalOcean.\n\nWe appreciate you reaching out to us about your Hugo static site. From what you mentioned it does sound like your app is getting detected as a python webservice rather then a static site due to the requirements.txt file you had in the root of your repo.\n\nUnfortunately this is currently what App platform uses to detect applications as python apps. Either having a requirements.txt file or a setup.py file will cause that detection. Our engineers are looking into options to specify the build pack used rather then relying upon the auto detection, which would address this issue in your case, but don't have a timeline yet for implementing it.\n\nIn the mean time the work around that you have specified here should work fine for this. It should cause the app to be detected as a static site rather then python. Hopefully it isn't impacting anything else in your app's build process.\n\nIf you have any questions, please let us know.\n\nRegards, Nate Senior Cloud Support Engineer Check out our community for great tutorials, articles and FAQs! digitalocean.com/community\n\nref:_00Df218t5m._5004P21l4JM:ref\n\n\nRemedy\n\nBased on the response above I'm making final changes to eliminate the .python folder, renaming .python/requirements.txt as python-requirements.txt, and pulling all other contents of .python into the root of the project.",
            "feature_image": "https://images.unsplash.com/photo-1529978515127-dba8c80bbf05?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDQ4fHxweXRob258ZW58MHx8fHwxNjgwNzAwNTM2&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-03-21T02:54:38.000Z",
            "updated_at": "2023-07-24T18:35:05.000Z",
            "published_at": "2022-09-24T17:00:00.000Z",
            "custom_excerpt": "A new Python approach based on my `blog.summittdweller.com` site.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6419261f23ad590d103c0685",
            "uuid": "d5e4fc2a-ec72-4235-94e3-dbde64d3e69e",
            "title": "matomo-notes",
            "slug": "matomo-notes",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Last weekend Mackenzie and I created a new Matomo analytics server on a DigitalOcean droplet w/ 2G of RAM. The story of its development and maintenance is being told in Matomo Installation Notes and its dashboard is available at https://analytics.summittservices.com.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Toledo, IA\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Last weekend Mackenzie and I created a new Matomo analytics server on a DigitalOcean droplet w/ 2G of RAM. The story of its development and maintenance is being told in Matomo Installation Notes and its dashboard is available at <a href=\"https://analytics.summittservices.com\">https://analytics.summittservices.com</a>.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "6419261f23ad590d103c0685",
            "plaintext": "Last weekend Mackenzie and I created a new Matomo analytics server on a DigitalOcean droplet w/ 2G of RAM. The story of its development and maintenance is being told in Matomo Installation Notes and its dashboard is available at https://analytics.summittservices.com.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-03-21T03:35:59.000Z",
            "updated_at": "2023-04-05T03:23:57.000Z",
            "published_at": "2023-03-17T13:16:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "641baef38e5f7604af103353",
            "uuid": "d8d8d458-a3d7-4889-8616-7136eb6bfd44",
            "title": "My Blog To-Do List",
            "slug": "my-blog-to-do-list",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Witness the birth of a new blog! Actually, a new version of a very old blog. There's still a lot of work to do.\\n\\nSo, here's my \\\"to-do\\\" list, as it pertains to this blog, along with possible sources of guidance and inspiration.\"}],[\"hr\",{}],[\"markdown\",{\"markdown\":\"#### Update social icons and links in the blog.\\nLose Twitter in favor of Mastodon, perhaps?  Again, see https://ghost.org/tutorials/add-social-media-icons/. <hr/>\"}],[\"markdown\",{\"markdown\":\"#### Add the `OneTab` content type.\\nMy old Hugo blog distinguished between a \\\"post\\\" and other types that I called \\\"micropost\\\" and \\\"onetab\\\".  Each type had its own unique metadata fields.  For example, each \\\"micropost\\\" had `location:` and detailed `published-date:` fields, but no `title:`.  See https://ghost.org/docs/themes/routing for possible guidance. \\n\\nSee my previous \\\"**Add `Micropost` and `OneTab` content types**\\\" as well as \\\"**Add `For Sale` and `OneTab` content types**\\\" solutions below for guidance.<hr/>\"}],[\"markdown\",{\"markdown\":\"#### Process new `.env` variables.\\nSome of this has already been implemented to achieve the site banner that you see on the home page. See https://www.11ty.dev/docs/data-js/#example-exposing-environment-variables for the guidance I used to pull that off. <hr/>\"}],[\"markdown\",{\"markdown\":\"\\n#### Add a photo gallery.\\nMaybe.  Another feature that my old Hugo blog supported, although I rarely kept it up-to-date.<hr/>\\n\"}],[\"markdown\",{\"markdown\":\"#### Implement my Hugo Timeline module.\\nMake an 11ty version of https://github.com/SummittDweller/hugo-timeline and implement it here. <hr/>\\n\\n\"}],[\"markdown\",{\"markdown\":\"#### Engage Disqus Comments.\\nAnother feature that my old Hugo blog had, and my [professional blog](https://static.grinnell.edu/dlad-blog) still uses.  Rinse and repeat.\"}],[\"hr\",{}],[\"markdown\",{\"markdown\":\"#### Pulling Too Much Data\\nToday (April 20, 2023) I received notice from _Mediacom_, my ISP, that I've used 75% of my monthly data allotment with about a week left in the term.  That's not a huge problem, but I've never come close to using even one-half of my data in any previous month.  I suspect this is due to all the massive image downloads taking place each time I build a dev copy of this blog.\\n\\nThe `yarn start` command that I use to build the `localhost` copy of this blog defines `ELEVENTY_ENV=dev`.  I'm going to see if I can use this environment setting to limit image downloads to the first ten in order to limit the \\\"dev\\\" download requirements.  If this works a switch of some kind might need to be defined so that I can override the limit as needed. \\n\\nâ˜‘ï¸ __Solved 20-Apr-2023__: This played out nicely, but rather than limited the number of images I simply limit the number of `posts` pulled by `.eleventy.js`.  The code looks like this now:\\n\\n```js\\n var environ = process.env.ELEVENTY_ENV;\\n console.log(\\\"ELEVENTY_ENV is: \\\", environ);\\n if (environ == \\\"dev\\\") {\\n   post_limit = 6;\\n } else {\\n   post_limit = 'all';\\n }\\n\\n collection = await api.posts\\n   .browse({\\n     filter: \\\"tag:-micropost\\\",\\n     include: \\\"tags,authors\\\",\\n     limit: post_limit\\n   })\\n...\\n```\\n\\n<hr/> \"}],[\"markdown\",{\"markdown\":\"\\n#### Implement robust site search.\\nJust like it says ^^^ there.  Using Lunr, [Pagefind](https://pagefind.app/), something else? \\n\\nâ˜‘ï¸ __Solved 20-Apr-2023__: This is done and I did indeed use [Pagefind](https://pagefind.app/) for the solution.  The details can be found elsewhere in this blog at [Searching for a Search Solution](__GHOST_URL__/glad-i-found-pagefind/) and also in this blog project's `README.md` file. <hr/> \"}],[\"markdown\",{\"markdown\":\"#### Add `For Sale` and `OneTab` content types.\\nMy old Hugo blog distinguished between a \\\"post\\\" and other types that I called \\\"micropost\\\" and \\\"onetab\\\".  Each type had its own unique metadata fields.  For example, each \\\"micropost\\\" had `location:` and detailed `published-date:` fields, but no `title:`.  See https://ghost.org/docs/themes/routing for possible guidance. \\n\\nSee my previous \\\"**Add `Micropost` and `OneTab` content types**\\\" solution below for guidance.\\n\\nâ˜‘ï¸ __Solved 6-Apr-2023__: Ok, the `micropost` and `for_sale` portions of this is done, and documented (somewhat) in https://github.com/SummittDweller/blog-eleventy-ghost/blob/main/README.md.  Note that in the end I introduced a new `for_sale` tag (note that it's all lowercase to set it apart from others) after trying to use other techniques.\\n\\nI'm pushing the addtion of a `onetab` content type back up into this list, again.\\n<hr/>\"}],[\"markdown\",{\"markdown\":\"#### Improve Front Matter Processing\\n\\nThis effort will make a significant change to the solution shown in \\\"**Add and process post front matter**\\\" below.  Specifically, I'm going to move the \\\"front matter\\\" for all content types out of the `excerpt`, because it's difficult/impossible to edit excerpts in my iPhone's _Ghost Publisher_ software, and put it at the bottom of the content body with a `---` seperator marking the start of the data.  It should look something like this example:\\n\\n```\\n---\\nlocation: Toledo, IA\\nprice: $50.00\\nnote: This is just a note.\\n```\\n\\nBasically, anything found at the bottom of a post, of any TYPE, below a `---` delimiter, becomes a key:value pair available in `post.data.<key>`. \\n\\nâ˜‘ï¸ __Solved 5-Apr-2023__: This is done but not as originally planned, and it may still need some work.  So, in the end I introduced a new `for_sale` tag (note that like `micropost` it's all lowercase to set it apart from others) after trying to use other techniques.  \\n\\nMy new \\\"rear matter\\\" solution, detailed in the project's `README.md` file, actually uses a `dash-slash-dash` delimiter at the bottom of the content body, immediately followed by a `slash-dash-slash` delimiter... all run together in 6 characters, no spaces.\\n\\nThe first delimiter marks the end of the content, while the second one marks the start of the \\\"rear matter\\\".  I can't show you explicitly how that works here because putting those characters into a post like this will cause errant processing on this post. ðŸ™ƒ\\n<hr/>\"}],[\"markdown\",{\"markdown\":\"#### Add `Micropost` and `OneTab` content types.\\nMy old Hugo blog distinguished between a \\\"post\\\" and other types that I called \\\"micropost\\\" and \\\"onetab\\\".  Each type had its own unique metadata fields.  For example, each \\\"micropost\\\" had `location:` and detailed `published-date:` fields, but no `title:`.  See https://ghost.org/docs/themes/routing for possible guidance. \\n\\nâ˜‘ï¸ __Solved 2-Apr-2023__: Ok, the `micropost` portion of this is done, and it's documented (somewhat) in https://github.com/SummittDweller/blog-eleventy-ghost/blob/main/README.md.  Note that in the end I introduced a new `micropost` tag (note that it's all lowercase to set it apart from others) after trying to use other techniques like bits of `excerpt` and internal tags like `#micropost`.  \\n\\nI'm pushing the addtion of a `onetab` content type back up into this list, and will add a new `for-sale` tag and type to the mix.\\n<hr/>\"}],[\"markdown\",{\"markdown\":\"\\n#### Support better bulk ingest of content.\\nI have a lot of old blog posts to enter here, and research tells me that capability might be lacking.  Perhaps I can construct something using https://ghost.org/docs/admin-api/javascript/ or provide an update of https://github.com/dumrauf/post2ghost that works with the newest Ghost API? \\n\\nâ˜‘ï¸ __Solved 2-Apr-2023__: Well, I got this done after several failures.  Ultimately look to https://github.com/SummittDweller/migrate-hugo-to-ghost and more recently, https://github.com/SummittDweller/migrate-html-to-ghost for my solution. <hr/>  \"}],[\"markdown\",{\"markdown\":\"#### Investigate using \\\"special control\\\" tags.\\nControl Ghost and Eleventy behavior using tags that with @, #, or some other special character.  For example: `#Micropost`, or `$Micropost`.\\n\\nðŸš« __CANCELED 26-Mar-2023__: Now that front matter via the `excerpt` is working, I don't think this will be necessary. <hr/>\"}],[\"markdown\",{\"markdown\":\"#### Add FontAwesome support for emoji.\\nI really miss those from my Hugo days, and they would be so handy to have for things like checking items off this list!  See https://ghost.org/tutorials/add-social-media-icons/ for guidance.  \\n\\nLooks like this is already avaialble in 11ty, https://www.npmjs.com/package/@vidhill/fortawesome-free-regular-11ty-shortcode, but can I code a shortcode call in Ghost and pass it through?  I'll bet not... NOPE. \\n\\nâ˜‘ï¸ __Solved 26-Mar-2023__: This turned out to be a bit of a gut ðŸ¥Š.  So, I've scrapped the idea in favor of just using `CTRL - COMMAND - SPACE` on my Mac.<hr/>\"}],[\"markdown\",{\"markdown\":\"\\n\\n#### Add and process post front matter.\\nSee https://forum.ghost.org/t/custom-data-fields/8884/4 and https://github.com/nchaulet/ghost-app-frontmatter.  Maybe this old project can be resurected and implemented here so that posts, and other types, can have robust \\\"front matter\\\" with custom display.\\n\\nâ˜‘ï¸ __Solved 26-Mar-2023__: Following the logic of the `parseFrontMatter` function in https://github.com/nchaulet/ghost-app-frontmatter/blob/master/index.js, I added the following code to `.eleventy.js`.\\n\\n```js\\n// Add front matter processing of Ghost posts here, \\n// pulling data from the `post.excerpt`\\n// Note that pulling from `post.codeinjection_head` and\\n// `post.custom_excerpt` did NOT work!\\n      \\n// console.log(post);\\n// console.log(\\\"Before:\\\", post.excerpt);\\nvar parsed = matter(post.excerpt, { delims: ['---', '---'] });\\npost.data = parsed.data;\\nvar removed = post.excerpt.replace(/---[\\\\S\\\\s]*---/m, '');\\npost.excerpt = removed;\\n\\n// console.log(\\\"After:\\\", post.excerpt);\\n// console.log(\\\"Data:\\\", post.data);\\n``` \\n\\nIt looks for typical `---` delimiters in the `excerpt` portion of a post and parses it into `data.<element>` key:value pairs that are available to my templates.<hr/>\\n\"}],[\"markdown\",{\"markdown\":\"#### Display `publication` and `last-mod` dates.\\nJust what the title says. Displaying these things was something my old Hugo blog always did. \\n\\nâ˜‘ï¸ __Solved 26-Mar-2023__: Another easy addition in `src/_includes/partials/card.njk` where the Nunjucks now checks for matching `published_at` and `updated_at` dates, and reports \\\"Published\\\" if they match, or \\\"Updated\\\" if they don't. Also, `microposts` now show differnt data, including `location:` and the publication date AND time. <hr/> \"}],[\"markdown\",{\"markdown\":\"#### Improve the display of `tags`.\\nMaybe seperate tags using `&middot;` symbols &middot; like &middot; this?  Perhaps have a look at https://ghost.org/docs/themes/helpers/tags/.\\n\\nâ˜‘ï¸ __Solved 25-Mar-2023__: An easy addition in `src/_includes/partials/card.njk` where the Nunjucks now looks like this: \\n\\n```\\n<div class=\\\"post-card-tags\\\">\\n  {% if post.tags %}\\n    {% for tag in post.tags %}\\n      {{ tag.name }} {% if not loop.last %} &middot; {% endif %}\\n    {% endfor %}\\n  {% endif %}\\n</div>\\n```\\n<hr/>\"}],[\"markdown\",{\"markdown\":\"#### Rebuild and deploy the site when content is published.\\nThe site already builds and auto-deploys when changes are pushed to the code/structure, but the forerunner of this site also included a hook that did a build and deploy (per Netlify) when changes to the Ghost content are published. See https://github.com/TryGhost/eleventy-starter-ghost for possible guidance. \\n\\nBetter yet, check out https://docs.digitalocean.com/reference/api/api-reference/#operation/apps_create_deployment.  It seems the mechanism that's required here is to make a request, like a `curl` or `POST`, to a particular URL (see sample below) perhaps with an auth token included for security.  \\n\\n```\\ncurl -X POST \\\\\\n  -H \\\"Content-Type: application/json\\\" \\\\\\n  -H \\\"Authorization: Bearer $DIGITALOCEAN_TOKEN\\\" \\\\\\n  \\\"https://api.digitalocean.com/v2/apps/{app_id}/deployments\\\"\\n```\\n\\nNow, the question is, how to make my Ghost install dispatch such a request?  Simple, see https://ghost.org/docs/webhooks/ but note that the request might need to be a `POST`, not a `curl`.  \\n\\nHmmm, this is more difficult than I imagined, so this write-up might soon become a post of its own! \\n\\n#### Preliminary Findings\\n\\nUnfortunately, it looks like Ghost's webhooks don't integrate well with DigitalOcean.  DO requires a `POST` request that looks like this in `curl` form:\\n\\n```\\ncurl -X POST \\\\\\n  -H \\\"Content-Type: application/json\\\" \\\\\\n  -H \\\"Authorization: Bearer { $DIGITALOCEAN_TOKEN }\\\" \\\\\\n  -d '{ \\\"force_build\\\":true }' \\\\\\n  \\\"https://api.digitalocean.com/v2/apps/{ app ID }/deployments\\\"\\n```\\n\\nI can't find a way to build such a request in Ghost since the headers and  body of the webhooks it builds don't look like what you see above. The only thing that can be easily configured in a Ghost webhook is the destination address. So, now I'm going to look into the possibility of using an iOS or MacOS app that triggers a `curl` like the one you see above. Or, maybe I can add a protected page to the site itself and embed a Javascript `POST` request within? \\n\\nâ˜‘ï¸ __Solved 23-Mar-2023__: Please see [Built by Webhook + Password Protection](https://blog.summittdweller.com/built-by-webhook-password-protection/) for all the gory details.\\n<hr/>\\n\"}],[\"markdown\",{\"markdown\":\"#### Force rebuild with \\\"Trigger Site Update\\\" draft.\\nThe idea here is to delay rebuilding the site until triggered by an editor, perhaps using a \\\"special\\\" trigger post.  This could help avoid multipe back-to-back rebuilds when lots of content is updated in a short period of time. Of course, if a \\\"special\\\" post were used for this it would have to be implicitly \\\"ignored\\\" and always in a \\\"draft\\\" state.\\n\\nðŸš« __CANCELED 23-Mar-2023__: No longer needed. Please see [Built by Webhook + Password Protection](https://blog.summittdweller.com/built-by-webhook-password-protection/) for all the gory details.\\n<hr/>\\n\"}],[\"markdown\",{\"markdown\":\"#### Engage spell checking.\\nIndications from as early as 2015 indicate that this should work straight from the browser, but I'm not so sure? \\n\\nâ˜‘ï¸ __Solved 23-Mar-2023__: Just toggle the little `abc-checkmark` icon down in the lower right corner of the editor window. Also, the `question-mark` icon down there is helpful too!  <hr/>\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[10,3],[10,4],[10,5],[10,6],[10,7],[10,8],[1,\"h2\",[[0,[],0,\"Everything below this line is DONE!  For now.\"]]],[10,9],[10,10],[10,11],[10,12],[10,13],[10,14],[10,15],[10,16],[10,17],[10,18],[10,19],[10,20],[10,21],[10,22],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Witness the birth of a new blog! Actually, a new version of a very old blog. There's still a lot of work to do.</p>\n<p>So, here's my &quot;to-do&quot; list, as it pertains to this blog, along with possible sources of guidance and inspiration.</p>\n<!--kg-card-end: markdown--><hr><!--kg-card-begin: markdown--><h4 id=\"update-social-icons-and-links-in-the-blog\">Update social icons and links in the blog.</h4>\n<p>Lose Twitter in favor of Mastodon, perhaps?  Again, see <a href=\"https://ghost.org/tutorials/add-social-media-icons/\">https://ghost.org/tutorials/add-social-media-icons/</a>. <hr/></p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"add-the-onetab-content-type\">Add the <code>OneTab</code> content type.</h4>\n<p>My old Hugo blog distinguished between a &quot;post&quot; and other types that I called &quot;micropost&quot; and &quot;onetab&quot;.  Each type had its own unique metadata fields.  For example, each &quot;micropost&quot; had <code>location:</code> and detailed <code>published-date:</code> fields, but no <code>title:</code>.  See <a href=\"https://ghost.org/docs/themes/routing\">https://ghost.org/docs/themes/routing</a> for possible guidance.</p>\n<p>See my previous &quot;<strong>Add <code>Micropost</code> and <code>OneTab</code> content types</strong>&quot; as well as &quot;<strong>Add <code>For Sale</code> and <code>OneTab</code> content types</strong>&quot; solutions below for guidance.<hr/></p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"process-new-env-variables\">Process new <code>.env</code> variables.</h4>\n<p>Some of this has already been implemented to achieve the site banner that you see on the home page. See <a href=\"https://www.11ty.dev/docs/data-js/#example-exposing-environment-variables\">https://www.11ty.dev/docs/data-js/#example-exposing-environment-variables</a> for the guidance I used to pull that off. <hr/></p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"add-a-photo-gallery\">Add a photo gallery.</h4>\n<p>Maybe.  Another feature that my old Hugo blog supported, although I rarely kept it up-to-date.<hr/></p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"implement-my-hugo-timeline-module\">Implement my Hugo Timeline module.</h4>\n<p>Make an 11ty version of <a href=\"https://github.com/SummittDweller/hugo-timeline\">https://github.com/SummittDweller/hugo-timeline</a> and implement it here. <hr/></p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"engage-disqus-comments\">Engage Disqus Comments.</h4>\n<p>Another feature that my old Hugo blog had, and my <a href=\"https://static.grinnell.edu/dlad-blog\">professional blog</a> still uses.  Rinse and repeat.</p>\n<!--kg-card-end: markdown--><hr><h2 id=\"everything-below-this-line-is-done-for-now\">Everything below this line is DONE! Â For now.</h2><!--kg-card-begin: markdown--><h4 id=\"pulling-too-much-data\">Pulling Too Much Data</h4>\n<p>Today (April 20, 2023) I received notice from <em>Mediacom</em>, my ISP, that I've used 75% of my monthly data allotment with about a week left in the term.  That's not a huge problem, but I've never come close to using even one-half of my data in any previous month.  I suspect this is due to all the massive image downloads taking place each time I build a dev copy of this blog.</p>\n<p>The <code>yarn start</code> command that I use to build the <code>localhost</code> copy of this blog defines <code>ELEVENTY_ENV=dev</code>.  I'm going to see if I can use this environment setting to limit image downloads to the first ten in order to limit the &quot;dev&quot; download requirements.  If this works a switch of some kind might need to be defined so that I can override the limit as needed.</p>\n<p>â˜‘ï¸ <strong>Solved 20-Apr-2023</strong>: This played out nicely, but rather than limited the number of images I simply limit the number of <code>posts</code> pulled by <code>.eleventy.js</code>.  The code looks like this now:</p>\n<pre><code class=\"language-js\"> var environ = process.env.ELEVENTY_ENV;\n console.log(&quot;ELEVENTY_ENV is: &quot;, environ);\n if (environ == &quot;dev&quot;) {\n   post_limit = 6;\n } else {\n   post_limit = 'all';\n }\n\n collection = await api.posts\n   .browse({\n     filter: &quot;tag:-micropost&quot;,\n     include: &quot;tags,authors&quot;,\n     limit: post_limit\n   })\n...\n</code></pre>\n<hr/> <!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"implement-robust-site-search\">Implement robust site search.</h4>\n<p>Just like it says ^^^ there.  Using Lunr, <a href=\"https://pagefind.app/\">Pagefind</a>, something else?</p>\n<p>â˜‘ï¸ <strong>Solved 20-Apr-2023</strong>: This is done and I did indeed use <a href=\"https://pagefind.app/\">Pagefind</a> for the solution.  The details can be found elsewhere in this blog at <a href=\"__GHOST_URL__/glad-i-found-pagefind/\">Searching for a Search Solution</a> and also in this blog project's <code>README.md</code> file. <hr/></p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"add-for-sale-and-onetab-content-types\">Add <code>For Sale</code> and <code>OneTab</code> content types.</h4>\n<p>My old Hugo blog distinguished between a &quot;post&quot; and other types that I called &quot;micropost&quot; and &quot;onetab&quot;.  Each type had its own unique metadata fields.  For example, each &quot;micropost&quot; had <code>location:</code> and detailed <code>published-date:</code> fields, but no <code>title:</code>.  See <a href=\"https://ghost.org/docs/themes/routing\">https://ghost.org/docs/themes/routing</a> for possible guidance.</p>\n<p>See my previous &quot;<strong>Add <code>Micropost</code> and <code>OneTab</code> content types</strong>&quot; solution below for guidance.</p>\n<p>â˜‘ï¸ <strong>Solved 6-Apr-2023</strong>: Ok, the <code>micropost</code> and <code>for_sale</code> portions of this is done, and documented (somewhat) in <a href=\"https://github.com/SummittDweller/blog-eleventy-ghost/blob/main/README.md\">https://github.com/SummittDweller/blog-eleventy-ghost/blob/main/README.md</a>.  Note that in the end I introduced a new <code>for_sale</code> tag (note that it's all lowercase to set it apart from others) after trying to use other techniques.</p>\n<p>I'm pushing the addtion of a <code>onetab</code> content type back up into this list, again.</p>\n<hr/><!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"improve-front-matter-processing\">Improve Front Matter Processing</h4>\n<p>This effort will make a significant change to the solution shown in &quot;<strong>Add and process post front matter</strong>&quot; below.  Specifically, I'm going to move the &quot;front matter&quot; for all content types out of the <code>excerpt</code>, because it's difficult/impossible to edit excerpts in my iPhone's <em>Ghost Publisher</em> software, and put it at the bottom of the content body with a <code>---</code> seperator marking the start of the data.  It should look something like this example:</p>\n<pre><code>---\nlocation: Toledo, IA\nprice: $50.00\nnote: This is just a note.\n</code></pre>\n<p>Basically, anything found at the bottom of a post, of any TYPE, below a <code>---</code> delimiter, becomes a key:value pair available in <code>post.data.&lt;key&gt;</code>.</p>\n<p>â˜‘ï¸ <strong>Solved 5-Apr-2023</strong>: This is done but not as originally planned, and it may still need some work.  So, in the end I introduced a new <code>for_sale</code> tag (note that like <code>micropost</code> it's all lowercase to set it apart from others) after trying to use other techniques.</p>\n<p>My new &quot;rear matter&quot; solution, detailed in the project's <code>README.md</code> file, actually uses a <code>dash-slash-dash</code> delimiter at the bottom of the content body, immediately followed by a <code>slash-dash-slash</code> delimiter... all run together in 6 characters, no spaces.</p>\n<p>The first delimiter marks the end of the content, while the second one marks the start of the &quot;rear matter&quot;.  I can't show you explicitly how that works here because putting those characters into a post like this will cause errant processing on this post. ðŸ™ƒ</p>\n<hr/><!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"add-micropost-and-onetab-content-types\">Add <code>Micropost</code> and <code>OneTab</code> content types.</h4>\n<p>My old Hugo blog distinguished between a &quot;post&quot; and other types that I called &quot;micropost&quot; and &quot;onetab&quot;.  Each type had its own unique metadata fields.  For example, each &quot;micropost&quot; had <code>location:</code> and detailed <code>published-date:</code> fields, but no <code>title:</code>.  See <a href=\"https://ghost.org/docs/themes/routing\">https://ghost.org/docs/themes/routing</a> for possible guidance.</p>\n<p>â˜‘ï¸ <strong>Solved 2-Apr-2023</strong>: Ok, the <code>micropost</code> portion of this is done, and it's documented (somewhat) in <a href=\"https://github.com/SummittDweller/blog-eleventy-ghost/blob/main/README.md\">https://github.com/SummittDweller/blog-eleventy-ghost/blob/main/README.md</a>.  Note that in the end I introduced a new <code>micropost</code> tag (note that it's all lowercase to set it apart from others) after trying to use other techniques like bits of <code>excerpt</code> and internal tags like <code>#micropost</code>.</p>\n<p>I'm pushing the addtion of a <code>onetab</code> content type back up into this list, and will add a new <code>for-sale</code> tag and type to the mix.</p>\n<hr/><!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"support-better-bulk-ingest-of-content\">Support better bulk ingest of content.</h4>\n<p>I have a lot of old blog posts to enter here, and research tells me that capability might be lacking.  Perhaps I can construct something using <a href=\"https://ghost.org/docs/admin-api/javascript/\">https://ghost.org/docs/admin-api/javascript/</a> or provide an update of <a href=\"https://github.com/dumrauf/post2ghost\">https://github.com/dumrauf/post2ghost</a> that works with the newest Ghost API?</p>\n<p>â˜‘ï¸ <strong>Solved 2-Apr-2023</strong>: Well, I got this done after several failures.  Ultimately look to <a href=\"https://github.com/SummittDweller/migrate-hugo-to-ghost\">https://github.com/SummittDweller/migrate-hugo-to-ghost</a> and more recently, <a href=\"https://github.com/SummittDweller/migrate-html-to-ghost\">https://github.com/SummittDweller/migrate-html-to-ghost</a> for my solution. <hr/></p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"investigate-using-special-control-tags\">Investigate using &quot;special control&quot; tags.</h4>\n<p>Control Ghost and Eleventy behavior using tags that with @, #, or some other special character.  For example: <code>#Micropost</code>, or <code>$Micropost</code>.</p>\n<p>ðŸš« <strong>CANCELED 26-Mar-2023</strong>: Now that front matter via the <code>excerpt</code> is working, I don't think this will be necessary. <hr/></p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"add-fontawesome-support-for-emoji\">Add FontAwesome support for emoji.</h4>\n<p>I really miss those from my Hugo days, and they would be so handy to have for things like checking items off this list!  See <a href=\"https://ghost.org/tutorials/add-social-media-icons/\">https://ghost.org/tutorials/add-social-media-icons/</a> for guidance.</p>\n<p>Looks like this is already avaialble in 11ty, <a href=\"https://www.npmjs.com/package/@vidhill/fortawesome-free-regular-11ty-shortcode\">https://www.npmjs.com/package/@vidhill/fortawesome-free-regular-11ty-shortcode</a>, but can I code a shortcode call in Ghost and pass it through?  I'll bet not... NOPE.</p>\n<p>â˜‘ï¸ <strong>Solved 26-Mar-2023</strong>: This turned out to be a bit of a gut ðŸ¥Š.  So, I've scrapped the idea in favor of just using <code>CTRL - COMMAND - SPACE</code> on my Mac.<hr/></p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"add-and-process-post-front-matter\">Add and process post front matter.</h4>\n<p>See <a href=\"https://forum.ghost.org/t/custom-data-fields/8884/4\">https://forum.ghost.org/t/custom-data-fields/8884/4</a> and <a href=\"https://github.com/nchaulet/ghost-app-frontmatter\">https://github.com/nchaulet/ghost-app-frontmatter</a>.  Maybe this old project can be resurected and implemented here so that posts, and other types, can have robust &quot;front matter&quot; with custom display.</p>\n<p>â˜‘ï¸ <strong>Solved 26-Mar-2023</strong>: Following the logic of the <code>parseFrontMatter</code> function in <a href=\"https://github.com/nchaulet/ghost-app-frontmatter/blob/master/index.js\">https://github.com/nchaulet/ghost-app-frontmatter/blob/master/index.js</a>, I added the following code to <code>.eleventy.js</code>.</p>\n<pre><code class=\"language-js\">// Add front matter processing of Ghost posts here, \n// pulling data from the `post.excerpt`\n// Note that pulling from `post.codeinjection_head` and\n// `post.custom_excerpt` did NOT work!\n      \n// console.log(post);\n// console.log(&quot;Before:&quot;, post.excerpt);\nvar parsed = matter(post.excerpt, { delims: ['---', '---'] });\npost.data = parsed.data;\nvar removed = post.excerpt.replace(/---[\\S\\s]*---/m, '');\npost.excerpt = removed;\n\n// console.log(&quot;After:&quot;, post.excerpt);\n// console.log(&quot;Data:&quot;, post.data);\n</code></pre>\n<p>It looks for typical <code>---</code> delimiters in the <code>excerpt</code> portion of a post and parses it into <code>data.&lt;element&gt;</code> key:value pairs that are available to my templates.<hr/></p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"display-publication-and-last-mod-dates\">Display <code>publication</code> and <code>last-mod</code> dates.</h4>\n<p>Just what the title says. Displaying these things was something my old Hugo blog always did.</p>\n<p>â˜‘ï¸ <strong>Solved 26-Mar-2023</strong>: Another easy addition in <code>src/_includes/partials/card.njk</code> where the Nunjucks now checks for matching <code>published_at</code> and <code>updated_at</code> dates, and reports &quot;Published&quot; if they match, or &quot;Updated&quot; if they don't. Also, <code>microposts</code> now show differnt data, including <code>location:</code> and the publication date AND time. <hr/></p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"improve-the-display-of-tags\">Improve the display of <code>tags</code>.</h4>\n<p>Maybe seperate tags using <code>&amp;middot;</code> symbols Â· like Â· this?  Perhaps have a look at <a href=\"https://ghost.org/docs/themes/helpers/tags/\">https://ghost.org/docs/themes/helpers/tags/</a>.</p>\n<p>â˜‘ï¸ <strong>Solved 25-Mar-2023</strong>: An easy addition in <code>src/_includes/partials/card.njk</code> where the Nunjucks now looks like this:</p>\n<pre><code>&lt;div class=&quot;post-card-tags&quot;&gt;\n  {% if post.tags %}\n    {% for tag in post.tags %}\n      {{ tag.name }} {% if not loop.last %} &amp;middot; {% endif %}\n    {% endfor %}\n  {% endif %}\n&lt;/div&gt;\n</code></pre>\n<hr/><!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"rebuild-and-deploy-the-site-when-content-is-published\">Rebuild and deploy the site when content is published.</h4>\n<p>The site already builds and auto-deploys when changes are pushed to the code/structure, but the forerunner of this site also included a hook that did a build and deploy (per Netlify) when changes to the Ghost content are published. See <a href=\"https://github.com/TryGhost/eleventy-starter-ghost\">https://github.com/TryGhost/eleventy-starter-ghost</a> for possible guidance.</p>\n<p>Better yet, check out <a href=\"https://docs.digitalocean.com/reference/api/api-reference/#operation/apps_create_deployment\">https://docs.digitalocean.com/reference/api/api-reference/#operation/apps_create_deployment</a>.  It seems the mechanism that's required here is to make a request, like a <code>curl</code> or <code>POST</code>, to a particular URL (see sample below) perhaps with an auth token included for security.</p>\n<pre><code>curl -X POST \\\n  -H &quot;Content-Type: application/json&quot; \\\n  -H &quot;Authorization: Bearer $DIGITALOCEAN_TOKEN&quot; \\\n  &quot;https://api.digitalocean.com/v2/apps/{app_id}/deployments&quot;\n</code></pre>\n<p>Now, the question is, how to make my Ghost install dispatch such a request?  Simple, see <a href=\"https://ghost.org/docs/webhooks/\">https://ghost.org/docs/webhooks/</a> but note that the request might need to be a <code>POST</code>, not a <code>curl</code>.</p>\n<p>Hmmm, this is more difficult than I imagined, so this write-up might soon become a post of its own!</p>\n<h4 id=\"preliminary-findings\">Preliminary Findings</h4>\n<p>Unfortunately, it looks like Ghost's webhooks don't integrate well with DigitalOcean.  DO requires a <code>POST</code> request that looks like this in <code>curl</code> form:</p>\n<pre><code>curl -X POST \\\n  -H &quot;Content-Type: application/json&quot; \\\n  -H &quot;Authorization: Bearer { $DIGITALOCEAN_TOKEN }&quot; \\\n  -d '{ &quot;force_build&quot;:true }' \\\n  &quot;https://api.digitalocean.com/v2/apps/{ app ID }/deployments&quot;\n</code></pre>\n<p>I can't find a way to build such a request in Ghost since the headers and  body of the webhooks it builds don't look like what you see above. The only thing that can be easily configured in a Ghost webhook is the destination address. So, now I'm going to look into the possibility of using an iOS or MacOS app that triggers a <code>curl</code> like the one you see above. Or, maybe I can add a protected page to the site itself and embed a Javascript <code>POST</code> request within?</p>\n<p>â˜‘ï¸ <strong>Solved 23-Mar-2023</strong>: Please see <a href=\"https://blog.summittdweller.com/built-by-webhook-password-protection/\">Built by Webhook + Password Protection</a> for all the gory details.</p>\n<hr/>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"force-rebuild-with-trigger-site-update-draft\">Force rebuild with &quot;Trigger Site Update&quot; draft.</h4>\n<p>The idea here is to delay rebuilding the site until triggered by an editor, perhaps using a &quot;special&quot; trigger post.  This could help avoid multipe back-to-back rebuilds when lots of content is updated in a short period of time. Of course, if a &quot;special&quot; post were used for this it would have to be implicitly &quot;ignored&quot; and always in a &quot;draft&quot; state.</p>\n<p>ðŸš« <strong>CANCELED 23-Mar-2023</strong>: No longer needed. Please see <a href=\"https://blog.summittdweller.com/built-by-webhook-password-protection/\">Built by Webhook + Password Protection</a> for all the gory details.</p>\n<hr/>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h4 id=\"engage-spell-checking\">Engage spell checking.</h4>\n<p>Indications from as early as 2015 indicate that this should work straight from the browser, but I'm not so sure?</p>\n<p>â˜‘ï¸ <strong>Solved 23-Mar-2023</strong>: Just toggle the little <code>abc-checkmark</code> icon down in the lower right corner of the editor window. Also, the <code>question-mark</code> icon down there is helpful too!  <hr/></p>\n<!--kg-card-end: markdown-->",
            "comment_id": "641baef38e5f7604af103353",
            "plaintext": "Witness the birth of a new blog! Actually, a new version of a very old blog. There's still a lot of work to do.\n\n\nSo, here's my \"to-do\" list, as it pertains to this blog, along with possible sources of guidance and inspiration.\n\n\nUpdate social icons and links in the blog.\n\n\nLose Twitter in favor of Mastodon, perhaps? Again, see https://ghost.org/tutorials/add-social-media-icons/.\n\n\n\n\nAdd the OneTab content type.\n\n\nMy old Hugo blog distinguished between a \"post\" and other types that I called \"micropost\" and \"onetab\". Each type had its own unique metadata fields. For example, each \"micropost\" had location: and detailed published-date: fields, but no title:. See https://ghost.org/docs/themes/routing for possible guidance.\n\n\nSee my previous \"Add Micropost and OneTab content types\" as well as \"Add For Sale and OneTab content types\" solutions below for guidance.\n\n\n\n\nProcess new .env variables.\n\n\nSome of this has already been implemented to achieve the site banner that you see on the home page. See https://www.11ty.dev/docs/data-js/#example-exposing-environment-variables for the guidance I used to pull that off.\n\n\n\n\nAdd a photo gallery.\n\n\nMaybe. Another feature that my old Hugo blog supported, although I rarely kept it up-to-date.\n\n\n\n\nImplement my Hugo Timeline module.\n\n\nMake an 11ty version of https://github.com/SummittDweller/hugo-timeline and implement it here.\n\n\n\n\nEngage Disqus Comments.\n\n\nAnother feature that my old Hugo blog had, and my professional blog still uses. Rinse and repeat.\n\n\n\nEverything below this line is DONE! Â For now.\n\nPulling Too Much Data\n\n\nToday (April 20, 2023) I received notice from Mediacom, my ISP, that I've used 75% of my monthly data allotment with about a week left in the term. That's not a huge problem, but I've never come close to using even one-half of my data in any previous month. I suspect this is due to all the massive image downloads taking place each time I build a dev copy of this blog.\n\n\nThe yarn start command that I use to build the localhost copy of this blog defines ELEVENTY_ENV=dev. I'm going to see if I can use this environment setting to limit image downloads to the first ten in order to limit the \"dev\" download requirements. If this works a switch of some kind might need to be defined so that I can override the limit as needed.\n\n\nâ˜‘ï¸ Solved 20-Apr-2023: This played out nicely, but rather than limited the number of images I simply limit the number of posts pulled by .eleventy.js. The code looks like this now:\n\n\n var environ = process.env.ELEVENTY_ENV;\n console.log(\"ELEVENTY_ENV is: \", environ);\n if (environ == \"dev\") {\n   post_limit = 6;\n } else {\n   post_limit = 'all';\n }\n\n collection = await api.posts\n   .browse({\n     filter: \"tag:-micropost\",\n     include: \"tags,authors\",\n     limit: post_limit\n   })\n...\n\n\n\nImplement robust site search.\n\n\nJust like it says ^^^ there. Using Lunr, Pagefind, something else?\n\n\nâ˜‘ï¸ Solved 20-Apr-2023: This is done and I did indeed use Pagefind for the solution. The details can be found elsewhere in this blog at Searching for a Search Solution and also in this blog project's README.md file.\n\n\n\n\nAdd For Sale and OneTab content types.\n\n\nMy old Hugo blog distinguished between a \"post\" and other types that I called \"micropost\" and \"onetab\". Each type had its own unique metadata fields. For example, each \"micropost\" had location: and detailed published-date: fields, but no title:. See https://ghost.org/docs/themes/routing for possible guidance.\n\n\nSee my previous \"Add Micropost and OneTab content types\" solution below for guidance.\n\n\nâ˜‘ï¸ Solved 6-Apr-2023: Ok, the micropost and for_sale portions of this is done, and documented (somewhat) in https://github.com/SummittDweller/blog-eleventy-ghost/blob/main/README.md. Note that in the end I introduced a new for_sale tag (note that it's all lowercase to set it apart from others) after trying to use other techniques.\n\n\nI'm pushing the addtion of a onetab content type back up into this list, again.\n\n\nImprove Front Matter Processing\n\n\nThis effort will make a significant change to the solution shown in \"Add and process post front matter\" below. Specifically, I'm going to move the \"front matter\" for all content types out of the excerpt, because it's difficult/impossible to edit excerpts in my iPhone's Ghost Publisher software, and put it at the bottom of the content body with a --- seperator marking the start of the data. It should look something like this example:\n\n\n---\nlocation: Toledo, IA\nprice: $50.00\nnote: This is just a note.\n\n\n\nBasically, anything found at the bottom of a post, of any TYPE, below a --- delimiter, becomes a key:value pair available in post.data.<key>.\n\n\nâ˜‘ï¸ Solved 5-Apr-2023: This is done but not as originally planned, and it may still need some work. So, in the end I introduced a new for_sale tag (note that like micropost it's all lowercase to set it apart from others) after trying to use other techniques.\n\n\nMy new \"rear matter\" solution, detailed in the project's README.md file, actually uses a dash-slash-dash delimiter at the bottom of the content body, immediately followed by a slash-dash-slash delimiter... all run together in 6 characters, no spaces.\n\n\nThe first delimiter marks the end of the content, while the second one marks the start of the \"rear matter\". I can't show you explicitly how that works here because putting those characters into a post like this will cause errant processing on this post. ðŸ™ƒ\n\n\nAdd Micropost and OneTab content types.\n\n\nMy old Hugo blog distinguished between a \"post\" and other types that I called \"micropost\" and \"onetab\". Each type had its own unique metadata fields. For example, each \"micropost\" had location: and detailed published-date: fields, but no title:. See https://ghost.org/docs/themes/routing for possible guidance.\n\n\nâ˜‘ï¸ Solved 2-Apr-2023: Ok, the micropost portion of this is done, and it's documented (somewhat) in https://github.com/SummittDweller/blog-eleventy-ghost/blob/main/README.md. Note that in the end I introduced a new micropost tag (note that it's all lowercase to set it apart from others) after trying to use other techniques like bits of excerpt and internal tags like #micropost.\n\n\nI'm pushing the addtion of a onetab content type back up into this list, and will add a new for-sale tag and type to the mix.\n\n\nSupport better bulk ingest of content.\n\n\nI have a lot of old blog posts to enter here, and research tells me that capability might be lacking. Perhaps I can construct something using https://ghost.org/docs/admin-api/javascript/ or provide an update of https://github.com/dumrauf/post2ghost that works with the newest Ghost API?\n\n\nâ˜‘ï¸ Solved 2-Apr-2023: Well, I got this done after several failures. Ultimately look to https://github.com/SummittDweller/migrate-hugo-to-ghost and more recently, https://github.com/SummittDweller/migrate-html-to-ghost for my solution.\n\n\n\n\nInvestigate using \"special control\" tags.\n\n\nControl Ghost and Eleventy behavior using tags that with @, #, or some other special character. For example: #Micropost, or $Micropost.\n\n\nðŸš« CANCELED 26-Mar-2023: Now that front matter via the excerpt is working, I don't think this will be necessary.\n\n\n\n\nAdd FontAwesome support for emoji.\n\n\nI really miss those from my Hugo days, and they would be so handy to have for things like checking items off this list! See https://ghost.org/tutorials/add-social-media-icons/ for guidance.\n\n\nLooks like this is already avaialble in 11ty, https://www.npmjs.com/package/@vidhill/fortawesome-free-regular-11ty-shortcode, but can I code a shortcode call in Ghost and pass it through? I'll bet not... NOPE.\n\n\nâ˜‘ï¸ Solved 26-Mar-2023: This turned out to be a bit of a gut ðŸ¥Š. So, I've scrapped the idea in favor of just using CTRL - COMMAND - SPACE on my Mac.\n\n\n\n\nAdd and process post front matter.\n\n\nSee https://forum.ghost.org/t/custom-data-fields/8884/4 and https://github.com/nchaulet/ghost-app-frontmatter. Maybe this old project can be resurected and implemented here so that posts, and other types, can have robust \"front matter\" with custom display.\n\n\nâ˜‘ï¸ Solved 26-Mar-2023: Following the logic of the parseFrontMatter function in https://github.com/nchaulet/ghost-app-frontmatter/blob/master/index.js, I added the following code to .eleventy.js.\n\n\n// Add front matter processing of Ghost posts here, \n// pulling data from the `post.excerpt`\n// Note that pulling from `post.codeinjection_head` and\n// `post.custom_excerpt` did NOT work!\n      \n// console.log(post);\n// console.log(\"Before:\", post.excerpt);\nvar parsed = matter(post.excerpt, { delims: ['---', '---'] });\npost.data = parsed.data;\nvar removed = post.excerpt.replace(/---[\\S\\s]*---/m, '');\npost.excerpt = removed;\n\n// console.log(\"After:\", post.excerpt);\n// console.log(\"Data:\", post.data);\n\n\n\nIt looks for typical --- delimiters in the excerpt portion of a post and parses it into data.<element> key:value pairs that are available to my templates.\n\n\n\n\nDisplay publication and last-mod dates.\n\n\nJust what the title says. Displaying these things was something my old Hugo blog always did.\n\n\nâ˜‘ï¸ Solved 26-Mar-2023: Another easy addition in src/_includes/partials/card.njk where the Nunjucks now checks for matching published_at and updated_at dates, and reports \"Published\" if they match, or \"Updated\" if they don't. Also, microposts now show differnt data, including location: and the publication date AND time.\n\n\n\n\nImprove the display of tags.\n\n\nMaybe seperate tags using &middot; symbols Â· like Â· this? Perhaps have a look at https://ghost.org/docs/themes/helpers/tags/.\n\n\nâ˜‘ï¸ Solved 25-Mar-2023: An easy addition in src/_includes/partials/card.njk where the Nunjucks now looks like this:\n\n\n<div class=\"post-card-tags\">\n  {% if post.tags %}\n    {% for tag in post.tags %}\n      {{ tag.name }} {% if not loop.last %} &middot; {% endif %}\n    {% endfor %}\n  {% endif %}\n</div>\n\n\n\nRebuild and deploy the site when content is published.\n\n\nThe site already builds and auto-deploys when changes are pushed to the code/structure, but the forerunner of this site also included a hook that did a build and deploy (per Netlify) when changes to the Ghost content are published. See https://github.com/TryGhost/eleventy-starter-ghost for possible guidance.\n\n\nBetter yet, check out https://docs.digitalocean.com/reference/api/api-reference/#operation/apps_create_deployment. It seems the mechanism that's required here is to make a request, like a curl or POST, to a particular URL (see sample below) perhaps with an auth token included for security.\n\n\ncurl -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $DIGITALOCEAN_TOKEN\" \\\n  \"https://api.digitalocean.com/v2/apps/{app_id}/deployments\"\n\n\n\nNow, the question is, how to make my Ghost install dispatch such a request? Simple, see https://ghost.org/docs/webhooks/ but note that the request might need to be a POST, not a curl.\n\n\nHmmm, this is more difficult than I imagined, so this write-up might soon become a post of its own!\n\n\nPreliminary Findings\n\n\nUnfortunately, it looks like Ghost's webhooks don't integrate well with DigitalOcean. DO requires a POST request that looks like this in curl form:\n\n\ncurl -X POST \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer { $DIGITALOCEAN_TOKEN }\" \\\n  -d '{ \"force_build\":true }' \\\n  \"https://api.digitalocean.com/v2/apps/{ app ID }/deployments\"\n\n\n\nI can't find a way to build such a request in Ghost since the headers and body of the webhooks it builds don't look like what you see above. The only thing that can be easily configured in a Ghost webhook is the destination address. So, now I'm going to look into the possibility of using an iOS or MacOS app that triggers a curl like the one you see above. Or, maybe I can add a protected page to the site itself and embed a Javascript POST request within?\n\n\nâ˜‘ï¸ Solved 23-Mar-2023: Please see Built by Webhook + Password Protection for all the gory details.\n\n\n\nForce rebuild with \"Trigger Site Update\" draft.\n\n\nThe idea here is to delay rebuilding the site until triggered by an editor, perhaps using a \"special\" trigger post. This could help avoid multipe back-to-back rebuilds when lots of content is updated in a short period of time. Of course, if a \"special\" post were used for this it would have to be implicitly \"ignored\" and always in a \"draft\" state.\n\n\nðŸš« CANCELED 23-Mar-2023: No longer needed. Please see Built by Webhook + Password Protection for all the gory details.\n\n\n\nEngage spell checking.\n\n\nIndications from as early as 2015 indicate that this should work straight from the browser, but I'm not so sure?\n\n\nâ˜‘ï¸ Solved 23-Mar-2023: Just toggle the little abc-checkmark icon down in the lower right corner of the editor window. Also, the question-mark icon down there is helpful too!\n\n\n",
            "feature_image": "__GHOST_URL__/content/images/2023/03/jessica-lewis-fJXv46LT7Xk-unsplash.jpg",
            "featured": 1,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-03-23T01:44:19.000Z",
            "updated_at": "2023-04-21T01:57:33.000Z",
            "published_at": "2023-03-23T02:20:28.000Z",
            "custom_excerpt": "Witness the birth of a new blog! Actually, a new version of a very old blog. There's still a lot of work to do.\n\nSo, here's my \"to-do\" list, as it pertains to this blog, along with possible sources of guidance and inspriration.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "641d0d8d8e5f7604af1034a7",
            "uuid": "d4145de6-3924-4749-9e92-7d98e7cc8dec",
            "title": "Built by Webhook + Password Protection",
            "slug": "build-per-webhook-password-protection",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Today I used the resources you see in the [OneTab](https://www.one-tab.com/page/yNIzSr1nS_eCow7rVQFwdw) shown above to build a trigger from a [password-protected page in this blog](https://blog.SummittDweller.com/rebuild.html) to a DigitalOcean webhook.  The purpose of the webhook is to rebuild and subsequently deploy the entire blog. \\n\\nI thought about using a traditional Ghost action, like `site.changed`, to do this but I frequently like to post 3 or more blog updates in rapid succession, and I didn't want Ghost triggering back-to-back-to-back rebuilds all of the time. Why not?  Because I'm cheap and I didn't want to blow through the limited quota of build minutes that my inexpensive DigitalOcean account provides.\"}],[\"markdown\",{\"markdown\":\"My `https://blog.SummittDweller.com/rebuild.html -> DigitalOcean` trigger and webhook should do the job nicely since I'll be able to trigger it even from my iPhone when needed.\"}],[\"markdown\",{\"markdown\":\"## The POST in `rebuild.njk`\\nSometime soon I hope to create a diagram showing all the components and relationships/communication between the parts, but for now this brief explanation will have to suffice.\\n\\n`rebuild.njk` is a Nunjucks template at the root of my Eleventy site with a defined permalink of `rebuild.html`.  Inside that `.njk` is a POST script that begins in the third line of the snippet shown below. \\n\\n```njk\\n{% extends 'layouts/default.njk' %}\\n\\n{% set codeinjection_head = \\\"<script>\\n  fetch('https://api.digitalocean.com/v2/apps/86d9d69d-4a0e-4686-931b-69650094db15/deployments', {\\n    method: 'POST',\\n    headers: {\\n        'Accept': 'application/json',\\n        'Content-Type': 'application/json',\\n        'Authorization': 'Bearer ********** obfuscated ************',\\n    },\\n    body: JSON.stringify({ 'force_build': true })\\n  })\\n  .then(response => response.json())\\n  .then(response => console.log(JSON.stringify(response)))\\n</script>\\\" %}\\n{% set codeinjection_foot = doc.codeinjection_foot %}\\n\\n{% set title = \\\"Rebuild!\\\" %}\\n...\\n```\\n\\nThe *** obfuscated *** portion is a secret.\\n\"}],[\"markdown\",{\"markdown\":\"## DigitalOcean's Response\\nThat POST, when received by DigitalOcean, signals DO to trigger a rebuild of the site which has been programmed in the apps' DO settings to execute a build command of `yarn build` followed by `yarn encrypt`.  \\n\\n- The first command, `build` is defined in `package.json`, and using `.eleventy.js` it builds the site into a static collection of files in the project's `./dist` directory. \\n   \\n- The second command, `encrypt`, also defined in `package.json`, executes the `staticrypt` utility to encrypt `./dist/rebuild.html` placing a login page in front of it.  \\n\\n## StatiCrypt\\nThe encryption provided by StatiCrypt effectively \\\"hides\\\" the authorization token, obfuscated above, from pyring eyes.  \\n\\nI built the encryption process in this site based on previous experience described in [Protecting Pages with StatiCrypt CLI](https://static.grinnell.edu/dlad-blog/posts/141-gating-my-content-and-more-parts-34/) and the references listed therein.  I borrowed pieces of several files from the project chronicled in that blog post, namely:\\n\\n- `auth/login.html` - The login page that gets placed in front of `rebuild.html`\\n\\n- The `encrypt` script definition which appears in `package.json`.  It reads:\\n\\n```\\n    \\\"encrypt\\\": \\\"staticrypt ./dist/rebuild.html '***************' --short -o ./dist/rebuild.html -f ./src/auth/login.html -t 'Summitt Dweller Blog - Rebuild' -i 'Please enter the passphrase.<br/>Hint: gh0st' --label-error 'Sorry, Ella says no. Try again.'\\\"\\n```\\n\\n- The `\\\"staticrypt\\\": \\\"^2.4.0\\\"` addition to the `dependencies:` portion of `package.json`\\n\\n- The `- run: yarn encrypt` addition to the end of the `steps:` of the project's `.github/workflows/build-and-deploy.yml` file.  \\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[10,3],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Today I used the resources you see in the <a href=\"https://www.one-tab.com/page/yNIzSr1nS_eCow7rVQFwdw\">OneTab</a> shown above to build a trigger from a <a href=\"https://blog.SummittDweller.com/rebuild.html\">password-protected page in this blog</a> to a DigitalOcean webhook.  The purpose of the webhook is to rebuild and subsequently deploy the entire blog.</p>\n<p>I thought about using a traditional Ghost action, like <code>site.changed</code>, to do this but I frequently like to post 3 or more blog updates in rapid succession, and I didn't want Ghost triggering back-to-back-to-back rebuilds all of the time. Why not?  Because I'm cheap and I didn't want to blow through the limited quota of build minutes that my inexpensive DigitalOcean account provides.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>My <code>https://blog.SummittDweller.com/rebuild.html -&gt; DigitalOcean</code> trigger and webhook should do the job nicely since I'll be able to trigger it even from my iPhone when needed.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"the-post-in-rebuildnjk\">The POST in <code>rebuild.njk</code></h2>\n<p>Sometime soon I hope to create a diagram showing all the components and relationships/communication between the parts, but for now this brief explanation will have to suffice.</p>\n<p><code>rebuild.njk</code> is a Nunjucks template at the root of my Eleventy site with a defined permalink of <code>rebuild.html</code>.  Inside that <code>.njk</code> is a POST script that begins in the third line of the snippet shown below.</p>\n<pre><code class=\"language-njk\">{% extends 'layouts/default.njk' %}\n\n{% set codeinjection_head = &quot;&lt;script&gt;\n  fetch('https://api.digitalocean.com/v2/apps/86d9d69d-4a0e-4686-931b-69650094db15/deployments', {\n    method: 'POST',\n    headers: {\n        'Accept': 'application/json',\n        'Content-Type': 'application/json',\n        'Authorization': 'Bearer ********** obfuscated ************',\n    },\n    body: JSON.stringify({ 'force_build': true })\n  })\n  .then(response =&gt; response.json())\n  .then(response =&gt; console.log(JSON.stringify(response)))\n&lt;/script&gt;&quot; %}\n{% set codeinjection_foot = doc.codeinjection_foot %}\n\n{% set title = &quot;Rebuild!&quot; %}\n...\n</code></pre>\n<p>The *** obfuscated *** portion is a secret.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"digitaloceans-response\">DigitalOcean's Response</h2>\n<p>That POST, when received by DigitalOcean, signals DO to trigger a rebuild of the site which has been programmed in the apps' DO settings to execute a build command of <code>yarn build</code> followed by <code>yarn encrypt</code>.</p>\n<ul>\n<li>\n<p>The first command, <code>build</code> is defined in <code>package.json</code>, and using <code>.eleventy.js</code> it builds the site into a static collection of files in the project's <code>./dist</code> directory.</p>\n</li>\n<li>\n<p>The second command, <code>encrypt</code>, also defined in <code>package.json</code>, executes the <code>staticrypt</code> utility to encrypt <code>./dist/rebuild.html</code> placing a login page in front of it.</p>\n</li>\n</ul>\n<h2 id=\"staticrypt\">StatiCrypt</h2>\n<p>The encryption provided by StatiCrypt effectively &quot;hides&quot; the authorization token, obfuscated above, from pyring eyes.</p>\n<p>I built the encryption process in this site based on previous experience described in <a href=\"https://static.grinnell.edu/dlad-blog/posts/141-gating-my-content-and-more-parts-34/\">Protecting Pages with StatiCrypt CLI</a> and the references listed therein.  I borrowed pieces of several files from the project chronicled in that blog post, namely:</p>\n<ul>\n<li>\n<p><code>auth/login.html</code> - The login page that gets placed in front of <code>rebuild.html</code></p>\n</li>\n<li>\n<p>The <code>encrypt</code> script definition which appears in <code>package.json</code>.  It reads:</p>\n</li>\n</ul>\n<pre><code>    &quot;encrypt&quot;: &quot;staticrypt ./dist/rebuild.html '***************' --short -o ./dist/rebuild.html -f ./src/auth/login.html -t 'Summitt Dweller Blog - Rebuild' -i 'Please enter the passphrase.&lt;br/&gt;Hint: gh0st' --label-error 'Sorry, Ella says no. Try again.'&quot;\n</code></pre>\n<ul>\n<li>\n<p>The <code>&quot;staticrypt&quot;: &quot;^2.4.0&quot;</code> addition to the <code>dependencies:</code> portion of <code>package.json</code></p>\n</li>\n<li>\n<p>The <code>- run: yarn encrypt</code> addition to the end of the <code>steps:</code> of the project's <code>.github/workflows/build-and-deploy.yml</code> file.</p>\n</li>\n</ul>\n<!--kg-card-end: markdown-->",
            "comment_id": "641d0d8d8e5f7604af1034a7",
            "plaintext": "Today I used the resources you see in the OneTab shown above to build a trigger from a password-protected page in this blog to a DigitalOcean webhook. The purpose of the webhook is to rebuild and subsequently deploy the entire blog.\n\n\nI thought about using a traditional Ghost action, like site.changed, to do this but I frequently like to post 3 or more blog updates in rapid succession, and I didn't want Ghost triggering back-to-back-to-back rebuilds all of the time. Why not? Because I'm cheap and I didn't want to blow through the limited quota of build minutes that my inexpensive DigitalOcean account provides.\n\n\nMy https://blog.SummittDweller.com/rebuild.html -> DigitalOcean trigger and webhook should do the job nicely since I'll be able to trigger it even from my iPhone when needed.\n\n\n\nThe POST in rebuild.njk\n\n\nSometime soon I hope to create a diagram showing all the components and relationships/communication between the parts, but for now this brief explanation will have to suffice.\n\n\nrebuild.njk is a Nunjucks template at the root of my Eleventy site with a defined permalink of rebuild.html. Inside that .njk is a POST script that begins in the third line of the snippet shown below.\n\n\n{% extends 'layouts/default.njk' %}\n\n{% set codeinjection_head = \"<script>\n  fetch('https://api.digitalocean.com/v2/apps/86d9d69d-4a0e-4686-931b-69650094db15/deployments', {\n    method: 'POST',\n    headers: {\n        'Accept': 'application/json',\n        'Content-Type': 'application/json',\n        'Authorization': 'Bearer ********** obfuscated ************',\n    },\n    body: JSON.stringify({ 'force_build': true })\n  })\n  .then(response => response.json())\n  .then(response => console.log(JSON.stringify(response)))\n</script>\" %}\n{% set codeinjection_foot = doc.codeinjection_foot %}\n\n{% set title = \"Rebuild!\" %}\n...\n\n\n\nThe *** obfuscated *** portion is a secret.\n\n\n\nDigitalOcean's Response\n\n\nThat POST, when received by DigitalOcean, signals DO to trigger a rebuild of the site which has been programmed in the apps' DO settings to execute a build command of yarn build followed by yarn encrypt.\n\n\n * \n   \n   \n   The first command, build is defined in package.json, and using .eleventy.js it builds the site into a static collection of files in the project's ./dist directory.\n   \n\n * \n   \n   \n   The second command, encrypt, also defined in package.json, executes the staticrypt utility to encrypt ./dist/rebuild.html placing a login page in front of it.\n   \n\n\n\nStatiCrypt\n\n\nThe encryption provided by StatiCrypt effectively \"hides\" the authorization token, obfuscated above, from pyring eyes.\n\n\nI built the encryption process in this site based on previous experience described in Protecting Pages with StatiCrypt CLI and the references listed therein. I borrowed pieces of several files from the project chronicled in that blog post, namely:\n\n\n * \n   \n   \n   auth/login.html - The login page that gets placed in front of rebuild.html\n   \n\n * \n   \n   \n   The encrypt script definition which appears in package.json. It reads:\n   \n\n\n    \"encrypt\": \"staticrypt ./dist/rebuild.html '***************' --short -o ./dist/rebuild.html -f ./src/auth/login.html -t 'Summitt Dweller Blog - Rebuild' -i 'Please enter the passphrase.<br/>Hint: gh0st' --label-error 'Sorry, Ella says no. Try again.'\"\n\n\n\n * \n   \n   \n   The \"staticrypt\": \"^2.4.0\" addition to the dependencies: portion of package.json\n   \n\n * \n   \n   \n   The - run: yarn encrypt addition to the end of the steps: of the project's .github/workflows/build-and-deploy.yml file.\n   \n",
            "feature_image": "__GHOST_URL__/content/images/2023/03/Screenshot-2023-03-23-at-21.38.05.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-03-24T02:40:13.000Z",
            "updated_at": "2023-03-24T03:44:16.000Z",
            "published_at": "2023-03-24T03:32:33.000Z",
            "custom_excerpt": "My `https://blog.SummittDweller.com/rebuild.html -> DigitalOcean` trigger and webhook should do the job nicely since I'll be able to trigger it even from my iPhone when needed.",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428cbf91e78d1110e1d7363",
            "uuid": "b40e0edd-4dad-4432-9d92-2159e775282a",
            "title": "Last of the Clean-up? - Derecho Follow-Up for September 6",
            "slug": "last-of-the-clean-up----derecho-follow-up-for-september-6",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>Tomorrow is Labor Day 2020, but it also will mark 4 weeks since the August 10 derecho. Thankfully, I believe today marked the end of the clean-up, at least on my own property. I was going to write this post yesterday after another 6+ hours of work outdoors, but last night we had another storm roll through, and all day the winds have been blowing upwards of 40 mph, so I put in another 6 hours or so cleaning up even more debris. The only good news here is that the city has not yet made a 2nd-pass of curbside debris pick-up, so I donâ€™t have to haul it away, just keep adding to the â€œbomaâ€ at the curb.</p><h2 id='the-west-side-boma-round-2'>The West-side Boma, Round 2</h2><p>My <a href='https://summittdweller.com/blogs/mark/posts/iowahurricane2020/'>post from August 20</a> includes photos of both our south and west bomas, massive curbside piles of tree debris that surrounded our property on two sides, plus a pile we placed next door in a church parking lot.  Well, since that time we had to have our largest pine taken down, and many dead limbs removed from the other three large trees.  All of that debris, plus whatâ€™s fallen just today, formed a new boma on along the curb to our west.  I took some photos of that monster today:</p><p><figure><img alt='The West Boma - Round 2' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0373.png'/><figcaption>The West Boma - Round 2 - Looking North</figcaption></figure></p><p><figure><img alt='The West Boma - Round 2' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0374.png'/><figcaption>The West Boma - Round 2 - Looking South: Remnants of the Pine in the Foreground</figcaption></figure></p><p>Before the storm my backyard was looking pretty good. Itâ€™s not gone, but I just hope next year some of it might return to its previous glory.</p><p><figure><img alt='The West Boma - Round 2' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0375.png'/><figcaption>What's Left of My Backyard</figcaption></figure></p><h2 id='insurance-not-very-reassuring'>Insurance, Not Very Reassuring</h2><p>I wonâ€™t name names here, but the company that carries my home-ownerâ€™s insurance has been NO help at all. I filed a claim with them on August 14 or so, and still have not heard anything from them. In fact, once I found out how badly damaged our big pine tree was I decided to call them directly, that was on Monday, August 24, I believe. I asked them if someone could come take a look at this tree because Iâ€™d put a plumb-line on it a few days before and was therefore able to detect that it was indeed tilting farther to the east each day. Their response was literally â€œItâ€™s not covered unless itâ€™s damaged your house.â€</p><p>I told them I wasnâ€™t concerned about the coverage, I just wanted to know if they could help me determine what to do about it, or if they could even recommend someone who could give me an expert opinion about it. â€œNo, we donâ€™t do that.â€, was their answer. So I told them, â€œItâ€™s leaning to the northeast and the wind is out of the south, it could easily fall on the neighborâ€™s house.â€ Their response left me speechless, they said, â€œIf it falls on their house it is their problem, and their insurance will take care of it.â€</p><p>I guess I am just naive when it comes to insurance, I always thought they actually cared about people and were intent on helping prevent disasters, but apparently they just crunch numbers and dole out money, as little as possible Iâ€™m sure. <strong>I was, and still am, disgusted</strong>.</p><p>If they ever do contact me Iâ€™ll listen to them as well and as long as they listened to me, and then Iâ€™m going to dump them just as soon as I can find coverage from someone who actually gives a damn.</p><h2 id='brothers-tree-service-to-the-rescue'>Brotherâ€™s Tree Service To the Rescue</h2><p>While I was checking up on some apparent fly-by-night tree â€œprofessionalsâ€ from out-of-state, I had the good fortune of meeting Shelby, the wife of Martin, an owner of Brotherâ€™s Tree Service. Martin looked at my tree damage and gave me a very reasonable quote to take care of all the â€œwidow-makersâ€.  At that time I wasnâ€™t planning to have the big pine taken down, but after my insurance disappointment I called Martin and asked him to come look at it ASAP. He thought it should come down AND he interrupted his busy schedule to sweep in on the evening of Wednesday, August 26, to render that leaning tree harmless.</p><p>I was impressed at how quickly, professionally, and safely, Martin and his partner brought the bulk of that tree down! Finally, I could get some sleep without worrying about which way the wind was blowing. I took a couple photos of that tree removal operation too.</p><p><figure><img alt='Brother&amp;rsquo;s Rendering the Pine Harmless' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0352.png'/><figcaption>About 30 Minutes into the Pine Tree Removal</figcaption></figure></p><p><figure><img alt='Brother&amp;rsquo;s Rendering the Pine Harmless - Progress' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0362.png'/><figcaption>After About 1 Hour of Pine Tree Removal</figcaption></figure></p><p>A few days after bringing most of the pine down, Brotherâ€™s returned to remove some dangerous hanging limbs from my three remaining trees. Now I could even park my car in my own driveway again!</p><p><figure><img alt='Brother&amp;rsquo;s Rendering the Pine Harmless - Progress' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0367.png'/><figcaption>A Few Days Later Brother's Returned to Clean-Up Hanging Limbs</figcaption></figure></p><h2 id='what-to-do-about-my-lawn'>What To Do About My Lawn?</h2><p>The one remaining concern I have is with my lawn; the combination of severe drought and lots of heavy equipment traffic has left great canyons in the grass. It litterally is too rough to drive my riding mower over it in most places. Iâ€™m frankly surprised the rough ride hasnâ€™t ruined my mower or any of my lawn equipment yet, or maybe it has?</p><p>So Iâ€™m thinking, once the city has removed the newest debris (and there will almost certainly be more lawn-canyons after that), and after Iâ€™ve subsequently removed whatever they leave behind, I will probably ask one of the local landscape pros to come in. Iâ€™d like to have them dump a few loads of topsoil on the lawn and top-dress it all with a nice, smooth layer of soil that Iâ€™d hope to get planted for a new lawn before winter.</p><p>Wish me luck.</p><p>Thatâ€™s a warp. Until the next derecho, or the next time, whatever that may beâ€¦</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>Tomorrow is Labor Day 2020, but it also will mark 4 weeks since the August 10 derecho. Thankfully, I believe today marked the end of the clean-up, at least on my own property. I was going to write this post yesterday after another 6+ hours of work outdoors, but last night we had another storm roll through, and all day the winds have been blowing upwards of 40 mph, so I put in another 6 hours or so cleaning up even more debris. The only good news here is that the city has not yet made a 2nd-pass of curbside debris pick-up, so I donâ€™t have to haul it away, just keep adding to the â€œbomaâ€ at the curb.</p><h2 id='the-west-side-boma-round-2'>The West-side Boma, Round 2</h2><p>My <a href='https://summittdweller.com/blogs/mark/posts/iowahurricane2020/'>post from August 20</a> includes photos of both our south and west bomas, massive curbside piles of tree debris that surrounded our property on two sides, plus a pile we placed next door in a church parking lot.  Well, since that time we had to have our largest pine taken down, and many dead limbs removed from the other three large trees.  All of that debris, plus whatâ€™s fallen just today, formed a new boma on along the curb to our west.  I took some photos of that monster today:</p><p><figure><img alt='The West Boma - Round 2' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0373.png'/><figcaption>The West Boma - Round 2 - Looking North</figcaption></figure></p><p><figure><img alt='The West Boma - Round 2' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0374.png'/><figcaption>The West Boma - Round 2 - Looking South: Remnants of the Pine in the Foreground</figcaption></figure></p><p>Before the storm my backyard was looking pretty good. Itâ€™s not gone, but I just hope next year some of it might return to its previous glory.</p><p><figure><img alt='The West Boma - Round 2' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0375.png'/><figcaption>What's Left of My Backyard</figcaption></figure></p><h2 id='insurance-not-very-reassuring'>Insurance, Not Very Reassuring</h2><p>I wonâ€™t name names here, but the company that carries my home-ownerâ€™s insurance has been NO help at all. I filed a claim with them on August 14 or so, and still have not heard anything from them. In fact, once I found out how badly damaged our big pine tree was I decided to call them directly, that was on Monday, August 24, I believe. I asked them if someone could come take a look at this tree because Iâ€™d put a plumb-line on it a few days before and was therefore able to detect that it was indeed tilting farther to the east each day. Their response was literally â€œItâ€™s not covered unless itâ€™s damaged your house.â€</p><p>I told them I wasnâ€™t concerned about the coverage, I just wanted to know if they could help me determine what to do about it, or if they could even recommend someone who could give me an expert opinion about it. â€œNo, we donâ€™t do that.â€, was their answer. So I told them, â€œItâ€™s leaning to the northeast and the wind is out of the south, it could easily fall on the neighborâ€™s house.â€ Their response left me speechless, they said, â€œIf it falls on their house it is their problem, and their insurance will take care of it.â€</p><p>I guess I am just naive when it comes to insurance, I always thought they actually cared about people and were intent on helping prevent disasters, but apparently they just crunch numbers and dole out money, as little as possible Iâ€™m sure. <strong>I was, and still am, disgusted</strong>.</p><p>If they ever do contact me Iâ€™ll listen to them as well and as long as they listened to me, and then Iâ€™m going to dump them just as soon as I can find coverage from someone who actually gives a damn.</p><h2 id='brothers-tree-service-to-the-rescue'>Brotherâ€™s Tree Service To the Rescue</h2><p>While I was checking up on some apparent fly-by-night tree â€œprofessionalsâ€ from out-of-state, I had the good fortune of meeting Shelby, the wife of Martin, an owner of Brotherâ€™s Tree Service. Martin looked at my tree damage and gave me a very reasonable quote to take care of all the â€œwidow-makersâ€.  At that time I wasnâ€™t planning to have the big pine taken down, but after my insurance disappointment I called Martin and asked him to come look at it ASAP. He thought it should come down AND he interrupted his busy schedule to sweep in on the evening of Wednesday, August 26, to render that leaning tree harmless.</p><p>I was impressed at how quickly, professionally, and safely, Martin and his partner brought the bulk of that tree down! Finally, I could get some sleep without worrying about which way the wind was blowing. I took a couple photos of that tree removal operation too.</p><p><figure><img alt='Brother&amp;rsquo;s Rendering the Pine Harmless' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0352.png'/><figcaption>About 30 Minutes into the Pine Tree Removal</figcaption></figure></p><p><figure><img alt='Brother&amp;rsquo;s Rendering the Pine Harmless - Progress' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0362.png'/><figcaption>After About 1 Hour of Pine Tree Removal</figcaption></figure></p><p>A few days after bringing most of the pine down, Brotherâ€™s returned to remove some dangerous hanging limbs from my three remaining trees. Now I could even park my car in my own driveway again!</p><p><figure><img alt='Brother&amp;rsquo;s Rendering the Pine Harmless - Progress' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0367.png'/><figcaption>A Few Days Later Brother's Returned to Clean-Up Hanging Limbs</figcaption></figure></p><h2 id='what-to-do-about-my-lawn'>What To Do About My Lawn?</h2><p>The one remaining concern I have is with my lawn; the combination of severe drought and lots of heavy equipment traffic has left great canyons in the grass. It litterally is too rough to drive my riding mower over it in most places. Iâ€™m frankly surprised the rough ride hasnâ€™t ruined my mower or any of my lawn equipment yet, or maybe it has?</p><p>So Iâ€™m thinking, once the city has removed the newest debris (and there will almost certainly be more lawn-canyons after that), and after Iâ€™ve subsequently removed whatever they leave behind, I will probably ask one of the local landscape pros to come in. Iâ€™d like to have them dump a few loads of topsoil on the lawn and top-dress it all with a nice, smooth layer of soil that Iâ€™d hope to get planted for a new lawn before winter.</p><p>Wish me luck.</p><p>Thatâ€™s a warp. Until the next derecho, or the next time, whatever that may beâ€¦</p></p></article><!--kg-card-end: html-->",
            "comment_id": "38",
            "plaintext": "Tomorrow is Labor Day 2020, but it also will mark 4 weeks since the August 10 derecho. Thankfully, I believe today marked the end of the clean-up, at least on my own property. I was going to write this post yesterday after another 6+ hours of work outdoors, but last night we had another storm roll through, and all day the winds have been blowing upwards of 40 mph, so I put in another 6 hours or so cleaning up even more debris. The only good news here is that the city has not yet made a 2nd-pass of curbside debris pick-up, so I donâ€™t have to haul it away, just keep adding to the â€œbomaâ€ at the curb.\n\n\nThe West-side Boma, Round 2\n\nMy post from August 20 includes photos of both our south and west bomas, massive curbside piles of tree debris that surrounded our property on two sides, plus a pile we placed next door in a church parking lot. Well, since that time we had to have our largest pine taken down, and many dead limbs removed from the other three large trees. All of that debris, plus whatâ€™s fallen just today, formed a new boma on along the curb to our west. I took some photos of that monster today:\n\n\n\n\n\n\n\n\n\nBefore the storm my backyard was looking pretty good. Itâ€™s not gone, but I just hope next year some of it might return to its previous glory.\n\n\n\n\n\n\nInsurance, Not Very Reassuring\n\nI wonâ€™t name names here, but the company that carries my home-ownerâ€™s insurance has been NO help at all. I filed a claim with them on August 14 or so, and still have not heard anything from them. In fact, once I found out how badly damaged our big pine tree was I decided to call them directly, that was on Monday, August 24, I believe. I asked them if someone could come take a look at this tree because Iâ€™d put a plumb-line on it a few days before and was therefore able to detect that it was indeed tilting farther to the east each day. Their response was literally â€œItâ€™s not covered unless itâ€™s damaged your house.â€\n\nI told them I wasnâ€™t concerned about the coverage, I just wanted to know if they could help me determine what to do about it, or if they could even recommend someone who could give me an expert opinion about it. â€œNo, we donâ€™t do that.â€, was their answer. So I told them, â€œItâ€™s leaning to the northeast and the wind is out of the south, it could easily fall on the neighborâ€™s house.â€ Their response left me speechless, they said, â€œIf it falls on their house it is their problem, and their insurance will take care of it.â€\n\nI guess I am just naive when it comes to insurance, I always thought they actually cared about people and were intent on helping prevent disasters, but apparently they just crunch numbers and dole out money, as little as possible Iâ€™m sure. I was, and still am, disgusted.\n\nIf they ever do contact me Iâ€™ll listen to them as well and as long as they listened to me, and then Iâ€™m going to dump them just as soon as I can find coverage from someone who actually gives a damn.\n\n\nBrotherâ€™s Tree Service To the Rescue\n\nWhile I was checking up on some apparent fly-by-night tree â€œprofessionalsâ€ from out-of-state, I had the good fortune of meeting Shelby, the wife of Martin, an owner of Brotherâ€™s Tree Service. Martin looked at my tree damage and gave me a very reasonable quote to take care of all the â€œwidow-makersâ€. At that time I wasnâ€™t planning to have the big pine taken down, but after my insurance disappointment I called Martin and asked him to come look at it ASAP. He thought it should come down AND he interrupted his busy schedule to sweep in on the evening of Wednesday, August 26, to render that leaning tree harmless.\n\nI was impressed at how quickly, professionally, and safely, Martin and his partner brought the bulk of that tree down! Finally, I could get some sleep without worrying about which way the wind was blowing. I took a couple photos of that tree removal operation too.\n\n\n\n\n\n\n\n\n\nA few days after bringing most of the pine down, Brotherâ€™s returned to remove some dangerous hanging limbs from my three remaining trees. Now I could even park my car in my own driveway again!\n\n\n\n\n\n\nWhat To Do About My Lawn?\n\nThe one remaining concern I have is with my lawn; the combination of severe drought and lots of heavy equipment traffic has left great canyons in the grass. It litterally is too rough to drive my riding mower over it in most places. Iâ€™m frankly surprised the rough ride hasnâ€™t ruined my mower or any of my lawn equipment yet, or maybe it has?\n\nSo Iâ€™m thinking, once the city has removed the newest debris (and there will almost certainly be more lawn-canyons after that), and after Iâ€™ve subsequently removed whatever they leave behind, I will probably ask one of the local landscape pros to come in. Iâ€™d like to have them dump a few loads of topsoil on the lawn and top-dress it all with a nice, smooth layer of soil that Iâ€™d hope to get planted for a new lawn before winter.\n\nWish me luck.\n\nThatâ€™s a warp. Until the next derecho, or the next time, whatever that may beâ€¦\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T00:27:37.000Z",
            "updated_at": "2023-04-02T00:29:32.000Z",
            "published_at": "2020-09-07T00:27:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428d2991e78d1110e1d736b",
            "uuid": "71da3b6a-b83d-4e9c-a53b-b4473fb7894c",
            "title": "Westbound to Seattle - Day 3",
            "slug": "westbound-to-seattle---day-3",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><h1 id='day-3---moses-lake-wa-to-seattle'>Day 3 - Moses Lake, WA to Seattle</h1><p>This is our planned route for Day 3 using a <code>speed factor of 1.0</code> (traveling at the speed limit).  Fuel cost is based on <code>40 mpg</code> and <code>$4.00 per gallon</code> averages.  Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.</p><p>A list of possible geocache targets for the entire route can be found at <a href='https://www.geocaching.com/play/map/lists/BMBBMD6'>https://www.geocaching.com/play/map/lists/BMBBMD6</a>.</p><iframe src='http://localhost:1313/html/Westbound-Day-3.html' style='width: 100%; height: 400px; border:1;' title='Westbound Day 3'></iframe></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><h1 id='day-3---moses-lake-wa-to-seattle'>Day 3 - Moses Lake, WA to Seattle</h1><p>This is our planned route for Day 3 using a <code>speed factor of 1.0</code> (traveling at the speed limit).  Fuel cost is based on <code>40 mpg</code> and <code>$4.00 per gallon</code> averages.  Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.</p><p>A list of possible geocache targets for the entire route can be found at <a href='https://www.geocaching.com/play/map/lists/BMBBMD6'>https://www.geocaching.com/play/map/lists/BMBBMD6</a>.</p><iframe src='http://localhost:1313/html/Westbound-Day-3.html' style='width: 100%; height: 400px; border:1;' title='Westbound Day 3'></iframe></p></article><!--kg-card-end: html-->",
            "comment_id": "0",
            "plaintext": "Day 3 - Moses Lake, WA to Seattle\n\nThis is our planned route for Day 3 using a speed factor of 1.0 (traveling at the speed limit). Fuel cost is based on 40 mpg and $4.00 per gallon averages. Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.\n\nA list of possible geocache targets for the entire route can be found at https://www.geocaching.com/play/map/lists/BMBBMD6.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T00:55:53.000Z",
            "updated_at": "2023-04-02T01:00:06.000Z",
            "published_at": "2022-08-08T00:55:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428d2991e78d1110e1d736c",
            "uuid": "911bb4a2-2bad-4f26-8531-2f032fbad962",
            "title": "One of Many Challenges",
            "slug": "one-of-many-challenges",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>For 2021 Iâ€™ve signed on to be a member of the steering committee for Toledoâ€™s 2021 <a href='https://www.communityvisioning.org/toledo/'>Community Visioning (CV)</a> project coordinated by <a href='http://www.treesforever.org/IowasLivingRoadways'>Treeâ€™s Forever and Iowaâ€™s Living Roadways</a>, <a href='https://www.extension.iastate.edu/'>Iowa State University Extension and Outreach</a>, and other partners.  Tama is also a <a href='https://www.communityvisioning.org/tama/'>Community Visioning</a> participant in 2021.</p><h2 id='i-like-to-walk'>I Like to Walk</h2><p>I try to get outside and walk as much as I can, but I especially like walking with a purposeâ€¦ not just walking for the sake of exercise or stress-relief. I guess thatâ€™s also why I dislike walking indoors on a treadmill, or the â€œdreadmillâ€ as I like to call it. So, if I have somewhere to go in Tama-Toledo Iâ€™ll walk there and back whenever possible. Fortunately, my home in Toledo is geographically centered between the two communities.  If you draw a 1.5-mile radius circle around my house it will include ALL of the two communities. Itâ€™s ideal for walking, except for the hills ðŸŒ„, and the <strong>challenge of finding a safe route</strong>.</p><h2 id='formidable-challenges'>Formidable Challenges</h2><p>Tama-Toledo does have some nice sidewalks and trails that I try to take advantage of when I walk; however, there are three <strong>BIG</strong> challenges to using them safely:</p><ul><li>Gaps,</li><li>Lack of Safe Crossings, and</li><li>Snow.</li></ul><h3 id='gaps'>Gaps</h3><p>This challenge is going to be difficult to explain in detail at this time.  Why, you ask?  Because I really need a map to do it justice, and probably some photos too.  I donâ€™t have a good map at this time, but I hope that the Tama and Toledo CV teams will come up with one (or two) soon. Iâ€™d also like to collect and post some photos, but thereâ€™s about a foot of snow covering everything, and I do mean everything (see below), right now.</p><h3 id='lack-of-safe-crossings'>Lack of Safe Crossings</h3><p>Tama-Toledo, and my home, are situated at the intersection of two major highways:</p><ul><li>US Highway 30, running east-west, and</li><li>US Highway 63, running north-south.</li></ul><p>Iâ€™ll write more about these two obstacles later, when I have that map.</p><h3 id='snow-'>Snow â„ï¸</h3><p>I should probably include rain in this paragraph too, and the mud that naturally comes with either snow or rain, in locations where there is no pavement (thatâ€™s a gap!). I think everyone can agree that safely traversing any wet surface can be a challenge, espeically where thereâ€™s no pavement.  Anyone whoâ€™s experienced winter in the upper-midwest also knows that snow and ice make that challenge even greater, even where there is pavement!</p><h4 id='20-feb-2021'>20-Feb-2021</h4><p>This morning my daugther called and asked if I could bring her a USB â€œprinter cableâ€; sheâ€™s volunteering at a local <a href='https://www.facebook.com/southtamaarchery/'>youth archery tournament</a> at the South Tama County High School, less than 1/2-mile from my home. A perfect opportunity for a short walk! There are no sidewalks on my street (another gap) but the roadway is not too busy so thatâ€™s okay. There is a nice sidewalk that runs part of the way (yup, another gap!) from my street to the High School along US 63, so thatâ€™s also helpful. Unfortunately, the photos Iâ€™m including below show the condition of that sidewalk on this lovely Saturday morning.</p><p><figure><img alt='Sidewalk on US 63 at Summitt Street - Looking North' src='https://images-summittdweller.nyc3.cdn.digitaloceanspaces.com/blogs-SummittDweller/4FF7047A-0A7B-4A55-B62B-46FF4B200C57_1_105_c.jpeg'/><figcaption>There's a sidewalk under there somewhere</figcaption></figure></p><p><figure><img alt='Sidewalk on US 63 at Summitt Street - Looking South' src='https://images-summittdweller.nyc3.cdn.digitaloceanspaces.com/blogs-SummittDweller/4FAD6EDE-0D09-4CB0-836A-4D181AD667CF_1_105_c.jpeg'/><figcaption>You'll just have to take my word for it</figcaption></figure></p><p>Thereâ€™s about 1/2-mile segment of sidewalk, some would say â€œto nowhereâ€, along this side of US 63 in Toledo.  The north end of the segment terminates at 2nd Ave. in Toledo, but thereâ€™s no sidewalk on the north side of that intersection, nor any to the north <strong>for more than a mile!</strong>  The south end of the segment terminates, literally in the middle of a field, presumably at the cityâ€™s shared boundary with Tama.  Fortunately, on the west side of US 63 thereâ€™s an infrequently-used access/frontage road and itâ€™s paved to provide access to some South Tama High School athletic fields. <em>Itâ€™s ironic, you canâ€™t safely walk to school because there are so few sidewalks, but thereâ€™s a paved drive to the the baseball diamond, where thereâ€™s no place to park.</em> ðŸ˜¦</p><p>The entire length of this sidewalk is covered in snow, and I canâ€™t recall any time this winter when any portion of it has been cleared. ðŸ˜¦ In fact, the snow here is exceptionally deep and difficult to walk trough because it includes everything that the snow plows have churned up. ðŸ˜¦ðŸ˜¦ Spring canâ€™t come soon enough for me!</p><p><em>Iâ€™ll post more regarding gaps and crossings as soon as I have that map and maybe some photos.</em></p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>For 2021 Iâ€™ve signed on to be a member of the steering committee for Toledoâ€™s 2021 <a href='https://www.communityvisioning.org/toledo/'>Community Visioning (CV)</a> project coordinated by <a href='http://www.treesforever.org/IowasLivingRoadways'>Treeâ€™s Forever and Iowaâ€™s Living Roadways</a>, <a href='https://www.extension.iastate.edu/'>Iowa State University Extension and Outreach</a>, and other partners.  Tama is also a <a href='https://www.communityvisioning.org/tama/'>Community Visioning</a> participant in 2021.</p><h2 id='i-like-to-walk'>I Like to Walk</h2><p>I try to get outside and walk as much as I can, but I especially like walking with a purposeâ€¦ not just walking for the sake of exercise or stress-relief. I guess thatâ€™s also why I dislike walking indoors on a treadmill, or the â€œdreadmillâ€ as I like to call it. So, if I have somewhere to go in Tama-Toledo Iâ€™ll walk there and back whenever possible. Fortunately, my home in Toledo is geographically centered between the two communities.  If you draw a 1.5-mile radius circle around my house it will include ALL of the two communities. Itâ€™s ideal for walking, except for the hills ðŸŒ„, and the <strong>challenge of finding a safe route</strong>.</p><h2 id='formidable-challenges'>Formidable Challenges</h2><p>Tama-Toledo does have some nice sidewalks and trails that I try to take advantage of when I walk; however, there are three <strong>BIG</strong> challenges to using them safely:</p><ul><li>Gaps,</li><li>Lack of Safe Crossings, and</li><li>Snow.</li></ul><h3 id='gaps'>Gaps</h3><p>This challenge is going to be difficult to explain in detail at this time.  Why, you ask?  Because I really need a map to do it justice, and probably some photos too.  I donâ€™t have a good map at this time, but I hope that the Tama and Toledo CV teams will come up with one (or two) soon. Iâ€™d also like to collect and post some photos, but thereâ€™s about a foot of snow covering everything, and I do mean everything (see below), right now.</p><h3 id='lack-of-safe-crossings'>Lack of Safe Crossings</h3><p>Tama-Toledo, and my home, are situated at the intersection of two major highways:</p><ul><li>US Highway 30, running east-west, and</li><li>US Highway 63, running north-south.</li></ul><p>Iâ€™ll write more about these two obstacles later, when I have that map.</p><h3 id='snow-'>Snow â„ï¸</h3><p>I should probably include rain in this paragraph too, and the mud that naturally comes with either snow or rain, in locations where there is no pavement (thatâ€™s a gap!). I think everyone can agree that safely traversing any wet surface can be a challenge, espeically where thereâ€™s no pavement.  Anyone whoâ€™s experienced winter in the upper-midwest also knows that snow and ice make that challenge even greater, even where there is pavement!</p><h4 id='20-feb-2021'>20-Feb-2021</h4><p>This morning my daugther called and asked if I could bring her a USB â€œprinter cableâ€; sheâ€™s volunteering at a local <a href='https://www.facebook.com/southtamaarchery/'>youth archery tournament</a> at the South Tama County High School, less than 1/2-mile from my home. A perfect opportunity for a short walk! There are no sidewalks on my street (another gap) but the roadway is not too busy so thatâ€™s okay. There is a nice sidewalk that runs part of the way (yup, another gap!) from my street to the High School along US 63, so thatâ€™s also helpful. Unfortunately, the photos Iâ€™m including below show the condition of that sidewalk on this lovely Saturday morning.</p><p><figure><img alt='Sidewalk on US 63 at Summitt Street - Looking North' src='https://images-summittdweller.nyc3.cdn.digitaloceanspaces.com/blogs-SummittDweller/4FF7047A-0A7B-4A55-B62B-46FF4B200C57_1_105_c.jpeg'/><figcaption>There's a sidewalk under there somewhere</figcaption></figure></p><p><figure><img alt='Sidewalk on US 63 at Summitt Street - Looking South' src='https://images-summittdweller.nyc3.cdn.digitaloceanspaces.com/blogs-SummittDweller/4FAD6EDE-0D09-4CB0-836A-4D181AD667CF_1_105_c.jpeg'/><figcaption>You'll just have to take my word for it</figcaption></figure></p><p>Thereâ€™s about 1/2-mile segment of sidewalk, some would say â€œto nowhereâ€, along this side of US 63 in Toledo.  The north end of the segment terminates at 2nd Ave. in Toledo, but thereâ€™s no sidewalk on the north side of that intersection, nor any to the north <strong>for more than a mile!</strong>  The south end of the segment terminates, literally in the middle of a field, presumably at the cityâ€™s shared boundary with Tama.  Fortunately, on the west side of US 63 thereâ€™s an infrequently-used access/frontage road and itâ€™s paved to provide access to some South Tama High School athletic fields. <em>Itâ€™s ironic, you canâ€™t safely walk to school because there are so few sidewalks, but thereâ€™s a paved drive to the the baseball diamond, where thereâ€™s no place to park.</em> ðŸ˜¦</p><p>The entire length of this sidewalk is covered in snow, and I canâ€™t recall any time this winter when any portion of it has been cleared. ðŸ˜¦ In fact, the snow here is exceptionally deep and difficult to walk trough because it includes everything that the snow plows have churned up. ðŸ˜¦ðŸ˜¦ Spring canâ€™t come soon enough for me!</p><p><em>Iâ€™ll post more regarding gaps and crossings as soon as I have that map and maybe some photos.</em></p></p></article><!--kg-card-end: html-->",
            "comment_id": "1",
            "plaintext": "For 2021 Iâ€™ve signed on to be a member of the steering committee for Toledoâ€™s 2021 Community Visioning (CV) project coordinated by Treeâ€™s Forever and Iowaâ€™s Living Roadways, Iowa State University Extension and Outreach, and other partners. Tama is also a Community Visioning participant in 2021.\n\n\nI Like to Walk\n\nI try to get outside and walk as much as I can, but I especially like walking with a purposeâ€¦ not just walking for the sake of exercise or stress-relief. I guess thatâ€™s also why I dislike walking indoors on a treadmill, or the â€œdreadmillâ€ as I like to call it. So, if I have somewhere to go in Tama-Toledo Iâ€™ll walk there and back whenever possible. Fortunately, my home in Toledo is geographically centered between the two communities. If you draw a 1.5-mile radius circle around my house it will include ALL of the two communities. Itâ€™s ideal for walking, except for the hills ðŸŒ„, and the challenge of finding a safe route.\n\n\nFormidable Challenges\n\nTama-Toledo does have some nice sidewalks and trails that I try to take advantage of when I walk; however, there are three BIG challenges to using them safely:\n\n * Gaps,\n * Lack of Safe Crossings, and\n * Snow.\n\n\nGaps\n\nThis challenge is going to be difficult to explain in detail at this time. Why, you ask? Because I really need a map to do it justice, and probably some photos too. I donâ€™t have a good map at this time, but I hope that the Tama and Toledo CV teams will come up with one (or two) soon. Iâ€™d also like to collect and post some photos, but thereâ€™s about a foot of snow covering everything, and I do mean everything (see below), right now.\n\n\nLack of Safe Crossings\n\nTama-Toledo, and my home, are situated at the intersection of two major highways:\n\n * US Highway 30, running east-west, and\n * US Highway 63, running north-south.\n\nIâ€™ll write more about these two obstacles later, when I have that map.\n\n\nSnow â„ï¸\n\nI should probably include rain in this paragraph too, and the mud that naturally comes with either snow or rain, in locations where there is no pavement (thatâ€™s a gap!). I think everyone can agree that safely traversing any wet surface can be a challenge, espeically where thereâ€™s no pavement. Anyone whoâ€™s experienced winter in the upper-midwest also knows that snow and ice make that challenge even greater, even where there is pavement!\n\n20-Feb-2021\n\nThis morning my daugther called and asked if I could bring her a USB â€œprinter cableâ€; sheâ€™s volunteering at a local youth archery tournament at the South Tama County High School, less than 1/2-mile from my home. A perfect opportunity for a short walk! There are no sidewalks on my street (another gap) but the roadway is not too busy so thatâ€™s okay. There is a nice sidewalk that runs part of the way (yup, another gap!) from my street to the High School along US 63, so thatâ€™s also helpful. Unfortunately, the photos Iâ€™m including below show the condition of that sidewalk on this lovely Saturday morning.\n\n\n\n\n\n\n\n\n\nThereâ€™s about 1/2-mile segment of sidewalk, some would say â€œto nowhereâ€, along this side of US 63 in Toledo. The north end of the segment terminates at 2nd Ave. in Toledo, but thereâ€™s no sidewalk on the north side of that intersection, nor any to the north for more than a mile! The south end of the segment terminates, literally in the middle of a field, presumably at the cityâ€™s shared boundary with Tama. Fortunately, on the west side of US 63 thereâ€™s an infrequently-used access/frontage road and itâ€™s paved to provide access to some South Tama High School athletic fields. Itâ€™s ironic, you canâ€™t safely walk to school because there are so few sidewalks, but thereâ€™s a paved drive to the the baseball diamond, where thereâ€™s no place to park. ðŸ˜¦\n\nThe entire length of this sidewalk is covered in snow, and I canâ€™t recall any time this winter when any portion of it has been cleared. ðŸ˜¦ In fact, the snow here is exceptionally deep and difficult to walk trough because it includes everything that the snow plows have churned up. ðŸ˜¦ðŸ˜¦ Spring canâ€™t come soon enough for me!\n\nIâ€™ll post more regarding gaps and crossings as soon as I have that map and maybe some photos.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T00:55:53.000Z",
            "updated_at": "2023-04-02T00:59:03.000Z",
            "published_at": "2021-02-21T01:55:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428de1979896513c53f3a95",
            "uuid": "9575d38c-bb57-447e-9125-530a5acb362f",
            "title": "Thanksgiving 2020",
            "slug": "thanksgiving-2020",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>Sorry, Iâ€™ve posted and experienced too much sadness in the last two weeks, and more. Two members of our immediate family, Sully and Stitch, passed away on November 14th and 20th, respectively. Sully was our male kitty, only about 6 years old and his passing was a real shock.  He was an ornery, sometimes grumpy cat, but very loveable at times. We miss him very much. Stitch was the matriarch of our cat family, about 18 years old and a gorgeous long-haired kitty. Stitch was in poor health the last year or so and not very playful so her passing was not such a shock, but itâ€™s still hard to take. Fortunately, she passed comfortably in her sleep, nestled up on the couch between Mackenzie and Christine. We miss her too.</p><p>Sully and Stitch were buried on the McCune farm just a few days apart, not immediately next to one another, but not too far apart.  They sometimes played together when Stitch would tolerate Sully, but most of the time they were a short distance apart, just as they are now.</p><p>Enough of that, since today is Thanksgiving Iâ€™ll post no more sad news.  Instead, I want to share what Iâ€™m most thankful forâ€¦ family.  And our family has two new fur babies too, Georgie and Jo.  Both are named after characters from Stephen King novelsâ€¦ perhaps a new trend?  Let me explainâ€¦</p><p>Georgie is the best-tempered cat I have ever known. ðŸ˜¸ Sheâ€™s a little over a year old now so she still loves to play, and sheâ€™s made a habit of insisting that I hold her at least a couple of times each day, and give her kitty treats in exchange for snuggles. We captured Georgie in December 2019, she was the last of 3 kittens and 5 adult cats (Uno, Deuce, Tres, Veer and Go) that we caught as part of a TNR (Trap, Neuter and Release) effort that we started as the weather started to turn colder.  Georgieâ€™s siblings found homes at the Tama Co. Humane Shelter (and later with a family in Belle Plaine) and with Morgan, who adpoted â€œLintâ€, a long-haired solid gray kitten that was an odd part of the short-haired tuxedo cats living next door.</p><p><figure><img alt='Georgie - Approx. Age 13 Months' src='https://images.summittdweller.com/Kitty-Photos/Georgie/IMG_0051.png'/><figcaption>Georgie - Approx. Age 13 Months</figcaption></figure><figure><img alt='Georgie - Play with Me!' src='https://images.summittdweller.com/Kitty-Photos/Georgie/IMG_0057.png'/><figcaption>Georgie - Play with Me!</figcaption></figure></p><p>Georgie was the last of the 8 cats that we caught and she managed to avoid the traps quite well. Since we were concerned for her wellbeing, as she was all alone, we decided to try and catch her without a trap, and managed to do so after she elluded us for an hour or so.  She managed to get away by ducking into a storm sewer opening down the street, thatâ€™s why we named her Georgie, after the poor little boy featured in the opening of Kingâ€™s story, â€œItâ€. Like â€œItâ€, sheâ€™s also a â€œcollectorâ€, always picking things up and carrying them away to who-knows-where.  ðŸ˜„</p><p>Jo, or JoJo, or Joey, or Cujo, is the new addition to the family. ðŸ±  Even before Stitch passed we put the word out that we might be looking for another kitty, somebody to keep Georgie company when no humans are home.  Well, we received word of a farm kitten looking for a home and paid it a visit one week ago on Thursday night, November 19. Stitch passed the next evening and on Sunday, November 22nd, the kitten came to live with us.  She saw the vet on Monday for an initial checkup and sheâ€™s sequestered in a spare bedroom for about 2 weeks to give her eyes and nose a chance to clear upâ€¦ that process has started but sheâ€™s still got some eye goop as you can see.</p><p><figure><img alt='Jo - Approx. Age 2 Months' src='https://images.summittdweller.com/Kitty-Photos/Jo/IMG_0038.png'/><figcaption>Jo - Approx. Age 2 Months</figcaption></figure><figure><img alt='Jo - In a Rare, Calm Moment' src='https://images.summittdweller.com/Kitty-Photos/Jo/IMG_0034.png'/><figcaption>Jo - In a Rare, Calm Moment</figcaption></figure><figure><img alt='Jo - The Wee Beastie Sleeps After Turkey Dinner' src='https://images.summittdweller.com/Kitty-Photos/Jo/theWeeBeastieSleeps.jpg'/><figcaption>The Wee Beastie Sleeps after Turkey Dinner</figcaption></figure></p><p>Mackenzie suggested we name her â€œCujoâ€ since the farmerâ€™s dog got hold of her in the farmyard. Also, Stephen King. ðŸ˜„ The farmer was going to keep her as an indoor kitty due to the dog incident, but was overruled by her spouse. Their loss, our gain. We decided that the name could also stand for â€œCute Joâ€, and that stuck, along with all the other forms of the name. Jo is all kitten, but not afraid of anyone. Sheâ€™s quick to snuggle up, but also loves to claw and bite when sheâ€™s in a mood to play.  We are trying to teach her that toys=play while toes=snuggles, and the same for other body parts. I think sheâ€™ll come around just fine.  Just wish she didnâ€™t have to quarantine for another 10 days. ðŸ˜¦  But of course, itâ€™s #2020.</p><p>Thatâ€™s a wrap. Until next timeâ€¦ but only after I play with Georgie and give Jo another snuggle.</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>Sorry, Iâ€™ve posted and experienced too much sadness in the last two weeks, and more. Two members of our immediate family, Sully and Stitch, passed away on November 14th and 20th, respectively. Sully was our male kitty, only about 6 years old and his passing was a real shock.  He was an ornery, sometimes grumpy cat, but very loveable at times. We miss him very much. Stitch was the matriarch of our cat family, about 18 years old and a gorgeous long-haired kitty. Stitch was in poor health the last year or so and not very playful so her passing was not such a shock, but itâ€™s still hard to take. Fortunately, she passed comfortably in her sleep, nestled up on the couch between Mackenzie and Christine. We miss her too.</p><p>Sully and Stitch were buried on the McCune farm just a few days apart, not immediately next to one another, but not too far apart.  They sometimes played together when Stitch would tolerate Sully, but most of the time they were a short distance apart, just as they are now.</p><p>Enough of that, since today is Thanksgiving Iâ€™ll post no more sad news.  Instead, I want to share what Iâ€™m most thankful forâ€¦ family.  And our family has two new fur babies too, Georgie and Jo.  Both are named after characters from Stephen King novelsâ€¦ perhaps a new trend?  Let me explainâ€¦</p><p>Georgie is the best-tempered cat I have ever known. ðŸ˜¸ Sheâ€™s a little over a year old now so she still loves to play, and sheâ€™s made a habit of insisting that I hold her at least a couple of times each day, and give her kitty treats in exchange for snuggles. We captured Georgie in December 2019, she was the last of 3 kittens and 5 adult cats (Uno, Deuce, Tres, Veer and Go) that we caught as part of a TNR (Trap, Neuter and Release) effort that we started as the weather started to turn colder.  Georgieâ€™s siblings found homes at the Tama Co. Humane Shelter (and later with a family in Belle Plaine) and with Morgan, who adpoted â€œLintâ€, a long-haired solid gray kitten that was an odd part of the short-haired tuxedo cats living next door.</p><p><figure><img alt='Georgie - Approx. Age 13 Months' src='https://images.summittdweller.com/Kitty-Photos/Georgie/IMG_0051.png'/><figcaption>Georgie - Approx. Age 13 Months</figcaption></figure><figure><img alt='Georgie - Play with Me!' src='https://images.summittdweller.com/Kitty-Photos/Georgie/IMG_0057.png'/><figcaption>Georgie - Play with Me!</figcaption></figure></p><p>Georgie was the last of the 8 cats that we caught and she managed to avoid the traps quite well. Since we were concerned for her wellbeing, as she was all alone, we decided to try and catch her without a trap, and managed to do so after she elluded us for an hour or so.  She managed to get away by ducking into a storm sewer opening down the street, thatâ€™s why we named her Georgie, after the poor little boy featured in the opening of Kingâ€™s story, â€œItâ€. Like â€œItâ€, sheâ€™s also a â€œcollectorâ€, always picking things up and carrying them away to who-knows-where.  ðŸ˜„</p><p>Jo, or JoJo, or Joey, or Cujo, is the new addition to the family. ðŸ±  Even before Stitch passed we put the word out that we might be looking for another kitty, somebody to keep Georgie company when no humans are home.  Well, we received word of a farm kitten looking for a home and paid it a visit one week ago on Thursday night, November 19. Stitch passed the next evening and on Sunday, November 22nd, the kitten came to live with us.  She saw the vet on Monday for an initial checkup and sheâ€™s sequestered in a spare bedroom for about 2 weeks to give her eyes and nose a chance to clear upâ€¦ that process has started but sheâ€™s still got some eye goop as you can see.</p><p><figure><img alt='Jo - Approx. Age 2 Months' src='https://images.summittdweller.com/Kitty-Photos/Jo/IMG_0038.png'/><figcaption>Jo - Approx. Age 2 Months</figcaption></figure><figure><img alt='Jo - In a Rare, Calm Moment' src='https://images.summittdweller.com/Kitty-Photos/Jo/IMG_0034.png'/><figcaption>Jo - In a Rare, Calm Moment</figcaption></figure><figure><img alt='Jo - The Wee Beastie Sleeps After Turkey Dinner' src='https://images.summittdweller.com/Kitty-Photos/Jo/theWeeBeastieSleeps.jpg'/><figcaption>The Wee Beastie Sleeps after Turkey Dinner</figcaption></figure></p><p>Mackenzie suggested we name her â€œCujoâ€ since the farmerâ€™s dog got hold of her in the farmyard. Also, Stephen King. ðŸ˜„ The farmer was going to keep her as an indoor kitty due to the dog incident, but was overruled by her spouse. Their loss, our gain. We decided that the name could also stand for â€œCute Joâ€, and that stuck, along with all the other forms of the name. Jo is all kitten, but not afraid of anyone. Sheâ€™s quick to snuggle up, but also loves to claw and bite when sheâ€™s in a mood to play.  We are trying to teach her that toys=play while toes=snuggles, and the same for other body parts. I think sheâ€™ll come around just fine.  Just wish she didnâ€™t have to quarantine for another 10 days. ðŸ˜¦  But of course, itâ€™s #2020.</p><p>Thatâ€™s a wrap. Until next timeâ€¦ but only after I play with Georgie and give Jo another snuggle.</p></p></article><!--kg-card-end: html-->",
            "comment_id": "1",
            "plaintext": "Sorry, Iâ€™ve posted and experienced too much sadness in the last two weeks, and more. Two members of our immediate family, Sully and Stitch, passed away on November 14th and 20th, respectively. Sully was our male kitty, only about 6 years old and his passing was a real shock. He was an ornery, sometimes grumpy cat, but very loveable at times. We miss him very much. Stitch was the matriarch of our cat family, about 18 years old and a gorgeous long-haired kitty. Stitch was in poor health the last year or so and not very playful so her passing was not such a shock, but itâ€™s still hard to take. Fortunately, she passed comfortably in her sleep, nestled up on the couch between Mackenzie and Christine. We miss her too.\n\nSully and Stitch were buried on the McCune farm just a few days apart, not immediately next to one another, but not too far apart. They sometimes played together when Stitch would tolerate Sully, but most of the time they were a short distance apart, just as they are now.\n\nEnough of that, since today is Thanksgiving Iâ€™ll post no more sad news. Instead, I want to share what Iâ€™m most thankful forâ€¦ family. And our family has two new fur babies too, Georgie and Jo. Both are named after characters from Stephen King novelsâ€¦ perhaps a new trend? Let me explainâ€¦\n\nGeorgie is the best-tempered cat I have ever known. ðŸ˜¸ Sheâ€™s a little over a year old now so she still loves to play, and sheâ€™s made a habit of insisting that I hold her at least a couple of times each day, and give her kitty treats in exchange for snuggles. We captured Georgie in December 2019, she was the last of 3 kittens and 5 adult cats (Uno, Deuce, Tres, Veer and Go) that we caught as part of a TNR (Trap, Neuter and Release) effort that we started as the weather started to turn colder. Georgieâ€™s siblings found homes at the Tama Co. Humane Shelter (and later with a family in Belle Plaine) and with Morgan, who adpoted â€œLintâ€, a long-haired solid gray kitten that was an odd part of the short-haired tuxedo cats living next door.\n\n\n\n\n\nGeorgie was the last of the 8 cats that we caught and she managed to avoid the traps quite well. Since we were concerned for her wellbeing, as she was all alone, we decided to try and catch her without a trap, and managed to do so after she elluded us for an hour or so. She managed to get away by ducking into a storm sewer opening down the street, thatâ€™s why we named her Georgie, after the poor little boy featured in the opening of Kingâ€™s story, â€œItâ€. Like â€œItâ€, sheâ€™s also a â€œcollectorâ€, always picking things up and carrying them away to who-knows-where. ðŸ˜„\n\nJo, or JoJo, or Joey, or Cujo, is the new addition to the family. ðŸ± Even before Stitch passed we put the word out that we might be looking for another kitty, somebody to keep Georgie company when no humans are home. Well, we received word of a farm kitten looking for a home and paid it a visit one week ago on Thursday night, November 19. Stitch passed the next evening and on Sunday, November 22nd, the kitten came to live with us. She saw the vet on Monday for an initial checkup and sheâ€™s sequestered in a spare bedroom for about 2 weeks to give her eyes and nose a chance to clear upâ€¦ that process has started but sheâ€™s still got some eye goop as you can see.\n\n\n\n\n\nMackenzie suggested we name her â€œCujoâ€ since the farmerâ€™s dog got hold of her in the farmyard. Also, Stephen King. ðŸ˜„ The farmer was going to keep her as an indoor kitty due to the dog incident, but was overruled by her spouse. Their loss, our gain. We decided that the name could also stand for â€œCute Joâ€, and that stuck, along with all the other forms of the name. Jo is all kitten, but not afraid of anyone. Sheâ€™s quick to snuggle up, but also loves to claw and bite when sheâ€™s in a mood to play. We are trying to teach her that toys=play while toes=snuggles, and the same for other body parts. I think sheâ€™ll come around just fine. Just wish she didnâ€™t have to quarantine for another 10 days. ðŸ˜¦ But of course, itâ€™s #2020.\n\nThatâ€™s a wrap. Until next timeâ€¦ but only after I play with Georgie and give Jo another snuggle.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:44:57.000Z",
            "updated_at": "2023-04-02T03:48:00.000Z",
            "published_at": "2020-11-26T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e0e465e54c1436c5785d",
            "uuid": "afe1db8e-a78e-4992-a224-9f19782249d1",
            "title": "Moving to Netlify CMS",
            "slug": "moving-to-netlify-cms",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>In my last post, <a href='http://localhost:1313/posts/2021/04/moving-to-netlify-cms/posts/2021/03/adding-netlify-to-this-blog/'>Adding <em>Netlify CMS</em> for Editing This Blog</a>, I was able to successfully engage the <a href='https://www.netlifycms.org/'><em>Netlify CMS</em></a> with a â€œlocalâ€ copy of this blog.  But I never got the CMS to work in production with this blogâ€™s App on <a href='https://www.digitalocean.com/'><em>DigitalOcean</em></a> (<em>DO</em>). I should note that <em>DO</em>â€™s support folks were very helpful, but in the end I think all of the client-side stuff that <em>Netlify CMS</em> is doing was more than they were willing (capable?) of helping me overcome. Thatâ€™s probably my fault more than theirâ€™s; client-side isnâ€™t my strong suit.</p><p>In the week since then I have, however, been able to stand up a new working copy of the <a href='https://wieting.Tama-Toledo.com'><em>Wieting Theatre</em> website</a> on <a href='https://www.netlify.com/'><em>Netlify.com</em></a>, where it enjoys the same kind of automated builds and automatic deployment that I previously found at <em>DO</em>.  The big difference, at Netlify.com my <em>Netlify CMS</em> depoloyment works locally AND in production, giving me the ability to allow content editors, even those who donâ€™t have a <em>Netlify.com</em> or <em>GitHub</em> account, to do what they do best, edit their content.</p><h2 id='the-_wieting-theatre_s-new-site-and-the-_crb_'>The <em>Wieting Theatre</em>â€™s New Site, and the <em>CRB</em></h2><p>So this post started as a brain dump, chronicling how I got <a href='https://Wieting.Tama-Toledo.com'>https://Wieting.Tama-Toledo.com</a> to work.  But, instead of hashing out how I â€œdidâ€ it, Iâ€™m going to show you how Iâ€™m doing something similar, for a site that features the <em>Compass Rose Band</em>, or <em>CRB</em>, my brother-in-lawâ€™s band out of Cedar Rapids, Iowa.</p><h2 id='netlify-identity'>Netlify Identity</h2><p>I think the real key to all of this is a <em>Netlify.com</em> agent called <a href='https://docs.netlify.com/visitor-access/identity/'><em>Netlify Identity</em></a>. From the <em>Netlify.com</em> site and documentationâ€¦</p><div class='original'><p><em>Netlify Identity</em> service brings a full suite of authentication functionality, backed by the <em>GoTrue</em> API. This allows you to manage and authenticate users on your site or app, without requiring them to be users of <em>Netlify</em> or any other service. You can use this for gated content, site administration, and more.</p></div><p>In theory, <em>Netlify Identity</em> can be deployed anywhere, but in practice, setting it up can be quite tricky (at least it was for me).  Thatâ€™s where <em>Netlify.com</em> shines, and thatâ€™s understandable since they created both <em>Netlify CMS</em> and <em>Netlify Identity</em>. The two creations play well together, and make life easier for a devops like me. Well played indeed.</p><p>If you read my previous post you know that in a <a href='https://gohugo.io'><em>Hugo</em></a> site, like this one, the <code>./static/admin/config.yml</code> file holds all of your CMS info.  If you host content on <em>Netlify.com</em> with <em>Netlify CMS</em> and <em>Netlify Identity</em> engaged, all you really need in that config file is something like this:</p><pre tabindex='0'><code>backend:  name: git-gateway  branch: main...</code></pre><p>The rest of the CMS â€œmagicâ€ takes place in a server-side access manager that you can find at your <em>Netlify.com</em> site folder at <code>https://app.netlify.com/sites/[site-name]/identity</code>.  The client-side of the access/identity equation can be handled with an app template, and you can choose from many starter templates found at <a href='https://www.netlifycms.org/docs/start-with-a-template'>Start with a Template</a>.</p><h3 id='external-oauth-without-_netlifycom_'>External OAuth without <em>Netlify.com</em></h3><p>If you wish to proceed without using <em>Netlify.com</em> as your host, youâ€™ll find a number of options at <a href='https://www.netlifycms.org/docs/external-oauth-clients/'>External OAuth Client</a>. Beware, this option isnâ€™t for a server-side guy like me, and the <em>Netlify.com</em> option is quick, easy, and cheapâ€¦ at least I think so.</p><h2 id='building-a-new-_compass-rose-band_-site-on-_netlifycom_'>Building a New <em>Compass Rose Band</em> Site on <em>Netlify.com</em></h2><p>Rather than rehashing the story of my <em>Wieting Theatre</em> migration to <em>Netlify.com</em>, Iâ€™m going to repeat that process and capture the journey while migrating our existing <em>Compass Rose Band</em> site from <em>DO</em>.</p><h3 id='using-_netlifycom_-and-one-click-hugo-cms'>Using <em>Netlify.com</em> and <code>one-click-hugo-cms</code></h3><p>From the <a href='https://www.netlifycms.org/docs/start-with-a-template'>Start with a Template</a> I clicked the <code>Deploy to Netlify</code> button under the â€˜Hugo Site Starterâ€™ option. This was super easy since <em>Netlify.com</em> already knows meâ€¦ because I created a free account about a week ago. That selection took me to a screen where I was asked to identify a new <em>Github</em> repostory. Again, super easy because I had already logged in to <em>Github</em> earlier.</p><p>The default name for this new repository is <code>one-click-hugo-cms</code>, same as the template repository it will be built from. I choose to name my new repo <code>compass-rose-band-one-click</code>, for obvious reasons. That repository can be found at <a href='https://github.com/SummittDweller/compass-rose-band-one-click'>https://github.com/SummittDweller/compass-rose-band-one-click</a> where the <code>README.md</code> file is titled â€œHugo template for Netlify CMS with Netlify Identityâ€. The initial repository contents looked like this:</p><p><figure><img alt='one-click-hugo-cms' src='http://localhost:1313/img/one-click-hugo-cms.png'/><figcaption></figcaption></figure></p><h3 id='replacing-the-site'>Replacing the <code>/site</code></h3><p>A default <em>Hugo</em> site is automatically built and deployed for you as part of the one-click process, and <em>Netlify.com</em> will supply an address so you can see your creation. But thatâ€™s not the <em>Compass Rose Band</em>! No problem, I found it quick and easy to replace the default template site by first cloning my new repo to my workstation, and replacing the <code>/site</code> directory with my own contents.  It went like thisâ€¦</p><ul><li><code>cd ~/GitHub</code>  â¬… This is where I keep local copies of all my GitHub projects.</li><li><code>git clone https://github.com/SummittDweller/compass-rose-band-one-click</code></li><li><code>cd compass-rose-band-one-click</code></li><li><code>git branch -m master main</code>  â¬… Optional step, changes my local branch name to â€˜mainâ€™.</li><li><code>rm -fr site/*</code>  â¬… Remove the template site, the contents of <code>/site</code>.</li><li><code>cp -fr ~/GitHub/compass-rose-band/* site/.</code>  â¬… Copy my local CRB site<sup>*</sup> to <code>/site</code>.</li></ul><p><sup>*</sup>Note that copying in the manner excludes all . files and directories, so the <code>.git</code> folder is NOT copied. This is IMPORTANT!</p><p>At this point, your old site has a new home in <code>./site</code> so if you navigate there and do <code>hugo server</code> you should see a local instance of the site.  Like soâ€¦</p><ul><li><code>cd site</code></li><li><code>hugo server</code></li><li>Visit <code>localhost:1313</code>, or whatever localhost site is indicated, to see your site.</li></ul><h3 id='pushing-the-site-to-_github_'>Pushing the Site to <em>Github</em></h3><p>So, now your <em>Netlify.com</em> project lives in a directory like my <code>~/GitHub/compass-rose-band-one-click</code>, and the corresponding <em>Hugo</em> site contents are in the <code>./site</code> folder there. To deploy this new copy of your site to <em>Netlify.com</em> simply do like thisâ€¦</p><ul><li><code>cd ~/GitHub/compass-rose-band-one-click</code></li><li><code>git add .</code></li><li><code>git commit -m 'Now with CRB site contents in ./site'</code></li><li><code>git push -u origin main</code></li></ul><h3 id='deploying-the-site-on-_netlifycom_'>Deploying the Site on <em>Netlify.com</em></h3><p>By default, pushing your changes to <em>Github</em> will automatically deploy them to your <em>Netlify.com</em> site, but you pushed to <code>main</code>, not <code>master</code>, so no synchornization is likely. But thatâ€™s easy to fix.</p><p>Navigate your browser to your <em>Netlify.com</em> â€œteamâ€ page, find your new project there, and click on <code>Site Settings</code>. Next youâ€™ll see options for things like changing the name of your project and site.  I changed mine to <code>compass-rose-band-one-click</code> to match my <em>Github</em> repo name.</p><p>Visit the <code>Build &amp; Deploy</code> link in the menu on the left side of the page, find the <code>Deploy contexts</code> info and click <code>Edit settings</code> there so you can change the production branch setting from <code>master</code> to <code>main</code>.  Leave the default setting of â€œAny pull request against your production branch / branch deploy branchesâ€ selected.</p><p>Next, visit the â€œDeploysâ€ page in your <em>Netlify.com</em> project page at <code>https://app.netlify.com/sites/[project-name]/deploys</code>, mine is <a href='https://app.netlify.com/sites/compass-rose-band-one-click/deploys'>https://app.netlify.com/sites/compass-rose-band-one-click/deploys</a>, and click the <code>Trigger deploy</code> button there.  You should then see a log of the deployment as it runs, and this time it should target your new <code>main</code> branch with your updated <code>./site</code> contents.</p><p>If successful you should see a screen featuring a block like this one:</p><p><figure><img alt='Successfuly deployed on &lt;em&gt;Netlify.com&lt;/em&gt;' src='http://localhost:1313/img/netlify-preview-deploy.png'/><figcaption></figcaption></figure></p><p>Click on the <code>Preview deploy â¬ˆ</code> link and voilÃ , your site!</p><h2 id='now_netlify-cms_'>Nowâ€¦<em>Netlify CMS</em></h2><p>Itâ€™s getting late on this Sunday night so Iâ€™ll share the first few lines from the latest copy of my new projectâ€™s <code>./site/static/admin/config.yml</code> file for <em>Netlify CMS</em>.</p><pre tabindex='0'><code>backend:  name: git-gateway  branch: main## To make local_backend mode work you must run 'npx netlify-cms-proxy-server' in its own terminal window##   from the project root.  See https://www.netlifycms.org/docs/beta-features/ for details.local_backend: truemedia_folder: site/static/img    public_folder: /img...</code></pre><h3 id='whats-all-that'>Whatâ€™s All That?</h3><p>Iâ€™m back, as promised, and youâ€™re probably asking what all that stuff in the <code>config.yml</code> file is doing? Well, as mentioned earlier, the simple <code>backend:</code> section (first three lines) links the CMS to the <code>main</code> branch of our new <em>Github</em> project.  The rest isnâ€™t required, unless you also want to use the CMS on a local clone of the project, like when making mass edits locally.</p><p>Let me try to explain.</p><h3 id='local_backend-a-_netlify-cms_-beta-feature'><code>local_backend:</code> A <em>Netlify CMS</em> Beta Feature</h3><p>If you visit the <em>Netlify CMS</em>â€™ <a href='https://www.netlifycms.org/docs/beta-features/'>Beta Features!</a> pages youâ€™ll see <code>local_backend</code> mentioned near the very top. [<em>Note that as a beta feature this information is bound to move at some point.</em>] That feature enables configuration of an option to make the CMS avaialble when working locally on a cloned, presumably, copy of the <em>Github</em> repository.  The beta documentation mentions running <code>npx netlify-cms-proxy-server</code> as part of the process.</p><h3 id='a-local-problem-with-site--no-not-really'>A Local Problem with <code>./site</code>?  No, Not Really</h3><p>So, in the local clone of my new <em>Compass Rose Band</em> one-click <em>Hugo</em> website, the â€œone-clickâ€ <em>Netlify CMS</em> parts live in the projectâ€™s root directory, and the <em>Hugo</em> site lives just â€œbelowâ€ it in <code>./site</code>.  Accordingly my <code>media_folder:</code> setting shown above includes the <code>site/</code> prefix, and the same is true of all the <code>config.yml</code> keys that end in <code>folder:</code>.  This is correct for production, and it also works with a local clone IF I launch things correctly!</p><p><em>Hugo</em> and the <code>hugo server</code> command that I need to preview local changes demands that I either <code>cd site</code> before I run it, or override the commandâ€™s path by specifying <code>hugo server -s site</code>.  Only this 2nd approach works!</p><p>So the process thatâ€™s needed for local development and testing, including <em>Netlify CMS</em> looks like this for me:</p><ul><li>If I donâ€™t yet have the project locally I will begin withâ€¦<code>cd ~/GitHub; git clone --recursive https://github.com/SummittDweller/compass-rose-band-one-click; cd compass-rose-band-one-click</code></li><li>If I already have a local clone Iâ€™ll do thisâ€¦<code>cd ~/GitHub/compass-rose-band-one-click; git pull</code></li></ul><p>From here on out thereâ€™s just one process, like soâ€¦</p><ul><li><code>npx netlify-cms-proxy-server</code>   â¬… In a new terminal window. See next section of this post.</li><li><code>atom .</code>  â¬… Launch <em>Atom</em> in the working directory.</li><li><code>hugo server -s site</code>  â¬… <strong>Important:</strong> Donâ€™t forget the <code>-s site</code> option!</li><li>Create and edit files as needed. Changes should be immediately visible in <code>http://localhost:1313</code>.</li><li>To edit or create content using <em>Netlify CMS</em>, just visit <code>http://localhost:1313/admin/</code>.</li><li>When all changes are completeâ€¦<ul><li><code>git add .</code></li><li><code>git commit -m 'a brief message here'</code></li><li><code>git push</code></li></ul></li></ul><h3 id='requires-_npx_-part-of-_nodejs_'>Requires <em>npx</em>, Part of <em>Node.js</em></h3><p>The <code>npx</code> command mentioned above requires that <em>npx</em> be installed, and itâ€™s part of <em>Node.js</em>.  To make it run properly I followed guidance from <a href='https://treehouse.github.io/installation-guides/mac/node-mac.html'>https://treehouse.github.io/installation-guides/mac/node-mac.html</a> to ensure both were installed.  In at least one instance I also had to run <code>brew upgrade node</code> and <code>npm i -g npx</code> to ensure that <em>Node.js</em> was up-to-date, and that <em>npx</em> was available as needed.</p><p>The <code>npx netlify-cms-proxy-server</code>, loads and runs the <em>netlify-cms-proxy-server</em> script, and in doing so it will tie up your terminal window.  So, itâ€™s best to <strong>do this in a separate terminal window!</strong>  Donâ€™t put the command in the background (using a <code>&amp;</code> flag at the end) as this wonâ€™t allow you to see if the command is working properly. When you run this command you should see some feedback from the script indicating what it is doing. The script binds to your working directory then effectively routes all <em>Netlify CMS</em> actions, performed in this instance via <code>http://localhost:1313/admin/</code>, to the local <em>git</em> repo there.</p><h2 id='ok-now-we-need-a-proper-domain'>Ok, Now We Need a Proper Domain</h2><p>So, in its original form the <em>Compass Rose Band</em> site is aliased to three different domains:</p><ul><li><a href='https://compassroseband.net'>https://compassroseband.net</a>,</li><li><a href='https://thecompassroseband.com'>https://thecompassroseband.com</a>, and</li><li><a href='https://thecompassroseband.net'>https://thecompassroseband.net</a></li></ul><p>I choose to try migrating these domains to the new <em>Netlify.com</em> site one-at-a-time, starting with the least-used domain, <em>thecompassroseband.net</em>.</p><p>To do this I started by visiting my <em>Netlify.com</em> account/team and the <code>Domains</code> menu, then my project-specific domain settings at <a href='https://app.netlify.com/teams/summittdweller/dns/thecompassroseband.net'>https://app.netlify.com/teams/summittdweller/dns/thecompassroseband.net</a>.  In this page Iâ€™m given a list of 4 <em>Netlify.com</em> name servers that I can use for this particular project.  I made note of the four before moving on.</p><p>Next step was to visit my registrar, <em>enom.com</em>, where I have a control screen for editing DNS records and name servers.  I set the name server values for <em>thecompassroseband.net</em> there to the values that <em>Netlify.com</em> provided. And then, we waitâ€¦ for the changes to propogate.</p><p>Fortunately, <em>Netlify.com</em> is on the ballâ€¦ when I visit my new siteâ€™s domain controls page, <a href='https://app.netlify.com/sites/compass-rose-band-one-click/settings/domain'>https://app.netlify.com/sites/compass-rose-band-one-click/settings/domain</a>, I find a widget that looks like this:</p><p><figure><img alt='DNS Propogation' src='http://localhost:1313/img/netlify-dns-propogation.png'/><figcaption></figcaption></figure></p><p>The cog behind â€œWaiting on DNS propagationâ€ is spinning while <em>Netlify.com</em> waits for the transfer to happen.  So, Iâ€™m going to go for a walk and see what that cog looks like in an hour or two.</p><hr/><p>Clear as mud?  Give it a try, and hopefully it will begin to make sense.  Until next timeâ€¦</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>In my last post, <a href='http://localhost:1313/posts/2021/04/moving-to-netlify-cms/posts/2021/03/adding-netlify-to-this-blog/'>Adding <em>Netlify CMS</em> for Editing This Blog</a>, I was able to successfully engage the <a href='https://www.netlifycms.org/'><em>Netlify CMS</em></a> with a â€œlocalâ€ copy of this blog.  But I never got the CMS to work in production with this blogâ€™s App on <a href='https://www.digitalocean.com/'><em>DigitalOcean</em></a> (<em>DO</em>). I should note that <em>DO</em>â€™s support folks were very helpful, but in the end I think all of the client-side stuff that <em>Netlify CMS</em> is doing was more than they were willing (capable?) of helping me overcome. Thatâ€™s probably my fault more than theirâ€™s; client-side isnâ€™t my strong suit.</p><p>In the week since then I have, however, been able to stand up a new working copy of the <a href='https://wieting.Tama-Toledo.com'><em>Wieting Theatre</em> website</a> on <a href='https://www.netlify.com/'><em>Netlify.com</em></a>, where it enjoys the same kind of automated builds and automatic deployment that I previously found at <em>DO</em>.  The big difference, at Netlify.com my <em>Netlify CMS</em> depoloyment works locally AND in production, giving me the ability to allow content editors, even those who donâ€™t have a <em>Netlify.com</em> or <em>GitHub</em> account, to do what they do best, edit their content.</p><h2 id='the-_wieting-theatre_s-new-site-and-the-_crb_'>The <em>Wieting Theatre</em>â€™s New Site, and the <em>CRB</em></h2><p>So this post started as a brain dump, chronicling how I got <a href='https://Wieting.Tama-Toledo.com'>https://Wieting.Tama-Toledo.com</a> to work.  But, instead of hashing out how I â€œdidâ€ it, Iâ€™m going to show you how Iâ€™m doing something similar, for a site that features the <em>Compass Rose Band</em>, or <em>CRB</em>, my brother-in-lawâ€™s band out of Cedar Rapids, Iowa.</p><h2 id='netlify-identity'>Netlify Identity</h2><p>I think the real key to all of this is a <em>Netlify.com</em> agent called <a href='https://docs.netlify.com/visitor-access/identity/'><em>Netlify Identity</em></a>. From the <em>Netlify.com</em> site and documentationâ€¦</p><div class='original'><p><em>Netlify Identity</em> service brings a full suite of authentication functionality, backed by the <em>GoTrue</em> API. This allows you to manage and authenticate users on your site or app, without requiring them to be users of <em>Netlify</em> or any other service. You can use this for gated content, site administration, and more.</p></div><p>In theory, <em>Netlify Identity</em> can be deployed anywhere, but in practice, setting it up can be quite tricky (at least it was for me).  Thatâ€™s where <em>Netlify.com</em> shines, and thatâ€™s understandable since they created both <em>Netlify CMS</em> and <em>Netlify Identity</em>. The two creations play well together, and make life easier for a devops like me. Well played indeed.</p><p>If you read my previous post you know that in a <a href='https://gohugo.io'><em>Hugo</em></a> site, like this one, the <code>./static/admin/config.yml</code> file holds all of your CMS info.  If you host content on <em>Netlify.com</em> with <em>Netlify CMS</em> and <em>Netlify Identity</em> engaged, all you really need in that config file is something like this:</p><pre tabindex='0'><code>backend:  name: git-gateway  branch: main...</code></pre><p>The rest of the CMS â€œmagicâ€ takes place in a server-side access manager that you can find at your <em>Netlify.com</em> site folder at <code>https://app.netlify.com/sites/[site-name]/identity</code>.  The client-side of the access/identity equation can be handled with an app template, and you can choose from many starter templates found at <a href='https://www.netlifycms.org/docs/start-with-a-template'>Start with a Template</a>.</p><h3 id='external-oauth-without-_netlifycom_'>External OAuth without <em>Netlify.com</em></h3><p>If you wish to proceed without using <em>Netlify.com</em> as your host, youâ€™ll find a number of options at <a href='https://www.netlifycms.org/docs/external-oauth-clients/'>External OAuth Client</a>. Beware, this option isnâ€™t for a server-side guy like me, and the <em>Netlify.com</em> option is quick, easy, and cheapâ€¦ at least I think so.</p><h2 id='building-a-new-_compass-rose-band_-site-on-_netlifycom_'>Building a New <em>Compass Rose Band</em> Site on <em>Netlify.com</em></h2><p>Rather than rehashing the story of my <em>Wieting Theatre</em> migration to <em>Netlify.com</em>, Iâ€™m going to repeat that process and capture the journey while migrating our existing <em>Compass Rose Band</em> site from <em>DO</em>.</p><h3 id='using-_netlifycom_-and-one-click-hugo-cms'>Using <em>Netlify.com</em> and <code>one-click-hugo-cms</code></h3><p>From the <a href='https://www.netlifycms.org/docs/start-with-a-template'>Start with a Template</a> I clicked the <code>Deploy to Netlify</code> button under the â€˜Hugo Site Starterâ€™ option. This was super easy since <em>Netlify.com</em> already knows meâ€¦ because I created a free account about a week ago. That selection took me to a screen where I was asked to identify a new <em>Github</em> repostory. Again, super easy because I had already logged in to <em>Github</em> earlier.</p><p>The default name for this new repository is <code>one-click-hugo-cms</code>, same as the template repository it will be built from. I choose to name my new repo <code>compass-rose-band-one-click</code>, for obvious reasons. That repository can be found at <a href='https://github.com/SummittDweller/compass-rose-band-one-click'>https://github.com/SummittDweller/compass-rose-band-one-click</a> where the <code>README.md</code> file is titled â€œHugo template for Netlify CMS with Netlify Identityâ€. The initial repository contents looked like this:</p><p><figure><img alt='one-click-hugo-cms' src='http://localhost:1313/img/one-click-hugo-cms.png'/><figcaption></figcaption></figure></p><h3 id='replacing-the-site'>Replacing the <code>/site</code></h3><p>A default <em>Hugo</em> site is automatically built and deployed for you as part of the one-click process, and <em>Netlify.com</em> will supply an address so you can see your creation. But thatâ€™s not the <em>Compass Rose Band</em>! No problem, I found it quick and easy to replace the default template site by first cloning my new repo to my workstation, and replacing the <code>/site</code> directory with my own contents.  It went like thisâ€¦</p><ul><li><code>cd ~/GitHub</code>  â¬… This is where I keep local copies of all my GitHub projects.</li><li><code>git clone https://github.com/SummittDweller/compass-rose-band-one-click</code></li><li><code>cd compass-rose-band-one-click</code></li><li><code>git branch -m master main</code>  â¬… Optional step, changes my local branch name to â€˜mainâ€™.</li><li><code>rm -fr site/*</code>  â¬… Remove the template site, the contents of <code>/site</code>.</li><li><code>cp -fr ~/GitHub/compass-rose-band/* site/.</code>  â¬… Copy my local CRB site<sup>*</sup> to <code>/site</code>.</li></ul><p><sup>*</sup>Note that copying in the manner excludes all . files and directories, so the <code>.git</code> folder is NOT copied. This is IMPORTANT!</p><p>At this point, your old site has a new home in <code>./site</code> so if you navigate there and do <code>hugo server</code> you should see a local instance of the site.  Like soâ€¦</p><ul><li><code>cd site</code></li><li><code>hugo server</code></li><li>Visit <code>localhost:1313</code>, or whatever localhost site is indicated, to see your site.</li></ul><h3 id='pushing-the-site-to-_github_'>Pushing the Site to <em>Github</em></h3><p>So, now your <em>Netlify.com</em> project lives in a directory like my <code>~/GitHub/compass-rose-band-one-click</code>, and the corresponding <em>Hugo</em> site contents are in the <code>./site</code> folder there. To deploy this new copy of your site to <em>Netlify.com</em> simply do like thisâ€¦</p><ul><li><code>cd ~/GitHub/compass-rose-band-one-click</code></li><li><code>git add .</code></li><li><code>git commit -m 'Now with CRB site contents in ./site'</code></li><li><code>git push -u origin main</code></li></ul><h3 id='deploying-the-site-on-_netlifycom_'>Deploying the Site on <em>Netlify.com</em></h3><p>By default, pushing your changes to <em>Github</em> will automatically deploy them to your <em>Netlify.com</em> site, but you pushed to <code>main</code>, not <code>master</code>, so no synchornization is likely. But thatâ€™s easy to fix.</p><p>Navigate your browser to your <em>Netlify.com</em> â€œteamâ€ page, find your new project there, and click on <code>Site Settings</code>. Next youâ€™ll see options for things like changing the name of your project and site.  I changed mine to <code>compass-rose-band-one-click</code> to match my <em>Github</em> repo name.</p><p>Visit the <code>Build &amp; Deploy</code> link in the menu on the left side of the page, find the <code>Deploy contexts</code> info and click <code>Edit settings</code> there so you can change the production branch setting from <code>master</code> to <code>main</code>.  Leave the default setting of â€œAny pull request against your production branch / branch deploy branchesâ€ selected.</p><p>Next, visit the â€œDeploysâ€ page in your <em>Netlify.com</em> project page at <code>https://app.netlify.com/sites/[project-name]/deploys</code>, mine is <a href='https://app.netlify.com/sites/compass-rose-band-one-click/deploys'>https://app.netlify.com/sites/compass-rose-band-one-click/deploys</a>, and click the <code>Trigger deploy</code> button there.  You should then see a log of the deployment as it runs, and this time it should target your new <code>main</code> branch with your updated <code>./site</code> contents.</p><p>If successful you should see a screen featuring a block like this one:</p><p><figure><img alt='Successfuly deployed on &lt;em&gt;Netlify.com&lt;/em&gt;' src='http://localhost:1313/img/netlify-preview-deploy.png'/><figcaption></figcaption></figure></p><p>Click on the <code>Preview deploy â¬ˆ</code> link and voilÃ , your site!</p><h2 id='now_netlify-cms_'>Nowâ€¦<em>Netlify CMS</em></h2><p>Itâ€™s getting late on this Sunday night so Iâ€™ll share the first few lines from the latest copy of my new projectâ€™s <code>./site/static/admin/config.yml</code> file for <em>Netlify CMS</em>.</p><pre tabindex='0'><code>backend:  name: git-gateway  branch: main## To make local_backend mode work you must run 'npx netlify-cms-proxy-server' in its own terminal window##   from the project root.  See https://www.netlifycms.org/docs/beta-features/ for details.local_backend: truemedia_folder: site/static/img    public_folder: /img...</code></pre><h3 id='whats-all-that'>Whatâ€™s All That?</h3><p>Iâ€™m back, as promised, and youâ€™re probably asking what all that stuff in the <code>config.yml</code> file is doing? Well, as mentioned earlier, the simple <code>backend:</code> section (first three lines) links the CMS to the <code>main</code> branch of our new <em>Github</em> project.  The rest isnâ€™t required, unless you also want to use the CMS on a local clone of the project, like when making mass edits locally.</p><p>Let me try to explain.</p><h3 id='local_backend-a-_netlify-cms_-beta-feature'><code>local_backend:</code> A <em>Netlify CMS</em> Beta Feature</h3><p>If you visit the <em>Netlify CMS</em>â€™ <a href='https://www.netlifycms.org/docs/beta-features/'>Beta Features!</a> pages youâ€™ll see <code>local_backend</code> mentioned near the very top. [<em>Note that as a beta feature this information is bound to move at some point.</em>] That feature enables configuration of an option to make the CMS avaialble when working locally on a cloned, presumably, copy of the <em>Github</em> repository.  The beta documentation mentions running <code>npx netlify-cms-proxy-server</code> as part of the process.</p><h3 id='a-local-problem-with-site--no-not-really'>A Local Problem with <code>./site</code>?  No, Not Really</h3><p>So, in the local clone of my new <em>Compass Rose Band</em> one-click <em>Hugo</em> website, the â€œone-clickâ€ <em>Netlify CMS</em> parts live in the projectâ€™s root directory, and the <em>Hugo</em> site lives just â€œbelowâ€ it in <code>./site</code>.  Accordingly my <code>media_folder:</code> setting shown above includes the <code>site/</code> prefix, and the same is true of all the <code>config.yml</code> keys that end in <code>folder:</code>.  This is correct for production, and it also works with a local clone IF I launch things correctly!</p><p><em>Hugo</em> and the <code>hugo server</code> command that I need to preview local changes demands that I either <code>cd site</code> before I run it, or override the commandâ€™s path by specifying <code>hugo server -s site</code>.  Only this 2nd approach works!</p><p>So the process thatâ€™s needed for local development and testing, including <em>Netlify CMS</em> looks like this for me:</p><ul><li>If I donâ€™t yet have the project locally I will begin withâ€¦<code>cd ~/GitHub; git clone --recursive https://github.com/SummittDweller/compass-rose-band-one-click; cd compass-rose-band-one-click</code></li><li>If I already have a local clone Iâ€™ll do thisâ€¦<code>cd ~/GitHub/compass-rose-band-one-click; git pull</code></li></ul><p>From here on out thereâ€™s just one process, like soâ€¦</p><ul><li><code>npx netlify-cms-proxy-server</code>   â¬… In a new terminal window. See next section of this post.</li><li><code>atom .</code>  â¬… Launch <em>Atom</em> in the working directory.</li><li><code>hugo server -s site</code>  â¬… <strong>Important:</strong> Donâ€™t forget the <code>-s site</code> option!</li><li>Create and edit files as needed. Changes should be immediately visible in <code>http://localhost:1313</code>.</li><li>To edit or create content using <em>Netlify CMS</em>, just visit <code>http://localhost:1313/admin/</code>.</li><li>When all changes are completeâ€¦<ul><li><code>git add .</code></li><li><code>git commit -m 'a brief message here'</code></li><li><code>git push</code></li></ul></li></ul><h3 id='requires-_npx_-part-of-_nodejs_'>Requires <em>npx</em>, Part of <em>Node.js</em></h3><p>The <code>npx</code> command mentioned above requires that <em>npx</em> be installed, and itâ€™s part of <em>Node.js</em>.  To make it run properly I followed guidance from <a href='https://treehouse.github.io/installation-guides/mac/node-mac.html'>https://treehouse.github.io/installation-guides/mac/node-mac.html</a> to ensure both were installed.  In at least one instance I also had to run <code>brew upgrade node</code> and <code>npm i -g npx</code> to ensure that <em>Node.js</em> was up-to-date, and that <em>npx</em> was available as needed.</p><p>The <code>npx netlify-cms-proxy-server</code>, loads and runs the <em>netlify-cms-proxy-server</em> script, and in doing so it will tie up your terminal window.  So, itâ€™s best to <strong>do this in a separate terminal window!</strong>  Donâ€™t put the command in the background (using a <code>&amp;</code> flag at the end) as this wonâ€™t allow you to see if the command is working properly. When you run this command you should see some feedback from the script indicating what it is doing. The script binds to your working directory then effectively routes all <em>Netlify CMS</em> actions, performed in this instance via <code>http://localhost:1313/admin/</code>, to the local <em>git</em> repo there.</p><h2 id='ok-now-we-need-a-proper-domain'>Ok, Now We Need a Proper Domain</h2><p>So, in its original form the <em>Compass Rose Band</em> site is aliased to three different domains:</p><ul><li><a href='https://compassroseband.net'>https://compassroseband.net</a>,</li><li><a href='https://thecompassroseband.com'>https://thecompassroseband.com</a>, and</li><li><a href='https://thecompassroseband.net'>https://thecompassroseband.net</a></li></ul><p>I choose to try migrating these domains to the new <em>Netlify.com</em> site one-at-a-time, starting with the least-used domain, <em>thecompassroseband.net</em>.</p><p>To do this I started by visiting my <em>Netlify.com</em> account/team and the <code>Domains</code> menu, then my project-specific domain settings at <a href='https://app.netlify.com/teams/summittdweller/dns/thecompassroseband.net'>https://app.netlify.com/teams/summittdweller/dns/thecompassroseband.net</a>.  In this page Iâ€™m given a list of 4 <em>Netlify.com</em> name servers that I can use for this particular project.  I made note of the four before moving on.</p><p>Next step was to visit my registrar, <em>enom.com</em>, where I have a control screen for editing DNS records and name servers.  I set the name server values for <em>thecompassroseband.net</em> there to the values that <em>Netlify.com</em> provided. And then, we waitâ€¦ for the changes to propogate.</p><p>Fortunately, <em>Netlify.com</em> is on the ballâ€¦ when I visit my new siteâ€™s domain controls page, <a href='https://app.netlify.com/sites/compass-rose-band-one-click/settings/domain'>https://app.netlify.com/sites/compass-rose-band-one-click/settings/domain</a>, I find a widget that looks like this:</p><p><figure><img alt='DNS Propogation' src='http://localhost:1313/img/netlify-dns-propogation.png'/><figcaption></figcaption></figure></p><p>The cog behind â€œWaiting on DNS propagationâ€ is spinning while <em>Netlify.com</em> waits for the transfer to happen.  So, Iâ€™m going to go for a walk and see what that cog looks like in an hour or two.</p><hr/><p>Clear as mud?  Give it a try, and hopefully it will begin to make sense.  Until next timeâ€¦</p></p></article><!--kg-card-end: html-->",
            "comment_id": "1",
            "plaintext": "In my last post, Adding Netlify CMS for Editing This Blog, I was able to successfully engage the Netlify CMS with a â€œlocalâ€ copy of this blog. But I never got the CMS to work in production with this blogâ€™s App on DigitalOcean (DO). I should note that DOâ€™s support folks were very helpful, but in the end I think all of the client-side stuff that Netlify CMS is doing was more than they were willing (capable?) of helping me overcome. Thatâ€™s probably my fault more than theirâ€™s; client-side isnâ€™t my strong suit.\n\nIn the week since then I have, however, been able to stand up a new working copy of the Wieting Theatre website on Netlify.com, where it enjoys the same kind of automated builds and automatic deployment that I previously found at DO. The big difference, at Netlify.com my Netlify CMS depoloyment works locally AND in production, giving me the ability to allow content editors, even those who donâ€™t have a Netlify.com or GitHub account, to do what they do best, edit their content.\n\n\nThe Wieting Theatreâ€™s New Site, and the CRB\n\nSo this post started as a brain dump, chronicling how I got https://Wieting.Tama-Toledo.com to work. But, instead of hashing out how I â€œdidâ€ it, Iâ€™m going to show you how Iâ€™m doing something similar, for a site that features the Compass Rose Band, or CRB, my brother-in-lawâ€™s band out of Cedar Rapids, Iowa.\n\n\nNetlify Identity\n\nI think the real key to all of this is a Netlify.com agent called Netlify Identity. From the Netlify.com site and documentationâ€¦\n\nNetlify Identity service brings a full suite of authentication functionality, backed by the GoTrue API. This allows you to manage and authenticate users on your site or app, without requiring them to be users of Netlify or any other service. You can use this for gated content, site administration, and more.\n\nIn theory, Netlify Identity can be deployed anywhere, but in practice, setting it up can be quite tricky (at least it was for me). Thatâ€™s where Netlify.com shines, and thatâ€™s understandable since they created both Netlify CMS and Netlify Identity. The two creations play well together, and make life easier for a devops like me. Well played indeed.\n\nIf you read my previous post you know that in a Hugo site, like this one, the ./static/admin/config.yml file holds all of your CMS info. If you host content on Netlify.com with Netlify CMS and Netlify Identity engaged, all you really need in that config file is something like this:\n\nbackend:  name: git-gateway  branch: main...\n\nThe rest of the CMS â€œmagicâ€ takes place in a server-side access manager that you can find at your Netlify.com site folder at https://app.netlify.com/sites/[site-name]/identity. The client-side of the access/identity equation can be handled with an app template, and you can choose from many starter templates found at Start with a Template.\n\n\nExternal OAuth without Netlify.com\n\nIf you wish to proceed without using Netlify.com as your host, youâ€™ll find a number of options at External OAuth Client. Beware, this option isnâ€™t for a server-side guy like me, and the Netlify.com option is quick, easy, and cheapâ€¦ at least I think so.\n\n\nBuilding a New Compass Rose Band Site on Netlify.com\n\nRather than rehashing the story of my Wieting Theatre migration to Netlify.com, Iâ€™m going to repeat that process and capture the journey while migrating our existing Compass Rose Band site from DO.\n\n\nUsing Netlify.com and one-click-hugo-cms\n\nFrom the Start with a Template I clicked the Deploy to Netlify button under the â€˜Hugo Site Starterâ€™ option. This was super easy since Netlify.com already knows meâ€¦ because I created a free account about a week ago. That selection took me to a screen where I was asked to identify a new Github repostory. Again, super easy because I had already logged in to Github earlier.\n\nThe default name for this new repository is one-click-hugo-cms, same as the template repository it will be built from. I choose to name my new repo compass-rose-band-one-click, for obvious reasons. That repository can be found at https://github.com/SummittDweller/compass-rose-band-one-click where the README.md file is titled â€œHugo template for Netlify CMS with Netlify Identityâ€. The initial repository contents looked like this:\n\n\n\n\n\n\nReplacing the /site\n\nA default Hugo site is automatically built and deployed for you as part of the one-click process, and Netlify.com will supply an address so you can see your creation. But thatâ€™s not the Compass Rose Band! No problem, I found it quick and easy to replace the default template site by first cloning my new repo to my workstation, and replacing the /site directory with my own contents. It went like thisâ€¦\n\n * cd ~/GitHub â¬… This is where I keep local copies of all my GitHub projects.\n * git clone https://github.com/SummittDweller/compass-rose-band-one-click\n * cd compass-rose-band-one-click\n * git branch -m master main â¬… Optional step, changes my local branch name to â€˜mainâ€™.\n * rm -fr site/* â¬… Remove the template site, the contents of /site.\n * cp -fr ~/GitHub/compass-rose-band/* site/. â¬… Copy my local CRB site* to /site.\n\n*Note that copying in the manner excludes all . files and directories, so the .git folder is NOT copied. This is IMPORTANT!\n\nAt this point, your old site has a new home in ./site so if you navigate there and do hugo server you should see a local instance of the site. Like soâ€¦\n\n * cd site\n * hugo server\n * Visit localhost:1313, or whatever localhost site is indicated, to see your site.\n\n\nPushing the Site to Github\n\nSo, now your Netlify.com project lives in a directory like my ~/GitHub/compass-rose-band-one-click, and the corresponding Hugo site contents are in the ./site folder there. To deploy this new copy of your site to Netlify.com simply do like thisâ€¦\n\n * cd ~/GitHub/compass-rose-band-one-click\n * git add .\n * git commit -m 'Now with CRB site contents in ./site'\n * git push -u origin main\n\n\nDeploying the Site on Netlify.com\n\nBy default, pushing your changes to Github will automatically deploy them to your Netlify.com site, but you pushed to main, not master, so no synchornization is likely. But thatâ€™s easy to fix.\n\nNavigate your browser to your Netlify.com â€œteamâ€ page, find your new project there, and click on Site Settings. Next youâ€™ll see options for things like changing the name of your project and site. I changed mine to compass-rose-band-one-click to match my Github repo name.\n\nVisit the Build & Deploy link in the menu on the left side of the page, find the Deploy contexts info and click Edit settings there so you can change the production branch setting from master to main. Leave the default setting of â€œAny pull request against your production branch / branch deploy branchesâ€ selected.\n\nNext, visit the â€œDeploysâ€ page in your Netlify.com project page at https://app.netlify.com/sites/[project-name]/deploys, mine is https://app.netlify.com/sites/compass-rose-band-one-click/deploys, and click the Trigger deploy button there. You should then see a log of the deployment as it runs, and this time it should target your new main branch with your updated ./site contents.\n\nIf successful you should see a screen featuring a block like this one:\n\n\n\n\n\nClick on the Preview deploy â¬ˆ link and voilÃ , your site!\n\n\nNowâ€¦Netlify CMS\n\nItâ€™s getting late on this Sunday night so Iâ€™ll share the first few lines from the latest copy of my new projectâ€™s ./site/static/admin/config.yml file for Netlify CMS.\n\nbackend:  name: git-gateway  branch: main## To make local_backend mode work you must run 'npx netlify-cms-proxy-server' in its own terminal window##   from the project root.  See https://www.netlifycms.org/docs/beta-features/ for details.local_backend: truemedia_folder: site/static/img    public_folder: /img...\n\n\nWhatâ€™s All That?\n\nIâ€™m back, as promised, and youâ€™re probably asking what all that stuff in the config.yml file is doing? Well, as mentioned earlier, the simple backend: section (first three lines) links the CMS to the main branch of our new Github project. The rest isnâ€™t required, unless you also want to use the CMS on a local clone of the project, like when making mass edits locally.\n\nLet me try to explain.\n\n\nlocal_backend: A Netlify CMS Beta Feature\n\nIf you visit the Netlify CMSâ€™ Beta Features! pages youâ€™ll see local_backend mentioned near the very top. [Note that as a beta feature this information is bound to move at some point.] That feature enables configuration of an option to make the CMS avaialble when working locally on a cloned, presumably, copy of the Github repository. The beta documentation mentions running npx netlify-cms-proxy-server as part of the process.\n\n\nA Local Problem with ./site? No, Not Really\n\nSo, in the local clone of my new Compass Rose Band one-click Hugo website, the â€œone-clickâ€ Netlify CMS parts live in the projectâ€™s root directory, and the Hugo site lives just â€œbelowâ€ it in ./site. Accordingly my media_folder: setting shown above includes the site/ prefix, and the same is true of all the config.yml keys that end in folder:. This is correct for production, and it also works with a local clone IF I launch things correctly!\n\nHugo and the hugo server command that I need to preview local changes demands that I either cd site before I run it, or override the commandâ€™s path by specifying hugo server -s site. Only this 2nd approach works!\n\nSo the process thatâ€™s needed for local development and testing, including Netlify CMS looks like this for me:\n\n * If I donâ€™t yet have the project locally I will begin withâ€¦cd ~/GitHub; git clone --recursive https://github.com/SummittDweller/compass-rose-band-one-click; cd compass-rose-band-one-click\n * If I already have a local clone Iâ€™ll do thisâ€¦cd ~/GitHub/compass-rose-band-one-click; git pull\n\nFrom here on out thereâ€™s just one process, like soâ€¦\n\n * npx netlify-cms-proxy-server â¬… In a new terminal window. See next section of this post.\n * atom . â¬… Launch Atom in the working directory.\n * hugo server -s site â¬… Important: Donâ€™t forget the -s site option!\n * Create and edit files as needed. Changes should be immediately visible in http://localhost:1313.\n * To edit or create content using Netlify CMS, just visit http://localhost:1313/admin/.\n * When all changes are completeâ€¦\n   * git add .\n   * git commit -m 'a brief message here'\n   * git push\n\n\nRequires npx, Part of Node.js\n\nThe npx command mentioned above requires that npx be installed, and itâ€™s part of Node.js. To make it run properly I followed guidance from https://treehouse.github.io/installation-guides/mac/node-mac.html to ensure both were installed. In at least one instance I also had to run brew upgrade node and npm i -g npx to ensure that Node.js was up-to-date, and that npx was available as needed.\n\nThe npx netlify-cms-proxy-server, loads and runs the netlify-cms-proxy-server script, and in doing so it will tie up your terminal window. So, itâ€™s best to do this in a separate terminal window! Donâ€™t put the command in the background (using a & flag at the end) as this wonâ€™t allow you to see if the command is working properly. When you run this command you should see some feedback from the script indicating what it is doing. The script binds to your working directory then effectively routes all Netlify CMS actions, performed in this instance via http://localhost:1313/admin/, to the local git repo there.\n\n\nOk, Now We Need a Proper Domain\n\nSo, in its original form the Compass Rose Band site is aliased to three different domains:\n\n * https://compassroseband.net,\n * https://thecompassroseband.com, and\n * https://thecompassroseband.net\n\nI choose to try migrating these domains to the new Netlify.com site one-at-a-time, starting with the least-used domain, thecompassroseband.net.\n\nTo do this I started by visiting my Netlify.com account/team and the Domains menu, then my project-specific domain settings at https://app.netlify.com/teams/summittdweller/dns/thecompassroseband.net. In this page Iâ€™m given a list of 4 Netlify.com name servers that I can use for this particular project. I made note of the four before moving on.\n\nNext step was to visit my registrar, enom.com, where I have a control screen for editing DNS records and name servers. I set the name server values for thecompassroseband.net there to the values that Netlify.com provided. And then, we waitâ€¦ for the changes to propogate.\n\nFortunately, Netlify.com is on the ballâ€¦ when I visit my new siteâ€™s domain controls page, https://app.netlify.com/sites/compass-rose-band-one-click/settings/domain, I find a widget that looks like this:\n\n\n\n\n\nThe cog behind â€œWaiting on DNS propagationâ€ is spinning while Netlify.com waits for the transfer to happen. So, Iâ€™m going to go for a walk and see what that cog looks like in an hour or two.\n\nClear as mud? Give it a try, and hopefully it will begin to make sense. Until next timeâ€¦\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:56:52.000Z",
            "updated_at": "2023-04-02T03:48:19.000Z",
            "published_at": "2021-04-04T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e0e465e54c1436c5785e",
            "uuid": "5850b2b9-87c1-41db-a504-279c6000c831",
            "title": "Paperless-ng on CentOS7",
            "slug": "paperless-ng-on-centos7",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>Over the end-of-year holiday break in 2020 I managed to ressurect my old home-office CentOS 7 development server.  I had a mind salvage and update <a href='https://github.com/the-paperless-project/paperless'>Paperless</a> on that server, and I did manage to do that.  However, along the way I discovered the <em>Paperless-ng</em> branch of the project and I installed it, using <em>Docker</em> as suggested, by creating a new project and configuration Iâ€™ve saved as <a href='https://github.com/SummittDweller/paperless-ng-dockerfiles'>summittdweller/paperless-ng-dockerfiles</a>.</p><h2 id='mounting-my-readynas-share'>Mounting my ReadyNAS Share</h2><p>To successfully mount my <em>ReadyNAS/Paperless</em> SMB share I had to do the following on <em>centos7</em> as <em>root</em>:</p><pre tabindex='0'><code>mount -t cifs -o username=mark,vers=1.0 //192.168.1.48/Paperless /mnt/paperless</code></pre><p>Unfortunately, this did NOT work!  Everything appeeared to be working properly except that files copied into <em>//ReadyNAS/Paperless/consume</em> were NOT shared into the container as mapped, so no ingest was triggered.  I could only get the ingest to start if I used <em>docker cpâ€¦</em> to copy the files into the mapped <em>./consume</em> directory.</p><h2 id='mounting-homemarkpaperless-ng-to-support-ingest'>Mounting <em>/home/mark/paperless-ng</em> To Support Ingest</h2><p>So, I turned to <a href='https://devopspoints.com/centos-7-setting-up-samba-and-nfs-for-file-sharing.html'>https://devopspoints.com/centos-7-setting-up-samba-and-nfs-for-file-sharing.html</a> for setup of SAMBA on <em>CentOS7</em> at <em>192.168.1.22</em> with hopes that I could mount <em>/home/mark/paperless-ng/consume</em> and get Paperless auto-ingest working.</p><p>It works!  In fact, it works quite well.</p><p>Paperless-ng is configured to watch for changes in <em>/home/mark/paperless-ng/consume</em> and will ingest any unique .pdf files dropped there.  Note that <em>Paperless-ng</em> is smart enough to keep track of all the files it has ingested so it wonâ€™t knowingly ingest a duplicate.</p><p>Itâ€™s worth noting that there is also a <em>/home/mark/paperless-ng/exported</em> directory where regular exports of Paperless documents can be kept before back-up to <em>//ReadyNAS</em> storage.</p><h2 id='still-no-good'>Still NO Good</h2><p>So, the network configuration indicated above appears to work when copying files from a Mac into the target share, <em>/home/mark/paperless-ng/consume</em>.  Unfortunately Iâ€™ve had NO luck whatsoever getting my <em>Brother ADS-1500W</em> scanner to network with ANYTHING.  The setup seems just fine, but whatever I scan eventually gives me a â€œSend Failedâ€ message with NO other explanation.</p><p>After spending many, many, many hours dealing with this I have officially given up!</p><h2 id='a-new-usb-workflow'>A New USB Workflow</h2><p>My <em>Brother ADS-1500W</em> scanner supports a number of transfer options including USB. Thereâ€™s only one USB port on the back of the scanner so itâ€™s relatively foolproof.</p><p>To engage this workflow I formatted a USB stick as <em>FAT32</em> and named it <em>PAPERLESS</em>.  When this stick is inserted into the scanner a <em>BROTHER</em> directory is created and scans named <em>mmddyynn.pdf</em> are generated there.</p><p>Once a set of documents has been scanned using the <em>to USB</em> profile, the USB stick can be removed from the scanner and plugged in to any <em>CentOS7</em> USB input port.  The <em>PAPERLESS</em> volume will automatically appear on the desktop and all that one must do is copy/paste (select and drag) each of the .pdf files from <em>/mnt/paperless/BROTHER</em> to the target <em>consume</em> diretory at <em>/home/mark/paperless-ng/consume</em>.</p><h2 id='modifying-inotify-in-centos-7'>Modifying <em>inotify</em> in CentOS 7</h2><p>The <em>~/Desktop/README.md</em> file on node <em>centos7</em> documents a necessary step that I discovered as the key to making <em>Paperless</em> consume/ingest process work.  The commands are:</p><pre tabindex='0'><code>cat /proc/sys/fs/inotify/max_user_watches          # default is 8192sudo sysctl fs.inotify.max_user_watdhes=1048576    # necessary increase</code></pre><h2 id='starting-and-stopping-paperless-ng'>Starting and Stopping <em>Paperless-ng</em></h2><h3 id='starting-paperless-ng'>Starting <em>Paperless-ng</em></h3><p>Simple, to start it on <em>CentOS7</em>:</p><pre tabindex='0'><code>cd /home/mark/GitHub/paperless-ng-dockerfilesdocker-compose up -d</code></pre><p>Or, simply reboot <em>CentOS7</em>.  See auto-start details in the section below.</p><h3 id='stopping-paperless-ng'>Stopping <em>Paperless-ng</em></h3><p>Also simple, on <em>CentOS7</em>:</p><pre tabindex='0'><code>cd /home/mark/GitHub/paperless-ng-dockerfilesdocker-compose down</code></pre><h2 id='auto-starting-paperless-ng'>Auto-Starting <em>Paperless-ng</em></h2><p>I found and followed <a href='https://www.thegeekdiary.com/centos-rhel-7-how-to-make-custom-script-to-run-automatically-during-boot/'>this resource</a> to create a boot-time auto-start script to configure and launch <em>Paperless-ng</em> whenever <em>CentOS7</em> is booted.  My script is <em>/var/tmp/startup_script.sh</em> and the process of running it echoes some output to <em>/var/tmp/script.out</em>.</p><p>I saved the script as a <a href='https://gist.github.com/SummittDweller/9e179f948faf0d30fe8069f684b7d762'>public gist</a> for safe-keeping.</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>Over the end-of-year holiday break in 2020 I managed to ressurect my old home-office CentOS 7 development server.  I had a mind salvage and update <a href='https://github.com/the-paperless-project/paperless'>Paperless</a> on that server, and I did manage to do that.  However, along the way I discovered the <em>Paperless-ng</em> branch of the project and I installed it, using <em>Docker</em> as suggested, by creating a new project and configuration Iâ€™ve saved as <a href='https://github.com/SummittDweller/paperless-ng-dockerfiles'>summittdweller/paperless-ng-dockerfiles</a>.</p><h2 id='mounting-my-readynas-share'>Mounting my ReadyNAS Share</h2><p>To successfully mount my <em>ReadyNAS/Paperless</em> SMB share I had to do the following on <em>centos7</em> as <em>root</em>:</p><pre tabindex='0'><code>mount -t cifs -o username=mark,vers=1.0 //192.168.1.48/Paperless /mnt/paperless</code></pre><p>Unfortunately, this did NOT work!  Everything appeeared to be working properly except that files copied into <em>//ReadyNAS/Paperless/consume</em> were NOT shared into the container as mapped, so no ingest was triggered.  I could only get the ingest to start if I used <em>docker cpâ€¦</em> to copy the files into the mapped <em>./consume</em> directory.</p><h2 id='mounting-homemarkpaperless-ng-to-support-ingest'>Mounting <em>/home/mark/paperless-ng</em> To Support Ingest</h2><p>So, I turned to <a href='https://devopspoints.com/centos-7-setting-up-samba-and-nfs-for-file-sharing.html'>https://devopspoints.com/centos-7-setting-up-samba-and-nfs-for-file-sharing.html</a> for setup of SAMBA on <em>CentOS7</em> at <em>192.168.1.22</em> with hopes that I could mount <em>/home/mark/paperless-ng/consume</em> and get Paperless auto-ingest working.</p><p>It works!  In fact, it works quite well.</p><p>Paperless-ng is configured to watch for changes in <em>/home/mark/paperless-ng/consume</em> and will ingest any unique .pdf files dropped there.  Note that <em>Paperless-ng</em> is smart enough to keep track of all the files it has ingested so it wonâ€™t knowingly ingest a duplicate.</p><p>Itâ€™s worth noting that there is also a <em>/home/mark/paperless-ng/exported</em> directory where regular exports of Paperless documents can be kept before back-up to <em>//ReadyNAS</em> storage.</p><h2 id='still-no-good'>Still NO Good</h2><p>So, the network configuration indicated above appears to work when copying files from a Mac into the target share, <em>/home/mark/paperless-ng/consume</em>.  Unfortunately Iâ€™ve had NO luck whatsoever getting my <em>Brother ADS-1500W</em> scanner to network with ANYTHING.  The setup seems just fine, but whatever I scan eventually gives me a â€œSend Failedâ€ message with NO other explanation.</p><p>After spending many, many, many hours dealing with this I have officially given up!</p><h2 id='a-new-usb-workflow'>A New USB Workflow</h2><p>My <em>Brother ADS-1500W</em> scanner supports a number of transfer options including USB. Thereâ€™s only one USB port on the back of the scanner so itâ€™s relatively foolproof.</p><p>To engage this workflow I formatted a USB stick as <em>FAT32</em> and named it <em>PAPERLESS</em>.  When this stick is inserted into the scanner a <em>BROTHER</em> directory is created and scans named <em>mmddyynn.pdf</em> are generated there.</p><p>Once a set of documents has been scanned using the <em>to USB</em> profile, the USB stick can be removed from the scanner and plugged in to any <em>CentOS7</em> USB input port.  The <em>PAPERLESS</em> volume will automatically appear on the desktop and all that one must do is copy/paste (select and drag) each of the .pdf files from <em>/mnt/paperless/BROTHER</em> to the target <em>consume</em> diretory at <em>/home/mark/paperless-ng/consume</em>.</p><h2 id='modifying-inotify-in-centos-7'>Modifying <em>inotify</em> in CentOS 7</h2><p>The <em>~/Desktop/README.md</em> file on node <em>centos7</em> documents a necessary step that I discovered as the key to making <em>Paperless</em> consume/ingest process work.  The commands are:</p><pre tabindex='0'><code>cat /proc/sys/fs/inotify/max_user_watches          # default is 8192sudo sysctl fs.inotify.max_user_watdhes=1048576    # necessary increase</code></pre><h2 id='starting-and-stopping-paperless-ng'>Starting and Stopping <em>Paperless-ng</em></h2><h3 id='starting-paperless-ng'>Starting <em>Paperless-ng</em></h3><p>Simple, to start it on <em>CentOS7</em>:</p><pre tabindex='0'><code>cd /home/mark/GitHub/paperless-ng-dockerfilesdocker-compose up -d</code></pre><p>Or, simply reboot <em>CentOS7</em>.  See auto-start details in the section below.</p><h3 id='stopping-paperless-ng'>Stopping <em>Paperless-ng</em></h3><p>Also simple, on <em>CentOS7</em>:</p><pre tabindex='0'><code>cd /home/mark/GitHub/paperless-ng-dockerfilesdocker-compose down</code></pre><h2 id='auto-starting-paperless-ng'>Auto-Starting <em>Paperless-ng</em></h2><p>I found and followed <a href='https://www.thegeekdiary.com/centos-rhel-7-how-to-make-custom-script-to-run-automatically-during-boot/'>this resource</a> to create a boot-time auto-start script to configure and launch <em>Paperless-ng</em> whenever <em>CentOS7</em> is booted.  My script is <em>/var/tmp/startup_script.sh</em> and the process of running it echoes some output to <em>/var/tmp/script.out</em>.</p><p>I saved the script as a <a href='https://gist.github.com/SummittDweller/9e179f948faf0d30fe8069f684b7d762'>public gist</a> for safe-keeping.</p></p></article><!--kg-card-end: html-->",
            "comment_id": "2",
            "plaintext": "Over the end-of-year holiday break in 2020 I managed to ressurect my old home-office CentOS 7 development server. I had a mind salvage and update Paperless on that server, and I did manage to do that. However, along the way I discovered the Paperless-ng branch of the project and I installed it, using Docker as suggested, by creating a new project and configuration Iâ€™ve saved as summittdweller/paperless-ng-dockerfiles.\n\n\nMounting my ReadyNAS Share\n\nTo successfully mount my ReadyNAS/Paperless SMB share I had to do the following on centos7 as root:\n\nmount -t cifs -o username=mark,vers=1.0 //192.168.1.48/Paperless /mnt/paperless\n\nUnfortunately, this did NOT work! Everything appeeared to be working properly except that files copied into //ReadyNAS/Paperless/consume were NOT shared into the container as mapped, so no ingest was triggered. I could only get the ingest to start if I used docker cpâ€¦ to copy the files into the mapped ./consume directory.\n\n\nMounting /home/mark/paperless-ng To Support Ingest\n\nSo, I turned to https://devopspoints.com/centos-7-setting-up-samba-and-nfs-for-file-sharing.html for setup of SAMBA on CentOS7 at 192.168.1.22 with hopes that I could mount /home/mark/paperless-ng/consume and get Paperless auto-ingest working.\n\nIt works! In fact, it works quite well.\n\nPaperless-ng is configured to watch for changes in /home/mark/paperless-ng/consume and will ingest any unique .pdf files dropped there. Note that Paperless-ng is smart enough to keep track of all the files it has ingested so it wonâ€™t knowingly ingest a duplicate.\n\nItâ€™s worth noting that there is also a /home/mark/paperless-ng/exported directory where regular exports of Paperless documents can be kept before back-up to //ReadyNAS storage.\n\n\nStill NO Good\n\nSo, the network configuration indicated above appears to work when copying files from a Mac into the target share, /home/mark/paperless-ng/consume. Unfortunately Iâ€™ve had NO luck whatsoever getting my Brother ADS-1500W scanner to network with ANYTHING. The setup seems just fine, but whatever I scan eventually gives me a â€œSend Failedâ€ message with NO other explanation.\n\nAfter spending many, many, many hours dealing with this I have officially given up!\n\n\nA New USB Workflow\n\nMy Brother ADS-1500W scanner supports a number of transfer options including USB. Thereâ€™s only one USB port on the back of the scanner so itâ€™s relatively foolproof.\n\nTo engage this workflow I formatted a USB stick as FAT32 and named it PAPERLESS. When this stick is inserted into the scanner a BROTHER directory is created and scans named mmddyynn.pdf are generated there.\n\nOnce a set of documents has been scanned using the to USB profile, the USB stick can be removed from the scanner and plugged in to any CentOS7 USB input port. The PAPERLESS volume will automatically appear on the desktop and all that one must do is copy/paste (select and drag) each of the .pdf files from /mnt/paperless/BROTHER to the target consume diretory at /home/mark/paperless-ng/consume.\n\n\nModifying inotify in CentOS 7\n\nThe ~/Desktop/README.md file on node centos7 documents a necessary step that I discovered as the key to making Paperless consume/ingest process work. The commands are:\n\ncat /proc/sys/fs/inotify/max_user_watches          # default is 8192sudo sysctl fs.inotify.max_user_watdhes=1048576    # necessary increase\n\n\nStarting and Stopping Paperless-ng\n\n\nStarting Paperless-ng\n\nSimple, to start it on CentOS7:\n\ncd /home/mark/GitHub/paperless-ng-dockerfilesdocker-compose up -d\n\nOr, simply reboot CentOS7. See auto-start details in the section below.\n\n\nStopping Paperless-ng\n\nAlso simple, on CentOS7:\n\ncd /home/mark/GitHub/paperless-ng-dockerfilesdocker-compose down\n\n\nAuto-Starting Paperless-ng\n\nI found and followed this resource to create a boot-time auto-start script to configure and launch Paperless-ng whenever CentOS7 is booted. My script is /var/tmp/startup_script.sh and the process of running it echoes some output to /var/tmp/script.out.\n\nI saved the script as a public gist for safe-keeping.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:56:52.000Z",
            "updated_at": "2023-04-02T03:48:27.000Z",
            "published_at": "2021-01-07T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e0e465e54c1436c57860",
            "uuid": "03879c5d-c472-4ad8-9710-0ca9b0360de7",
            "title": "â†’ Home Automation",
            "slug": "--home-automation",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>During the <a href='https://en.wikipedia.org/wiki/COVID-19_pandemic'>COVID-19 pandemic</a> I decided, while working endlessly from my home office, to resurect the hanging bird feeder outside my office window.  I like having the birds visit, but Iâ€™ve noticed one problemâ€¦ starlings! They are cranky, bully bastards and chase all the welcome visitors away, if I let them. Well, I donâ€™t intend to let them anymore. ðŸ˜ I wonâ€™t go into details here but my remedy involves removing the screen from my office window, and occasionally opening the window itself.</p><p>There are two issues with the windowâ€¦ itâ€™s a big, double casement window with a pair of crank mechanisms for opening, and the one that I need to open most often is situated behind my mini-fridge. Itâ€™s difficult to get to the opener crank, and even hard to open or close it â€œgentlyâ€. The other issue is that while the window is open my office door needs to be closed so that our house cats wonâ€™t wander in and decide to â€œescapeâ€ through the open window. ðŸ˜¾ I suppose the cats could provide some extra starling deternt, but they are not as selective as I am. If it moves, they want to catch it. ðŸˆ</p><p>The solution, I hope, is to build and install an automated window opener, one that I can control without getting out of my seat. It would also be nice if I had the same option to open, or at least close, my office door. I have a spare <a href='https://en.wikipedia.org/wiki/Raspberry_Pi'>Raspberry Pi Zero W</a> and some related parts so thatâ€™s a start. Iâ€™ve also just purchased a little <a href='https://www.amazon.com/gp/product/B07252J5GV/ref=ppx_yo_dt_b_asin_title_o02_s00?ie=UTF8&amp;psc=1'>High-Torque DC Motor</a> and a RPI-compatible <a href='https://www.amazon.com/gp/product/B01MQ2MZDV/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;psc=1'>motor controller</a>.</p><h2 id='web-resources'>Web Resources</h2><p>This post captures the resources Iâ€™ll use (or used, depending on when you read this) to set my plan in motion. The first step, my <a href='https://www.one-tab.com/help'>OneTab</a> that holds my initial web resources: <a href='https://www.one-tab.com/page/0fj_WcQ0TkG256iDV3EE2g'>https://www.one-tab.com/page/0fj_WcQ0TkG256iDV3EE2g</a>.</p><h2 id='my-build'>My Build</h2><p>Check here for some follow-up soon, I hope.</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>During the <a href='https://en.wikipedia.org/wiki/COVID-19_pandemic'>COVID-19 pandemic</a> I decided, while working endlessly from my home office, to resurect the hanging bird feeder outside my office window.  I like having the birds visit, but Iâ€™ve noticed one problemâ€¦ starlings! They are cranky, bully bastards and chase all the welcome visitors away, if I let them. Well, I donâ€™t intend to let them anymore. ðŸ˜ I wonâ€™t go into details here but my remedy involves removing the screen from my office window, and occasionally opening the window itself.</p><p>There are two issues with the windowâ€¦ itâ€™s a big, double casement window with a pair of crank mechanisms for opening, and the one that I need to open most often is situated behind my mini-fridge. Itâ€™s difficult to get to the opener crank, and even hard to open or close it â€œgentlyâ€. The other issue is that while the window is open my office door needs to be closed so that our house cats wonâ€™t wander in and decide to â€œescapeâ€ through the open window. ðŸ˜¾ I suppose the cats could provide some extra starling deternt, but they are not as selective as I am. If it moves, they want to catch it. ðŸˆ</p><p>The solution, I hope, is to build and install an automated window opener, one that I can control without getting out of my seat. It would also be nice if I had the same option to open, or at least close, my office door. I have a spare <a href='https://en.wikipedia.org/wiki/Raspberry_Pi'>Raspberry Pi Zero W</a> and some related parts so thatâ€™s a start. Iâ€™ve also just purchased a little <a href='https://www.amazon.com/gp/product/B07252J5GV/ref=ppx_yo_dt_b_asin_title_o02_s00?ie=UTF8&amp;psc=1'>High-Torque DC Motor</a> and a RPI-compatible <a href='https://www.amazon.com/gp/product/B01MQ2MZDV/ref=ppx_yo_dt_b_asin_title_o01_s00?ie=UTF8&amp;psc=1'>motor controller</a>.</p><h2 id='web-resources'>Web Resources</h2><p>This post captures the resources Iâ€™ll use (or used, depending on when you read this) to set my plan in motion. The first step, my <a href='https://www.one-tab.com/help'>OneTab</a> that holds my initial web resources: <a href='https://www.one-tab.com/page/0fj_WcQ0TkG256iDV3EE2g'>https://www.one-tab.com/page/0fj_WcQ0TkG256iDV3EE2g</a>.</p><h2 id='my-build'>My Build</h2><p>Check here for some follow-up soon, I hope.</p></p></article><!--kg-card-end: html-->",
            "comment_id": "4",
            "plaintext": "During the COVID-19 pandemic I decided, while working endlessly from my home office, to resurect the hanging bird feeder outside my office window. I like having the birds visit, but Iâ€™ve noticed one problemâ€¦ starlings! They are cranky, bully bastards and chase all the welcome visitors away, if I let them. Well, I donâ€™t intend to let them anymore. ðŸ˜ I wonâ€™t go into details here but my remedy involves removing the screen from my office window, and occasionally opening the window itself.\n\nThere are two issues with the windowâ€¦ itâ€™s a big, double casement window with a pair of crank mechanisms for opening, and the one that I need to open most often is situated behind my mini-fridge. Itâ€™s difficult to get to the opener crank, and even hard to open or close it â€œgentlyâ€. The other issue is that while the window is open my office door needs to be closed so that our house cats wonâ€™t wander in and decide to â€œescapeâ€ through the open window. ðŸ˜¾ I suppose the cats could provide some extra starling deternt, but they are not as selective as I am. If it moves, they want to catch it. ðŸˆ\n\nThe solution, I hope, is to build and install an automated window opener, one that I can control without getting out of my seat. It would also be nice if I had the same option to open, or at least close, my office door. I have a spare Raspberry Pi Zero W and some related parts so thatâ€™s a start. Iâ€™ve also just purchased a little High-Torque DC Motor and a RPI-compatible motor controller.\n\n\nWeb Resources\n\nThis post captures the resources Iâ€™ll use (or used, depending on when you read this) to set my plan in motion. The first step, my OneTab that holds my initial web resources: https://www.one-tab.com/page/0fj_WcQ0TkG256iDV3EE2g.\n\n\nMy Build\n\nCheck here for some follow-up soon, I hope.\n\n",
            "feature_image": "https://images.unsplash.com/photo-1611117775350-ac3950990985?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDZ8fGF1dG9tYXRpb258ZW58MHx8fHwxNjgwNjk5MjQ0&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:56:53.000Z",
            "updated_at": "2023-04-05T12:56:28.000Z",
            "published_at": "2020-05-09T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e0e465e54c1436c57861",
            "uuid": "8cf96fe8-e7d2-4604-9aea-a3715456cfc1",
            "title": "Westbound to Seattle - Day 2",
            "slug": "westbound-to-seattle---day-2",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><h1 id='day-2---glendive-mt-to-moses-lake-wa'>Day 2 - Glendive, MT to Moses Lake, WA</h1><p>This is our planned route for Day 2 using a <code>speed factor of 1.0</code> (traveling at the speed limit).  Fuel cost is based on <code>40 mpg</code> and <code>$4.00 per gallon</code> averages.  Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.</p><p>A list of possible geocache targets for the entire route can be found at <a href='https://www.geocaching.com/play/map/lists/BMBBMD6'>https://www.geocaching.com/play/map/lists/BMBBMD6</a>.</p><iframe src='http://localhost:1313/html/Westbound-Day-2.html' style='width: 100%; height: 400px; border:1;' title='Westbound Day 2'></iframe></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><h1 id='day-2---glendive-mt-to-moses-lake-wa'>Day 2 - Glendive, MT to Moses Lake, WA</h1><p>This is our planned route for Day 2 using a <code>speed factor of 1.0</code> (traveling at the speed limit).  Fuel cost is based on <code>40 mpg</code> and <code>$4.00 per gallon</code> averages.  Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.</p><p>A list of possible geocache targets for the entire route can be found at <a href='https://www.geocaching.com/play/map/lists/BMBBMD6'>https://www.geocaching.com/play/map/lists/BMBBMD6</a>.</p><iframe src='http://localhost:1313/html/Westbound-Day-2.html' style='width: 100%; height: 400px; border:1;' title='Westbound Day 2'></iframe></p></article><!--kg-card-end: html-->",
            "comment_id": "5",
            "plaintext": "Day 2 - Glendive, MT to Moses Lake, WA\n\nThis is our planned route for Day 2 using a speed factor of 1.0 (traveling at the speed limit). Fuel cost is based on 40 mpg and $4.00 per gallon averages. Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.\n\nA list of possible geocache targets for the entire route can be found at https://www.geocaching.com/play/map/lists/BMBBMD6.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:56:53.000Z",
            "updated_at": "2023-04-02T03:48:13.000Z",
            "published_at": "2022-08-07T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c5786e",
            "uuid": "9d442910-d066-486e-8c6d-6687a4f9a936",
            "title": "CentOS 7 Remote Using VNC",
            "slug": "centos-7-remote-using-vnc",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>This past weekend I managed to get a <em>VNC</em> server running on my <strong>centos7</strong> node, where I run <em>Paperless</em>.  The build instructions came from <a href='https://www.howtoforge.com/vnc-server-installation-on-centos-7'>https://www.howtoforge.com/vnc-server-installation-on-centos-7</a>. The node is available at <code>192.168.1.22:5901</code>.</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>This past weekend I managed to get a <em>VNC</em> server running on my <strong>centos7</strong> node, where I run <em>Paperless</em>.  The build instructions came from <a href='https://www.howtoforge.com/vnc-server-installation-on-centos-7'>https://www.howtoforge.com/vnc-server-installation-on-centos-7</a>. The node is available at <code>192.168.1.22:5901</code>.</p></p></article><!--kg-card-end: html-->",
            "comment_id": "0",
            "plaintext": "This past weekend I managed to get a VNC server running on my centos7 node, where I run Paperless. The build instructions came from https://www.howtoforge.com/vnc-server-installation-on-centos-7. The node is available at 192.168.1.22:5901.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:01.000Z",
            "updated_at": "2023-04-02T03:50:06.000Z",
            "published_at": "2021-01-04T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c5786f",
            "uuid": "9736fc6d-95c1-4a75-932e-a09d6ab13647",
            "title": "A Simple Sign-up Form",
            "slug": "a-simple-sign-up-form",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>For 2021 Iâ€™ve signed on to be a member of the steering committee for Toledoâ€™s 2021 <a href='https://www.communityvisioning.org/toledo/'>Community Visioning (CV)</a> project coordinated by <a href='http://www.treesforever.org/IowasLivingRoadways'>Treeâ€™s Forever and Iowaâ€™s Living Roadways</a>, <a href='https://www.extension.iastate.edu/'>Iowa State University Extension and Outreach</a>, and other partners.  Tama is also a <a href='https://www.communityvisioning.org/tama/'>Community Visioning</a> participant in 2021.</p><h2 id='a-simple-e-mail-sign-up'>A Simple E-Mail Sign-Up</h2><p>Iâ€™m only posting this as a test of what I think might be a very simple sign-up form using email.  What you see below is just a test, so please donâ€™t expect any invitation from this!</p><h3 id='this-form-is-for-testing-only'>This Form is for Testing ONLY!</h3><p><strong>Are you interested in helping Toledo plan for the future with regard to transportation and recreation?</strong> Click ONE of the following links to receive an invitation by email to join a 90-minute online focus group on Saturday, March 6:</p><ul><li><a href='mailto:mark.mcfate@icloud.com?subject=Toledo:Active%20Adult&amp;body=Please%20send%20this%20email%20to%20confirm%20your%20interest.%20Thank%20You!'><strong>Active Adult</strong> - 10:30am-Noon</a></li><li><a href='mailto:mark.mcfate@icloud.com?subject=Toledo:Youth&amp;body=Please%20send%20this%20email%20to%20confirm%20your%20interest.%20Thank%20You!'><strong>Youth to Age 12</strong> - Noon-1:30pm</a></li><li><a href='mailto:mark.mcfate@icloud.com?subject=Toledo:Young%20Adult&amp;body=Please%20send%20this%20email%20to%20confirm%20your%20interest.%20Thank%20You!'><strong>Young Adult Ages 13-21</strong> - 1:30pm-3pm</a></li></ul><p><em>Remember, this is just a TEST!</em></p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>For 2021 Iâ€™ve signed on to be a member of the steering committee for Toledoâ€™s 2021 <a href='https://www.communityvisioning.org/toledo/'>Community Visioning (CV)</a> project coordinated by <a href='http://www.treesforever.org/IowasLivingRoadways'>Treeâ€™s Forever and Iowaâ€™s Living Roadways</a>, <a href='https://www.extension.iastate.edu/'>Iowa State University Extension and Outreach</a>, and other partners.  Tama is also a <a href='https://www.communityvisioning.org/tama/'>Community Visioning</a> participant in 2021.</p><h2 id='a-simple-e-mail-sign-up'>A Simple E-Mail Sign-Up</h2><p>Iâ€™m only posting this as a test of what I think might be a very simple sign-up form using email.  What you see below is just a test, so please donâ€™t expect any invitation from this!</p><h3 id='this-form-is-for-testing-only'>This Form is for Testing ONLY!</h3><p><strong>Are you interested in helping Toledo plan for the future with regard to transportation and recreation?</strong> Click ONE of the following links to receive an invitation by email to join a 90-minute online focus group on Saturday, March 6:</p><ul><li><a href='mailto:mark.mcfate@icloud.com?subject=Toledo:Active%20Adult&amp;body=Please%20send%20this%20email%20to%20confirm%20your%20interest.%20Thank%20You!'><strong>Active Adult</strong> - 10:30am-Noon</a></li><li><a href='mailto:mark.mcfate@icloud.com?subject=Toledo:Youth&amp;body=Please%20send%20this%20email%20to%20confirm%20your%20interest.%20Thank%20You!'><strong>Youth to Age 12</strong> - Noon-1:30pm</a></li><li><a href='mailto:mark.mcfate@icloud.com?subject=Toledo:Young%20Adult&amp;body=Please%20send%20this%20email%20to%20confirm%20your%20interest.%20Thank%20You!'><strong>Young Adult Ages 13-21</strong> - 1:30pm-3pm</a></li></ul><p><em>Remember, this is just a TEST!</em></p></p></article><!--kg-card-end: html-->",
            "comment_id": "1",
            "plaintext": "For 2021 Iâ€™ve signed on to be a member of the steering committee for Toledoâ€™s 2021 Community Visioning (CV) project coordinated by Treeâ€™s Forever and Iowaâ€™s Living Roadways, Iowa State University Extension and Outreach, and other partners. Tama is also a Community Visioning participant in 2021.\n\n\nA Simple E-Mail Sign-Up\n\nIâ€™m only posting this as a test of what I think might be a very simple sign-up form using email. What you see below is just a test, so please donâ€™t expect any invitation from this!\n\n\nThis Form is for Testing ONLY!\n\nAre you interested in helping Toledo plan for the future with regard to transportation and recreation? Click ONE of the following links to receive an invitation by email to join a 90-minute online focus group on Saturday, March 6:\n\n * Active Adult - 10:30am-Noon\n * Youth to Age 12 - Noon-1:30pm\n * Young Adult Ages 13-21 - 1:30pm-3pm\n\nRemember, this is just a TEST!\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:01.000Z",
            "updated_at": "2023-04-02T03:49:47.000Z",
            "published_at": "2021-03-06T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57870",
            "uuid": "47f8e2e6-e5cc-4432-a383-69a0333a6f4a",
            "title": "Eastbound from Seattle - Day 2",
            "slug": "eastbound-from-seattle---day-2",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><h1 id='day-3---lakeview-or-to-laramie-wy'>Day 3 - Lakeview, OR to Laramie, WY</h1><p>This is our planned route for Day 2 (eastbound) using a <code>speed factor of 1.0</code> (traveling at the speed limit).  Fuel cost is based on <code>40 mpg</code> and <code>$4.00 per gallon</code> averages.  Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.</p><p>A list of possible geocache targets for the entire route can be found at <a href='https://www.geocaching.com/play/map/lists/BMBBMD6'>https://www.geocaching.com/play/map/lists/BMBBMD6</a>.</p><iframe src='http://localhost:1313/html/Eastbound-Day-2.html' style='width: 100%; height: 400px; border:1;' title='Eastbound Day 2'></iframe></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><h1 id='day-3---lakeview-or-to-laramie-wy'>Day 3 - Lakeview, OR to Laramie, WY</h1><p>This is our planned route for Day 2 (eastbound) using a <code>speed factor of 1.0</code> (traveling at the speed limit).  Fuel cost is based on <code>40 mpg</code> and <code>$4.00 per gallon</code> averages.  Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.</p><p>A list of possible geocache targets for the entire route can be found at <a href='https://www.geocaching.com/play/map/lists/BMBBMD6'>https://www.geocaching.com/play/map/lists/BMBBMD6</a>.</p><iframe src='http://localhost:1313/html/Eastbound-Day-2.html' style='width: 100%; height: 400px; border:1;' title='Eastbound Day 2'></iframe></p></article><!--kg-card-end: html-->",
            "comment_id": "2",
            "plaintext": "Day 3 - Lakeview, OR to Laramie, WY\n\nThis is our planned route for Day 2 (eastbound) using a speed factor of 1.0 (traveling at the speed limit). Fuel cost is based on 40 mpg and $4.00 per gallon averages. Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.\n\nA list of possible geocache targets for the entire route can be found at https://www.geocaching.com/play/map/lists/BMBBMD6.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:01.000Z",
            "updated_at": "2023-04-02T03:49:10.000Z",
            "published_at": "2022-08-08T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57871",
            "uuid": "2ffbdd10-deb4-41bf-b79f-a123dad45ebb",
            "title": "August 2022 - Geocaching's 20th Anniversary Celebration Event",
            "slug": "august-2022---geocachings-20th-anniversary-celebration-event",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>The following is a chronological consolidation of posts and microposts from August 6 through August 25, 2022.</p><article class='post'><h2><a href='../geocaching-westbound-day-1/index.html' rel='full-article'>Westbound to Seattle - Day 1</a></h2><div class='postmeta'>    Posted on 2022/08/07 4:57 PM          from Toledo, IA      </div></article><article class='post'><h2><a href='../geocaching-westbound-day-2/index.html' rel='full-article'>Westbound to Seattle - Day 2</a></h2><div class='postmeta'>    Posted on 2022/08/07 4:58 PM          from Toledo, IA      </div></article><article class='post'><h2><a href='../geocaching-westbound-day-3/index.html' rel='full-article'>Westbound to Seattle - Day 3</a></h2><div class='postmeta'>    Posted on 2022/08/07 4:58 PM          from Toledo, IA      </div></article><article class='post'><h2><a href='../geocaching-eastbound-day-1/index.html' rel='full-article'>Eastbound from Seattle - Day 1</a></h2><div class='postmeta'>    Posted on 2022/08/07 9:13 PM          from Toledo, IA      </div></article><article class='post'><h2><a href='../geocaching-eastbound-day-2/index.html' rel='full-article'>Eastbound from Seattle - Day 2</a></h2><div class='postmeta'>    Posted on 2022/08/08 1:39 PM          from Toledo, IA      </div></article><article class='post'><h2><a href='../geocaching-eastbound-day-3/index.html' rel='full-article'>Eastbound from Seattle - Day 3</a></h2><div class='postmeta'>    Posted on 2022/08/08 2:44 PM          from Toledo, IA      </div></article><article class='micropost'><p>  Waiting for my ride to Johnston.  <aside class='postmeta'>â†’ 2022/08/12 7:37 AM          posted from Toledo, IA      </aside></p></article><article class='micropost'><p>  Departed for Seattle a few minutes  after 6 AM.  <aside class='postmeta'>â†’ 2022/08/16 6:14 AM          posted from Montour, IA      </aside></p></article><article class='micropost'><p>  Lunch at Culverâ€™s in Brookings, SD.  <aside class='postmeta'>â†’ 2022/08/16 11:52 AM          posted from Brookings, SD      </aside></p></article><article class='micropost'><p>  Got my first North Dakota geocache find a few miles back down the road.  <aside class='postmeta'>â†’ 2022/08/16 2:18 PM          posted from Wahpeton, ND      </aside></p></article><article class='micropost'><p>  Passing through the outskirts of metropolitan Fargo.  <aside class='postmeta'>â†’ 2022/08/16 3:10 PM          posted from West Fargo, ND      </aside></p></article><article class='micropost'><p>  Headed west across North Dakota for GC 551, the stateâ€™s oldest active geocache.  <aside class='postmeta'>â†’ 2022/08/16 5:24 PM          posted from Steele, ND      </aside></p></article><article class='micropost'><p>  Arrived for the night around 9:25 pm in Miles City, Montana, about 70 miles past our intended stop.  <aside class='postmeta'>â†’ 2022/08/16 9:52 PM          posted from Miles City, MT      </aside></p></article><article class='micropost'><p>  First cache of the day:  Headed to GCHGZZ in a rest area in Montana.  <aside class='postmeta'>â†’ 2022/08/17 6:43 AM          posted from Rosebud, MT      </aside></p></article><article class='micropost'><p>  GCKHRJ:  Was not on our original list but a really quick stop and well worth the time out.  <aside class='postmeta'>â†’ 2022/08/17 9:46 AM          posted from Big Timber, MT      </aside></p></article><article class='micropost'><p>  Just departed from the headwaters of the Missouri river state park in Montana and the stateâ€™s oldest pair of geocaches.  Check my track logs on <a href='https://hikes.summittdweller.com'>https://hikes.summittdweller.com</a> for more details.  <aside class='postmeta'>â†’ 2022/08/17 1:21 PM          posted from Headwaters of the Missouri River, Montana      </aside></p></article><article class='micropost'><p>  Stopped for dinner in Coeur dâ€™Alene at Rogers Ice Cream and Burgers.  <aside class='postmeta'>â†’ 2022/08/17 6:13 PM          posted from Coeur d'Alene, ID      </aside></p></article><article class='micropost'><p>  Excellent company for the reviewers lunch after the APE geocache at Snoqualmie Pass, Washington.  <aside class='postmeta'>â†’ 2022/08/18 2:32 PM          posted from Snoqualmie Pass, WA      </aside></p></article><article class='micropost'><p>  Relaxing and catching up in the hotel (the Maxwell near the Space Needle) after a great day of geocaching, hiking (10 miles or more) and lite travel.  <aside class='postmeta'>â†’ 2022/08/18 9:46 PM          posted from Seattle, WA      </aside></p></article><article class='micropost'><p>  No time to blog!  Attending the Geocaching 20th Celebration.  <aside class='postmeta'>â†’ 2022/08/20 10:38 AM          posted from Seattle, WA      </aside></p></article><article class='micropost'><p>  Southbound on I5 to the Original Stash SE of Portland.  <aside class='postmeta'>â†’ 2022/08/21 5:55 AM          posted from Tukwila, WA      </aside></p></article><article class='micropost'><p>  Grabbing a quick lunch at McDonaldâ€™s.  <aside class='postmeta'>â†’ 2022/08/21 1:59 PM          posted from Madras, OR      </aside></p></article><article class='micropost'><p>  The apex of an epic road-trip!  <aside class='postmeta'>â†’ 2022/08/21 7:11 PM          posted from Davis Creek, CA      </aside></p></article><article class='micropost'><p>  Winnemucca ETA is 11:35pm.  Never have I seen so many stars.  <aside class='postmeta'>â†’ 2022/08/21 10:09 PM          posted from Denico Junction, NV      </aside></p></article><article class='micropost'><p>  Tomâ€™s reaction when we popped over the hill to see the Bonneville salt flats was â€œholy shitâ€.  <aside class='postmeta'>â†’ 2022/08/22 11:22 AM          posted from West Wendover, NV      </aside></p></article><article class='micropost'><p>  Posting an <a href='../geocaching-eastbound-day-3/index.html'>updated itinerary</a> for eastbound day 3.  <aside class='postmeta'>â†’ 2022/08/22 7:22 PM          posted from Rawlins, WY      </aside></p></article><article class='micropost'><p>  Planning a lunch stop in Grand Island with Heartland Cacher and then on home to Iowa so Reviewer Smith can get back to Illinois this evening.  <aside class='postmeta'>â†’ 2022/08/23 8:42 AM          posted from North Platte, NE      </aside></p></article></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>The following is a chronological consolidation of posts and microposts from August 6 through August 25, 2022.</p><article class='post'><h2><a href='../geocaching-westbound-day-1/index.html' rel='full-article'>Westbound to Seattle - Day 1</a></h2><div class='postmeta'>    Posted on 2022/08/07 4:57 PM          from Toledo, IA      </div></article><article class='post'><h2><a href='../geocaching-westbound-day-2/index.html' rel='full-article'>Westbound to Seattle - Day 2</a></h2><div class='postmeta'>    Posted on 2022/08/07 4:58 PM          from Toledo, IA      </div></article><article class='post'><h2><a href='../geocaching-westbound-day-3/index.html' rel='full-article'>Westbound to Seattle - Day 3</a></h2><div class='postmeta'>    Posted on 2022/08/07 4:58 PM          from Toledo, IA      </div></article><article class='post'><h2><a href='../geocaching-eastbound-day-1/index.html' rel='full-article'>Eastbound from Seattle - Day 1</a></h2><div class='postmeta'>    Posted on 2022/08/07 9:13 PM          from Toledo, IA      </div></article><article class='post'><h2><a href='../geocaching-eastbound-day-2/index.html' rel='full-article'>Eastbound from Seattle - Day 2</a></h2><div class='postmeta'>    Posted on 2022/08/08 1:39 PM          from Toledo, IA      </div></article><article class='post'><h2><a href='../geocaching-eastbound-day-3/index.html' rel='full-article'>Eastbound from Seattle - Day 3</a></h2><div class='postmeta'>    Posted on 2022/08/08 2:44 PM          from Toledo, IA      </div></article><article class='micropost'><p>  Waiting for my ride to Johnston.  <aside class='postmeta'>â†’ 2022/08/12 7:37 AM          posted from Toledo, IA      </aside></p></article><article class='micropost'><p>  Departed for Seattle a few minutes  after 6 AM.  <aside class='postmeta'>â†’ 2022/08/16 6:14 AM          posted from Montour, IA      </aside></p></article><article class='micropost'><p>  Lunch at Culverâ€™s in Brookings, SD.  <aside class='postmeta'>â†’ 2022/08/16 11:52 AM          posted from Brookings, SD      </aside></p></article><article class='micropost'><p>  Got my first North Dakota geocache find a few miles back down the road.  <aside class='postmeta'>â†’ 2022/08/16 2:18 PM          posted from Wahpeton, ND      </aside></p></article><article class='micropost'><p>  Passing through the outskirts of metropolitan Fargo.  <aside class='postmeta'>â†’ 2022/08/16 3:10 PM          posted from West Fargo, ND      </aside></p></article><article class='micropost'><p>  Headed west across North Dakota for GC 551, the stateâ€™s oldest active geocache.  <aside class='postmeta'>â†’ 2022/08/16 5:24 PM          posted from Steele, ND      </aside></p></article><article class='micropost'><p>  Arrived for the night around 9:25 pm in Miles City, Montana, about 70 miles past our intended stop.  <aside class='postmeta'>â†’ 2022/08/16 9:52 PM          posted from Miles City, MT      </aside></p></article><article class='micropost'><p>  First cache of the day:  Headed to GCHGZZ in a rest area in Montana.  <aside class='postmeta'>â†’ 2022/08/17 6:43 AM          posted from Rosebud, MT      </aside></p></article><article class='micropost'><p>  GCKHRJ:  Was not on our original list but a really quick stop and well worth the time out.  <aside class='postmeta'>â†’ 2022/08/17 9:46 AM          posted from Big Timber, MT      </aside></p></article><article class='micropost'><p>  Just departed from the headwaters of the Missouri river state park in Montana and the stateâ€™s oldest pair of geocaches.  Check my track logs on <a href='https://hikes.summittdweller.com'>https://hikes.summittdweller.com</a> for more details.  <aside class='postmeta'>â†’ 2022/08/17 1:21 PM          posted from Headwaters of the Missouri River, Montana      </aside></p></article><article class='micropost'><p>  Stopped for dinner in Coeur dâ€™Alene at Rogers Ice Cream and Burgers.  <aside class='postmeta'>â†’ 2022/08/17 6:13 PM          posted from Coeur d'Alene, ID      </aside></p></article><article class='micropost'><p>  Excellent company for the reviewers lunch after the APE geocache at Snoqualmie Pass, Washington.  <aside class='postmeta'>â†’ 2022/08/18 2:32 PM          posted from Snoqualmie Pass, WA      </aside></p></article><article class='micropost'><p>  Relaxing and catching up in the hotel (the Maxwell near the Space Needle) after a great day of geocaching, hiking (10 miles or more) and lite travel.  <aside class='postmeta'>â†’ 2022/08/18 9:46 PM          posted from Seattle, WA      </aside></p></article><article class='micropost'><p>  No time to blog!  Attending the Geocaching 20th Celebration.  <aside class='postmeta'>â†’ 2022/08/20 10:38 AM          posted from Seattle, WA      </aside></p></article><article class='micropost'><p>  Southbound on I5 to the Original Stash SE of Portland.  <aside class='postmeta'>â†’ 2022/08/21 5:55 AM          posted from Tukwila, WA      </aside></p></article><article class='micropost'><p>  Grabbing a quick lunch at McDonaldâ€™s.  <aside class='postmeta'>â†’ 2022/08/21 1:59 PM          posted from Madras, OR      </aside></p></article><article class='micropost'><p>  The apex of an epic road-trip!  <aside class='postmeta'>â†’ 2022/08/21 7:11 PM          posted from Davis Creek, CA      </aside></p></article><article class='micropost'><p>  Winnemucca ETA is 11:35pm.  Never have I seen so many stars.  <aside class='postmeta'>â†’ 2022/08/21 10:09 PM          posted from Denico Junction, NV      </aside></p></article><article class='micropost'><p>  Tomâ€™s reaction when we popped over the hill to see the Bonneville salt flats was â€œholy shitâ€.  <aside class='postmeta'>â†’ 2022/08/22 11:22 AM          posted from West Wendover, NV      </aside></p></article><article class='micropost'><p>  Posting an <a href='../geocaching-eastbound-day-3/index.html'>updated itinerary</a> for eastbound day 3.  <aside class='postmeta'>â†’ 2022/08/22 7:22 PM          posted from Rawlins, WY      </aside></p></article><article class='micropost'><p>  Planning a lunch stop in Grand Island with Heartland Cacher and then on home to Iowa so Reviewer Smith can get back to Illinois this evening.  <aside class='postmeta'>â†’ 2022/08/23 8:42 AM          posted from North Platte, NE      </aside></p></article></p></article><!--kg-card-end: html-->",
            "comment_id": "3",
            "plaintext": "The following is a chronological consolidation of posts and microposts from August 6 through August 25, 2022.\n\n\nWestbound to Seattle - Day 1\n\nPosted on 2022/08/07 4:57 PM from Toledo, IA\n\n\nWestbound to Seattle - Day 2\n\nPosted on 2022/08/07 4:58 PM from Toledo, IA\n\n\nWestbound to Seattle - Day 3\n\nPosted on 2022/08/07 4:58 PM from Toledo, IA\n\n\nEastbound from Seattle - Day 1\n\nPosted on 2022/08/07 9:13 PM from Toledo, IA\n\n\nEastbound from Seattle - Day 2\n\nPosted on 2022/08/08 1:39 PM from Toledo, IA\n\n\nEastbound from Seattle - Day 3\n\nPosted on 2022/08/08 2:44 PM from Toledo, IA\n\nWaiting for my ride to Johnston.\n\nâ†’ 2022/08/12 7:37 AM posted from Toledo, IA\n\n\n\nDeparted for Seattle a few minutes after 6 AM.\n\nâ†’ 2022/08/16 6:14 AM posted from Montour, IA\n\n\n\nLunch at Culverâ€™s in Brookings, SD.\n\nâ†’ 2022/08/16 11:52 AM posted from Brookings, SD\n\n\n\nGot my first North Dakota geocache find a few miles back down the road.\n\nâ†’ 2022/08/16 2:18 PM posted from Wahpeton, ND\n\n\n\nPassing through the outskirts of metropolitan Fargo.\n\nâ†’ 2022/08/16 3:10 PM posted from West Fargo, ND\n\n\n\nHeaded west across North Dakota for GC 551, the stateâ€™s oldest active geocache.\n\nâ†’ 2022/08/16 5:24 PM posted from Steele, ND\n\n\n\nArrived for the night around 9:25 pm in Miles City, Montana, about 70 miles past our intended stop.\n\nâ†’ 2022/08/16 9:52 PM posted from Miles City, MT\n\n\n\nFirst cache of the day: Headed to GCHGZZ in a rest area in Montana.\n\nâ†’ 2022/08/17 6:43 AM posted from Rosebud, MT\n\n\n\nGCKHRJ: Was not on our original list but a really quick stop and well worth the time out.\n\nâ†’ 2022/08/17 9:46 AM posted from Big Timber, MT\n\n\n\nJust departed from the headwaters of the Missouri river state park in Montana and the stateâ€™s oldest pair of geocaches. Check my track logs on https://hikes.summittdweller.com for more details.\n\nâ†’ 2022/08/17 1:21 PM posted from Headwaters of the Missouri River, Montana\n\n\n\nStopped for dinner in Coeur dâ€™Alene at Rogers Ice Cream and Burgers.\n\nâ†’ 2022/08/17 6:13 PM posted from Coeur d'Alene, ID\n\n\n\nExcellent company for the reviewers lunch after the APE geocache at Snoqualmie Pass, Washington.\n\nâ†’ 2022/08/18 2:32 PM posted from Snoqualmie Pass, WA\n\n\n\nRelaxing and catching up in the hotel (the Maxwell near the Space Needle) after a great day of geocaching, hiking (10 miles or more) and lite travel.\n\nâ†’ 2022/08/18 9:46 PM posted from Seattle, WA\n\n\n\nNo time to blog! Attending the Geocaching 20th Celebration.\n\nâ†’ 2022/08/20 10:38 AM posted from Seattle, WA\n\n\n\nSouthbound on I5 to the Original Stash SE of Portland.\n\nâ†’ 2022/08/21 5:55 AM posted from Tukwila, WA\n\n\n\nGrabbing a quick lunch at McDonaldâ€™s.\n\nâ†’ 2022/08/21 1:59 PM posted from Madras, OR\n\n\n\nThe apex of an epic road-trip!\n\nâ†’ 2022/08/21 7:11 PM posted from Davis Creek, CA\n\n\n\nWinnemucca ETA is 11:35pm. Never have I seen so many stars.\n\nâ†’ 2022/08/21 10:09 PM posted from Denico Junction, NV\n\n\n\nTomâ€™s reaction when we popped over the hill to see the Bonneville salt flats was â€œholy shitâ€.\n\nâ†’ 2022/08/22 11:22 AM posted from West Wendover, NV\n\n\n\nPosting an updated itinerary for eastbound day 3.\n\nâ†’ 2022/08/22 7:22 PM posted from Rawlins, WY\n\n\n\nPlanning a lunch stop in Grand Island with Heartland Cacher and then on home to Iowa so Reviewer Smith can get back to Illinois this evening.\n\nâ†’ 2022/08/23 8:42 AM posted from North Platte, NE\n\n\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:01.000Z",
            "updated_at": "2023-04-02T03:49:02.000Z",
            "published_at": "2022-09-25T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57873",
            "uuid": "5678cf19-cd20-46c9-a309-176e4c335943",
            "title": "Migrating the Wieting Site in Drupal 8",
            "slug": "migrating-the-wieting-site-in-drupal-8",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><h1 id='migrating-the-wieting-site-in-drupal-8'>Migrating the Wieting Site in Drupal 8</h1><p>Sorry for my extended absence here, Iâ€™ve been uber-busy with work, but have also been able to work a little (lots of long nights and weekends) on a long-overdue update of <a href='https://Wieting.TamaToledo.com'>https://Wieting.TamaToledo.com</a> in <em>Drupal 8</em>.  Itâ€™s true, I have been thinking about moving that site to make it static, almost certainly using <em>Hugo</em>, but I thought before doing so Iâ€™d give <em>Drupal 8</em> one more try.  Iâ€™m pleased to report that itâ€™s working nicely again.  Hereâ€™s how I did it, and how I plan to keep it updatedâ€¦</p><h2 id='saved-by-docker-compose-drupal'>Saved by â€œdocker-compose-drupalâ€</h2><p>I actually started the process of migrating and updating <a href='https://wieting.tamatoledo.com'>the Wieting website</a> in <em>Docksal</em>, but I failedâ€¦ I could never figure out how to reliably and easily push my work to production from there.  <em>Docksal</em> just seems to wrap so much of itself into the <code>cli</code> container that drives it, I found it difficult to de-couple from that in production.</p><p>So I went looking elsewhere and discovered <a href='https://devwithlando.org'>Lando</a>, and I did considerable work with it because <em>Lando</em>, at least in the case of <em>Drupal</em>, builds a 3-part development stack that looks a lot like what I wanted to deploy in production.  The parts of a <em>Lando</em> stack, and my production stack, are the same:</p><ul><li>An <code>nginx</code> web server container,</li><li>A <code>mysql</code> or <code>mariadb</code> database container, and</li><li>A <code>php</code> codebase container.</li></ul><p>But once again I had trouble figuring out exactly how to push that development stack to production.  So, I went looking again for an open (and by that I mean â€œfreeâ€ and freely modifiable) production-ready stack configuration that uses the 3-parts I had in mind.  I found <a href='https://github.com/mogtofu33/docker-compose-drupal'>docker-compose-drupal</a> and almost immediately created <a href='https://github.com/SummittDweller/docker-compose-drupal'>my own fork</a> of that project. Using <a href='https://github.com/SummittDweller/docker-compose-drupal'>my <code>docker-compose-drupal</code> fork</a> I set off to build a production instance, NOT a development instance, on my <code>summitt-dweller-DO-docker</code> droplet at <em>DigitalOcean</em>.  That project came to life in <code>/opt/docker-compose-drupal</code> there.</p><p>The evolution of <code>summitt-dweller-DO-docker:/opt/docker-compose-drupal</code> was quite an adventure, in large part because the <em>Wietingâ€™s</em> web site had gone almost a year without any updates.  That meant upgrading the <em>Drupal</em> core from version 8.2.? to version 8.8.2, along with countless modules that had changed rather dramatically, so there were lots of bumps along the way.  I also had to move the site from a multi-site configuration, the old site lived in a container at <code>/var/www/html/web/sites/wieting</code>, to a <em>default</em> configuration that lives in the container at <code>/var/www/localhost/web/sites/default</code>.</p><p>Fortunately, <a href='https://github.com/mogtofu33/docker-compose-drupal'>docker-compose-drupal</a> includes some nice scripts and features to help with things like that, and they are nicely documented in the <a href='https://github.com/mogtofu33/docker-compose-drupal/blob/master/README.md'>projectâ€™s README.md</a> file.  Iâ€™ll elaborate on a few of the key features later in this post, but most of what I did during the migration and update is water-under-the-bridge, and should not need to be repeated, ever, so I wonâ€™t elaborate on all of it here.  Itâ€™s worth noting here that the work I did in my fork all happened in a branch named <code>wieting</code>.</p><h2 id='moved-to-wieting-d8-do'>Moved to â€œwieting-D8-DOâ€</h2><p>Once I had a new site working as Iâ€™d hoped, I wanted to begin a fresh new development and update cycle, so I used a process Iâ€™ve documented in my work blog: <a href='https://static.grinnell.edu/blogs/McFateM/posts/065-create-new-github-project-from-a-branch/'>â€œHow to Create a New GitHub Repo from an Existing Branchâ€</a>. That work created the <em>Wieting</em> siteâ€™s new home, <a href='https://github.com/SummittDweller/wieting-D8-DO'>https://github.com/SummittDweller/wieting-D8-DO</a>, based on the <em>wieting</em> branch of the aforementioned fork of <em>docker-compose-drupal</em>.</p><h2 id='site-update-workflow'>Site Update Workflow</h2><p>Having built the <a href='https://github.com/SummittDweller/wieting-D8-DO'>wieting-D8-DO</a> project I need a reliable workflow that I could use to keep it up-to-date.  I created that workflow by migrating the existing production site at <code>summitt-dweller-DO-docker:/opt/docker-compose-drupal</code>, where it responded as <em><a href='https://Wieting.TamaToledo.org'>https://Wieting.TamaToledo.org</a></em>, to a new staging copy at <code>summitt-dweller-DO-docker:/opt/wieting-D8-DO</code>, where it would respond, temporarily, at my designated â€œstagingâ€ address, <em><a href='https://Wieting.SummittServices.com'>https://Wieting.SummittServices.com</a></em>.</p><p>While working as <em>administrator</em> on <code>summitt-dweller-DO-docker</code> the entire command-line process looked like this:</p><pre tabindex='0'><code>echo $(date --iso-8601)cd /opt/docker-compose-drupalgit ls-files --others --ignored --exclude-standard &gt; $(date --iso-8601).ignored.listtar czvf $(date --iso-8601).ignored.list.tar.gz --files-from $(date --iso-8601).ignored.listgpg --encrypt --recipient summitt.dweller@gmail.com $(date --iso-8601).ignored.list.tar.gzrm -fr $(date --iso-8601).ignored.list.tar.gzcd /optgit clone https://github.com/SummittDweller/wieting-D8-DO.gitcd wieting-D8-DOcp -f ../docker-compose-drupal/2020-02-27.ignored.list.tar.gz.gpg .gpg --decrypt 2020-02-27.ignored.list.tar.gz.gpg &gt; ignored.tar.gztar xzvf ignored.tar.gzrm -f ignored.tar.gzcd ../docker-compose-drupalscripts/mysql dumpmv -f database/dump/dump.sql /opt/wieting-D8-DO/database/mysql-initcd /opt/wieting-D8-DOnano .envnano docker-compose.ymldocker-compose up -d</code></pre><h3 id='breaking-the-workflow-down'>Breaking the Workflow Down</h3><p>Moving the site from <code>/opt/docker-compose-drupal</code> and <a href='https://Wieting.TamaToledo.com'>https://Wieting.TamaToledo.com</a>, to <code>/opt/wieting-D8-DO</code> and <a href='https://Wieting.SummittServices.com'>https://Wieting.SummittServices.com</a> is a command-line process like this, with commentsâ€¦</p><table><thead><tr><th>Comments / Commands</th></tr></thead><tbody><tr><td># Set the working directory to the serverâ€™s project root, then <code>git clone</code> the <em>wieting-D8-DO</em> project.<br/> <code>cd /opt</code> <br/> <code>git clone https://github.com/SummittDweller/wieting-D8-DO.git</code></td></tr><tr><td># Save todayâ€™s date in ISO 8601 format to <code>${today}</code>; we will use it a few times later on. <br/> <code>today=$(date --iso-8601)</code></td></tr><tr><td># Set working directory to the initial project. Put the site into â€˜maintenance_modeâ€™, flush all caches, dump a copy of the projectâ€™s database, move previously dumped databases to an <em>.inactive</em> directory, and move the dumped database so it will initialze the new site upon startup. <br/> <code>cd /opt/docker-compose-drupal</code> <br/> <code>scripts/drush sset system.maintenance_mode 1 --input-format=integer</code> <br/> <code>scripts/drush cr</code> <br/> <code>scripts/mysql dump -f dump_${today}.sql</code> <br/> <code>mv -f /opt/wieting-D8-DO/database/mysql-init/*.sql /opt/wieting-D8-DO/database/mysql-init/.inactive/</code> <br/> <code>mv -f database/dump/dump_${today}.sql /opt/wieting-D8-DO/database/mysql-init/</code></td></tr><tr><td># Fetch a list of ignored files, then <em>tar</em> the ignored files to make an archive, and encrypt the tarball for security purposes, then remove the itermediate tarball. <br/> <code>git ls-files --others --ignored --exclude-standard &gt; ${today}.ignored.list</code> <br/> <code>tar czvf ${today}.ignored.list.tar.gz --files-from ${today}.ignored.list</code> <br/> <code>gpg --encrypt --recipient summitt.dweller@gmail.com ${today}.ignored.list.tar.gz</code> <br/> <code>rm -fr ${today}.ignored.list.tar.gz</code></td></tr><tr><td># Now set the working directory to the new project, copy the tarball from the old site to the new one, decrypt and then restore/extract the tarball contents, and finally, remove the intermediate tarball. <br/> <code>cd /opt/wieting-D8-DO</code> <br/> <code>cp -f ../docker-compose-drupal/${today}.ignored.list.tar.gz.gpg .</code> <br/> <code>gpg --decrypt ${today}.ignored.list.tar.gz.gpg &gt; ignored.tar.gz</code> <br/> <code>tar xzvf ignored.tar.gz</code> <br/> <code>rm -f ignored.tar.gz</code></td></tr><tr><td># Working in the new directory, edit the <em>.env</em> file to set <code>PROJECT_NAME</code>, <code>NGINX_HOST_HTTP_PORT</code> and <code>NGINX_HOST_HTTPS_PORT</code> that wonâ€™t conflict with existing names. <br/> <code>nano .env</code></td></tr><tr><td># Still in the new directory, edit the <em>docker-compose.yml</em> file to set the <em>nginx</em> service <code>labels:</code> to include  <code>traefik.frontend.rule=Host:wieting.SummittServices.com</code>, to properly address the new site. <br/> <code>nano docker-compose.yml</code></td></tr><tr><td># Spin up the new site for testing. <br/> <code>docker-compose up -d</code></td></tr><tr><td># Turn off â€˜maintenance_modeâ€™ in both sites. <br/> <code>/opt/docker-compose-drupal/scripts/drush sset system.maintenance_mode 0 --input-format=integer</code> <br/> <code>/opt/wieting-D8-DO/scripts/drush sset system.maintenance_mode 0 --input-format=integer</code></td></tr></tbody></table><p>That worked nicely!  Time to end this saga, but Iâ€™ll return shortly, in another post, to document my workflow for ongoing maintenance and updates.  Until next timeâ€¦</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><h1 id='migrating-the-wieting-site-in-drupal-8'>Migrating the Wieting Site in Drupal 8</h1><p>Sorry for my extended absence here, Iâ€™ve been uber-busy with work, but have also been able to work a little (lots of long nights and weekends) on a long-overdue update of <a href='https://Wieting.TamaToledo.com'>https://Wieting.TamaToledo.com</a> in <em>Drupal 8</em>.  Itâ€™s true, I have been thinking about moving that site to make it static, almost certainly using <em>Hugo</em>, but I thought before doing so Iâ€™d give <em>Drupal 8</em> one more try.  Iâ€™m pleased to report that itâ€™s working nicely again.  Hereâ€™s how I did it, and how I plan to keep it updatedâ€¦</p><h2 id='saved-by-docker-compose-drupal'>Saved by â€œdocker-compose-drupalâ€</h2><p>I actually started the process of migrating and updating <a href='https://wieting.tamatoledo.com'>the Wieting website</a> in <em>Docksal</em>, but I failedâ€¦ I could never figure out how to reliably and easily push my work to production from there.  <em>Docksal</em> just seems to wrap so much of itself into the <code>cli</code> container that drives it, I found it difficult to de-couple from that in production.</p><p>So I went looking elsewhere and discovered <a href='https://devwithlando.org'>Lando</a>, and I did considerable work with it because <em>Lando</em>, at least in the case of <em>Drupal</em>, builds a 3-part development stack that looks a lot like what I wanted to deploy in production.  The parts of a <em>Lando</em> stack, and my production stack, are the same:</p><ul><li>An <code>nginx</code> web server container,</li><li>A <code>mysql</code> or <code>mariadb</code> database container, and</li><li>A <code>php</code> codebase container.</li></ul><p>But once again I had trouble figuring out exactly how to push that development stack to production.  So, I went looking again for an open (and by that I mean â€œfreeâ€ and freely modifiable) production-ready stack configuration that uses the 3-parts I had in mind.  I found <a href='https://github.com/mogtofu33/docker-compose-drupal'>docker-compose-drupal</a> and almost immediately created <a href='https://github.com/SummittDweller/docker-compose-drupal'>my own fork</a> of that project. Using <a href='https://github.com/SummittDweller/docker-compose-drupal'>my <code>docker-compose-drupal</code> fork</a> I set off to build a production instance, NOT a development instance, on my <code>summitt-dweller-DO-docker</code> droplet at <em>DigitalOcean</em>.  That project came to life in <code>/opt/docker-compose-drupal</code> there.</p><p>The evolution of <code>summitt-dweller-DO-docker:/opt/docker-compose-drupal</code> was quite an adventure, in large part because the <em>Wietingâ€™s</em> web site had gone almost a year without any updates.  That meant upgrading the <em>Drupal</em> core from version 8.2.? to version 8.8.2, along with countless modules that had changed rather dramatically, so there were lots of bumps along the way.  I also had to move the site from a multi-site configuration, the old site lived in a container at <code>/var/www/html/web/sites/wieting</code>, to a <em>default</em> configuration that lives in the container at <code>/var/www/localhost/web/sites/default</code>.</p><p>Fortunately, <a href='https://github.com/mogtofu33/docker-compose-drupal'>docker-compose-drupal</a> includes some nice scripts and features to help with things like that, and they are nicely documented in the <a href='https://github.com/mogtofu33/docker-compose-drupal/blob/master/README.md'>projectâ€™s README.md</a> file.  Iâ€™ll elaborate on a few of the key features later in this post, but most of what I did during the migration and update is water-under-the-bridge, and should not need to be repeated, ever, so I wonâ€™t elaborate on all of it here.  Itâ€™s worth noting here that the work I did in my fork all happened in a branch named <code>wieting</code>.</p><h2 id='moved-to-wieting-d8-do'>Moved to â€œwieting-D8-DOâ€</h2><p>Once I had a new site working as Iâ€™d hoped, I wanted to begin a fresh new development and update cycle, so I used a process Iâ€™ve documented in my work blog: <a href='https://static.grinnell.edu/blogs/McFateM/posts/065-create-new-github-project-from-a-branch/'>â€œHow to Create a New GitHub Repo from an Existing Branchâ€</a>. That work created the <em>Wieting</em> siteâ€™s new home, <a href='https://github.com/SummittDweller/wieting-D8-DO'>https://github.com/SummittDweller/wieting-D8-DO</a>, based on the <em>wieting</em> branch of the aforementioned fork of <em>docker-compose-drupal</em>.</p><h2 id='site-update-workflow'>Site Update Workflow</h2><p>Having built the <a href='https://github.com/SummittDweller/wieting-D8-DO'>wieting-D8-DO</a> project I need a reliable workflow that I could use to keep it up-to-date.  I created that workflow by migrating the existing production site at <code>summitt-dweller-DO-docker:/opt/docker-compose-drupal</code>, where it responded as <em><a href='https://Wieting.TamaToledo.org'>https://Wieting.TamaToledo.org</a></em>, to a new staging copy at <code>summitt-dweller-DO-docker:/opt/wieting-D8-DO</code>, where it would respond, temporarily, at my designated â€œstagingâ€ address, <em><a href='https://Wieting.SummittServices.com'>https://Wieting.SummittServices.com</a></em>.</p><p>While working as <em>administrator</em> on <code>summitt-dweller-DO-docker</code> the entire command-line process looked like this:</p><pre tabindex='0'><code>echo $(date --iso-8601)cd /opt/docker-compose-drupalgit ls-files --others --ignored --exclude-standard &gt; $(date --iso-8601).ignored.listtar czvf $(date --iso-8601).ignored.list.tar.gz --files-from $(date --iso-8601).ignored.listgpg --encrypt --recipient summitt.dweller@gmail.com $(date --iso-8601).ignored.list.tar.gzrm -fr $(date --iso-8601).ignored.list.tar.gzcd /optgit clone https://github.com/SummittDweller/wieting-D8-DO.gitcd wieting-D8-DOcp -f ../docker-compose-drupal/2020-02-27.ignored.list.tar.gz.gpg .gpg --decrypt 2020-02-27.ignored.list.tar.gz.gpg &gt; ignored.tar.gztar xzvf ignored.tar.gzrm -f ignored.tar.gzcd ../docker-compose-drupalscripts/mysql dumpmv -f database/dump/dump.sql /opt/wieting-D8-DO/database/mysql-initcd /opt/wieting-D8-DOnano .envnano docker-compose.ymldocker-compose up -d</code></pre><h3 id='breaking-the-workflow-down'>Breaking the Workflow Down</h3><p>Moving the site from <code>/opt/docker-compose-drupal</code> and <a href='https://Wieting.TamaToledo.com'>https://Wieting.TamaToledo.com</a>, to <code>/opt/wieting-D8-DO</code> and <a href='https://Wieting.SummittServices.com'>https://Wieting.SummittServices.com</a> is a command-line process like this, with commentsâ€¦</p><table><thead><tr><th>Comments / Commands</th></tr></thead><tbody><tr><td># Set the working directory to the serverâ€™s project root, then <code>git clone</code> the <em>wieting-D8-DO</em> project.<br/> <code>cd /opt</code> <br/> <code>git clone https://github.com/SummittDweller/wieting-D8-DO.git</code></td></tr><tr><td># Save todayâ€™s date in ISO 8601 format to <code>${today}</code>; we will use it a few times later on. <br/> <code>today=$(date --iso-8601)</code></td></tr><tr><td># Set working directory to the initial project. Put the site into â€˜maintenance_modeâ€™, flush all caches, dump a copy of the projectâ€™s database, move previously dumped databases to an <em>.inactive</em> directory, and move the dumped database so it will initialze the new site upon startup. <br/> <code>cd /opt/docker-compose-drupal</code> <br/> <code>scripts/drush sset system.maintenance_mode 1 --input-format=integer</code> <br/> <code>scripts/drush cr</code> <br/> <code>scripts/mysql dump -f dump_${today}.sql</code> <br/> <code>mv -f /opt/wieting-D8-DO/database/mysql-init/*.sql /opt/wieting-D8-DO/database/mysql-init/.inactive/</code> <br/> <code>mv -f database/dump/dump_${today}.sql /opt/wieting-D8-DO/database/mysql-init/</code></td></tr><tr><td># Fetch a list of ignored files, then <em>tar</em> the ignored files to make an archive, and encrypt the tarball for security purposes, then remove the itermediate tarball. <br/> <code>git ls-files --others --ignored --exclude-standard &gt; ${today}.ignored.list</code> <br/> <code>tar czvf ${today}.ignored.list.tar.gz --files-from ${today}.ignored.list</code> <br/> <code>gpg --encrypt --recipient summitt.dweller@gmail.com ${today}.ignored.list.tar.gz</code> <br/> <code>rm -fr ${today}.ignored.list.tar.gz</code></td></tr><tr><td># Now set the working directory to the new project, copy the tarball from the old site to the new one, decrypt and then restore/extract the tarball contents, and finally, remove the intermediate tarball. <br/> <code>cd /opt/wieting-D8-DO</code> <br/> <code>cp -f ../docker-compose-drupal/${today}.ignored.list.tar.gz.gpg .</code> <br/> <code>gpg --decrypt ${today}.ignored.list.tar.gz.gpg &gt; ignored.tar.gz</code> <br/> <code>tar xzvf ignored.tar.gz</code> <br/> <code>rm -f ignored.tar.gz</code></td></tr><tr><td># Working in the new directory, edit the <em>.env</em> file to set <code>PROJECT_NAME</code>, <code>NGINX_HOST_HTTP_PORT</code> and <code>NGINX_HOST_HTTPS_PORT</code> that wonâ€™t conflict with existing names. <br/> <code>nano .env</code></td></tr><tr><td># Still in the new directory, edit the <em>docker-compose.yml</em> file to set the <em>nginx</em> service <code>labels:</code> to include  <code>traefik.frontend.rule=Host:wieting.SummittServices.com</code>, to properly address the new site. <br/> <code>nano docker-compose.yml</code></td></tr><tr><td># Spin up the new site for testing. <br/> <code>docker-compose up -d</code></td></tr><tr><td># Turn off â€˜maintenance_modeâ€™ in both sites. <br/> <code>/opt/docker-compose-drupal/scripts/drush sset system.maintenance_mode 0 --input-format=integer</code> <br/> <code>/opt/wieting-D8-DO/scripts/drush sset system.maintenance_mode 0 --input-format=integer</code></td></tr></tbody></table><p>That worked nicely!  Time to end this saga, but Iâ€™ll return shortly, in another post, to document my workflow for ongoing maintenance and updates.  Until next timeâ€¦</p></p></article><!--kg-card-end: html-->",
            "comment_id": "5",
            "plaintext": "Migrating the Wieting Site in Drupal 8\n\nSorry for my extended absence here, Iâ€™ve been uber-busy with work, but have also been able to work a little (lots of long nights and weekends) on a long-overdue update of https://Wieting.TamaToledo.com in Drupal 8. Itâ€™s true, I have been thinking about moving that site to make it static, almost certainly using Hugo, but I thought before doing so Iâ€™d give Drupal 8 one more try. Iâ€™m pleased to report that itâ€™s working nicely again. Hereâ€™s how I did it, and how I plan to keep it updatedâ€¦\n\n\nSaved by â€œdocker-compose-drupalâ€\n\nI actually started the process of migrating and updating the Wieting website in Docksal, but I failedâ€¦ I could never figure out how to reliably and easily push my work to production from there. Docksal just seems to wrap so much of itself into the cli container that drives it, I found it difficult to de-couple from that in production.\n\nSo I went looking elsewhere and discovered Lando, and I did considerable work with it because Lando, at least in the case of Drupal, builds a 3-part development stack that looks a lot like what I wanted to deploy in production. The parts of a Lando stack, and my production stack, are the same:\n\n * An nginx web server container,\n * A mysql or mariadb database container, and\n * A php codebase container.\n\nBut once again I had trouble figuring out exactly how to push that development stack to production. So, I went looking again for an open (and by that I mean â€œfreeâ€ and freely modifiable) production-ready stack configuration that uses the 3-parts I had in mind. I found docker-compose-drupal and almost immediately created my own fork of that project. Using my docker-compose-drupal fork I set off to build a production instance, NOT a development instance, on my summitt-dweller-DO-docker droplet at DigitalOcean. That project came to life in /opt/docker-compose-drupal there.\n\nThe evolution of summitt-dweller-DO-docker:/opt/docker-compose-drupal was quite an adventure, in large part because the Wietingâ€™s web site had gone almost a year without any updates. That meant upgrading the Drupal core from version 8.2.? to version 8.8.2, along with countless modules that had changed rather dramatically, so there were lots of bumps along the way. I also had to move the site from a multi-site configuration, the old site lived in a container at /var/www/html/web/sites/wieting, to a default configuration that lives in the container at /var/www/localhost/web/sites/default.\n\nFortunately, docker-compose-drupal includes some nice scripts and features to help with things like that, and they are nicely documented in the projectâ€™s README.md file. Iâ€™ll elaborate on a few of the key features later in this post, but most of what I did during the migration and update is water-under-the-bridge, and should not need to be repeated, ever, so I wonâ€™t elaborate on all of it here. Itâ€™s worth noting here that the work I did in my fork all happened in a branch named wieting.\n\n\nMoved to â€œwieting-D8-DOâ€\n\nOnce I had a new site working as Iâ€™d hoped, I wanted to begin a fresh new development and update cycle, so I used a process Iâ€™ve documented in my work blog: â€œHow to Create a New GitHub Repo from an Existing Branchâ€. That work created the Wieting siteâ€™s new home, https://github.com/SummittDweller/wieting-D8-DO, based on the wieting branch of the aforementioned fork of docker-compose-drupal.\n\n\nSite Update Workflow\n\nHaving built the wieting-D8-DO project I need a reliable workflow that I could use to keep it up-to-date. I created that workflow by migrating the existing production site at summitt-dweller-DO-docker:/opt/docker-compose-drupal, where it responded as https://Wieting.TamaToledo.org, to a new staging copy at summitt-dweller-DO-docker:/opt/wieting-D8-DO, where it would respond, temporarily, at my designated â€œstagingâ€ address, https://Wieting.SummittServices.com.\n\nWhile working as administrator on summitt-dweller-DO-docker the entire command-line process looked like this:\n\necho $(date --iso-8601)cd /opt/docker-compose-drupalgit ls-files --others --ignored --exclude-standard > $(date --iso-8601).ignored.listtar czvf $(date --iso-8601).ignored.list.tar.gz --files-from $(date --iso-8601).ignored.listgpg --encrypt --recipient summitt.dweller@gmail.com $(date --iso-8601).ignored.list.tar.gzrm -fr $(date --iso-8601).ignored.list.tar.gzcd /optgit clone https://github.com/SummittDweller/wieting-D8-DO.gitcd wieting-D8-DOcp -f ../docker-compose-drupal/2020-02-27.ignored.list.tar.gz.gpg .gpg --decrypt 2020-02-27.ignored.list.tar.gz.gpg > ignored.tar.gztar xzvf ignored.tar.gzrm -f ignored.tar.gzcd ../docker-compose-drupalscripts/mysql dumpmv -f database/dump/dump.sql /opt/wieting-D8-DO/database/mysql-initcd /opt/wieting-D8-DOnano .envnano docker-compose.ymldocker-compose up -d\n\n\nBreaking the Workflow Down\n\nMoving the site from /opt/docker-compose-drupal and https://Wieting.TamaToledo.com, to /opt/wieting-D8-DO and https://Wieting.SummittServices.com is a command-line process like this, with commentsâ€¦\n\nComments / Commands# Set the working directory to the serverâ€™s project root, then git clone the wieting-D8-DO project.\ncd /opt\ngit clone https://github.com/SummittDweller/wieting-D8-DO.git# Save todayâ€™s date in ISO 8601 format to ${today}; we will use it a few times later on.\ntoday=$(date --iso-8601)# Set working directory to the initial project. Put the site into â€˜maintenance_modeâ€™, flush all caches, dump a copy of the projectâ€™s database, move previously dumped databases to an .inactive directory, and move the dumped database so it will initialze the new site upon startup.\ncd /opt/docker-compose-drupal\nscripts/drush sset system.maintenance_mode 1 --input-format=integer\nscripts/drush cr\nscripts/mysql dump -f dump_${today}.sql\nmv -f /opt/wieting-D8-DO/database/mysql-init/*.sql /opt/wieting-D8-DO/database/mysql-init/.inactive/\nmv -f database/dump/dump_${today}.sql /opt/wieting-D8-DO/database/mysql-init/# Fetch a list of ignored files, then tar the ignored files to make an archive, and encrypt the tarball for security purposes, then remove the itermediate tarball.\ngit ls-files --others --ignored --exclude-standard > ${today}.ignored.list\ntar czvf ${today}.ignored.list.tar.gz --files-from ${today}.ignored.list\ngpg --encrypt --recipient summitt.dweller@gmail.com ${today}.ignored.list.tar.gz\nrm -fr ${today}.ignored.list.tar.gz# Now set the working directory to the new project, copy the tarball from the old site to the new one, decrypt and then restore/extract the tarball contents, and finally, remove the intermediate tarball.\ncd /opt/wieting-D8-DO\ncp -f ../docker-compose-drupal/${today}.ignored.list.tar.gz.gpg .\ngpg --decrypt ${today}.ignored.list.tar.gz.gpg > ignored.tar.gz\ntar xzvf ignored.tar.gz\nrm -f ignored.tar.gz# Working in the new directory, edit the .env file to set PROJECT_NAME, NGINX_HOST_HTTP_PORT and NGINX_HOST_HTTPS_PORT that wonâ€™t conflict with existing names.\nnano .env# Still in the new directory, edit the docker-compose.yml file to set the nginx service labels: to include traefik.frontend.rule=Host:wieting.SummittServices.com, to properly address the new site.\nnano docker-compose.yml# Spin up the new site for testing.\ndocker-compose up -d# Turn off â€˜maintenance_modeâ€™ in both sites.\n/opt/docker-compose-drupal/scripts/drush sset system.maintenance_mode 0 --input-format=integer\n/opt/wieting-D8-DO/scripts/drush sset system.maintenance_mode 0 --input-format=integer\n\nThat worked nicely! Time to end this saga, but Iâ€™ll return shortly, in another post, to document my workflow for ongoing maintenance and updates. Until next timeâ€¦\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:02.000Z",
            "updated_at": "2023-04-02T03:50:55.000Z",
            "published_at": "2020-02-28T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57874",
            "uuid": "41abae99-a1ea-4f18-9e15-290807f18772",
            "title": "Derecho Follow-Up - Saturday, August 22",
            "slug": "derecho-follow-up---saturday--august-22",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>Almost every day for the past few months I have walked with my â€œscurryâ€ around Cherry Lake in Tama. We generally walk in the morning before the heat, humidity, and mosquitoes get too bad.  We finally got power back on Thursday evening, August 20, so on Friday morning, August 21, 2020, we walked for the first time since the derecho of August 10. It was actually more like an obstacle course than our usual stroll, but we still managed to collect quite a bit of trash, as usual. There were about a dozen places around the lake, a trail that is about 1.33 miles long, where fallen trees required that we climb over or weave around. Itâ€™s no fun to do either, especially since the â€œweavingâ€ sometimes involved venturing off-trail into the poison ivy. Makes me itch just thinking about it.</p><p>At the west end of Cherry Lake I placed a bench and engraved rock as a memorial for my parents, and my son, Ian. The most recent, pre-derecho photo of the rock and bench was taken on a â€œscurryâ€ walk around the lake early this Spring. Portions of scurry-partners Jeff Shaw, and the hind-quarters of four-legged scurry member, Titan Edward, can be seen in this photo from that excursion.</p><p><figure><img alt='McFate Memorial Bench at Cherry Lake - Early Spring 2020' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0121.png'/><figcaption>McFate Memorial Bench at Cherry Lake - Early Spring 2020</figcaption></figure></p><p>On the south side of the lake â€“ visible in the background of the photo above â€“ the trail runs parallel to a road that leads to a brush pile where Tama residents can dump tree limbs, brush and leaves collected from their yard.  Thereâ€™s been a LOT of that lately! On this occasion a friend of our, Charlie Betz, was hauling a pickup-load of derecho debris to the brush pile and stopped briefly to chat. Charlie suggested that someday soon he would return with his chainsaw to begin clearing deadfall from the trail. We told him to let us know when, and weâ€™d see if we could come help.  Well, that â€œwhenâ€ was 7 AM the next day, Saturday, August 22.</p><p>I arrived at the lake at 7 AM on the 22nd and found Charlie already there, preparing to fire up his saw. I brought my little 10' Ryobi cordless electric chainsaw and two fully-charged batteries. Jeff Shaw arrived about 20 minutes later and we proceeded to work our way counter-clockwise around the lake trail startring from the parking area on the east end of the lake.  It was slow going, especially at first since the north side of the lake is, or was, densely wooded with some mature trees.</p><p>After three hours of cutting and tossing debris to the side of the trail, we reached my familyâ€™s memorial bench at the west end of the lake.</p><p><figure><img alt='McFate Memorial Bench at Cherry Lake - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0324.png'/><figcaption>McFate Memorial Bench at Cherry Lake - After the Derecho</figcaption></figure></p><p>By this time we had waded through way too much PI, been briefly rained on, dulled Charlieâ€™s chainsaw blade, and drained both of the saw batteries I had on hand. I think we were drained too. Time for a break, so at 10 AM we departed for some rest, lunch, fresh batteries, and hopefully a new chain for Charlieâ€™s saw. We reconvened at Noon, as planned, and spent the next two hours clearing the deadfall around the McFate bench, plus a pair of gnarly monsters that had fallen across the trail near the southeast corner of the lake.</p><p>It felt really good to get it all done, and now we can engage in our â€œscurryâ€ walks around the lake without all the bobbing and weaving required to navigate the obstacle course that was.  Every good volunteer effort should conclude with a photo or two, so we got all cleaned up, NOT, and I shot this one.</p><p><figure><img alt='The Post-Derecho Cherry Lake Trail Cleanup Crew - Me, Charlie, and Jeff' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0325.png'/><figcaption>The Post-Derecho Cherry Lake Trail Cleanup Crew - Me, Charlie, and Jeff</figcaption></figure></p><p>Thatâ€™s a warp. Until next timeâ€¦ but only after Iâ€™ve had a pleasant scurry walk in the morning.</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>Almost every day for the past few months I have walked with my â€œscurryâ€ around Cherry Lake in Tama. We generally walk in the morning before the heat, humidity, and mosquitoes get too bad.  We finally got power back on Thursday evening, August 20, so on Friday morning, August 21, 2020, we walked for the first time since the derecho of August 10. It was actually more like an obstacle course than our usual stroll, but we still managed to collect quite a bit of trash, as usual. There were about a dozen places around the lake, a trail that is about 1.33 miles long, where fallen trees required that we climb over or weave around. Itâ€™s no fun to do either, especially since the â€œweavingâ€ sometimes involved venturing off-trail into the poison ivy. Makes me itch just thinking about it.</p><p>At the west end of Cherry Lake I placed a bench and engraved rock as a memorial for my parents, and my son, Ian. The most recent, pre-derecho photo of the rock and bench was taken on a â€œscurryâ€ walk around the lake early this Spring. Portions of scurry-partners Jeff Shaw, and the hind-quarters of four-legged scurry member, Titan Edward, can be seen in this photo from that excursion.</p><p><figure><img alt='McFate Memorial Bench at Cherry Lake - Early Spring 2020' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0121.png'/><figcaption>McFate Memorial Bench at Cherry Lake - Early Spring 2020</figcaption></figure></p><p>On the south side of the lake â€“ visible in the background of the photo above â€“ the trail runs parallel to a road that leads to a brush pile where Tama residents can dump tree limbs, brush and leaves collected from their yard.  Thereâ€™s been a LOT of that lately! On this occasion a friend of our, Charlie Betz, was hauling a pickup-load of derecho debris to the brush pile and stopped briefly to chat. Charlie suggested that someday soon he would return with his chainsaw to begin clearing deadfall from the trail. We told him to let us know when, and weâ€™d see if we could come help.  Well, that â€œwhenâ€ was 7 AM the next day, Saturday, August 22.</p><p>I arrived at the lake at 7 AM on the 22nd and found Charlie already there, preparing to fire up his saw. I brought my little 10' Ryobi cordless electric chainsaw and two fully-charged batteries. Jeff Shaw arrived about 20 minutes later and we proceeded to work our way counter-clockwise around the lake trail startring from the parking area on the east end of the lake.  It was slow going, especially at first since the north side of the lake is, or was, densely wooded with some mature trees.</p><p>After three hours of cutting and tossing debris to the side of the trail, we reached my familyâ€™s memorial bench at the west end of the lake.</p><p><figure><img alt='McFate Memorial Bench at Cherry Lake - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0324.png'/><figcaption>McFate Memorial Bench at Cherry Lake - After the Derecho</figcaption></figure></p><p>By this time we had waded through way too much PI, been briefly rained on, dulled Charlieâ€™s chainsaw blade, and drained both of the saw batteries I had on hand. I think we were drained too. Time for a break, so at 10 AM we departed for some rest, lunch, fresh batteries, and hopefully a new chain for Charlieâ€™s saw. We reconvened at Noon, as planned, and spent the next two hours clearing the deadfall around the McFate bench, plus a pair of gnarly monsters that had fallen across the trail near the southeast corner of the lake.</p><p>It felt really good to get it all done, and now we can engage in our â€œscurryâ€ walks around the lake without all the bobbing and weaving required to navigate the obstacle course that was.  Every good volunteer effort should conclude with a photo or two, so we got all cleaned up, NOT, and I shot this one.</p><p><figure><img alt='The Post-Derecho Cherry Lake Trail Cleanup Crew - Me, Charlie, and Jeff' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0325.png'/><figcaption>The Post-Derecho Cherry Lake Trail Cleanup Crew - Me, Charlie, and Jeff</figcaption></figure></p><p>Thatâ€™s a warp. Until next timeâ€¦ but only after Iâ€™ve had a pleasant scurry walk in the morning.</p></p></article><!--kg-card-end: html-->",
            "comment_id": "6",
            "plaintext": "Almost every day for the past few months I have walked with my â€œscurryâ€ around Cherry Lake in Tama. We generally walk in the morning before the heat, humidity, and mosquitoes get too bad. We finally got power back on Thursday evening, August 20, so on Friday morning, August 21, 2020, we walked for the first time since the derecho of August 10. It was actually more like an obstacle course than our usual stroll, but we still managed to collect quite a bit of trash, as usual. There were about a dozen places around the lake, a trail that is about 1.33 miles long, where fallen trees required that we climb over or weave around. Itâ€™s no fun to do either, especially since the â€œweavingâ€ sometimes involved venturing off-trail into the poison ivy. Makes me itch just thinking about it.\n\nAt the west end of Cherry Lake I placed a bench and engraved rock as a memorial for my parents, and my son, Ian. The most recent, pre-derecho photo of the rock and bench was taken on a â€œscurryâ€ walk around the lake early this Spring. Portions of scurry-partners Jeff Shaw, and the hind-quarters of four-legged scurry member, Titan Edward, can be seen in this photo from that excursion.\n\n\n\n\n\nOn the south side of the lake â€“ visible in the background of the photo above â€“ the trail runs parallel to a road that leads to a brush pile where Tama residents can dump tree limbs, brush and leaves collected from their yard. Thereâ€™s been a LOT of that lately! On this occasion a friend of our, Charlie Betz, was hauling a pickup-load of derecho debris to the brush pile and stopped briefly to chat. Charlie suggested that someday soon he would return with his chainsaw to begin clearing deadfall from the trail. We told him to let us know when, and weâ€™d see if we could come help. Well, that â€œwhenâ€ was 7 AM the next day, Saturday, August 22.\n\nI arrived at the lake at 7 AM on the 22nd and found Charlie already there, preparing to fire up his saw. I brought my little 10' Ryobi cordless electric chainsaw and two fully-charged batteries. Jeff Shaw arrived about 20 minutes later and we proceeded to work our way counter-clockwise around the lake trail startring from the parking area on the east end of the lake. It was slow going, especially at first since the north side of the lake is, or was, densely wooded with some mature trees.\n\nAfter three hours of cutting and tossing debris to the side of the trail, we reached my familyâ€™s memorial bench at the west end of the lake.\n\n\n\n\n\nBy this time we had waded through way too much PI, been briefly rained on, dulled Charlieâ€™s chainsaw blade, and drained both of the saw batteries I had on hand. I think we were drained too. Time for a break, so at 10 AM we departed for some rest, lunch, fresh batteries, and hopefully a new chain for Charlieâ€™s saw. We reconvened at Noon, as planned, and spent the next two hours clearing the deadfall around the McFate bench, plus a pair of gnarly monsters that had fallen across the trail near the southeast corner of the lake.\n\nIt felt really good to get it all done, and now we can engage in our â€œscurryâ€ walks around the lake without all the bobbing and weaving required to navigate the obstacle course that was. Every good volunteer effort should conclude with a photo or two, so we got all cleaned up, NOT, and I shot this one.\n\n\n\n\n\nThatâ€™s a warp. Until next timeâ€¦ but only after Iâ€™ve had a pleasant scurry walk in the morning.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:02.000Z",
            "updated_at": "2023-04-02T03:50:25.000Z",
            "published_at": "2020-08-22T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57876",
            "uuid": "676a7858-ed49-4b4c-8c0b-0a801babb742",
            "title": "Time for a Test Page",
            "slug": "time-for-a-test-page",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>My daughter, Mackenzie, and I have been using this blog for testing new features lately. If youâ€™ve been following me here youâ€™ve seen some of them pop-up on the home page. Now that we have a host of them working, I need to move some outâ€“of-the-way so they donâ€™t clutter things up too much.  However, I donâ€™t want to discard them, in some cases we didnâ€™t implement them anywhere else so this is the only <em>working</em> copy we have.</p><p>So, this morning I found a post at <a href='http://localhost:1313/posts/2021/03/time-for-a-test-page/%5Bhttps://formcake.com/'>formcake</a>, titled <a href='https://formcake.com/blog/adding-a-single-page-to-hugo'>How to add a Static Page to Hugo</a> by Joe Marshall.  Iâ€™m going to follow Joeâ€™s lead and try to add a static â€œTestingâ€ page here. If Iâ€™m successful, it will become the new home for 3 features (and maybe more in the future), specifically:</p><ul><li>A <em>markdown</em> (.md) file fetched from Dropbox,</li><li>A summary of my public gists, and</li><li>My latest <em>Tweet</em>, with automatic, timed expiration.</li></ul><p>These three features currently look like this on my home page:</p><figure><img src='http://localhost:1313/img/Hugo-features-03-07-2021.png'/><figcaption><h4>3 Features, Time for a New Home</h4></figcaption></figure><h2 id='it-worked-almost'>It Worked, Almost</h2><p>I did indeed manage to make this work, but not quite as Joe proposed. I found that in <a href='https://formcake.com/blog/adding-a-single-page-to-hugo'>How to add a Static Page to Hugo</a> thereâ€™s some confusion around the name of the <code>.html</code> file that Joe calls for. In at least one place the file is named <code>/layouts/_default/singlepage.html</code>, but in fact the file should be named <code>/layouts/_default/staticpage.html</code>.</p><p>The other issue I encountered was my fault. My implementation of this â€œtestingâ€ page means that I need to include not just text or markdown content, I also need quite a bit of code, mostly Javascript. So, in my case I duplicated the <code>/layouts/_default/staticpage.html</code> template, calling it <code>/layouts/_default/testpage.html</code>.  My <code>code</code> appears in this new template file. I also changed the content â€œtypeâ€ in the frontmatter of <code>/content/testing.md</code> from â€œstaticpageâ€ to â€œtestpageâ€.  And voilÃ¡â€¦</p><h2 id='it-just-works'>It Just Works!</h2><p>You can find the results on my <a href='https://blog.summittdweller.com/testing/'>Testing Page</a>. Enjoy.</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>My daughter, Mackenzie, and I have been using this blog for testing new features lately. If youâ€™ve been following me here youâ€™ve seen some of them pop-up on the home page. Now that we have a host of them working, I need to move some outâ€“of-the-way so they donâ€™t clutter things up too much.  However, I donâ€™t want to discard them, in some cases we didnâ€™t implement them anywhere else so this is the only <em>working</em> copy we have.</p><p>So, this morning I found a post at <a href='http://localhost:1313/posts/2021/03/time-for-a-test-page/%5Bhttps://formcake.com/'>formcake</a>, titled <a href='https://formcake.com/blog/adding-a-single-page-to-hugo'>How to add a Static Page to Hugo</a> by Joe Marshall.  Iâ€™m going to follow Joeâ€™s lead and try to add a static â€œTestingâ€ page here. If Iâ€™m successful, it will become the new home for 3 features (and maybe more in the future), specifically:</p><ul><li>A <em>markdown</em> (.md) file fetched from Dropbox,</li><li>A summary of my public gists, and</li><li>My latest <em>Tweet</em>, with automatic, timed expiration.</li></ul><p>These three features currently look like this on my home page:</p><figure><img src='http://localhost:1313/img/Hugo-features-03-07-2021.png'/><figcaption><h4>3 Features, Time for a New Home</h4></figcaption></figure><h2 id='it-worked-almost'>It Worked, Almost</h2><p>I did indeed manage to make this work, but not quite as Joe proposed. I found that in <a href='https://formcake.com/blog/adding-a-single-page-to-hugo'>How to add a Static Page to Hugo</a> thereâ€™s some confusion around the name of the <code>.html</code> file that Joe calls for. In at least one place the file is named <code>/layouts/_default/singlepage.html</code>, but in fact the file should be named <code>/layouts/_default/staticpage.html</code>.</p><p>The other issue I encountered was my fault. My implementation of this â€œtestingâ€ page means that I need to include not just text or markdown content, I also need quite a bit of code, mostly Javascript. So, in my case I duplicated the <code>/layouts/_default/staticpage.html</code> template, calling it <code>/layouts/_default/testpage.html</code>.  My <code>code</code> appears in this new template file. I also changed the content â€œtypeâ€ in the frontmatter of <code>/content/testing.md</code> from â€œstaticpageâ€ to â€œtestpageâ€.  And voilÃ¡â€¦</p><h2 id='it-just-works'>It Just Works!</h2><p>You can find the results on my <a href='https://blog.summittdweller.com/testing/'>Testing Page</a>. Enjoy.</p></p></article><!--kg-card-end: html-->",
            "comment_id": "8",
            "plaintext": "My daughter, Mackenzie, and I have been using this blog for testing new features lately. If youâ€™ve been following me here youâ€™ve seen some of them pop-up on the home page. Now that we have a host of them working, I need to move some outâ€“of-the-way so they donâ€™t clutter things up too much. However, I donâ€™t want to discard them, in some cases we didnâ€™t implement them anywhere else so this is the only working copy we have.\n\nSo, this morning I found a post at formcake, titled How to add a Static Page to Hugo by Joe Marshall. Iâ€™m going to follow Joeâ€™s lead and try to add a static â€œTestingâ€ page here. If Iâ€™m successful, it will become the new home for 3 features (and maybe more in the future), specifically:\n\n * A markdown (.md) file fetched from Dropbox,\n * A summary of my public gists, and\n * My latest Tweet, with automatic, timed expiration.\n\nThese three features currently look like this on my home page:\n\n\nIt Worked, Almost\n\nI did indeed manage to make this work, but not quite as Joe proposed. I found that in How to add a Static Page to Hugo thereâ€™s some confusion around the name of the .html file that Joe calls for. In at least one place the file is named /layouts/_default/singlepage.html, but in fact the file should be named /layouts/_default/staticpage.html.\n\nThe other issue I encountered was my fault. My implementation of this â€œtestingâ€ page means that I need to include not just text or markdown content, I also need quite a bit of code, mostly Javascript. So, in my case I duplicated the /layouts/_default/staticpage.html template, calling it /layouts/_default/testpage.html. My code appears in this new template file. I also changed the content â€œtypeâ€ in the frontmatter of /content/testing.md from â€œstaticpageâ€ to â€œtestpageâ€. And voilÃ¡â€¦\n\n\nIt Just Works!\n\nYou can find the results on my Testing Page. Enjoy.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:02.000Z",
            "updated_at": "2023-04-02T03:49:39.000Z",
            "published_at": "2021-03-07T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57877",
            "uuid": "7e8cacb0-b057-4186-88bf-56a816b633be",
            "title": "New Announcement Feature",
            "slug": "new-announcement-feature",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>Quite some time ago I added an <strong>Announcement</strong> feature to the <a href='https://rootstalk.grinnell.edu'>Rootstalk</a> website that I helped design and maintain for <a href='https://grinnell.edu'>Grinnell College</a>. Events of the past week have driven me to implement this feature as part of this blog and one other site, with some minor improvements.</p><p>The original <a href='https://rootstalk.grinnell.edu'>Rootstalk</a> version of the feature is very simple, it works around this logic:</p><ul><li>The siteâ€™s <code>content/_index.html</code> page invokes a shortcode named <code>announcement.html</code>.</li><li>The <code>announcement.html</code> shortcode checks for existence of a file path of <code>static/announcement.md</code>.</li><li>If the <code>static/announcement.md</code> file exists, its <em>markdown</em> content is read and displayed prominently on the home page.</li></ul><p>Removing or disabling the announcement is as simple as deleting the file, or simply changing the filename to something like <code>static/.announcement.md</code>, and republishing the site.</p><h2 id='implemented-for-the-compass-rose-band'>Implemented for the Compass Rose Band</h2><p>My brother-in-law, the founder and lead-singer for the <a href='https://compassroseband.net'>Compass Rose Band</a>, out of greater metropolitan Cedar Rapids, fell ill, and literally fell down the stairs, on Thursday evening, September 10, 2020.  Since my daughter publishes the aforementioned <a href='https://compassroseband.net'>CRB</a> website, we wanted to alert their fans that the show set for Friday evening, September 11, would be canceled. We immediately thought of the <a href='https://rootstalk.grinnell.edu'>Rootstalk</a> <strong>Announcement</strong> feature and subsequently implemented it for the <a href='https://compassroseband.net'>CRB</a> site.</p><p>In the case of <a href='https://compassroseband.net'>CRB</a> the feature is implemented just a little differently:</p><ul><li>Instead of a shortcode the <code>layouts/index.html</code> file includes a new block of code that looks for a file named <code>content/announcement.md</code>.</li><li>If the file exists, its <em>markdown</em> content is prominently displayed with an orange border near the top of the home page.</li></ul><p>Removing or disabling the announcement is just like in <a href='https://rootstalk.grinnell.edu'>Rootstalk</a>, we delete or change the filename to something like <code>content/.announcement.md</code>, and republish the site.</p><h2 id='implemented-here-in-this-blog'>Implemented Here In This blog</h2><p>Since Iâ€™m essentially documenting the new feature here, I thought it only prudent to also implement it here, and that implementation is currently <strong>identical</strong> to what we did for the <a href='https://compassroseband.net'>CRB</a>.</p><p>So watch the top of this blogâ€™s home for prominent announcements in the future, hopefully none that report dire emergencies. ðŸ˜ƒ</p><p>Thatâ€™s a warp. Until next timeâ€¦</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>Quite some time ago I added an <strong>Announcement</strong> feature to the <a href='https://rootstalk.grinnell.edu'>Rootstalk</a> website that I helped design and maintain for <a href='https://grinnell.edu'>Grinnell College</a>. Events of the past week have driven me to implement this feature as part of this blog and one other site, with some minor improvements.</p><p>The original <a href='https://rootstalk.grinnell.edu'>Rootstalk</a> version of the feature is very simple, it works around this logic:</p><ul><li>The siteâ€™s <code>content/_index.html</code> page invokes a shortcode named <code>announcement.html</code>.</li><li>The <code>announcement.html</code> shortcode checks for existence of a file path of <code>static/announcement.md</code>.</li><li>If the <code>static/announcement.md</code> file exists, its <em>markdown</em> content is read and displayed prominently on the home page.</li></ul><p>Removing or disabling the announcement is as simple as deleting the file, or simply changing the filename to something like <code>static/.announcement.md</code>, and republishing the site.</p><h2 id='implemented-for-the-compass-rose-band'>Implemented for the Compass Rose Band</h2><p>My brother-in-law, the founder and lead-singer for the <a href='https://compassroseband.net'>Compass Rose Band</a>, out of greater metropolitan Cedar Rapids, fell ill, and literally fell down the stairs, on Thursday evening, September 10, 2020.  Since my daughter publishes the aforementioned <a href='https://compassroseband.net'>CRB</a> website, we wanted to alert their fans that the show set for Friday evening, September 11, would be canceled. We immediately thought of the <a href='https://rootstalk.grinnell.edu'>Rootstalk</a> <strong>Announcement</strong> feature and subsequently implemented it for the <a href='https://compassroseband.net'>CRB</a> site.</p><p>In the case of <a href='https://compassroseband.net'>CRB</a> the feature is implemented just a little differently:</p><ul><li>Instead of a shortcode the <code>layouts/index.html</code> file includes a new block of code that looks for a file named <code>content/announcement.md</code>.</li><li>If the file exists, its <em>markdown</em> content is prominently displayed with an orange border near the top of the home page.</li></ul><p>Removing or disabling the announcement is just like in <a href='https://rootstalk.grinnell.edu'>Rootstalk</a>, we delete or change the filename to something like <code>content/.announcement.md</code>, and republish the site.</p><h2 id='implemented-here-in-this-blog'>Implemented Here In This blog</h2><p>Since Iâ€™m essentially documenting the new feature here, I thought it only prudent to also implement it here, and that implementation is currently <strong>identical</strong> to what we did for the <a href='https://compassroseband.net'>CRB</a>.</p><p>So watch the top of this blogâ€™s home for prominent announcements in the future, hopefully none that report dire emergencies. ðŸ˜ƒ</p><p>Thatâ€™s a warp. Until next timeâ€¦</p></p></article><!--kg-card-end: html-->",
            "comment_id": "9",
            "plaintext": "Quite some time ago I added an Announcement feature to the Rootstalk website that I helped design and maintain for Grinnell College. Events of the past week have driven me to implement this feature as part of this blog and one other site, with some minor improvements.\n\nThe original Rootstalk version of the feature is very simple, it works around this logic:\n\n * The siteâ€™s content/_index.html page invokes a shortcode named announcement.html.\n * The announcement.html shortcode checks for existence of a file path of static/announcement.md.\n * If the static/announcement.md file exists, its markdown content is read and displayed prominently on the home page.\n\nRemoving or disabling the announcement is as simple as deleting the file, or simply changing the filename to something like static/.announcement.md, and republishing the site.\n\n\nImplemented for the Compass Rose Band\n\nMy brother-in-law, the founder and lead-singer for the Compass Rose Band, out of greater metropolitan Cedar Rapids, fell ill, and literally fell down the stairs, on Thursday evening, September 10, 2020. Since my daughter publishes the aforementioned CRB website, we wanted to alert their fans that the show set for Friday evening, September 11, would be canceled. We immediately thought of the Rootstalk Announcement feature and subsequently implemented it for the CRB site.\n\nIn the case of CRB the feature is implemented just a little differently:\n\n * Instead of a shortcode the layouts/index.html file includes a new block of code that looks for a file named content/announcement.md.\n * If the file exists, its markdown content is prominently displayed with an orange border near the top of the home page.\n\nRemoving or disabling the announcement is just like in Rootstalk, we delete or change the filename to something like content/.announcement.md, and republish the site.\n\n\nImplemented Here In This blog\n\nSince Iâ€™m essentially documenting the new feature here, I thought it only prudent to also implement it here, and that implementation is currently identical to what we did for the CRB.\n\nSo watch the top of this blogâ€™s home for prominent announcements in the future, hopefully none that report dire emergencies. ðŸ˜ƒ\n\nThatâ€™s a warp. Until next timeâ€¦\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:02.000Z",
            "updated_at": "2023-04-02T03:50:14.000Z",
            "published_at": "2020-09-13T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57878",
            "uuid": "0e9850c8-7337-42bc-8252-6d6cb7c42cd4",
            "title": "How MY Web Works",
            "slug": "how-my-web-works-2",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>Iâ€™ve been building websites and apps for a lot of years now, and over time Iâ€™ve used a plethora of different frameworks and tools to do so.  Iâ€™ve also involved a number of registrars, DNS strategies, source code repositories, and web hostsâ€¦ frankly too many to remember or even count.</p><p>In my old age Iâ€™d love to have a dynamic document, or two, where I can track things like this:</p><h3 id='for-websites'>For Websites:</h3><ul><li>the siteâ€™s purpose</li><li>the siteâ€™s address and aliases</li><li>the domain registrar</li><li>the DNS host and siteâ€™s record structure</li></ul><h3 id='for-apps'>For Apps:</h3><ul><li>the applicationâ€™s purpose</li><li>the applicationâ€™s web address (if deployed to the web)</li><li>a link to the applicationâ€™s user guide or instruction</li></ul><h3 id='for-both-sites-and-apps'>For Both Sites and Apps:</h3><ul><li>the programming language(s) used</li><li>the location of the code repository</li><li>a link to development and deployment guidance</li></ul><h1 id='mackenzies-project'>Mackenzieâ€™s Project</h1><p>I feel like Iâ€™m a little too close to this material and perhaps my memory is clouded by too much outdated documentation to accurately determine where things stand today.  So, Iâ€™m asking my daughter, Mackenzie, to look at the artifacts I can provide and piece together this document for me.</p><h2 id='some-background-research'>Some Background Research</h2><p>Iâ€™ll start by asking Mackenzie to find, share, and document some resources to help her understand how to identify and document the working parts of my sites and appsâ€¦ discovering how the web works, and more.</p><p>Letâ€™s begin with a short list of documents/pages to help in that regard:</p><ul><li><a href='https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/How_the_Web_works'>How the web works</a></li><li><a href='https://www.freecodecamp.org/news/how-the-web-works-a-primer-for-newcomers-to-web-development-or-anyone-really-b4584e63585c/'>How the Web Works: A Primer for Newcomers to Web Development (or anyone, really)</a></li><li><a href='https://www.paperstreet.com/blog/domains-registrars-name-servers-and-dns-oh-my/'>Understanding Basics of Domains, Registrars, Name Servers and DNS</a></li><li><a href='https://www.paperstreet.com/blog/how-domains-name-servers-dns-and-websites-work/'>How Domains, Name Servers, DNS and Websites Work</a></li></ul><p>Some â€œformalâ€ educational materials:</p><ul><li><a href='https://www.codecademy.com/learn/deploy-a-website'>How to Deploy a Website</a></li></ul></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>Iâ€™ve been building websites and apps for a lot of years now, and over time Iâ€™ve used a plethora of different frameworks and tools to do so.  Iâ€™ve also involved a number of registrars, DNS strategies, source code repositories, and web hostsâ€¦ frankly too many to remember or even count.</p><p>In my old age Iâ€™d love to have a dynamic document, or two, where I can track things like this:</p><h3 id='for-websites'>For Websites:</h3><ul><li>the siteâ€™s purpose</li><li>the siteâ€™s address and aliases</li><li>the domain registrar</li><li>the DNS host and siteâ€™s record structure</li></ul><h3 id='for-apps'>For Apps:</h3><ul><li>the applicationâ€™s purpose</li><li>the applicationâ€™s web address (if deployed to the web)</li><li>a link to the applicationâ€™s user guide or instruction</li></ul><h3 id='for-both-sites-and-apps'>For Both Sites and Apps:</h3><ul><li>the programming language(s) used</li><li>the location of the code repository</li><li>a link to development and deployment guidance</li></ul><h1 id='mackenzies-project'>Mackenzieâ€™s Project</h1><p>I feel like Iâ€™m a little too close to this material and perhaps my memory is clouded by too much outdated documentation to accurately determine where things stand today.  So, Iâ€™m asking my daughter, Mackenzie, to look at the artifacts I can provide and piece together this document for me.</p><h2 id='some-background-research'>Some Background Research</h2><p>Iâ€™ll start by asking Mackenzie to find, share, and document some resources to help her understand how to identify and document the working parts of my sites and appsâ€¦ discovering how the web works, and more.</p><p>Letâ€™s begin with a short list of documents/pages to help in that regard:</p><ul><li><a href='https://developer.mozilla.org/en-US/docs/Learn/Getting_started_with_the_web/How_the_Web_works'>How the web works</a></li><li><a href='https://www.freecodecamp.org/news/how-the-web-works-a-primer-for-newcomers-to-web-development-or-anyone-really-b4584e63585c/'>How the Web Works: A Primer for Newcomers to Web Development (or anyone, really)</a></li><li><a href='https://www.paperstreet.com/blog/domains-registrars-name-servers-and-dns-oh-my/'>Understanding Basics of Domains, Registrars, Name Servers and DNS</a></li><li><a href='https://www.paperstreet.com/blog/how-domains-name-servers-dns-and-websites-work/'>How Domains, Name Servers, DNS and Websites Work</a></li></ul><p>Some â€œformalâ€ educational materials:</p><ul><li><a href='https://www.codecademy.com/learn/deploy-a-website'>How to Deploy a Website</a></li></ul></p></article><!--kg-card-end: html-->",
            "comment_id": "10",
            "plaintext": "Iâ€™ve been building websites and apps for a lot of years now, and over time Iâ€™ve used a plethora of different frameworks and tools to do so. Iâ€™ve also involved a number of registrars, DNS strategies, source code repositories, and web hostsâ€¦ frankly too many to remember or even count.\n\nIn my old age Iâ€™d love to have a dynamic document, or two, where I can track things like this:\n\n\nFor Websites:\n\n * the siteâ€™s purpose\n * the siteâ€™s address and aliases\n * the domain registrar\n * the DNS host and siteâ€™s record structure\n\n\nFor Apps:\n\n * the applicationâ€™s purpose\n * the applicationâ€™s web address (if deployed to the web)\n * a link to the applicationâ€™s user guide or instruction\n\n\nFor Both Sites and Apps:\n\n * the programming language(s) used\n * the location of the code repository\n * a link to development and deployment guidance\n\n\nMackenzieâ€™s Project\n\nI feel like Iâ€™m a little too close to this material and perhaps my memory is clouded by too much outdated documentation to accurately determine where things stand today. So, Iâ€™m asking my daughter, Mackenzie, to look at the artifacts I can provide and piece together this document for me.\n\n\nSome Background Research\n\nIâ€™ll start by asking Mackenzie to find, share, and document some resources to help her understand how to identify and document the working parts of my sites and appsâ€¦ discovering how the web works, and more.\n\nLetâ€™s begin with a short list of documents/pages to help in that regard:\n\n * How the web works\n * How the Web Works: A Primer for Newcomers to Web Development (or anyone, really)\n * Understanding Basics of Domains, Registrars, Name Servers and DNS\n * How Domains, Name Servers, DNS and Websites Work\n\nSome â€œformalâ€ educational materials:\n\n * How to Deploy a Website\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:02.000Z",
            "updated_at": "2023-04-02T03:48:47.000Z",
            "published_at": "2022-11-30T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57879",
            "uuid": "e09d7f5f-d9b7-43b9-864d-dbd984a4c085",
            "title": "Tama-Toledo Parks - Derecho Follow-Up for August 24",
            "slug": "tama-toledo-parks---derecho-follow-up-for-august-24",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>So, the <a href='https://iowageocachers.org'>Iowa Geocacherâ€™s Organization</a> annual <a href='https://coord.info/GC8TJ9F'>Hike-n-Seek</a> event is coming to Tama County and Otter Creek Lake on Friday-Sunday, September 25-27, barring any more 2020 disasters. ðŸ€ The weekend is slated to include Septemberâ€™s Friday Lunch Club (FLC) too, but the restaurant that was slated to host FLC was destroyed in the August 10 derecho.</p><p>This morning <a href='https://www.geocaching.com/p/default.aspx?guid=77b132a8-363f-4989-97d0-8e44db236ada&amp;wid=caae59c7-5c17-43b9-a980-98d6c1a7d7da&amp;ds=2'>The FLC Committee</a>, aka Borky00, aka Bill, asked me about possible outdoor park settings for FLC as a means of giving folks plenty of room for social distancing. Bill mentioned a couple of possibilities including a Tama city park on east 4th Street, and the Lincoln Highway Bridge park at the intersection of 5th Street and old US Highway 30.</p><p>The city park on east 4th Street is a no-go. Thereâ€™s never been much in the way of facilities there, and after the storm there is literally nothing there. I did have three other possibilities in mind, and needed to check up on them after the storm anyway, so I took a few minutes this morning to gather some information.</p><h2 id='lincoln-highway-bridge-park---east-5th-street-in-tama'>Lincoln Highway Bridge Park - East 5th Street in Tama</h2><p>This little park, and I do mean little, features two very small shelters but NO grills for cooking. Itâ€™s a small outdoor meeting place near Tamaâ€™s iconic Lincoln Highway Bridge, and home to a couple of my own geocache hides.  Hereâ€™s what it looks like after the storm.</p><p><figure><img alt='Lincoln Highway Bridge Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0331.png'/><figcaption>Lincoln Highway Bridge Park - After the Derecho</figcaption></figure></p><p><figure><img alt='Lincoln Highway Bridge Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0330.png'/><figcaption>Lincoln Highway Bridge Park - After the Derecho</figcaption></figure></p><h2 id='tama-city-park---near-17th-street-and-mclelland-in-tama'>Tama City Park - Near 17th Street and Mclelland in Tama</h2><p>This is Tamaâ€™ primary park and Iâ€™d heard it was cleaned up right after the storm, but thereâ€™s still LOTs of damage here and lots more cleanup to be done. Also, thereâ€™s only a fireplace in the small shelter, and no grills left on the grounds, at least none that I could see.</p><p><figure><img alt='Tama City Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0332.png'/><figcaption>Tama City Park - After the Derecho</figcaption></figure></p><p><figure><img alt='Tama City Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0333.png'/><figcaption>Tama City Park - After the Derecho</figcaption></figure></p><p><figure><img alt='Tama City Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0334.png'/><figcaption>Tama City Park - After the Derecho</figcaption></figure></p><p><figure><img alt='Tama City Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0335.png'/><figcaption>Tama City Park - After the Derecho</figcaption></figure></p><h2 id='toledo-heights-city-park---west-side-of-toledo-on-old-us-30'>Toledo Heights City Park - West Side of Toledo on Old US 30</h2><p>I think this is probably our best bet, assuming the City of Toledo can get the major debris taken care of before the FLC event. I just called the city and spoke with the City Clerk, she made a tentative reservation for me to have the shelter on Friday, September 25 for a reservation fee of $25. There is normally a $50 refundable deposit required but thatâ€™s being waved because the restroom in the shelter is not open due to the pandemic.</p><p>This park, about 1/2-mile west of the restaurant that FLC previously booked, has one nice large open shelter with a fireplace, AND two large grills just north of the shelter.  Have a look, and note that the park is currently not reserved for any other events on Hike-n-Seek weekend.</p><p><figure><img alt='Toledo Heights City Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0327.png'/><figcaption>Toledo Heights City Park - After the Derecho</figcaption></figure></p><p><figure><img alt='Toledo Heights City Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0328.png'/><figcaption>Toledo Heights City Park - After the Derecho</figcaption></figure></p><p><figure><img alt='Toledo Heights City Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0329.png'/><figcaption>Toledo Heights City Park - After the Derecho</figcaption></figure></p><p>Thatâ€™s a warp. Until next timeâ€¦</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>So, the <a href='https://iowageocachers.org'>Iowa Geocacherâ€™s Organization</a> annual <a href='https://coord.info/GC8TJ9F'>Hike-n-Seek</a> event is coming to Tama County and Otter Creek Lake on Friday-Sunday, September 25-27, barring any more 2020 disasters. ðŸ€ The weekend is slated to include Septemberâ€™s Friday Lunch Club (FLC) too, but the restaurant that was slated to host FLC was destroyed in the August 10 derecho.</p><p>This morning <a href='https://www.geocaching.com/p/default.aspx?guid=77b132a8-363f-4989-97d0-8e44db236ada&amp;wid=caae59c7-5c17-43b9-a980-98d6c1a7d7da&amp;ds=2'>The FLC Committee</a>, aka Borky00, aka Bill, asked me about possible outdoor park settings for FLC as a means of giving folks plenty of room for social distancing. Bill mentioned a couple of possibilities including a Tama city park on east 4th Street, and the Lincoln Highway Bridge park at the intersection of 5th Street and old US Highway 30.</p><p>The city park on east 4th Street is a no-go. Thereâ€™s never been much in the way of facilities there, and after the storm there is literally nothing there. I did have three other possibilities in mind, and needed to check up on them after the storm anyway, so I took a few minutes this morning to gather some information.</p><h2 id='lincoln-highway-bridge-park---east-5th-street-in-tama'>Lincoln Highway Bridge Park - East 5th Street in Tama</h2><p>This little park, and I do mean little, features two very small shelters but NO grills for cooking. Itâ€™s a small outdoor meeting place near Tamaâ€™s iconic Lincoln Highway Bridge, and home to a couple of my own geocache hides.  Hereâ€™s what it looks like after the storm.</p><p><figure><img alt='Lincoln Highway Bridge Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0331.png'/><figcaption>Lincoln Highway Bridge Park - After the Derecho</figcaption></figure></p><p><figure><img alt='Lincoln Highway Bridge Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0330.png'/><figcaption>Lincoln Highway Bridge Park - After the Derecho</figcaption></figure></p><h2 id='tama-city-park---near-17th-street-and-mclelland-in-tama'>Tama City Park - Near 17th Street and Mclelland in Tama</h2><p>This is Tamaâ€™ primary park and Iâ€™d heard it was cleaned up right after the storm, but thereâ€™s still LOTs of damage here and lots more cleanup to be done. Also, thereâ€™s only a fireplace in the small shelter, and no grills left on the grounds, at least none that I could see.</p><p><figure><img alt='Tama City Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0332.png'/><figcaption>Tama City Park - After the Derecho</figcaption></figure></p><p><figure><img alt='Tama City Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0333.png'/><figcaption>Tama City Park - After the Derecho</figcaption></figure></p><p><figure><img alt='Tama City Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0334.png'/><figcaption>Tama City Park - After the Derecho</figcaption></figure></p><p><figure><img alt='Tama City Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0335.png'/><figcaption>Tama City Park - After the Derecho</figcaption></figure></p><h2 id='toledo-heights-city-park---west-side-of-toledo-on-old-us-30'>Toledo Heights City Park - West Side of Toledo on Old US 30</h2><p>I think this is probably our best bet, assuming the City of Toledo can get the major debris taken care of before the FLC event. I just called the city and spoke with the City Clerk, she made a tentative reservation for me to have the shelter on Friday, September 25 for a reservation fee of $25. There is normally a $50 refundable deposit required but thatâ€™s being waved because the restroom in the shelter is not open due to the pandemic.</p><p>This park, about 1/2-mile west of the restaurant that FLC previously booked, has one nice large open shelter with a fireplace, AND two large grills just north of the shelter.  Have a look, and note that the park is currently not reserved for any other events on Hike-n-Seek weekend.</p><p><figure><img alt='Toledo Heights City Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0327.png'/><figcaption>Toledo Heights City Park - After the Derecho</figcaption></figure></p><p><figure><img alt='Toledo Heights City Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0328.png'/><figcaption>Toledo Heights City Park - After the Derecho</figcaption></figure></p><p><figure><img alt='Toledo Heights City Park - After the Derecho' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/IMG_0329.png'/><figcaption>Toledo Heights City Park - After the Derecho</figcaption></figure></p><p>Thatâ€™s a warp. Until next timeâ€¦</p></p></article><!--kg-card-end: html-->",
            "comment_id": "11",
            "plaintext": "So, the Iowa Geocacherâ€™s Organization annual Hike-n-Seek event is coming to Tama County and Otter Creek Lake on Friday-Sunday, September 25-27, barring any more 2020 disasters. ðŸ€ The weekend is slated to include Septemberâ€™s Friday Lunch Club (FLC) too, but the restaurant that was slated to host FLC was destroyed in the August 10 derecho.\n\nThis morning The FLC Committee, aka Borky00, aka Bill, asked me about possible outdoor park settings for FLC as a means of giving folks plenty of room for social distancing. Bill mentioned a couple of possibilities including a Tama city park on east 4th Street, and the Lincoln Highway Bridge park at the intersection of 5th Street and old US Highway 30.\n\nThe city park on east 4th Street is a no-go. Thereâ€™s never been much in the way of facilities there, and after the storm there is literally nothing there. I did have three other possibilities in mind, and needed to check up on them after the storm anyway, so I took a few minutes this morning to gather some information.\n\n\nLincoln Highway Bridge Park - East 5th Street in Tama\n\nThis little park, and I do mean little, features two very small shelters but NO grills for cooking. Itâ€™s a small outdoor meeting place near Tamaâ€™s iconic Lincoln Highway Bridge, and home to a couple of my own geocache hides. Hereâ€™s what it looks like after the storm.\n\n\n\n\n\n\n\n\n\n\nTama City Park - Near 17th Street and Mclelland in Tama\n\nThis is Tamaâ€™ primary park and Iâ€™d heard it was cleaned up right after the storm, but thereâ€™s still LOTs of damage here and lots more cleanup to be done. Also, thereâ€™s only a fireplace in the small shelter, and no grills left on the grounds, at least none that I could see.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nToledo Heights City Park - West Side of Toledo on Old US 30\n\nI think this is probably our best bet, assuming the City of Toledo can get the major debris taken care of before the FLC event. I just called the city and spoke with the City Clerk, she made a tentative reservation for me to have the shelter on Friday, September 25 for a reservation fee of $25. There is normally a $50 refundable deposit required but thatâ€™s being waved because the restroom in the shelter is not open due to the pandemic.\n\nThis park, about 1/2-mile west of the restaurant that FLC previously booked, has one nice large open shelter with a fireplace, AND two large grills just north of the shelter. Have a look, and note that the park is currently not reserved for any other events on Hike-n-Seek weekend.\n\n\n\n\n\n\n\n\n\n\n\n\n\nThatâ€™s a warp. Until next timeâ€¦\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:02.000Z",
            "updated_at": "2023-04-02T03:50:19.000Z",
            "published_at": "2020-08-24T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c5787a",
            "uuid": "55ab82e3-ec72-4f15-a203-a09c576adb1b",
            "title": "Pandemic Pastime: Walking and Picking Up Trash",
            "slug": "pandemic-pastime--walking-and-picking-up-trash",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>Itâ€™s been far too long since I posted to this blog; I guess Iâ€™ve been busy? Nah, not any more than usual, but during the COVID-19 pandemic I have doubled my efforts to get out and walk in the fresh air whenever possible. Iâ€™m thankful for my small â€œscurryâ€ â€“ thatâ€™s the term for a collective of squirrels â€“ who not only take walks with me around Cherry Lake, but all around town.</p><p>About three months ago there was some vandalism at Cherry Lake, and there was a time when folks were leaving lots of trash around the lake.  So our scurry started carrying â€œ<a href='https://ungerconsumer.com/product/36-nifty-nabber/'>Niffty Nabbers</a>â€ and now we clean up what we can as we walk.  We have even extended the practice beyond the lake, and we generally walk twice a day now, most evenings somewhere in Tama or Toledo away from all the mosquitoes that inhabit Cherry Lake. True to form, we pick up trash as we go.</p><p>I would estimate that both solo and with my scurry, I/we have picked up about 100 pounds of trash so far.</p><p>This past weekend I was thinkingâ€¦ now that we have expaned to more than just Cherry Lake, it would be nice to plot our routes walked somewhere online so that we can keep track of progress, and see where we havenâ€™t been yet. Fortunately, I tend to activate a â€œworkoutâ€ recording on my Apple Watch whenever we go out, and I just realized that those routes can be exported from my iPhone as .gpx files.  So, one day soon I hope to create a new section in this blog where I can post records, with maps, of our excursions. Look for it in this blog soon, or at least sooner or later.</p><p>Thatâ€™s a wrap. Until next timeâ€¦</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>Itâ€™s been far too long since I posted to this blog; I guess Iâ€™ve been busy? Nah, not any more than usual, but during the COVID-19 pandemic I have doubled my efforts to get out and walk in the fresh air whenever possible. Iâ€™m thankful for my small â€œscurryâ€ â€“ thatâ€™s the term for a collective of squirrels â€“ who not only take walks with me around Cherry Lake, but all around town.</p><p>About three months ago there was some vandalism at Cherry Lake, and there was a time when folks were leaving lots of trash around the lake.  So our scurry started carrying â€œ<a href='https://ungerconsumer.com/product/36-nifty-nabber/'>Niffty Nabbers</a>â€ and now we clean up what we can as we walk.  We have even extended the practice beyond the lake, and we generally walk twice a day now, most evenings somewhere in Tama or Toledo away from all the mosquitoes that inhabit Cherry Lake. True to form, we pick up trash as we go.</p><p>I would estimate that both solo and with my scurry, I/we have picked up about 100 pounds of trash so far.</p><p>This past weekend I was thinkingâ€¦ now that we have expaned to more than just Cherry Lake, it would be nice to plot our routes walked somewhere online so that we can keep track of progress, and see where we havenâ€™t been yet. Fortunately, I tend to activate a â€œworkoutâ€ recording on my Apple Watch whenever we go out, and I just realized that those routes can be exported from my iPhone as .gpx files.  So, one day soon I hope to create a new section in this blog where I can post records, with maps, of our excursions. Look for it in this blog soon, or at least sooner or later.</p><p>Thatâ€™s a wrap. Until next timeâ€¦</p></p></article><!--kg-card-end: html-->",
            "comment_id": "12",
            "plaintext": "Itâ€™s been far too long since I posted to this blog; I guess Iâ€™ve been busy? Nah, not any more than usual, but during the COVID-19 pandemic I have doubled my efforts to get out and walk in the fresh air whenever possible. Iâ€™m thankful for my small â€œscurryâ€ â€“ thatâ€™s the term for a collective of squirrels â€“ who not only take walks with me around Cherry Lake, but all around town.\n\nAbout three months ago there was some vandalism at Cherry Lake, and there was a time when folks were leaving lots of trash around the lake. So our scurry started carrying â€œNiffty Nabbersâ€ and now we clean up what we can as we walk. We have even extended the practice beyond the lake, and we generally walk twice a day now, most evenings somewhere in Tama or Toledo away from all the mosquitoes that inhabit Cherry Lake. True to form, we pick up trash as we go.\n\nI would estimate that both solo and with my scurry, I/we have picked up about 100 pounds of trash so far.\n\nThis past weekend I was thinkingâ€¦ now that we have expaned to more than just Cherry Lake, it would be nice to plot our routes walked somewhere online so that we can keep track of progress, and see where we havenâ€™t been yet. Fortunately, I tend to activate a â€œworkoutâ€ recording on my Apple Watch whenever we go out, and I just realized that those routes can be exported from my iPhone as .gpx files. So, one day soon I hope to create a new section in this blog where I can post records, with maps, of our excursions. Look for it in this blog soon, or at least sooner or later.\n\nThatâ€™s a wrap. Until next timeâ€¦\n\n",
            "feature_image": "https://images.unsplash.com/photo-1604761550394-7690adbf0318?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDM1fHx0cmFzaHxlbnwwfHx8fDE2ODA2OTk0NjM&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:02.000Z",
            "updated_at": "2023-04-05T12:58:09.000Z",
            "published_at": "2020-08-03T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c5787b",
            "uuid": "5366cb08-e15a-4c61-b166-87a8318ad261",
            "title": "Iowa's 2020 Hurricane",
            "slug": "iowas-2020-hurricane",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>Itâ€™s been far too long, again, since I posted to this blog, but this time I have a legitimate excuse: weâ€™ve been without power or internet, or much of anything, since about 11:45 AM on Monday, August 10, 2020.  So we have now been more than 10.5 days without power. Iâ€™m only able to post this because of a portable generator I bought on August 12 (that was an adventure in itself) and the wireless hotspot that my phone has provided almost 24/7 ever since the storm hit.</p><p>Update: Power was finally restored here at about 6:30 PM, on Thursday, August 20, 2020.  Now I just have 11.5 days of things to catch up on!</p><h2 id='preamble'>Preamble</h2><p>The preamble to this story dates back to Christmas 2019, when my daughter gave me a â€œDadâ€™s Loveâ€¦â€ daily calendar. There have been a couple of dates I kept because they are so accurate, like the day that says â€œWe child-proofed the house but somehow they still got in.â€  ðŸ˜„  Tama County has been in the grips of a moderate-to-severe drought for the past couple of months so the calendar page for August 10 looked like another â€œkeeperâ€. It says:</p><p><figure><img alt='Monday, August 10, &amp;ldquo;Dad&amp;rsquo;s Love&amp;hellip;&amp;rdquo; Calendar' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Photo-2020-08-18-09-54.jpg'/><figcaption>Monday, August 10, 'Dad's Love...' Calendar</figcaption></figure></p><h2 id='930-am---scurry-walk'>9:30 AM - Scurry Walk</h2><p>This story begins in earnest around 9:30 AM on Monday, August 10, 2020.  My â€œscurryâ€ and I were just completing a quick walk around Cherry Lake where we had picked up a little trash, as we usually do. We met a couple of neighbors out for a walk and chatted briefly about the weather, and I suggested that the line of storms now in western Iowa looked like they might just hold together. Every weather system thus far in the summer had passed either just to our north, just to the south, or formed just to the east, so the neighbors just scoffed at the notion of us getting any rain. I was so sure it would rain this time that I didnâ€™t hesitate to put a concrete block on the west-half of my hot tub cover to keep it closed in case of wind. I guess I should have used all eight blocks this time?  ðŸ˜•</p><h2 id='1145-am---the-wind'>11:45 AM - The Wind</h2><p>The storms did indeed â€œhold togetherâ€.  Oh boy, did they ever.  A wall of wind hit Tama-Toledo at about 11:45 AM that morning, with literally NO warning from the US Weather Service. I had received alerts from the WeatherBug app on my iPhone, but there was no â€œofficialâ€ word of impending doom.  The rain didnâ€™t begin until 5 or 10 minutes later, and Iâ€™m not sure any hit the ground because EVERYTHING, tree limbs, mailboxes, small animals, etc., was moving sideways. The power went out moments later. Itâ€™s still out as of this writing, a little more than 10 days since.</p><h2 id='1155-am---get-the-cats'>11:55 AM - Get the Cats!</h2><p>After hustling to the basement and realizing the house was not gone, yet, we thought weâ€™d better go back upstairs to get some candles, more flashlights, and our three cats.  Mackenzie and I managed to get two of the cats pretty easily, but the third one was stubborn and had to be â€œcapturedâ€.  While we were doing this I glanced out the window and saw nothing but tree limbs, still sailing past the windows on a nearly horizontal trajectory.</p><p>By the time we captured the last cat I thought to myself, the wind canâ€™t last much longerâ€¦it had been blowing for at least 5 minutes straight, and I do mean STRAIGHT. I was very wrong.  Thinking back, I do believe the wind blew at upwards of 100 MPH or more for at least 20 minutes.</p><h2 id='1158-am---morgans-story'>11:58 AM - Morganâ€™s Story</h2><p>My daughter, Morgan, had been at the STC Middle School in Toledo working on getting her classroom ready for the start of school. She got a call from a friend in Des Moines at about 11:30 AM telling her to watch out for a line of t-storms heading her way. There are no windows in her classroom so when she finally left the Middle School and saw how dark the sky was she got really concerned and promptly ordered the building secretary to open the office and get a handful of students back inside.  They had just dismissed from summer-school and were waiting outside for their parents to pick them up.  Good thing she did that.</p><p>Morgan drove away from the Middle School just minutes before a wall-of-wind roared in, and she called my cell phone at 11:50 AM just as she passed our house, letting me know that she was going straight to her apartment because her landlord wasnâ€™t home and she was worried about her cats. The 5-minute drive to her apartment took about 3 hours?  A couple of minutes later, at 11:55 AM we ran to our basement (after a 2nd mailbox went sailing past our front door) and Morgan called again at 11:58 AM. Her car had been hit by a falling tree limb, about 6' in diameter, near the crest of the hill on State Street in Tama, just south of the Tama Park. Her windshield was shattered, fortunately on the passengerâ€™s side, and she was freaking out. I told her to stay in her car and Christine called 9-1-1 to provide her with some emergency aid.</p><p>The 9-1-1 call had to route through Benton county (30 miles east of us) as the local center was already overwhelmed, and the storm hadnâ€™t hit there yet. A local police officer was dispatched and could get no closer than about 2.5 blocks from Morganâ€™s car due to downed trees, but made his way to her on-foot. He told her same as me, stay in your car to avoid downed power lines and potentially being hit by flying debris. He also told her to fasten her seatbelt in case the wind flipped the car over. Yikes!  That happened at 12:18 PM, and the wind was still fierce!</p><p>At 12:20 PM my wife realized where Morgan was and called a friend who lives at the location of Morganâ€™s â€œtree incidentâ€, and that friend managed to summon her inside once it was safe to make a run for it.</p><h2 id='1230-pm---the-wind-finally-stopped-time-to-rescue-morgan'>12:30 PM - The Wind Finally Stopped, Time to â€œRescueâ€ Morgan</h2><p>It was about 12:30 PM when I felt like it was finally safe to go back upstairs and outside. Our mission was to try and get to Morgan as soon as possible.  The power was out so I could not easily raise our double garage door, so I peeked out the front door to see what the situation was. OMG!</p><p>Our house is about 70 years old and it is (was) surrounded by five very large, mature treesâ€¦ two grand old Oaks flanking the front yard, an American Sycamore directly west of our garage and patio, and two very tall pines on the NW and NE corners of the house, plus a few smaller and younger trees and bushes. Our driveway measures about 15â€™ x 45â€™ and it was entirely covered in limbs from one of the oaks and the Sycamore. Some of the limbs down on the driveway measured more than 10' in diameter.  It ultimately took about 14 hours of back-breaking effort just to clear the driveway well enough for us to get both vehicles out of the garage.</p><p>In the immediate aftermath of the storm I had two other transportation options: the bicycle I had just purchased on Saturday, August 8; or my daughter Mackenzieâ€™s car which was parked at the curb west of our house. I was pretty sure that car, parked partly beneath one of the oaks and the Sycamore, would be badly damaged, but it was not. There were limbs and whole trees, from our neighbor to the west, lying all around it, but the car was unscathed and operable.  It took a little serpentine driving to navigate out of itâ€™s parking spot, but by about 12:45 PM Christine and I were able to get it out and on-the road to try and â€œrescueâ€ Morgan, roughly 1/2-mile away.</p><p>That 1/2-mile trip featured five impassable streets and a mile or two of back-tracking to find a suitable (barely) route.  The four-lane US Highway 63 proved to be the best route for most of the trip only because it was wide enough that trees on the west side generally didnâ€™t block all four lanes. We arrived in the vicinity of Morganâ€™s car at 1:02 PM and found that she had already pulled the largest limb off her car, what was left looked like this:</p><p><figure><img alt='Morgan&amp;rsquo;s Damaged Nissan Rogue - A Total Loss' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/IMG_2053.jpeg'/><figcaption>Morgan's Damaged Nissan Rogue - A Total Loss</figcaption></figure></p><p>Morganâ€™s apartment is about 1-mile from the location where we left her car, and she knew that her landlord and family were away in Cedar Rapids for the day, so we headed there to check on that property, and her cats. That trip took about 10 minutes with numerous â€œdetoursâ€ but I was able to drive to within a half-block of the house.  Thankfully we found the house intact with no visible, major damage, and the cats were safe, but obviously frightened, still inside Morganâ€™s apartment. Fortunately, the large old tree outside Morganâ€™s apartment window was damaged earlier this year in a storm, and had to be taken down entirely just a couple of weeks ago; otherwise it would have certainly damaged the house and her apartment. We called the landlord to report the relatively good news as they tried to begin their journey back home from CR. Then it started to rain again, just a little.</p><h2 id='the-damage'>The Damage</h2><p>This part of the story is perhaps best told in pictures. I took some photos and am posting them here in chronological order, with descriptive captions.</p><h3 id='first-glimpse-out-the-window'>First Glimpse Out the Window</h3><p><figure><img alt='18 First Glimpse from Inside the House - South Facing Window Looking Out on the Driveway' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2018.png'/><figcaption>First Glimpse from Inside the House - South Facing Window Looking Out on the Driveway</figcaption></figure></p><p><figure><img alt='19 First Glimpse from Inside the House - South Facing Window Looking SE at the Mailboxes' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2019.png'/><figcaption>First Glimpse from Inside the House - South Facing Window Looking SE at the Mailboxes</figcaption></figure></p><p><figure><img alt='17 View from My Home Office Window an Hour After - Lookng NE' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2017.png'/><figcaption>View from My Home Office Window an Hour After - Lookng NE</figcaption></figure></p><h3 id='headed-outside-to-shoot-more-photos'>Headed Outside to Shoot More Photos</h3><p>The power was out everywhere for 30 to 50 miles all around us so we assumed it was safe to get outside and take some better photos.  No chance of getting cars out of the garageâ€¦ our driveway was at least 80% covered by tree parts, some places it was 4 feet deep.</p><p><figure><img alt='20 Looking NW at the House from Where the Mailboxes Used to Be' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2020.png'/><figcaption>Looking NW at the House from Where the Mailboxes Used to Be</figcaption></figure></p><p><figure><img alt='21 Yes, That&amp;rsquo;s Our Mailbox' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2021.png'/><figcaption>Yup, That's Our Mailbox</figcaption></figure></p><p><figure><img alt='22 Looking NW from the Mailboxes - Our Driveway is Under All of That Forest' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2022.png'/><figcaption>Looking NW from the Mailboxes - Our Driveway is Under That Forest</figcaption></figure></p><p><figure><img alt='23 Looking North from the Bottom of Our Driveway' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2023.png'/><figcaption>Looking North from the Bottom of Our Driveway</figcaption></figure></p><p><figure><img alt='24 Looking SW from Just Outside Our Garage' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2024.png'/><figcaption>Looking SW from Just Outside Our Garage</figcaption></figure></p><p><figure><img alt='25 Looking Due South from Just Outside Our Garage' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2025.png'/><figcaption>Looking Due South from Just Outside Our Garage</figcaption></figure></p><p><figure><img alt='26 Looking East from the Top of Our Driveway' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2026.png'/><figcaption>Looking East from the Top of Our Driveway</figcaption></figure></p><h3 id='west-side-story---the-rolling-stone-hot-tub-grill-and-limbs-on-the-roof'>West Side Story - The â€œRolling Stoneâ€, Hot Tub, Grill, and Limbs on the Roof</h3><p>There were three pleasantly-amazing (lucky) things that happened, or didnâ€™t happen as the case may be, on the west, windward, side of the house.</p><p>First up, my home-made lightweight teardrop camper, â€œThe Rolling Stoneâ€.  Itâ€™s the gray thing that looks like a big old boulder on wheels in the right side of the first image below.  It survived, almost unscathed! The only damage was from the door being blown open.  That door hit the west wall of the house so hard that it bent a 1/8' thick steel latch plate back at a 120Â° angle. Because the door was open, things just inside the door also got a little wet, but they dried out well since then.  The whole camper pitched forward about 3â€™ in the wind, but the on-board drop-foot was down so it didnâ€™t fall to the ground. Had any large limbs fallen directly on it, weâ€™d have had a total loss of structure and contents.</p><p><figure><img alt='30 Looking SE from the NW Corner of Our Property' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2030.png'/><figcaption>Looking SE from the NW Corner of Our Property</figcaption></figure></p><p>Next, the hot tub and grill. The very first thing I did when I got outdoors after the storm was to flip the hot tub cover back down.  I have yet to clean all the leaves and debris out of the waterâ€¦maybe later today.</p><p>When I receive any alert of a possible storm I always move one of the concrete blocks, seen stacked on the right in the image below, over to the west edge of my hot tub cover in order to keep it from blowing open.  I made that move about 15 minutes before the storm hit, but it didnâ€™t help. In fact, it did more damage, I think.  The cover seems to be OK, but the wind did flip it open, sending the concrete block sailing about 10â€™ into the side of the house and narrowly missing the bathroom window that you can see. Lucky for us!</p><p>But our gas grill was not so lucky. That concrete block smashed down upon it leaving a big dent in the top, and causing the grill to â€œlistâ€ about 2' to port (the left side when looking from back to front).</p><p><figure><img alt='31 Looking at the Hot Tub and Limbs on the Roof' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2031.png'/><figcaption>Looking at the Hot Tub and Limbs on the Roof</figcaption></figure></p><p><figure><img alt='45 The Grill' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/IMG_3531.png'/><figcaption>Our 1-Year-Old Gas Grill</figcaption></figure></p><p><figure><img alt='27 Looking South from NW Corner of Our Property' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2027.png'/><figcaption>Looking South from NW Corner of Our Property</figcaption></figure></p><p>Finally, the limbs on the roof; you can see them clearly in some of these images. There were actually three of them, the largest with a diameter of about 5' at its base.  All three were from the Sycamore tree, which I suppose is lucky.  Sycamoreâ€™s have ENORMOUS leaves and while I feared severe damage to the roof, it looks like all three limbs just gently â€œfloatedâ€ down to where I found them. I got them sawed up, and down off the roof, including an informal damage inspection plus wasp nest encounter, on Tuesday, August 11.</p><p><figure><img alt='28 Looking SE from the NW Corner of Our Property' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2028.png'/><figcaption>Looking SE from the NW Corner of Our Property</figcaption></figure></p><p><figure><img alt='29 Looking East from the NW Corner of Our Property' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2029.png'/><figcaption>Looking East from the NW Corner of Our Property</figcaption></figure></p><h2 id='the-cleanup'>The Cleanup</h2><h3 id='building-the-worlds-largest--boma'>Building the Worldâ€™s Largest (?) Boma</h3><p>The mayors of Tama and Toledo, along with the Tama Co. Emergency Management office, called a public meeting, conducted in the parking lot of the nearby Tama-Toledo Family Aquatic Center, for 6 PM on Wednesday, August 12. At that meeting the cities informed everyone that any debris left at the curb would eventually be picked up and disposed of by a city crew. So, we started building what I like to think of as the worldâ€™s largest <a href='https://en.wikipedia.org/wiki/Boma_(enclosure)'>boma</a>.</p><p>In the images below you can see both our west and south bomas.  We didnâ€™t need any on the east or north since we have neighbors on those sides, but we did build a small boma (about 30â€™ long by 10â€™ wide) in the parking lot of the church that sits at the NE corner of our property, where our utilities pole is located.</p><p><figure><img alt='2 The West Boma - Panoramic' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%202.png'/><figcaption>The West Boma - Panoramic</figcaption></figure></p><p><figure><img alt='14 The South Boma - Panoramic' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2014.png'/><figcaption>The South Boma - Panoramic</figcaption></figure></p><p><figure><img alt='6 The West Boma - Close-up' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%206.png'/><figcaption>The West Boma - Close-up</figcaption></figure></p><p><figure><img alt='10 The South Boma - Close-up' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2010.png'/><figcaption>The South Boma - Close-up</figcaption></figure></p><p><figure><img alt='15 The South Boma - Close-up Looking West' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2015.png'/><figcaption>The South Boma - Close-up Looking West</figcaption></figure></p><p><figure><img alt='44 SE Corner of the Property Looking at the Start of the South Boma' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2044.png'/><figcaption>SE Corner of the Property Looking at the Start of the South Boma</figcaption></figure></p><h3 id='the-tree-wrangler'>The Tree Wrangler</h3><p>On Thursday, August 13, I started to address some of the potential widow-makers still hanging in our trees.  My first target was the one shown below. I managed to rig a short chain to the end of a nylon rope and after about 10 tries I got the chain wrapped around the most menacing widow-maker, and yanked that sucker right out of the tree. They call me the â€œTree Wranglerâ€. Iâ€™m pleased to report that subsequent limb-roping adventures took fewer tosses!</p><p><figure><img alt='40 The Tree Wrangler Roped His First Stray' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2040.png'/><figcaption>'The Tree Wrangler' Roped His First Stray</figcaption></figure></p><p><figure><img alt='42 Roped My First Stray Tree Limb' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2042.png'/><figcaption>Roped My First Stray Tree Limb</figcaption></figure></p><p>Do you remember seeing an ominous widow-maker in the Sycamore tree in earlier images?  Well she is no more.  At about 1:30 PM on Wednesday, August 19, I roped that critter and managed, with considerable effort, to yank that bad boy down.  Proof that â€œThe Tree Wranglerâ€ has struck againâ€¦</p><p><figure><img alt='I Hath Slain Another Widow-Maker' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/IMG_0592.jpeg'/><figcaption>I Hath Slain Another Widow-Maker</figcaption></figure></p><h3 id='more-random-photos---post-cleanup'>More Random Photos - Post Cleanup</h3><p>Just posting more random, post-cleanup photos here.</p><p><figure><img alt='3 The Back Yard - After Cleanup' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%203.png'/><figcaption>The Back Yard - After Cleanup</figcaption></figure></p><p><figure><img alt='5 Widow-Maker in the Sycamore' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%205.png'/><figcaption>Widow-Maker in the Sycamore</figcaption></figure></p><p><figure><img alt='7 Widow-Maker in the SW Oak' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%207.png'/><figcaption>Widow-Maker in the SW Oak</figcaption></figure></p><p><figure><img alt='8 SW Corner of the House After Cleanup' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%208.png'/><figcaption>SW Corner of the House After Cleanup</figcaption></figure></p><p><figure><img alt='9 Across the Street Looking South - After Cleanup' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%209.png'/><figcaption>Across the Street Looking South - After Cleanup</figcaption></figure></p><p><figure><img alt='11 The SE Oak - After Cleanup' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2011.png'/><figcaption>The SE Oak - After Cleanup</figcaption></figure></p><p><figure><img alt='12 NE Corner of the House - After Cleanup' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2012.png'/><figcaption>NE Corner of the House - After Cleanup</figcaption></figure></p><p><figure><img alt='13 NE Corner of the House - After Cleanup with Alliant&amp;rsquo;s Line Hanging Limp' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2013.png'/><figcaption>NE Corner of the House - After Cleanup with Alliant's Line Hanging Limp</figcaption></figure></p><h3 id='the-kansas-city-chiefs---still-world-champs'>The Kansas City Chiefs - Still World Champs</h3><p>After closing the hot tub cover I made sure to get out and untangle my KC Chiefs flag!</p><p><figure><img alt='43 SE Corner of the House - After I Untangled the Chief&amp;rsquo;s Flag' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2043.png'/><figcaption>SE Corner of the House - After I Untangled the Chief's Flag</figcaption></figure></p><h3 id='our-800-savior'>Our $800 Savior</h3><p>On Wednesday morning, August 12, I got word that some of the big-box hardware stores in Cedar Rapids and Waterloo were receiving shipments of portable generators. They were being sold on a first-come basis, right off the truck, so Morgan and I got in the van and headed to Waterloo as fast as possibleâ€¦we got one at Loweâ€™s for $800.  Had to wait in line for a couple of hours too, but managed to get home mid-afternoon with the generator, some ice and gasoline. None of those things would be available locally until Friday, August 14.</p><p><figure><img alt='16 Our Savior' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2016.png'/><figcaption>Our Savior</figcaption></figure></p><h3 id='my-biggest-remaining-concern---broken-at-the-base'>My Biggest Remaining Concern - Broken at the Base?</h3><p>My biggest remaining worry is the pine tree at the NW corner of the house.  On Thursday, August 13, during clean-up I discovered that the bark on the SE side of the tree is â€œcrushedâ€ as you can see in the image below, and thereâ€™s a visible â€œcrackâ€ on the NW side of the tree right at ground-level. Upon closer inspection it looks like the tree is leaning about 5Â°, naturally right toward our house. ðŸ˜Ÿ</p><p><figure><img alt='1 Broken at the Base?' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%201.png'/><figcaption>Broken at the Base?</figcaption></figure></p><h3 id='houston-we-have-a-problem-or-the-eagle-has-landed'>Houston, We Have a Problem OR The Eagle Has Landed!</h3><p>One block west of our house thereâ€™s a bank, and it used to have a large golden-colored eagle atop itâ€™s electronic sign at the intersection of Summit Street and US Highway 63.  When we told folks from out-of-town how to find us we would always use that eagle as a navigational aid, telling them to find the eagle and head one block east to our house.</p><p>Well, our navigational aid got its wings during the storm.  As you can see in the photos below, the eagle â€œflewâ€ about 200 feet and landed in the bankâ€™s lawn.</p><p><figure><img alt='33 The Eagle Has Landed!' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2033.png'/><figcaption>The Eagle Has Landed!</figcaption></figure></p><p><figure><img alt='35 The Eagle&amp;rsquo;s Flight Path - Panoramic' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2035.png'/><figcaption>The Eagle's Flight Path - Panoramic</figcaption></figure></p><h3 id='with-no-apparent-structural-damage-we-were-luckier-than-some'>With No Apparent Structural Damage, We Were Luckier Than Some</h3><p><figure><img alt='36 Formerly Thys Chevrolet - 1/2-mile from Home' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2036.png'/><figcaption>Formerly Thys Chevrolet - 1/2-mile from Home</figcaption></figure></p><p><figure><img alt='Just One of Several Collapsed Buildings on My In-Law&amp;rsquo;s Farm' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/IMG_2157.jpeg'/><figcaption>Just One of Several Collapsed Buildings on My In-Law's Farm</figcaption></figure></p><h2 id='oak-hill-cemetery---august-20-2020'>Oak Hill Cemetery - August 20, 2020</h2><p>Since all the Alliant trucks rolled past our house around 10 AM this morning, I thought it was time to visit Ian and my parents at Oak Hill Cemetery. Frustrations at home certainly werenâ€™t getting any better so I felt like getting away to take a deep breath and realign my perspective a little.  Oak Hill usually does that for me.</p><p>Oak Hill Cemetery is well-namedâ€¦it blankets the hill with Ian and my parentsâ€™ graves near the very top, and there are lots of oaks, but even more pines. Well, there used to be anyway.</p><p>This is perhaps another case where photos tell the story better than I.  However, Iâ€™m not sure the few photos I took will reflect the scale of the devastation. For starters, the main road up to the cemetery is still blocked, as are the three entrances into the original cemetery. Fortunately, the newest section where there are no mature trees, was relatively clear. So, Morgan and I were able to drive in and park about 100 yards from the hilltop.</p><p>This is a glimpse of what we found thereâ€¦</p><p><figure><img alt='Oak Hill Cemetery from Near the Hilltop Looking South' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Photo-2020-08-20-19-41.jpeg'/><figcaption>Oak Hill Cemetery from Our Parked Car, Looking South</figcaption></figure></p><p><figure><img alt='180 Degree Panorama' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Photo-2020-08-20-19-43.jpeg'/><figcaption>Oak Hill Cemetery - 180 Degree Panorama</figcaption></figure></p><p>I could not bear to shoot the panorama over the opposing 180Â° viewâ€¦it was just too sad. ðŸ˜¢</p><p><figure><img alt='The Big Pine Near the McFate Plots' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Photo-2020-08-20-19-49.jpeg'/><figcaption>The Big Pine Near the McFate Plots</figcaption></figure></p><p>The broken pine, shown above, is, or was, near my parentsâ€™ graves, and you can see their shared headstone just to the right in the image above.  My son, Ian, is buried a little to the left of the edge of the image, but you canâ€™t see that grave from this angle because of all the tree debris. <a href='https://coord.info/GC4BG3B'>â€œIanâ€™s Cacheâ€, GC4BG3B</a> is somewhere inside or under that tree. I looked for the container for about 15 minutes this morning, but came up empty-handed. ðŸ˜¦</p><p>Fortunately, when the olâ€™ tree fell it missed Ianâ€™s grave by a few feet. We got lucky and found all four of the clear acrylic cylinders that used to adorn his grave. They are all intact, but need a little TLC before we put them all back out.</p><p>My parentsâ€™ headstone is in good shape, but another tree toppled the nearby stone marker for my aunt, Dorothy Paddleford. Iâ€™ll see to it that gets fixed soon.</p><p>A few weeks ago my brother-in-law, Dennis, set in-motion a plan to install an engraved stone bench as a memorial for my sister, Marlene McFate Burkheimer. It was to be placed not far from the cemetery road at the very top of the hill, about 50â€™ from the big pine.  At one time we thought about looking into wrapping a bench around that olâ€™ pine to provide a nice place, in the shade, to sit and relax. However, providing a concrete base for such a bench would have been very difficult. Maybe if the pineâ€™s stump is removed we can place the bench where the tree was, and maybe one day plant another tree to provide the shady spot we hoped for?</p><p><figure><img alt='Another View to the South from Ian&amp;rsquo;s Grave - The Road is Still Impassable' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Photo-2020-08-20-19-51.jpeg'/><figcaption>Another View to the South from Ian's Grave - The Road is Still Impassable</figcaption></figure></p><p>Tomorrow morning I plan to contact the City of Tama and the Oak Hill Cemetery Association to see about volunteering to help with clean-up. I think they are going to want all the help they can get in the coming weeks and months.</p><h2 id='gnight'>Gâ€™night</h2><p>Itâ€™s late-evening again, but at least now I have some real lights to work by.  Tomorrow I need to start reprogramming all the devices that have been dead for 11.5 days, and begin making up for as many days of missed work. Time for bed. Gâ€™night all.</p><p>Until next timeâ€¦ but I hope thereâ€™s never another â€œnext timeâ€ quite like this one!</p></p></article>\"}]],\"markups\":[],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>Itâ€™s been far too long, again, since I posted to this blog, but this time I have a legitimate excuse: weâ€™ve been without power or internet, or much of anything, since about 11:45 AM on Monday, August 10, 2020.  So we have now been more than 10.5 days without power. Iâ€™m only able to post this because of a portable generator I bought on August 12 (that was an adventure in itself) and the wireless hotspot that my phone has provided almost 24/7 ever since the storm hit.</p><p>Update: Power was finally restored here at about 6:30 PM, on Thursday, August 20, 2020.  Now I just have 11.5 days of things to catch up on!</p><h2 id='preamble'>Preamble</h2><p>The preamble to this story dates back to Christmas 2019, when my daughter gave me a â€œDadâ€™s Loveâ€¦â€ daily calendar. There have been a couple of dates I kept because they are so accurate, like the day that says â€œWe child-proofed the house but somehow they still got in.â€  ðŸ˜„  Tama County has been in the grips of a moderate-to-severe drought for the past couple of months so the calendar page for August 10 looked like another â€œkeeperâ€. It says:</p><p><figure><img alt='Monday, August 10, &amp;ldquo;Dad&amp;rsquo;s Love&amp;hellip;&amp;rdquo; Calendar' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Photo-2020-08-18-09-54.jpg'/><figcaption>Monday, August 10, 'Dad's Love...' Calendar</figcaption></figure></p><h2 id='930-am---scurry-walk'>9:30 AM - Scurry Walk</h2><p>This story begins in earnest around 9:30 AM on Monday, August 10, 2020.  My â€œscurryâ€ and I were just completing a quick walk around Cherry Lake where we had picked up a little trash, as we usually do. We met a couple of neighbors out for a walk and chatted briefly about the weather, and I suggested that the line of storms now in western Iowa looked like they might just hold together. Every weather system thus far in the summer had passed either just to our north, just to the south, or formed just to the east, so the neighbors just scoffed at the notion of us getting any rain. I was so sure it would rain this time that I didnâ€™t hesitate to put a concrete block on the west-half of my hot tub cover to keep it closed in case of wind. I guess I should have used all eight blocks this time?  ðŸ˜•</p><h2 id='1145-am---the-wind'>11:45 AM - The Wind</h2><p>The storms did indeed â€œhold togetherâ€.  Oh boy, did they ever.  A wall of wind hit Tama-Toledo at about 11:45 AM that morning, with literally NO warning from the US Weather Service. I had received alerts from the WeatherBug app on my iPhone, but there was no â€œofficialâ€ word of impending doom.  The rain didnâ€™t begin until 5 or 10 minutes later, and Iâ€™m not sure any hit the ground because EVERYTHING, tree limbs, mailboxes, small animals, etc., was moving sideways. The power went out moments later. Itâ€™s still out as of this writing, a little more than 10 days since.</p><h2 id='1155-am---get-the-cats'>11:55 AM - Get the Cats!</h2><p>After hustling to the basement and realizing the house was not gone, yet, we thought weâ€™d better go back upstairs to get some candles, more flashlights, and our three cats.  Mackenzie and I managed to get two of the cats pretty easily, but the third one was stubborn and had to be â€œcapturedâ€.  While we were doing this I glanced out the window and saw nothing but tree limbs, still sailing past the windows on a nearly horizontal trajectory.</p><p>By the time we captured the last cat I thought to myself, the wind canâ€™t last much longerâ€¦it had been blowing for at least 5 minutes straight, and I do mean STRAIGHT. I was very wrong.  Thinking back, I do believe the wind blew at upwards of 100 MPH or more for at least 20 minutes.</p><h2 id='1158-am---morgans-story'>11:58 AM - Morganâ€™s Story</h2><p>My daughter, Morgan, had been at the STC Middle School in Toledo working on getting her classroom ready for the start of school. She got a call from a friend in Des Moines at about 11:30 AM telling her to watch out for a line of t-storms heading her way. There are no windows in her classroom so when she finally left the Middle School and saw how dark the sky was she got really concerned and promptly ordered the building secretary to open the office and get a handful of students back inside.  They had just dismissed from summer-school and were waiting outside for their parents to pick them up.  Good thing she did that.</p><p>Morgan drove away from the Middle School just minutes before a wall-of-wind roared in, and she called my cell phone at 11:50 AM just as she passed our house, letting me know that she was going straight to her apartment because her landlord wasnâ€™t home and she was worried about her cats. The 5-minute drive to her apartment took about 3 hours?  A couple of minutes later, at 11:55 AM we ran to our basement (after a 2nd mailbox went sailing past our front door) and Morgan called again at 11:58 AM. Her car had been hit by a falling tree limb, about 6' in diameter, near the crest of the hill on State Street in Tama, just south of the Tama Park. Her windshield was shattered, fortunately on the passengerâ€™s side, and she was freaking out. I told her to stay in her car and Christine called 9-1-1 to provide her with some emergency aid.</p><p>The 9-1-1 call had to route through Benton county (30 miles east of us) as the local center was already overwhelmed, and the storm hadnâ€™t hit there yet. A local police officer was dispatched and could get no closer than about 2.5 blocks from Morganâ€™s car due to downed trees, but made his way to her on-foot. He told her same as me, stay in your car to avoid downed power lines and potentially being hit by flying debris. He also told her to fasten her seatbelt in case the wind flipped the car over. Yikes!  That happened at 12:18 PM, and the wind was still fierce!</p><p>At 12:20 PM my wife realized where Morgan was and called a friend who lives at the location of Morganâ€™s â€œtree incidentâ€, and that friend managed to summon her inside once it was safe to make a run for it.</p><h2 id='1230-pm---the-wind-finally-stopped-time-to-rescue-morgan'>12:30 PM - The Wind Finally Stopped, Time to â€œRescueâ€ Morgan</h2><p>It was about 12:30 PM when I felt like it was finally safe to go back upstairs and outside. Our mission was to try and get to Morgan as soon as possible.  The power was out so I could not easily raise our double garage door, so I peeked out the front door to see what the situation was. OMG!</p><p>Our house is about 70 years old and it is (was) surrounded by five very large, mature treesâ€¦ two grand old Oaks flanking the front yard, an American Sycamore directly west of our garage and patio, and two very tall pines on the NW and NE corners of the house, plus a few smaller and younger trees and bushes. Our driveway measures about 15â€™ x 45â€™ and it was entirely covered in limbs from one of the oaks and the Sycamore. Some of the limbs down on the driveway measured more than 10' in diameter.  It ultimately took about 14 hours of back-breaking effort just to clear the driveway well enough for us to get both vehicles out of the garage.</p><p>In the immediate aftermath of the storm I had two other transportation options: the bicycle I had just purchased on Saturday, August 8; or my daughter Mackenzieâ€™s car which was parked at the curb west of our house. I was pretty sure that car, parked partly beneath one of the oaks and the Sycamore, would be badly damaged, but it was not. There were limbs and whole trees, from our neighbor to the west, lying all around it, but the car was unscathed and operable.  It took a little serpentine driving to navigate out of itâ€™s parking spot, but by about 12:45 PM Christine and I were able to get it out and on-the road to try and â€œrescueâ€ Morgan, roughly 1/2-mile away.</p><p>That 1/2-mile trip featured five impassable streets and a mile or two of back-tracking to find a suitable (barely) route.  The four-lane US Highway 63 proved to be the best route for most of the trip only because it was wide enough that trees on the west side generally didnâ€™t block all four lanes. We arrived in the vicinity of Morganâ€™s car at 1:02 PM and found that she had already pulled the largest limb off her car, what was left looked like this:</p><p><figure><img alt='Morgan&amp;rsquo;s Damaged Nissan Rogue - A Total Loss' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/IMG_2053.jpeg'/><figcaption>Morgan's Damaged Nissan Rogue - A Total Loss</figcaption></figure></p><p>Morganâ€™s apartment is about 1-mile from the location where we left her car, and she knew that her landlord and family were away in Cedar Rapids for the day, so we headed there to check on that property, and her cats. That trip took about 10 minutes with numerous â€œdetoursâ€ but I was able to drive to within a half-block of the house.  Thankfully we found the house intact with no visible, major damage, and the cats were safe, but obviously frightened, still inside Morganâ€™s apartment. Fortunately, the large old tree outside Morganâ€™s apartment window was damaged earlier this year in a storm, and had to be taken down entirely just a couple of weeks ago; otherwise it would have certainly damaged the house and her apartment. We called the landlord to report the relatively good news as they tried to begin their journey back home from CR. Then it started to rain again, just a little.</p><h2 id='the-damage'>The Damage</h2><p>This part of the story is perhaps best told in pictures. I took some photos and am posting them here in chronological order, with descriptive captions.</p><h3 id='first-glimpse-out-the-window'>First Glimpse Out the Window</h3><p><figure><img alt='18 First Glimpse from Inside the House - South Facing Window Looking Out on the Driveway' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2018.png'/><figcaption>First Glimpse from Inside the House - South Facing Window Looking Out on the Driveway</figcaption></figure></p><p><figure><img alt='19 First Glimpse from Inside the House - South Facing Window Looking SE at the Mailboxes' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2019.png'/><figcaption>First Glimpse from Inside the House - South Facing Window Looking SE at the Mailboxes</figcaption></figure></p><p><figure><img alt='17 View from My Home Office Window an Hour After - Lookng NE' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2017.png'/><figcaption>View from My Home Office Window an Hour After - Lookng NE</figcaption></figure></p><h3 id='headed-outside-to-shoot-more-photos'>Headed Outside to Shoot More Photos</h3><p>The power was out everywhere for 30 to 50 miles all around us so we assumed it was safe to get outside and take some better photos.  No chance of getting cars out of the garageâ€¦ our driveway was at least 80% covered by tree parts, some places it was 4 feet deep.</p><p><figure><img alt='20 Looking NW at the House from Where the Mailboxes Used to Be' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2020.png'/><figcaption>Looking NW at the House from Where the Mailboxes Used to Be</figcaption></figure></p><p><figure><img alt='21 Yes, That&amp;rsquo;s Our Mailbox' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2021.png'/><figcaption>Yup, That's Our Mailbox</figcaption></figure></p><p><figure><img alt='22 Looking NW from the Mailboxes - Our Driveway is Under All of That Forest' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2022.png'/><figcaption>Looking NW from the Mailboxes - Our Driveway is Under That Forest</figcaption></figure></p><p><figure><img alt='23 Looking North from the Bottom of Our Driveway' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2023.png'/><figcaption>Looking North from the Bottom of Our Driveway</figcaption></figure></p><p><figure><img alt='24 Looking SW from Just Outside Our Garage' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2024.png'/><figcaption>Looking SW from Just Outside Our Garage</figcaption></figure></p><p><figure><img alt='25 Looking Due South from Just Outside Our Garage' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2025.png'/><figcaption>Looking Due South from Just Outside Our Garage</figcaption></figure></p><p><figure><img alt='26 Looking East from the Top of Our Driveway' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2026.png'/><figcaption>Looking East from the Top of Our Driveway</figcaption></figure></p><h3 id='west-side-story---the-rolling-stone-hot-tub-grill-and-limbs-on-the-roof'>West Side Story - The â€œRolling Stoneâ€, Hot Tub, Grill, and Limbs on the Roof</h3><p>There were three pleasantly-amazing (lucky) things that happened, or didnâ€™t happen as the case may be, on the west, windward, side of the house.</p><p>First up, my home-made lightweight teardrop camper, â€œThe Rolling Stoneâ€.  Itâ€™s the gray thing that looks like a big old boulder on wheels in the right side of the first image below.  It survived, almost unscathed! The only damage was from the door being blown open.  That door hit the west wall of the house so hard that it bent a 1/8' thick steel latch plate back at a 120Â° angle. Because the door was open, things just inside the door also got a little wet, but they dried out well since then.  The whole camper pitched forward about 3â€™ in the wind, but the on-board drop-foot was down so it didnâ€™t fall to the ground. Had any large limbs fallen directly on it, weâ€™d have had a total loss of structure and contents.</p><p><figure><img alt='30 Looking SE from the NW Corner of Our Property' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2030.png'/><figcaption>Looking SE from the NW Corner of Our Property</figcaption></figure></p><p>Next, the hot tub and grill. The very first thing I did when I got outdoors after the storm was to flip the hot tub cover back down.  I have yet to clean all the leaves and debris out of the waterâ€¦maybe later today.</p><p>When I receive any alert of a possible storm I always move one of the concrete blocks, seen stacked on the right in the image below, over to the west edge of my hot tub cover in order to keep it from blowing open.  I made that move about 15 minutes before the storm hit, but it didnâ€™t help. In fact, it did more damage, I think.  The cover seems to be OK, but the wind did flip it open, sending the concrete block sailing about 10â€™ into the side of the house and narrowly missing the bathroom window that you can see. Lucky for us!</p><p>But our gas grill was not so lucky. That concrete block smashed down upon it leaving a big dent in the top, and causing the grill to â€œlistâ€ about 2' to port (the left side when looking from back to front).</p><p><figure><img alt='31 Looking at the Hot Tub and Limbs on the Roof' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2031.png'/><figcaption>Looking at the Hot Tub and Limbs on the Roof</figcaption></figure></p><p><figure><img alt='45 The Grill' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/IMG_3531.png'/><figcaption>Our 1-Year-Old Gas Grill</figcaption></figure></p><p><figure><img alt='27 Looking South from NW Corner of Our Property' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2027.png'/><figcaption>Looking South from NW Corner of Our Property</figcaption></figure></p><p>Finally, the limbs on the roof; you can see them clearly in some of these images. There were actually three of them, the largest with a diameter of about 5' at its base.  All three were from the Sycamore tree, which I suppose is lucky.  Sycamoreâ€™s have ENORMOUS leaves and while I feared severe damage to the roof, it looks like all three limbs just gently â€œfloatedâ€ down to where I found them. I got them sawed up, and down off the roof, including an informal damage inspection plus wasp nest encounter, on Tuesday, August 11.</p><p><figure><img alt='28 Looking SE from the NW Corner of Our Property' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2028.png'/><figcaption>Looking SE from the NW Corner of Our Property</figcaption></figure></p><p><figure><img alt='29 Looking East from the NW Corner of Our Property' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2029.png'/><figcaption>Looking East from the NW Corner of Our Property</figcaption></figure></p><h2 id='the-cleanup'>The Cleanup</h2><h3 id='building-the-worlds-largest--boma'>Building the Worldâ€™s Largest (?) Boma</h3><p>The mayors of Tama and Toledo, along with the Tama Co. Emergency Management office, called a public meeting, conducted in the parking lot of the nearby Tama-Toledo Family Aquatic Center, for 6 PM on Wednesday, August 12. At that meeting the cities informed everyone that any debris left at the curb would eventually be picked up and disposed of by a city crew. So, we started building what I like to think of as the worldâ€™s largest <a href='https://en.wikipedia.org/wiki/Boma_(enclosure)'>boma</a>.</p><p>In the images below you can see both our west and south bomas.  We didnâ€™t need any on the east or north since we have neighbors on those sides, but we did build a small boma (about 30â€™ long by 10â€™ wide) in the parking lot of the church that sits at the NE corner of our property, where our utilities pole is located.</p><p><figure><img alt='2 The West Boma - Panoramic' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%202.png'/><figcaption>The West Boma - Panoramic</figcaption></figure></p><p><figure><img alt='14 The South Boma - Panoramic' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2014.png'/><figcaption>The South Boma - Panoramic</figcaption></figure></p><p><figure><img alt='6 The West Boma - Close-up' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%206.png'/><figcaption>The West Boma - Close-up</figcaption></figure></p><p><figure><img alt='10 The South Boma - Close-up' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2010.png'/><figcaption>The South Boma - Close-up</figcaption></figure></p><p><figure><img alt='15 The South Boma - Close-up Looking West' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2015.png'/><figcaption>The South Boma - Close-up Looking West</figcaption></figure></p><p><figure><img alt='44 SE Corner of the Property Looking at the Start of the South Boma' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2044.png'/><figcaption>SE Corner of the Property Looking at the Start of the South Boma</figcaption></figure></p><h3 id='the-tree-wrangler'>The Tree Wrangler</h3><p>On Thursday, August 13, I started to address some of the potential widow-makers still hanging in our trees.  My first target was the one shown below. I managed to rig a short chain to the end of a nylon rope and after about 10 tries I got the chain wrapped around the most menacing widow-maker, and yanked that sucker right out of the tree. They call me the â€œTree Wranglerâ€. Iâ€™m pleased to report that subsequent limb-roping adventures took fewer tosses!</p><p><figure><img alt='40 The Tree Wrangler Roped His First Stray' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2040.png'/><figcaption>'The Tree Wrangler' Roped His First Stray</figcaption></figure></p><p><figure><img alt='42 Roped My First Stray Tree Limb' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2042.png'/><figcaption>Roped My First Stray Tree Limb</figcaption></figure></p><p>Do you remember seeing an ominous widow-maker in the Sycamore tree in earlier images?  Well she is no more.  At about 1:30 PM on Wednesday, August 19, I roped that critter and managed, with considerable effort, to yank that bad boy down.  Proof that â€œThe Tree Wranglerâ€ has struck againâ€¦</p><p><figure><img alt='I Hath Slain Another Widow-Maker' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/IMG_0592.jpeg'/><figcaption>I Hath Slain Another Widow-Maker</figcaption></figure></p><h3 id='more-random-photos---post-cleanup'>More Random Photos - Post Cleanup</h3><p>Just posting more random, post-cleanup photos here.</p><p><figure><img alt='3 The Back Yard - After Cleanup' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%203.png'/><figcaption>The Back Yard - After Cleanup</figcaption></figure></p><p><figure><img alt='5 Widow-Maker in the Sycamore' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%205.png'/><figcaption>Widow-Maker in the Sycamore</figcaption></figure></p><p><figure><img alt='7 Widow-Maker in the SW Oak' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%207.png'/><figcaption>Widow-Maker in the SW Oak</figcaption></figure></p><p><figure><img alt='8 SW Corner of the House After Cleanup' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%208.png'/><figcaption>SW Corner of the House After Cleanup</figcaption></figure></p><p><figure><img alt='9 Across the Street Looking South - After Cleanup' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%209.png'/><figcaption>Across the Street Looking South - After Cleanup</figcaption></figure></p><p><figure><img alt='11 The SE Oak - After Cleanup' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2011.png'/><figcaption>The SE Oak - After Cleanup</figcaption></figure></p><p><figure><img alt='12 NE Corner of the House - After Cleanup' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2012.png'/><figcaption>NE Corner of the House - After Cleanup</figcaption></figure></p><p><figure><img alt='13 NE Corner of the House - After Cleanup with Alliant&amp;rsquo;s Line Hanging Limp' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2013.png'/><figcaption>NE Corner of the House - After Cleanup with Alliant's Line Hanging Limp</figcaption></figure></p><h3 id='the-kansas-city-chiefs---still-world-champs'>The Kansas City Chiefs - Still World Champs</h3><p>After closing the hot tub cover I made sure to get out and untangle my KC Chiefs flag!</p><p><figure><img alt='43 SE Corner of the House - After I Untangled the Chief&amp;rsquo;s Flag' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2043.png'/><figcaption>SE Corner of the House - After I Untangled the Chief's Flag</figcaption></figure></p><h3 id='our-800-savior'>Our $800 Savior</h3><p>On Wednesday morning, August 12, I got word that some of the big-box hardware stores in Cedar Rapids and Waterloo were receiving shipments of portable generators. They were being sold on a first-come basis, right off the truck, so Morgan and I got in the van and headed to Waterloo as fast as possibleâ€¦we got one at Loweâ€™s for $800.  Had to wait in line for a couple of hours too, but managed to get home mid-afternoon with the generator, some ice and gasoline. None of those things would be available locally until Friday, August 14.</p><p><figure><img alt='16 Our Savior' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2016.png'/><figcaption>Our Savior</figcaption></figure></p><h3 id='my-biggest-remaining-concern---broken-at-the-base'>My Biggest Remaining Concern - Broken at the Base?</h3><p>My biggest remaining worry is the pine tree at the NW corner of the house.  On Thursday, August 13, during clean-up I discovered that the bark on the SE side of the tree is â€œcrushedâ€ as you can see in the image below, and thereâ€™s a visible â€œcrackâ€ on the NW side of the tree right at ground-level. Upon closer inspection it looks like the tree is leaning about 5Â°, naturally right toward our house. ðŸ˜Ÿ</p><p><figure><img alt='1 Broken at the Base?' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%201.png'/><figcaption>Broken at the Base?</figcaption></figure></p><h3 id='houston-we-have-a-problem-or-the-eagle-has-landed'>Houston, We Have a Problem OR The Eagle Has Landed!</h3><p>One block west of our house thereâ€™s a bank, and it used to have a large golden-colored eagle atop itâ€™s electronic sign at the intersection of Summit Street and US Highway 63.  When we told folks from out-of-town how to find us we would always use that eagle as a navigational aid, telling them to find the eagle and head one block east to our house.</p><p>Well, our navigational aid got its wings during the storm.  As you can see in the photos below, the eagle â€œflewâ€ about 200 feet and landed in the bankâ€™s lawn.</p><p><figure><img alt='33 The Eagle Has Landed!' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2033.png'/><figcaption>The Eagle Has Landed!</figcaption></figure></p><p><figure><img alt='35 The Eagle&amp;rsquo;s Flight Path - Panoramic' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2035.png'/><figcaption>The Eagle's Flight Path - Panoramic</figcaption></figure></p><h3 id='with-no-apparent-structural-damage-we-were-luckier-than-some'>With No Apparent Structural Damage, We Were Luckier Than Some</h3><p><figure><img alt='36 Formerly Thys Chevrolet - 1/2-mile from Home' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%2036.png'/><figcaption>Formerly Thys Chevrolet - 1/2-mile from Home</figcaption></figure></p><p><figure><img alt='Just One of Several Collapsed Buildings on My In-Law&amp;rsquo;s Farm' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/IMG_2157.jpeg'/><figcaption>Just One of Several Collapsed Buildings on My In-Law's Farm</figcaption></figure></p><h2 id='oak-hill-cemetery---august-20-2020'>Oak Hill Cemetery - August 20, 2020</h2><p>Since all the Alliant trucks rolled past our house around 10 AM this morning, I thought it was time to visit Ian and my parents at Oak Hill Cemetery. Frustrations at home certainly werenâ€™t getting any better so I felt like getting away to take a deep breath and realign my perspective a little.  Oak Hill usually does that for me.</p><p>Oak Hill Cemetery is well-namedâ€¦it blankets the hill with Ian and my parentsâ€™ graves near the very top, and there are lots of oaks, but even more pines. Well, there used to be anyway.</p><p>This is perhaps another case where photos tell the story better than I.  However, Iâ€™m not sure the few photos I took will reflect the scale of the devastation. For starters, the main road up to the cemetery is still blocked, as are the three entrances into the original cemetery. Fortunately, the newest section where there are no mature trees, was relatively clear. So, Morgan and I were able to drive in and park about 100 yards from the hilltop.</p><p>This is a glimpse of what we found thereâ€¦</p><p><figure><img alt='Oak Hill Cemetery from Near the Hilltop Looking South' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Photo-2020-08-20-19-41.jpeg'/><figcaption>Oak Hill Cemetery from Our Parked Car, Looking South</figcaption></figure></p><p><figure><img alt='180 Degree Panorama' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Photo-2020-08-20-19-43.jpeg'/><figcaption>Oak Hill Cemetery - 180 Degree Panorama</figcaption></figure></p><p>I could not bear to shoot the panorama over the opposing 180Â° viewâ€¦it was just too sad. ðŸ˜¢</p><p><figure><img alt='The Big Pine Near the McFate Plots' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Photo-2020-08-20-19-49.jpeg'/><figcaption>The Big Pine Near the McFate Plots</figcaption></figure></p><p>The broken pine, shown above, is, or was, near my parentsâ€™ graves, and you can see their shared headstone just to the right in the image above.  My son, Ian, is buried a little to the left of the edge of the image, but you canâ€™t see that grave from this angle because of all the tree debris. <a href='https://coord.info/GC4BG3B'>â€œIanâ€™s Cacheâ€, GC4BG3B</a> is somewhere inside or under that tree. I looked for the container for about 15 minutes this morning, but came up empty-handed. ðŸ˜¦</p><p>Fortunately, when the olâ€™ tree fell it missed Ianâ€™s grave by a few feet. We got lucky and found all four of the clear acrylic cylinders that used to adorn his grave. They are all intact, but need a little TLC before we put them all back out.</p><p>My parentsâ€™ headstone is in good shape, but another tree toppled the nearby stone marker for my aunt, Dorothy Paddleford. Iâ€™ll see to it that gets fixed soon.</p><p>A few weeks ago my brother-in-law, Dennis, set in-motion a plan to install an engraved stone bench as a memorial for my sister, Marlene McFate Burkheimer. It was to be placed not far from the cemetery road at the very top of the hill, about 50â€™ from the big pine.  At one time we thought about looking into wrapping a bench around that olâ€™ pine to provide a nice place, in the shade, to sit and relax. However, providing a concrete base for such a bench would have been very difficult. Maybe if the pineâ€™s stump is removed we can place the bench where the tree was, and maybe one day plant another tree to provide the shady spot we hoped for?</p><p><figure><img alt='Another View to the South from Ian&amp;rsquo;s Grave - The Road is Still Impassable' src='https://images-summittdweller.nyc3.digitaloceanspaces.com/2020-Aug-10-Derecho/web-ready/Photo-2020-08-20-19-51.jpeg'/><figcaption>Another View to the South from Ian's Grave - The Road is Still Impassable</figcaption></figure></p><p>Tomorrow morning I plan to contact the City of Tama and the Oak Hill Cemetery Association to see about volunteering to help with clean-up. I think they are going to want all the help they can get in the coming weeks and months.</p><h2 id='gnight'>Gâ€™night</h2><p>Itâ€™s late-evening again, but at least now I have some real lights to work by.  Tomorrow I need to start reprogramming all the devices that have been dead for 11.5 days, and begin making up for as many days of missed work. Time for bed. Gâ€™night all.</p><p>Until next timeâ€¦ but I hope thereâ€™s never another â€œnext timeâ€ quite like this one!</p></p></article><!--kg-card-end: html-->",
            "comment_id": "13",
            "plaintext": "Itâ€™s been far too long, again, since I posted to this blog, but this time I have a legitimate excuse: weâ€™ve been without power or internet, or much of anything, since about 11:45 AM on Monday, August 10, 2020. So we have now been more than 10.5 days without power. Iâ€™m only able to post this because of a portable generator I bought on August 12 (that was an adventure in itself) and the wireless hotspot that my phone has provided almost 24/7 ever since the storm hit.\n\nUpdate: Power was finally restored here at about 6:30 PM, on Thursday, August 20, 2020. Now I just have 11.5 days of things to catch up on!\n\n\nPreamble\n\nThe preamble to this story dates back to Christmas 2019, when my daughter gave me a â€œDadâ€™s Loveâ€¦â€ daily calendar. There have been a couple of dates I kept because they are so accurate, like the day that says â€œWe child-proofed the house but somehow they still got in.â€ ðŸ˜„ Tama County has been in the grips of a moderate-to-severe drought for the past couple of months so the calendar page for August 10 looked like another â€œkeeperâ€. It says:\n\n\n\n\n\n\n9:30 AM - Scurry Walk\n\nThis story begins in earnest around 9:30 AM on Monday, August 10, 2020. My â€œscurryâ€ and I were just completing a quick walk around Cherry Lake where we had picked up a little trash, as we usually do. We met a couple of neighbors out for a walk and chatted briefly about the weather, and I suggested that the line of storms now in western Iowa looked like they might just hold together. Every weather system thus far in the summer had passed either just to our north, just to the south, or formed just to the east, so the neighbors just scoffed at the notion of us getting any rain. I was so sure it would rain this time that I didnâ€™t hesitate to put a concrete block on the west-half of my hot tub cover to keep it closed in case of wind. I guess I should have used all eight blocks this time? ðŸ˜•\n\n\n11:45 AM - The Wind\n\nThe storms did indeed â€œhold togetherâ€. Oh boy, did they ever. A wall of wind hit Tama-Toledo at about 11:45 AM that morning, with literally NO warning from the US Weather Service. I had received alerts from the WeatherBug app on my iPhone, but there was no â€œofficialâ€ word of impending doom. The rain didnâ€™t begin until 5 or 10 minutes later, and Iâ€™m not sure any hit the ground because EVERYTHING, tree limbs, mailboxes, small animals, etc., was moving sideways. The power went out moments later. Itâ€™s still out as of this writing, a little more than 10 days since.\n\n\n11:55 AM - Get the Cats!\n\nAfter hustling to the basement and realizing the house was not gone, yet, we thought weâ€™d better go back upstairs to get some candles, more flashlights, and our three cats. Mackenzie and I managed to get two of the cats pretty easily, but the third one was stubborn and had to be â€œcapturedâ€. While we were doing this I glanced out the window and saw nothing but tree limbs, still sailing past the windows on a nearly horizontal trajectory.\n\nBy the time we captured the last cat I thought to myself, the wind canâ€™t last much longerâ€¦it had been blowing for at least 5 minutes straight, and I do mean STRAIGHT. I was very wrong. Thinking back, I do believe the wind blew at upwards of 100 MPH or more for at least 20 minutes.\n\n\n11:58 AM - Morganâ€™s Story\n\nMy daughter, Morgan, had been at the STC Middle School in Toledo working on getting her classroom ready for the start of school. She got a call from a friend in Des Moines at about 11:30 AM telling her to watch out for a line of t-storms heading her way. There are no windows in her classroom so when she finally left the Middle School and saw how dark the sky was she got really concerned and promptly ordered the building secretary to open the office and get a handful of students back inside. They had just dismissed from summer-school and were waiting outside for their parents to pick them up. Good thing she did that.\n\nMorgan drove away from the Middle School just minutes before a wall-of-wind roared in, and she called my cell phone at 11:50 AM just as she passed our house, letting me know that she was going straight to her apartment because her landlord wasnâ€™t home and she was worried about her cats. The 5-minute drive to her apartment took about 3 hours? A couple of minutes later, at 11:55 AM we ran to our basement (after a 2nd mailbox went sailing past our front door) and Morgan called again at 11:58 AM. Her car had been hit by a falling tree limb, about 6' in diameter, near the crest of the hill on State Street in Tama, just south of the Tama Park. Her windshield was shattered, fortunately on the passengerâ€™s side, and she was freaking out. I told her to stay in her car and Christine called 9-1-1 to provide her with some emergency aid.\n\nThe 9-1-1 call had to route through Benton county (30 miles east of us) as the local center was already overwhelmed, and the storm hadnâ€™t hit there yet. A local police officer was dispatched and could get no closer than about 2.5 blocks from Morganâ€™s car due to downed trees, but made his way to her on-foot. He told her same as me, stay in your car to avoid downed power lines and potentially being hit by flying debris. He also told her to fasten her seatbelt in case the wind flipped the car over. Yikes! That happened at 12:18 PM, and the wind was still fierce!\n\nAt 12:20 PM my wife realized where Morgan was and called a friend who lives at the location of Morganâ€™s â€œtree incidentâ€, and that friend managed to summon her inside once it was safe to make a run for it.\n\n\n12:30 PM - The Wind Finally Stopped, Time to â€œRescueâ€ Morgan\n\nIt was about 12:30 PM when I felt like it was finally safe to go back upstairs and outside. Our mission was to try and get to Morgan as soon as possible. The power was out so I could not easily raise our double garage door, so I peeked out the front door to see what the situation was. OMG!\n\nOur house is about 70 years old and it is (was) surrounded by five very large, mature treesâ€¦ two grand old Oaks flanking the front yard, an American Sycamore directly west of our garage and patio, and two very tall pines on the NW and NE corners of the house, plus a few smaller and younger trees and bushes. Our driveway measures about 15â€™ x 45â€™ and it was entirely covered in limbs from one of the oaks and the Sycamore. Some of the limbs down on the driveway measured more than 10' in diameter. It ultimately took about 14 hours of back-breaking effort just to clear the driveway well enough for us to get both vehicles out of the garage.\n\nIn the immediate aftermath of the storm I had two other transportation options: the bicycle I had just purchased on Saturday, August 8; or my daughter Mackenzieâ€™s car which was parked at the curb west of our house. I was pretty sure that car, parked partly beneath one of the oaks and the Sycamore, would be badly damaged, but it was not. There were limbs and whole trees, from our neighbor to the west, lying all around it, but the car was unscathed and operable. It took a little serpentine driving to navigate out of itâ€™s parking spot, but by about 12:45 PM Christine and I were able to get it out and on-the road to try and â€œrescueâ€ Morgan, roughly 1/2-mile away.\n\nThat 1/2-mile trip featured five impassable streets and a mile or two of back-tracking to find a suitable (barely) route. The four-lane US Highway 63 proved to be the best route for most of the trip only because it was wide enough that trees on the west side generally didnâ€™t block all four lanes. We arrived in the vicinity of Morganâ€™s car at 1:02 PM and found that she had already pulled the largest limb off her car, what was left looked like this:\n\n\n\n\n\nMorganâ€™s apartment is about 1-mile from the location where we left her car, and she knew that her landlord and family were away in Cedar Rapids for the day, so we headed there to check on that property, and her cats. That trip took about 10 minutes with numerous â€œdetoursâ€ but I was able to drive to within a half-block of the house. Thankfully we found the house intact with no visible, major damage, and the cats were safe, but obviously frightened, still inside Morganâ€™s apartment. Fortunately, the large old tree outside Morganâ€™s apartment window was damaged earlier this year in a storm, and had to be taken down entirely just a couple of weeks ago; otherwise it would have certainly damaged the house and her apartment. We called the landlord to report the relatively good news as they tried to begin their journey back home from CR. Then it started to rain again, just a little.\n\n\nThe Damage\n\nThis part of the story is perhaps best told in pictures. I took some photos and am posting them here in chronological order, with descriptive captions.\n\n\nFirst Glimpse Out the Window\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHeaded Outside to Shoot More Photos\n\nThe power was out everywhere for 30 to 50 miles all around us so we assumed it was safe to get outside and take some better photos. No chance of getting cars out of the garageâ€¦ our driveway was at least 80% covered by tree parts, some places it was 4 feet deep.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWest Side Story - The â€œRolling Stoneâ€, Hot Tub, Grill, and Limbs on the Roof\n\nThere were three pleasantly-amazing (lucky) things that happened, or didnâ€™t happen as the case may be, on the west, windward, side of the house.\n\nFirst up, my home-made lightweight teardrop camper, â€œThe Rolling Stoneâ€. Itâ€™s the gray thing that looks like a big old boulder on wheels in the right side of the first image below. It survived, almost unscathed! The only damage was from the door being blown open. That door hit the west wall of the house so hard that it bent a 1/8' thick steel latch plate back at a 120Â° angle. Because the door was open, things just inside the door also got a little wet, but they dried out well since then. The whole camper pitched forward about 3â€™ in the wind, but the on-board drop-foot was down so it didnâ€™t fall to the ground. Had any large limbs fallen directly on it, weâ€™d have had a total loss of structure and contents.\n\n\n\n\n\nNext, the hot tub and grill. The very first thing I did when I got outdoors after the storm was to flip the hot tub cover back down. I have yet to clean all the leaves and debris out of the waterâ€¦maybe later today.\n\nWhen I receive any alert of a possible storm I always move one of the concrete blocks, seen stacked on the right in the image below, over to the west edge of my hot tub cover in order to keep it from blowing open. I made that move about 15 minutes before the storm hit, but it didnâ€™t help. In fact, it did more damage, I think. The cover seems to be OK, but the wind did flip it open, sending the concrete block sailing about 10â€™ into the side of the house and narrowly missing the bathroom window that you can see. Lucky for us!\n\nBut our gas grill was not so lucky. That concrete block smashed down upon it leaving a big dent in the top, and causing the grill to â€œlistâ€ about 2' to port (the left side when looking from back to front).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFinally, the limbs on the roof; you can see them clearly in some of these images. There were actually three of them, the largest with a diameter of about 5' at its base. All three were from the Sycamore tree, which I suppose is lucky. Sycamoreâ€™s have ENORMOUS leaves and while I feared severe damage to the roof, it looks like all three limbs just gently â€œfloatedâ€ down to where I found them. I got them sawed up, and down off the roof, including an informal damage inspection plus wasp nest encounter, on Tuesday, August 11.\n\n\n\n\n\n\n\n\n\n\nThe Cleanup\n\n\nBuilding the Worldâ€™s Largest (?) Boma\n\nThe mayors of Tama and Toledo, along with the Tama Co. Emergency Management office, called a public meeting, conducted in the parking lot of the nearby Tama-Toledo Family Aquatic Center, for 6 PM on Wednesday, August 12. At that meeting the cities informed everyone that any debris left at the curb would eventually be picked up and disposed of by a city crew. So, we started building what I like to think of as the worldâ€™s largest boma.\n\nIn the images below you can see both our west and south bomas. We didnâ€™t need any on the east or north since we have neighbors on those sides, but we did build a small boma (about 30â€™ long by 10â€™ wide) in the parking lot of the church that sits at the NE corner of our property, where our utilities pole is located.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Tree Wrangler\n\nOn Thursday, August 13, I started to address some of the potential widow-makers still hanging in our trees. My first target was the one shown below. I managed to rig a short chain to the end of a nylon rope and after about 10 tries I got the chain wrapped around the most menacing widow-maker, and yanked that sucker right out of the tree. They call me the â€œTree Wranglerâ€. Iâ€™m pleased to report that subsequent limb-roping adventures took fewer tosses!\n\n\n\n\n\n\n\n\n\nDo you remember seeing an ominous widow-maker in the Sycamore tree in earlier images? Well she is no more. At about 1:30 PM on Wednesday, August 19, I roped that critter and managed, with considerable effort, to yank that bad boy down. Proof that â€œThe Tree Wranglerâ€ has struck againâ€¦\n\n\n\n\n\n\nMore Random Photos - Post Cleanup\n\nJust posting more random, post-cleanup photos here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Kansas City Chiefs - Still World Champs\n\nAfter closing the hot tub cover I made sure to get out and untangle my KC Chiefs flag!\n\n\n\n\n\n\nOur $800 Savior\n\nOn Wednesday morning, August 12, I got word that some of the big-box hardware stores in Cedar Rapids and Waterloo were receiving shipments of portable generators. They were being sold on a first-come basis, right off the truck, so Morgan and I got in the van and headed to Waterloo as fast as possibleâ€¦we got one at Loweâ€™s for $800. Had to wait in line for a couple of hours too, but managed to get home mid-afternoon with the generator, some ice and gasoline. None of those things would be available locally until Friday, August 14.\n\n\n\n\n\n\nMy Biggest Remaining Concern - Broken at the Base?\n\nMy biggest remaining worry is the pine tree at the NW corner of the house. On Thursday, August 13, during clean-up I discovered that the bark on the SE side of the tree is â€œcrushedâ€ as you can see in the image below, and thereâ€™s a visible â€œcrackâ€ on the NW side of the tree right at ground-level. Upon closer inspection it looks like the tree is leaning about 5Â°, naturally right toward our house. ðŸ˜Ÿ\n\n\n\n\n\n\nHouston, We Have a Problem OR The Eagle Has Landed!\n\nOne block west of our house thereâ€™s a bank, and it used to have a large golden-colored eagle atop itâ€™s electronic sign at the intersection of Summit Street and US Highway 63. When we told folks from out-of-town how to find us we would always use that eagle as a navigational aid, telling them to find the eagle and head one block east to our house.\n\nWell, our navigational aid got its wings during the storm. As you can see in the photos below, the eagle â€œflewâ€ about 200 feet and landed in the bankâ€™s lawn.\n\n\n\n\n\n\n\n\n\n\nWith No Apparent Structural Damage, We Were Luckier Than Some\n\n\n\n\n\n\n\n\n\n\nOak Hill Cemetery - August 20, 2020\n\nSince all the Alliant trucks rolled past our house around 10 AM this morning, I thought it was time to visit Ian and my parents at Oak Hill Cemetery. Frustrations at home certainly werenâ€™t getting any better so I felt like getting away to take a deep breath and realign my perspective a little. Oak Hill usually does that for me.\n\nOak Hill Cemetery is well-namedâ€¦it blankets the hill with Ian and my parentsâ€™ graves near the very top, and there are lots of oaks, but even more pines. Well, there used to be anyway.\n\nThis is perhaps another case where photos tell the story better than I. However, Iâ€™m not sure the few photos I took will reflect the scale of the devastation. For starters, the main road up to the cemetery is still blocked, as are the three entrances into the original cemetery. Fortunately, the newest section where there are no mature trees, was relatively clear. So, Morgan and I were able to drive in and park about 100 yards from the hilltop.\n\nThis is a glimpse of what we found thereâ€¦\n\n\n\n\n\n\n\n\n\nI could not bear to shoot the panorama over the opposing 180Â° viewâ€¦it was just too sad. ðŸ˜¢\n\n\n\n\n\nThe broken pine, shown above, is, or was, near my parentsâ€™ graves, and you can see their shared headstone just to the right in the image above. My son, Ian, is buried a little to the left of the edge of the image, but you canâ€™t see that grave from this angle because of all the tree debris. â€œIanâ€™s Cacheâ€, GC4BG3B is somewhere inside or under that tree. I looked for the container for about 15 minutes this morning, but came up empty-handed. ðŸ˜¦\n\nFortunately, when the olâ€™ tree fell it missed Ianâ€™s grave by a few feet. We got lucky and found all four of the clear acrylic cylinders that used to adorn his grave. They are all intact, but need a little TLC before we put them all back out.\n\nMy parentsâ€™ headstone is in good shape, but another tree toppled the nearby stone marker for my aunt, Dorothy Paddleford. Iâ€™ll see to it that gets fixed soon.\n\nA few weeks ago my brother-in-law, Dennis, set in-motion a plan to install an engraved stone bench as a memorial for my sister, Marlene McFate Burkheimer. It was to be placed not far from the cemetery road at the very top of the hill, about 50â€™ from the big pine. At one time we thought about looking into wrapping a bench around that olâ€™ pine to provide a nice place, in the shade, to sit and relax. However, providing a concrete base for such a bench would have been very difficult. Maybe if the pineâ€™s stump is removed we can place the bench where the tree was, and maybe one day plant another tree to provide the shady spot we hoped for?\n\n\n\n\n\nTomorrow morning I plan to contact the City of Tama and the Oak Hill Cemetery Association to see about volunteering to help with clean-up. I think they are going to want all the help they can get in the coming weeks and months.\n\n\nGâ€™night\n\nItâ€™s late-evening again, but at least now I have some real lights to work by. Tomorrow I need to start reprogramming all the devices that have been dead for 11.5 days, and begin making up for as many days of missed work. Time for bed. Gâ€™night all.\n\nUntil next timeâ€¦ but I hope thereâ€™s never another â€œnext timeâ€ quite like this one!\n\n",
            "feature_image": "__GHOST_URL__/content/images/2023/04/Derecho-20-1000px.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:03.000Z",
            "updated_at": "2023-04-16T19:02:07.000Z",
            "published_at": "2020-08-18T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c5787c",
            "uuid": "57018004-ec95-4c7e-a307-6ea0ae3f0677",
            "title": "The Derecho: Consolidated Posts and Microposts: August 10 thru September 6, 2020",
            "slug": "the-derecho--consolidated-posts-and-microposts--august-10-thru-september-6--2020",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>The following is a chronological consolidation of posts and microposts from August 10, commonly known in east and central Iowa as â€œThe Day of the Derechoâ€, through September 6, 2020.</p><div class='original'><p>The derecho hit my home in Toledo, Iowa, at about 11:30 AM on Monday, August 10, 2020.  Straight-line winds were clocked at nearly 140 miles per hour, and sustained for more than 20 minutes across a path almost 40 miles wide.</p></div><article class='micropost'><p>  The power is still out here, almost 10 days after the derecho knocked it out. So many power restoration predictions have come and gone, Iâ€™ve lost count. Still Iâ€™m told that what we need is a one-man, 15-minute fix. Perhaps in the morning Iâ€™ll stretch our broken power line across the street and pitch a tent next door until an Alliant truck stops and gets this done. I know they are busy, but 15 minutes of one linemanâ€™s time a week ago, when it was first â€œpromisedâ€, would have been so nice. I fixed my own Mediacom connection more than a week ago, and thereâ€™s evidence tonight that their service has been restored.  So, if I had power, I think we would also have TV and internet.  IF.  <aside class='postmeta'>â†’ 2020/08/19 11:45 PM          posted from Toledo, IA      </aside></p></article><article class='micropost'><p>  Itâ€™s the start of day number eleven, and still no power. Checked the forecast and itâ€™s getting hotâ€¦so am I!  <aside class='postmeta'>â†’ 2020/08/20 8:21 AM          posted from Toledo, IA      </aside></p></article><article class='micropost'><p>  Eleven days and seven hours without, but the power is now back on at 104 W. Summit Street in Toledo. Iâ€™d estimate that for the duration we burned about 105 gallons of gas just to keep the fridge, my CPAP, one lamp, and two fans running.  Glad to be back in the 21st century. Now, whatâ€™s all this I hear about a deadly virus and some political scuffles?  <aside class='postmeta'>â†’ 2020/08/20 7:48 PM          posted from Toledo, IA      </aside></p></article><article class='post'><h2><a href='../../08/iowahurricane2020/index.html' rel='full-article'>Iowa's 2020 Hurricane</a></h2><div class='postmeta'>    Posted on 2020/08/20 10:18 PM          from Toledo, Iowa      </div></article><article class='post'><h2><a href='../../08/2020-derecho-follow-up-august-23/index.html' rel='full-article'>Derecho Follow-Up - Saturday, August 22</a></h2><div class='postmeta'>    Posted on 2020/08/22 9:45 PM          from Toledo, Iowa      </div></article><article class='micropost'><p>  And so begins day number 11 without power. I think I have watched at least a dozen Alliant energy trucks Drive by the house already this morning. I honestly donâ€™t think they know where we are.  <aside class='postmeta'>â†’ 2021/08/21 9:28 AM          posted from Toledo, IA      </aside></p></article><article class='micropost'><p>  Today, Sunday, August 23, 2020, marked the start of what looks like another schorching heat-wave here. So I pitched in during the morning at the home of my â€œscurryâ€ partners Jeff and Mary Fasse-Shaw, to help with cutting up some of the deadfall along the creek on the west side of their property.  We got a good start, but thereâ€™s a lot of fallen timber to be cleared there!  <aside class='postmeta'>â†’ 2020/08/23 5:33 PM          posted from Toledo, Iowa      </aside></p></article><article class='post'><h2><a href='../../08/tama-toledo-parks-2020-derecho-follow-up-august-24/index.html' rel='full-article'>Tama-Toledo Parks - Derecho Follow-Up for August 24</a></h2><div class='postmeta'>    Posted on 2020/08/24 11:20 AM          from Toledo, Iowa      </div></article><article class='post'><h2><a href='../last-of-the-derecho-damage-september-6/index.html' rel='full-article'>Last of the Clean-up? - Derecho Follow-Up for September 6</a></h2><div class='postmeta'>    Posted on 2020/09/06 7:52 PM          from Toledo, Iowa      </div></article></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>The following is a chronological consolidation of posts and microposts from August 10, commonly known in east and central Iowa as â€œThe Day of the Derechoâ€, through September 6, 2020.</p><div class='original'><p>The derecho hit my home in Toledo, Iowa, at about 11:30 AM on Monday, August 10, 2020.  Straight-line winds were clocked at nearly 140 miles per hour, and sustained for more than 20 minutes across a path almost 40 miles wide.</p></div><article class='micropost'><p>  The power is still out here, almost 10 days after the derecho knocked it out. So many power restoration predictions have come and gone, Iâ€™ve lost count. Still Iâ€™m told that what we need is a one-man, 15-minute fix. Perhaps in the morning Iâ€™ll stretch our broken power line across the street and pitch a tent next door until an Alliant truck stops and gets this done. I know they are busy, but 15 minutes of one linemanâ€™s time a week ago, when it was first â€œpromisedâ€, would have been so nice. I fixed my own Mediacom connection more than a week ago, and thereâ€™s evidence tonight that their service has been restored.  So, if I had power, I think we would also have TV and internet.  IF.  <aside class='postmeta'>â†’ 2020/08/19 11:45 PM          posted from Toledo, IA      </aside></p></article><article class='micropost'><p>  Itâ€™s the start of day number eleven, and still no power. Checked the forecast and itâ€™s getting hotâ€¦so am I!  <aside class='postmeta'>â†’ 2020/08/20 8:21 AM          posted from Toledo, IA      </aside></p></article><article class='micropost'><p>  Eleven days and seven hours without, but the power is now back on at 104 W. Summit Street in Toledo. Iâ€™d estimate that for the duration we burned about 105 gallons of gas just to keep the fridge, my CPAP, one lamp, and two fans running.  Glad to be back in the 21st century. Now, whatâ€™s all this I hear about a deadly virus and some political scuffles?  <aside class='postmeta'>â†’ 2020/08/20 7:48 PM          posted from Toledo, IA      </aside></p></article><article class='post'><h2><a href='../../08/iowahurricane2020/index.html' rel='full-article'>Iowa's 2020 Hurricane</a></h2><div class='postmeta'>    Posted on 2020/08/20 10:18 PM          from Toledo, Iowa      </div></article><article class='post'><h2><a href='../../08/2020-derecho-follow-up-august-23/index.html' rel='full-article'>Derecho Follow-Up - Saturday, August 22</a></h2><div class='postmeta'>    Posted on 2020/08/22 9:45 PM          from Toledo, Iowa      </div></article><article class='micropost'><p>  And so begins day number 11 without power. I think I have watched at least a dozen Alliant energy trucks Drive by the house already this morning. I honestly donâ€™t think they know where we are.  <aside class='postmeta'>â†’ 2021/08/21 9:28 AM          posted from Toledo, IA      </aside></p></article><article class='micropost'><p>  Today, Sunday, August 23, 2020, marked the start of what looks like another schorching heat-wave here. So I pitched in during the morning at the home of my â€œscurryâ€ partners Jeff and Mary Fasse-Shaw, to help with cutting up some of the deadfall along the creek on the west side of their property.  We got a good start, but thereâ€™s a lot of fallen timber to be cleared there!  <aside class='postmeta'>â†’ 2020/08/23 5:33 PM          posted from Toledo, Iowa      </aside></p></article><article class='post'><h2><a href='../../08/tama-toledo-parks-2020-derecho-follow-up-august-24/index.html' rel='full-article'>Tama-Toledo Parks - Derecho Follow-Up for August 24</a></h2><div class='postmeta'>    Posted on 2020/08/24 11:20 AM          from Toledo, Iowa      </div></article><article class='post'><h2><a href='../last-of-the-derecho-damage-september-6/index.html' rel='full-article'>Last of the Clean-up? - Derecho Follow-Up for September 6</a></h2><div class='postmeta'>    Posted on 2020/09/06 7:52 PM          from Toledo, Iowa      </div></article></p></article><!--kg-card-end: html-->",
            "comment_id": "14",
            "plaintext": "The following is a chronological consolidation of posts and microposts from August 10, commonly known in east and central Iowa as â€œThe Day of the Derechoâ€, through September 6, 2020.\n\nThe derecho hit my home in Toledo, Iowa, at about 11:30 AM on Monday, August 10, 2020. Straight-line winds were clocked at nearly 140 miles per hour, and sustained for more than 20 minutes across a path almost 40 miles wide.\n\nThe power is still out here, almost 10 days after the derecho knocked it out. So many power restoration predictions have come and gone, Iâ€™ve lost count. Still Iâ€™m told that what we need is a one-man, 15-minute fix. Perhaps in the morning Iâ€™ll stretch our broken power line across the street and pitch a tent next door until an Alliant truck stops and gets this done. I know they are busy, but 15 minutes of one linemanâ€™s time a week ago, when it was first â€œpromisedâ€, would have been so nice. I fixed my own Mediacom connection more than a week ago, and thereâ€™s evidence tonight that their service has been restored. So, if I had power, I think we would also have TV and internet. IF.\n\nâ†’ 2020/08/19 11:45 PM posted from Toledo, IA\n\n\n\nItâ€™s the start of day number eleven, and still no power. Checked the forecast and itâ€™s getting hotâ€¦so am I!\n\nâ†’ 2020/08/20 8:21 AM posted from Toledo, IA\n\n\n\nEleven days and seven hours without, but the power is now back on at 104 W. Summit Street in Toledo. Iâ€™d estimate that for the duration we burned about 105 gallons of gas just to keep the fridge, my CPAP, one lamp, and two fans running. Glad to be back in the 21st century. Now, whatâ€™s all this I hear about a deadly virus and some political scuffles?\n\nâ†’ 2020/08/20 7:48 PM posted from Toledo, IA\n\n\n\n\nIowa's 2020 Hurricane\n\nPosted on 2020/08/20 10:18 PM from Toledo, Iowa\n\n\nDerecho Follow-Up - Saturday, August 22\n\nPosted on 2020/08/22 9:45 PM from Toledo, Iowa\n\nAnd so begins day number 11 without power. I think I have watched at least a dozen Alliant energy trucks Drive by the house already this morning. I honestly donâ€™t think they know where we are.\n\nâ†’ 2021/08/21 9:28 AM posted from Toledo, IA\n\n\n\nToday, Sunday, August 23, 2020, marked the start of what looks like another schorching heat-wave here. So I pitched in during the morning at the home of my â€œscurryâ€ partners Jeff and Mary Fasse-Shaw, to help with cutting up some of the deadfall along the creek on the west side of their property. We got a good start, but thereâ€™s a lot of fallen timber to be cleared there!\n\nâ†’ 2020/08/23 5:33 PM posted from Toledo, Iowa\n\n\n\n\nTama-Toledo Parks - Derecho Follow-Up for August 24\n\nPosted on 2020/08/24 11:20 AM from Toledo, Iowa\n\n\nLast of the Clean-up? - Derecho Follow-Up for September 6\n\nPosted on 2020/09/06 7:52 PM from Toledo, Iowa\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:03.000Z",
            "updated_at": "2023-04-02T03:48:55.000Z",
            "published_at": "2022-09-25T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c5787d",
            "uuid": "128313d9-488f-4bf1-b9a2-886652bbd476",
            "title": "Atom No More?",
            "slug": "atom-no-more-",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>Yesterday one of my library colleagues at Grinnell College posted an <a href='https://github.blog/2022-06-08-sunsetting-atom/'>announcement</a> that <a href='https://atom.io'>Atom</a> would be retired (sunset) in December 2022.  Ouch, I have a lot of workflows that depend on <em>Atom</em>!</p><p>So, today part of my mission is to begin the process of migrating workflows, both work-related and personal/at-home, from <em>Atom</em> to its most logical replacement, <a href='https://code.visualstudio.com/'>Visual Studio Code</a> or <em>VS Code</em> as itâ€™s largely known in the development community.  The other part of todayâ€™s mission was to update <a href='https://blog.summittdweller.com/'>this blog</a>, something Iâ€™ve not done in far too long!</p><p>What better time to begin using <em>VS Code</em> than right now, to edit <a href='http://localhost:1313/posts/2022/06/atom-no-more/posts/2022/06/atom-no-more/'>this blog post</a>?  So, thatâ€™s what I did, er, am doing.</p><p>This could be a long story, but Iâ€™ll keep it short and just share the links, mostly.  Iâ€™ll begin on my personal Mac Mini, where Iâ€™m editing now, so I can test the entire process before repeating it on my other Mac workstations.</p><h2 id='install-using-homebrew'>Install Using Homebrew</h2><p>I like to use <code>homebrew</code> whenever possible to manage installations on my Mac. On this Mac Mini I found <a href='https://formulae.brew.sh/cask/visual-studio-code'>this Homebrew Formulae</a> and put it to useâ€¦  All done.  Nice!</p><h2 id='adding-a-command-line--terminal-shortcut'>Adding a Command Line / Terminal Shortcut</h2><p>Iâ€™ve gotten quite used to launching <em>Atom</em> in my working directory with a simple command of the form <code>atom .</code>.  Can I do the same with <em>VS Code</em>?  Sure!  I used the guidance found in <a href='https://www.freecodecamp.org/news/how-to-open-visual-studio-code-from-your-terminal/'>How to Open Visual Studio Code From Your Terminal</a> to set that up.  Piece of cake.  I love finding timely, not stale, advice that just works!</p><p>Now I can simply navigate to a project folder on my Mac and type <code>code .</code> to open it all in <em>VS Code</em>.  Sweet!</p><h2 id='replacing-my-atom-packages'>Replacing My Atom Packages</h2><p>There are quite a few, nothing that Iâ€™ve written personally, but lots of published packages/extensions borrowed from others.  Thatâ€™s one of the things I love(d) about <em>Atom</em>. On my Mac Mini, and most other Macs, that list looks something like this:</p><p><figure><img alt='My Installed Atom Packages' src='http://localhost:1313/img/my-atom-packages.png'/><figcaption></figcaption></figure></p><p>I told you there were quite a few.  Iâ€™m posting this image of my list just so I have a document as I begin to build the same into <em>VS Code</em>.  Oh, when I added the above image to this post, I did so by dragging my screen-capture from my desktop directly into the <em>VS Code</em> <code>EXPLORER</code> panel (left side of my window), just like I used to do with <em>Atom</em>.  Nice!</p><p>Iâ€™ll take my time and start replacing these as-needed.  First upâ€¦</p><h3 id='replacing-iso-8601-timestamp'>Replacing <code>ISO 8601 timestamp</code></h3><p>This <em>Atom</em> package allows me to add the current date and time, in ISO 8601 format, to the frontmatter of a blog post like the one you are reading now.  I found and followed <a href='https://marketplace.visualstudio.com/items?itemName=jsynowiec.vscode-insertdatestring'>this documentation</a> to set it up in <em>VS Code</em>.  In <em>Atom</em> I put my cursor at the point where my timestamp was needed, and went to the <code>Packages</code> menu to insert it.  In <em>VS Code</em> there doesnâ€™t appear to be such a menu, but the documentation says I can use <code>command-shift-P</code> to open the â€œcommand palletteâ€, where I can scroll to or search for the command I want to engage.  Another piece of cake!</p><p>The result of inserting the current timestamp should be reflected in the frontmatter of this blog post.  ðŸ˜€</p><h2 id='more-goodies'>More Goodies</h2><p>This morning I updated this entry after adding a <code>Duplicate file or directory</code> command using the <a href='https://marketplace.visualstudio.com/items?itemName=mrmlnc.vscode-duplicate'>Duplicate Action</a> extension from the marketplace.  It works very nicely!</p><p>Whatâ€™s could be better?  Well, finding a list of <a href='https://dev.to/gsdev/10-vscode-extensions-i-can-t-live-without-1i5c'>10 â€œmust-haveâ€ <em>VSCode</em> extensions</a> and working my way through them!</p><h2 id='luna-paint'>Luna Paint</h2><p>I just stumbled across another handy <em>VSCode</em> extension, <code>Luna Paint</code>.  Iâ€™ve installed it, took all of 2 minutes to update TWO Macs, using the guidance provided in <a href='https://www.youtube.com/watch?v=I_6bZQZheC0'>this YouTube video</a>.  It rocks!   2022-07-19T10:07:39-05:00</p><hr/><p>With any luck Iâ€™ll be able to use this post to perform much the same configuration on my other Macs, soon.  I promised Iâ€™d keep this long story short, so, until next timeâ€¦</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>Yesterday one of my library colleagues at Grinnell College posted an <a href='https://github.blog/2022-06-08-sunsetting-atom/'>announcement</a> that <a href='https://atom.io'>Atom</a> would be retired (sunset) in December 2022.  Ouch, I have a lot of workflows that depend on <em>Atom</em>!</p><p>So, today part of my mission is to begin the process of migrating workflows, both work-related and personal/at-home, from <em>Atom</em> to its most logical replacement, <a href='https://code.visualstudio.com/'>Visual Studio Code</a> or <em>VS Code</em> as itâ€™s largely known in the development community.  The other part of todayâ€™s mission was to update <a href='https://blog.summittdweller.com/'>this blog</a>, something Iâ€™ve not done in far too long!</p><p>What better time to begin using <em>VS Code</em> than right now, to edit <a href='http://localhost:1313/posts/2022/06/atom-no-more/posts/2022/06/atom-no-more/'>this blog post</a>?  So, thatâ€™s what I did, er, am doing.</p><p>This could be a long story, but Iâ€™ll keep it short and just share the links, mostly.  Iâ€™ll begin on my personal Mac Mini, where Iâ€™m editing now, so I can test the entire process before repeating it on my other Mac workstations.</p><h2 id='install-using-homebrew'>Install Using Homebrew</h2><p>I like to use <code>homebrew</code> whenever possible to manage installations on my Mac. On this Mac Mini I found <a href='https://formulae.brew.sh/cask/visual-studio-code'>this Homebrew Formulae</a> and put it to useâ€¦  All done.  Nice!</p><h2 id='adding-a-command-line--terminal-shortcut'>Adding a Command Line / Terminal Shortcut</h2><p>Iâ€™ve gotten quite used to launching <em>Atom</em> in my working directory with a simple command of the form <code>atom .</code>.  Can I do the same with <em>VS Code</em>?  Sure!  I used the guidance found in <a href='https://www.freecodecamp.org/news/how-to-open-visual-studio-code-from-your-terminal/'>How to Open Visual Studio Code From Your Terminal</a> to set that up.  Piece of cake.  I love finding timely, not stale, advice that just works!</p><p>Now I can simply navigate to a project folder on my Mac and type <code>code .</code> to open it all in <em>VS Code</em>.  Sweet!</p><h2 id='replacing-my-atom-packages'>Replacing My Atom Packages</h2><p>There are quite a few, nothing that Iâ€™ve written personally, but lots of published packages/extensions borrowed from others.  Thatâ€™s one of the things I love(d) about <em>Atom</em>. On my Mac Mini, and most other Macs, that list looks something like this:</p><p><figure><img alt='My Installed Atom Packages' src='http://localhost:1313/img/my-atom-packages.png'/><figcaption></figcaption></figure></p><p>I told you there were quite a few.  Iâ€™m posting this image of my list just so I have a document as I begin to build the same into <em>VS Code</em>.  Oh, when I added the above image to this post, I did so by dragging my screen-capture from my desktop directly into the <em>VS Code</em> <code>EXPLORER</code> panel (left side of my window), just like I used to do with <em>Atom</em>.  Nice!</p><p>Iâ€™ll take my time and start replacing these as-needed.  First upâ€¦</p><h3 id='replacing-iso-8601-timestamp'>Replacing <code>ISO 8601 timestamp</code></h3><p>This <em>Atom</em> package allows me to add the current date and time, in ISO 8601 format, to the frontmatter of a blog post like the one you are reading now.  I found and followed <a href='https://marketplace.visualstudio.com/items?itemName=jsynowiec.vscode-insertdatestring'>this documentation</a> to set it up in <em>VS Code</em>.  In <em>Atom</em> I put my cursor at the point where my timestamp was needed, and went to the <code>Packages</code> menu to insert it.  In <em>VS Code</em> there doesnâ€™t appear to be such a menu, but the documentation says I can use <code>command-shift-P</code> to open the â€œcommand palletteâ€, where I can scroll to or search for the command I want to engage.  Another piece of cake!</p><p>The result of inserting the current timestamp should be reflected in the frontmatter of this blog post.  ðŸ˜€</p><h2 id='more-goodies'>More Goodies</h2><p>This morning I updated this entry after adding a <code>Duplicate file or directory</code> command using the <a href='https://marketplace.visualstudio.com/items?itemName=mrmlnc.vscode-duplicate'>Duplicate Action</a> extension from the marketplace.  It works very nicely!</p><p>Whatâ€™s could be better?  Well, finding a list of <a href='https://dev.to/gsdev/10-vscode-extensions-i-can-t-live-without-1i5c'>10 â€œmust-haveâ€ <em>VSCode</em> extensions</a> and working my way through them!</p><h2 id='luna-paint'>Luna Paint</h2><p>I just stumbled across another handy <em>VSCode</em> extension, <code>Luna Paint</code>.  Iâ€™ve installed it, took all of 2 minutes to update TWO Macs, using the guidance provided in <a href='https://www.youtube.com/watch?v=I_6bZQZheC0'>this YouTube video</a>.  It rocks!   2022-07-19T10:07:39-05:00</p><hr/><p>With any luck Iâ€™ll be able to use this post to perform much the same configuration on my other Macs, soon.  I promised Iâ€™d keep this long story short, so, until next timeâ€¦</p></p></article><!--kg-card-end: html-->",
            "comment_id": "15",
            "plaintext": "Yesterday one of my library colleagues at Grinnell College posted an announcement that Atom would be retired (sunset) in December 2022. Ouch, I have a lot of workflows that depend on Atom!\n\nSo, today part of my mission is to begin the process of migrating workflows, both work-related and personal/at-home, from Atom to its most logical replacement, Visual Studio Code or VS Code as itâ€™s largely known in the development community. The other part of todayâ€™s mission was to update this blog, something Iâ€™ve not done in far too long!\n\nWhat better time to begin using VS Code than right now, to edit this blog post? So, thatâ€™s what I did, er, am doing.\n\nThis could be a long story, but Iâ€™ll keep it short and just share the links, mostly. Iâ€™ll begin on my personal Mac Mini, where Iâ€™m editing now, so I can test the entire process before repeating it on my other Mac workstations.\n\n\nInstall Using Homebrew\n\nI like to use homebrew whenever possible to manage installations on my Mac. On this Mac Mini I found this Homebrew Formulae and put it to useâ€¦ All done. Nice!\n\n\nAdding a Command Line / Terminal Shortcut\n\nIâ€™ve gotten quite used to launching Atom in my working directory with a simple command of the form atom .. Can I do the same with VS Code? Sure! I used the guidance found in How to Open Visual Studio Code From Your Terminal to set that up. Piece of cake. I love finding timely, not stale, advice that just works!\n\nNow I can simply navigate to a project folder on my Mac and type code . to open it all in VS Code. Sweet!\n\n\nReplacing My Atom Packages\n\nThere are quite a few, nothing that Iâ€™ve written personally, but lots of published packages/extensions borrowed from others. Thatâ€™s one of the things I love(d) about Atom. On my Mac Mini, and most other Macs, that list looks something like this:\n\n\n\n\n\nI told you there were quite a few. Iâ€™m posting this image of my list just so I have a document as I begin to build the same into VS Code. Oh, when I added the above image to this post, I did so by dragging my screen-capture from my desktop directly into the VS Code EXPLORER panel (left side of my window), just like I used to do with Atom. Nice!\n\nIâ€™ll take my time and start replacing these as-needed. First upâ€¦\n\n\nReplacing ISO 8601 timestamp\n\nThis Atom package allows me to add the current date and time, in ISO 8601 format, to the frontmatter of a blog post like the one you are reading now. I found and followed this documentation to set it up in VS Code. In Atom I put my cursor at the point where my timestamp was needed, and went to the Packages menu to insert it. In VS Code there doesnâ€™t appear to be such a menu, but the documentation says I can use command-shift-P to open the â€œcommand palletteâ€, where I can scroll to or search for the command I want to engage. Another piece of cake!\n\nThe result of inserting the current timestamp should be reflected in the frontmatter of this blog post. ðŸ˜€\n\n\nMore Goodies\n\nThis morning I updated this entry after adding a Duplicate file or directory command using the Duplicate Action extension from the marketplace. It works very nicely!\n\nWhatâ€™s could be better? Well, finding a list of 10 â€œmust-haveâ€ VSCode extensions and working my way through them!\n\n\nLuna Paint\n\nI just stumbled across another handy VSCode extension, Luna Paint. Iâ€™ve installed it, took all of 2 minutes to update TWO Macs, using the guidance provided in this YouTube video. It rocks! 2022-07-19T10:07:39-05:00\n\nWith any luck Iâ€™ll be able to use this post to perform much the same configuration on my other Macs, soon. I promised Iâ€™d keep this long story short, so, until next timeâ€¦\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:03.000Z",
            "updated_at": "2023-04-02T03:49:32.000Z",
            "published_at": "2022-06-09T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c5787e",
            "uuid": "915fc5e6-03ab-4a17-b097-3f3340e46005",
            "title": "Travel...MSP to CDG to OSL to KKN",
            "slug": "travel---msp-to-cdg-to-osl-to-kkn",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><figure><img src='https://images-summittdweller.nyc3.digitaloceanspaces.com/Norway-Photos-2019/Minneapolis-Saint%20Paul%20International%20Airport%20-%20Minneapolis,%20MN,%20June%2011,%202019/IMG_0352.png'/><figcaption>This was a very long day in the air, and then we discovered the 'midnight sun'!</figcaption></figure><p>This post is really part of my <a href='http://weblog-sd.docksal/photos/norway-june-2019/norway-june-2019/'>Norway photo blog</a> which you can find elsewhere on this site.  Note that the photos here are in reverse-chronological order with the exception of one â€œleadâ€ post that lays out our itinerary.  So, read onâ€¦</p><p>I drove the 5 of us, plus luggage, in our mini-van to Minneapolis for our departure, and we left home early just in case there were surprises.  Good thing we did!  I drove US 20 to I35 with a stop in Storm Lake for a late lunch.  Not long after that stop we hit the first snag and found I35 closed, in both directions, just south of the Iowa-Minnesota border.  The stop and detour there set us back about a half hour or soâ€¦no problem.</p><p>We booked and found off-site parking near the airport in Minneapolis, and got dropped off at the correct terminal for <em>Iceland Air</em>, which will forever be known in this household as <code>Iceland Error</code>.  Thatâ€™s when things really go interesting.  <code>Iceland Error</code> had changed our flight, and itinerary, without notice (they have no mobile app).  We would be leaving the US about an hour later, good thing, and arriving in Kirkenes about 16 hours ahead of our original schedule! We werenâ€™t even booked on <code>Iceland Error</code> for our departure, instead we were flying <em>Air France</em> to Paris, then to Oslo, and connecting directly to Kirkenes.</p><p>The change meant we had to change terminals, back to the terminal weâ€™d just come from with luggage in tow. Not fun.</p><p>Ok, so <em>Air France</em> was GREAT!  They fed us, we had comfortable seats, they dimmed the lights, had nice entertainment, and provided whatever we needed at no extra charge. For the record, <code>Iceland Error</code> did NONE of that on our return to the U.S.</p><p>But I digressâ€¦ We got to Paris without a hitch and in good spirits, found our connecting flight to Oslo and made that leg in good shape.  Then on to Kirkenes rather than staying a night in Oslo, and that was OK, except that Kirkenes isnâ€™t a big city, and when we arrived ahead of schedule there was no shuttle waiting for us (the one that did arrive was full), but the good folks there dispatched one especially for us.</p><p>We arrived at our hotel around 11 PM local time, I think.  Of course, it was difficult to tell the time because the sun was still up, and would remain â€œupâ€ for pretty much the next 4 days!</p><p>The hotel had only one spare room for the night, so Chris and I took that one, and they arranged for Mark, Deb and Doug to taxi about 30 minutes outside of town to a â€œcabinâ€ near the Russian border.  Lucky for themâ€¦they got to set foot, or at least a big toe, in Russia, at about 2 AM, I think.  Silly Americans.  ðŸ˜</p><p>To be honest, I loved the â€œmidnight sunâ€, it was great for geocaching, but really put a dent in my already damaged sleep schedule. ðŸ˜‰</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><figure><img src='https://images-summittdweller.nyc3.digitaloceanspaces.com/Norway-Photos-2019/Minneapolis-Saint%20Paul%20International%20Airport%20-%20Minneapolis,%20MN,%20June%2011,%202019/IMG_0352.png'/><figcaption>This was a very long day in the air, and then we discovered the 'midnight sun'!</figcaption></figure><p>This post is really part of my <a href='http://weblog-sd.docksal/photos/norway-june-2019/norway-june-2019/'>Norway photo blog</a> which you can find elsewhere on this site.  Note that the photos here are in reverse-chronological order with the exception of one â€œleadâ€ post that lays out our itinerary.  So, read onâ€¦</p><p>I drove the 5 of us, plus luggage, in our mini-van to Minneapolis for our departure, and we left home early just in case there were surprises.  Good thing we did!  I drove US 20 to I35 with a stop in Storm Lake for a late lunch.  Not long after that stop we hit the first snag and found I35 closed, in both directions, just south of the Iowa-Minnesota border.  The stop and detour there set us back about a half hour or soâ€¦no problem.</p><p>We booked and found off-site parking near the airport in Minneapolis, and got dropped off at the correct terminal for <em>Iceland Air</em>, which will forever be known in this household as <code>Iceland Error</code>.  Thatâ€™s when things really go interesting.  <code>Iceland Error</code> had changed our flight, and itinerary, without notice (they have no mobile app).  We would be leaving the US about an hour later, good thing, and arriving in Kirkenes about 16 hours ahead of our original schedule! We werenâ€™t even booked on <code>Iceland Error</code> for our departure, instead we were flying <em>Air France</em> to Paris, then to Oslo, and connecting directly to Kirkenes.</p><p>The change meant we had to change terminals, back to the terminal weâ€™d just come from with luggage in tow. Not fun.</p><p>Ok, so <em>Air France</em> was GREAT!  They fed us, we had comfortable seats, they dimmed the lights, had nice entertainment, and provided whatever we needed at no extra charge. For the record, <code>Iceland Error</code> did NONE of that on our return to the U.S.</p><p>But I digressâ€¦ We got to Paris without a hitch and in good spirits, found our connecting flight to Oslo and made that leg in good shape.  Then on to Kirkenes rather than staying a night in Oslo, and that was OK, except that Kirkenes isnâ€™t a big city, and when we arrived ahead of schedule there was no shuttle waiting for us (the one that did arrive was full), but the good folks there dispatched one especially for us.</p><p>We arrived at our hotel around 11 PM local time, I think.  Of course, it was difficult to tell the time because the sun was still up, and would remain â€œupâ€ for pretty much the next 4 days!</p><p>The hotel had only one spare room for the night, so Chris and I took that one, and they arranged for Mark, Deb and Doug to taxi about 30 minutes outside of town to a â€œcabinâ€ near the Russian border.  Lucky for themâ€¦they got to set foot, or at least a big toe, in Russia, at about 2 AM, I think.  Silly Americans.  ðŸ˜</p><p>To be honest, I loved the â€œmidnight sunâ€, it was great for geocaching, but really put a dent in my already damaged sleep schedule. ðŸ˜‰</p></p></article><!--kg-card-end: html-->",
            "comment_id": "16",
            "plaintext": "This post is really part of my Norway photo blog which you can find elsewhere on this site. Note that the photos here are in reverse-chronological order with the exception of one â€œleadâ€ post that lays out our itinerary. So, read onâ€¦\n\nI drove the 5 of us, plus luggage, in our mini-van to Minneapolis for our departure, and we left home early just in case there were surprises. Good thing we did! I drove US 20 to I35 with a stop in Storm Lake for a late lunch. Not long after that stop we hit the first snag and found I35 closed, in both directions, just south of the Iowa-Minnesota border. The stop and detour there set us back about a half hour or soâ€¦no problem.\n\nWe booked and found off-site parking near the airport in Minneapolis, and got dropped off at the correct terminal for Iceland Air, which will forever be known in this household as Iceland Error. Thatâ€™s when things really go interesting. Iceland Error had changed our flight, and itinerary, without notice (they have no mobile app). We would be leaving the US about an hour later, good thing, and arriving in Kirkenes about 16 hours ahead of our original schedule! We werenâ€™t even booked on Iceland Error for our departure, instead we were flying Air France to Paris, then to Oslo, and connecting directly to Kirkenes.\n\nThe change meant we had to change terminals, back to the terminal weâ€™d just come from with luggage in tow. Not fun.\n\nOk, so Air France was GREAT! They fed us, we had comfortable seats, they dimmed the lights, had nice entertainment, and provided whatever we needed at no extra charge. For the record, Iceland Error did NONE of that on our return to the U.S.\n\nBut I digressâ€¦ We got to Paris without a hitch and in good spirits, found our connecting flight to Oslo and made that leg in good shape. Then on to Kirkenes rather than staying a night in Oslo, and that was OK, except that Kirkenes isnâ€™t a big city, and when we arrived ahead of schedule there was no shuttle waiting for us (the one that did arrive was full), but the good folks there dispatched one especially for us.\n\nWe arrived at our hotel around 11 PM local time, I think. Of course, it was difficult to tell the time because the sun was still up, and would remain â€œupâ€ for pretty much the next 4 days!\n\nThe hotel had only one spare room for the night, so Chris and I took that one, and they arranged for Mark, Deb and Doug to taxi about 30 minutes outside of town to a â€œcabinâ€ near the Russian border. Lucky for themâ€¦they got to set foot, or at least a big toe, in Russia, at about 2 AM, I think. Silly Americans. ðŸ˜\n\nTo be honest, I loved the â€œmidnight sunâ€, it was great for geocaching, but really put a dent in my already damaged sleep schedule. ðŸ˜‰\n\n",
            "feature_image": "https://images.unsplash.com/photo-1630414178593-26f610c7ad2e?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDI2fHxOb3J3YXl8ZW58MHx8fHwxNjgwNjk5MTU5&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:03.000Z",
            "updated_at": "2023-04-05T12:53:26.000Z",
            "published_at": "2019-06-12T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c5787f",
            "uuid": "35dfb24c-63a5-40f6-bdf5-972cd8479cd5",
            "title": "Eastbound from Seattle - Day 1",
            "slug": "eastbound-from-seattle---day-1",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><h1 id='day-1---seattle-wa-to-lakeview-or'>Day 1 - Seattle, WA to Lakeview, OR</h1><p>This is our planned route for Day 1 (eastbound) using a <code>speed factor of 1.0</code> (traveling at the speed limit).  Fuel cost is based on <code>40 mpg</code> and <code>$4.00 per gallon</code> averages.  Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.</p><p>A list of possible geocache targets for the entire route can be found at <a href='https://www.geocaching.com/play/map/lists/BMBBMD6'>https://www.geocaching.com/play/map/lists/BMBBMD6</a>.</p><iframe src='http://localhost:1313/html/Eastbound-Day-1.html' style='width: 100%; height: 400px; border:1;' title='Eastbound Day 1'></iframe></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><h1 id='day-1---seattle-wa-to-lakeview-or'>Day 1 - Seattle, WA to Lakeview, OR</h1><p>This is our planned route for Day 1 (eastbound) using a <code>speed factor of 1.0</code> (traveling at the speed limit).  Fuel cost is based on <code>40 mpg</code> and <code>$4.00 per gallon</code> averages.  Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.</p><p>A list of possible geocache targets for the entire route can be found at <a href='https://www.geocaching.com/play/map/lists/BMBBMD6'>https://www.geocaching.com/play/map/lists/BMBBMD6</a>.</p><iframe src='http://localhost:1313/html/Eastbound-Day-1.html' style='width: 100%; height: 400px; border:1;' title='Eastbound Day 1'></iframe></p></article><!--kg-card-end: html-->",
            "comment_id": "17",
            "plaintext": "Day 1 - Seattle, WA to Lakeview, OR\n\nThis is our planned route for Day 1 (eastbound) using a speed factor of 1.0 (traveling at the speed limit). Fuel cost is based on 40 mpg and $4.00 per gallon averages. Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.\n\nA list of possible geocache targets for the entire route can be found at https://www.geocaching.com/play/map/lists/BMBBMD6.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:03.000Z",
            "updated_at": "2023-04-02T03:49:26.000Z",
            "published_at": "2022-08-07T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57880",
            "uuid": "7c56fcc7-2f7f-4c67-be39-cbfd79d3feba",
            "title": "Westbound to Seattle - Day 1",
            "slug": "westbound-to-seattle---day-1",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><h1 id='day-1---toledo-ia-to-glendive-mt'>Day 1 - Toledo, IA to Glendive, MT</h1><p>This is our planned route for Day 1 using a <code>speed factor of 1.0</code> (traveling at the speed limit).  Fuel cost is based on <code>40 mpg</code> and <code>$4.00 per gallon</code> averages.  Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.</p><p>A list of possible geocache targets for the entire route can be found at <a href='https://www.geocaching.com/play/map/lists/BMBBMD6'>https://www.geocaching.com/play/map/lists/BMBBMD6</a>.</p><iframe src='http://localhost:1313/html/Westbound-Day-1.html' style='width: 100%; height: 400px; border:1;' title='Westbound Day 1'></iframe></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><h1 id='day-1---toledo-ia-to-glendive-mt'>Day 1 - Toledo, IA to Glendive, MT</h1><p>This is our planned route for Day 1 using a <code>speed factor of 1.0</code> (traveling at the speed limit).  Fuel cost is based on <code>40 mpg</code> and <code>$4.00 per gallon</code> averages.  Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.</p><p>A list of possible geocache targets for the entire route can be found at <a href='https://www.geocaching.com/play/map/lists/BMBBMD6'>https://www.geocaching.com/play/map/lists/BMBBMD6</a>.</p><iframe src='http://localhost:1313/html/Westbound-Day-1.html' style='width: 100%; height: 400px; border:1;' title='Westbound Day 1'></iframe></p></article><!--kg-card-end: html-->",
            "comment_id": "18",
            "plaintext": "Day 1 - Toledo, IA to Glendive, MT\n\nThis is our planned route for Day 1 using a speed factor of 1.0 (traveling at the speed limit). Fuel cost is based on 40 mpg and $4.00 per gallon averages. Fuel stops typically have a 15-minute duration and rest areas allow 5-minutes each.\n\nA list of possible geocache targets for the entire route can be found at https://www.geocaching.com/play/map/lists/BMBBMD6.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:03.000Z",
            "updated_at": "2023-04-02T03:49:18.000Z",
            "published_at": "2022-08-07T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57881",
            "uuid": "2486b41e-139f-4834-bfaa-c465ae4089d2",
            "title": "My MQTT Weekend",
            "slug": "my-mqtt-weekend",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>Now that Iâ€™ve cleared the driveway of the latest snowfall, I am officially declaring this to be â€œ<strong>My MQTT Weekend</strong>â€.  It actually started on Friday night, the weekend, not the snow.  Rather than posting a lot of gibberish here, Iâ€™ll just point you to my project repo at <a href='https://github.com/SummittDweller/Motorized_MQTT_Blinds'>https://github.com/SummittDweller/Motorized_MQTT_Blinds</a> and especially the <a href='https://github.com/SummittDweller/Motorized_MQTT_Blinds#additional-resources'>Additional Resources</a> portion of the <em>README.md</em> file there.  If/when I get this all working maybe I will post some photos, maybe.</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>Now that Iâ€™ve cleared the driveway of the latest snowfall, I am officially declaring this to be â€œ<strong>My MQTT Weekend</strong>â€.  It actually started on Friday night, the weekend, not the snow.  Rather than posting a lot of gibberish here, Iâ€™ll just point you to my project repo at <a href='https://github.com/SummittDweller/Motorized_MQTT_Blinds'>https://github.com/SummittDweller/Motorized_MQTT_Blinds</a> and especially the <a href='https://github.com/SummittDweller/Motorized_MQTT_Blinds#additional-resources'>Additional Resources</a> portion of the <em>README.md</em> file there.  If/when I get this all working maybe I will post some photos, maybe.</p></p></article><!--kg-card-end: html-->",
            "comment_id": "19",
            "plaintext": "Now that Iâ€™ve cleared the driveway of the latest snowfall, I am officially declaring this to be â€œMy MQTT Weekendâ€. It actually started on Friday night, the weekend, not the snow. Rather than posting a lot of gibberish here, Iâ€™ll just point you to my project repo at https://github.com/SummittDweller/Motorized_MQTT_Blinds and especially the Additional Resources portion of the README.md file there. If/when I get this all working maybe I will post some photos, maybe.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:03.000Z",
            "updated_at": "2023-04-02T03:50:00.000Z",
            "published_at": "2021-01-31T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57882",
            "uuid": "182aa636-5553-41d0-ac4e-280a7be13e75",
            "title": "5-Inch HDMI Raspberry Pi Touch Screen",
            "slug": "5-inch-hdmi-raspberry-pi-touch-screen",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>A couple of years have now passed since I purchased an <a href='https://www.amazon.com/Elecrow-Display-Monitor-800x480-Raspberry/dp/B013JECYF2/ref=as_li_ss_tl?ie=UTF8&amp;linkCode=ll1&amp;tag=mmjjg-20&amp;linkId=df2d8e154ca1d5ca9fb992d34677ebd3'>Elecrow 5' HDMI Touchscreen display for the Raspberry Pi</a> and put it to use.  I even 3D printed a very nice case for it.  So, thereâ€™s a bit of configuration code on the SD card that can be edited to determine if the 5' screen is active, or if the RPIâ€™s output is directed to its HDMI output port.  Well, in the last 2 years I forgot what to edit and what changes to make.</p><p>Fortunately, when I went looking for some info to refresh my memory, I found a great resourceâ€¦ a review posted in 2016 from none other than <a href='https://www.jeffgeerling.com/'>Jeff Geerling</a>, aka <a href='https://github.com/geerlingguy'>geerlingguy</a>.  His review/blog post is <a href='https://www.jeffgeerling.com/blog/2016/review-elecrow-hdmi-5-800x480-tft-display-xpt2046-touch-controller'>Review: Elecrow HDMI 5' 800x480 TFT Display with XPT2046 Touch Controller</a>.  In case Jeffâ€™s post should ever disappear, hereâ€™s the a key piece of info that I needed to jog my memory:</p><div class='original'><h2 id='getting-full-resolution-over-hdmi'>Getting full resolution over HDMI</h2><p>When I first booted the Pi attached to the display, there was a large white area on the right, and only the left portion of the screen was being used by the Pi (it was only using 640x480 of the 800x480 display). To fix this, you have to set a few display options in the configuration file the Raspberry Pi reads during startup to switch certain hardware settings.</p><p>Edit /boot/config.txt (either while booted into Raspbian, or on another computer directly on the microSD card), making sure the following values are set:</p><pre tabindex='0'><code># uncomment if you get no picture on HDMI for a # default 'safe' mode#hdmi_safe=1# uncomment this if your display has a black border of unused # pixels visible and your display can output without overscandisable_overscan=0# uncomment if hdmi display is not detected and composite # is being output#hdmi_force_hotplug=1# uncomment to force a specific HDMI mode (this will force VGA)hdmi_group=2hdmi_mode=1hdmi_mode=87hdmi_cvt=800 480 60 6 0 0 0</code></pre><p>Reboot the Pi either via the UI or by entering sudo reboot in the Terminal. Once rebooted, the Pi should fill up the full 800x480 display.</p><blockquote><p>Note: If the Pi boots up to a funny-looking screen and you canâ€™t see anything, you can either reformat the microSD card, or pull it, edit the /boot/config.txt file from another computer to fix it, and put it back in the Pi.</p></blockquote></div></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>A couple of years have now passed since I purchased an <a href='https://www.amazon.com/Elecrow-Display-Monitor-800x480-Raspberry/dp/B013JECYF2/ref=as_li_ss_tl?ie=UTF8&amp;linkCode=ll1&amp;tag=mmjjg-20&amp;linkId=df2d8e154ca1d5ca9fb992d34677ebd3'>Elecrow 5' HDMI Touchscreen display for the Raspberry Pi</a> and put it to use.  I even 3D printed a very nice case for it.  So, thereâ€™s a bit of configuration code on the SD card that can be edited to determine if the 5' screen is active, or if the RPIâ€™s output is directed to its HDMI output port.  Well, in the last 2 years I forgot what to edit and what changes to make.</p><p>Fortunately, when I went looking for some info to refresh my memory, I found a great resourceâ€¦ a review posted in 2016 from none other than <a href='https://www.jeffgeerling.com/'>Jeff Geerling</a>, aka <a href='https://github.com/geerlingguy'>geerlingguy</a>.  His review/blog post is <a href='https://www.jeffgeerling.com/blog/2016/review-elecrow-hdmi-5-800x480-tft-display-xpt2046-touch-controller'>Review: Elecrow HDMI 5' 800x480 TFT Display with XPT2046 Touch Controller</a>.  In case Jeffâ€™s post should ever disappear, hereâ€™s the a key piece of info that I needed to jog my memory:</p><div class='original'><h2 id='getting-full-resolution-over-hdmi'>Getting full resolution over HDMI</h2><p>When I first booted the Pi attached to the display, there was a large white area on the right, and only the left portion of the screen was being used by the Pi (it was only using 640x480 of the 800x480 display). To fix this, you have to set a few display options in the configuration file the Raspberry Pi reads during startup to switch certain hardware settings.</p><p>Edit /boot/config.txt (either while booted into Raspbian, or on another computer directly on the microSD card), making sure the following values are set:</p><pre tabindex='0'><code># uncomment if you get no picture on HDMI for a # default 'safe' mode#hdmi_safe=1# uncomment this if your display has a black border of unused # pixels visible and your display can output without overscandisable_overscan=0# uncomment if hdmi display is not detected and composite # is being output#hdmi_force_hotplug=1# uncomment to force a specific HDMI mode (this will force VGA)hdmi_group=2hdmi_mode=1hdmi_mode=87hdmi_cvt=800 480 60 6 0 0 0</code></pre><p>Reboot the Pi either via the UI or by entering sudo reboot in the Terminal. Once rebooted, the Pi should fill up the full 800x480 display.</p><blockquote><p>Note: If the Pi boots up to a funny-looking screen and you canâ€™t see anything, you can either reformat the microSD card, or pull it, edit the /boot/config.txt file from another computer to fix it, and put it back in the Pi.</p></blockquote></div></p></article><!--kg-card-end: html-->",
            "comment_id": "20",
            "plaintext": "A couple of years have now passed since I purchased an Elecrow 5' HDMI Touchscreen display for the Raspberry Pi and put it to use. I even 3D printed a very nice case for it. So, thereâ€™s a bit of configuration code on the SD card that can be edited to determine if the 5' screen is active, or if the RPIâ€™s output is directed to its HDMI output port. Well, in the last 2 years I forgot what to edit and what changes to make.\n\nFortunately, when I went looking for some info to refresh my memory, I found a great resourceâ€¦ a review posted in 2016 from none other than Jeff Geerling, aka geerlingguy. His review/blog post is Review: Elecrow HDMI 5' 800x480 TFT Display with XPT2046 Touch Controller. In case Jeffâ€™s post should ever disappear, hereâ€™s the a key piece of info that I needed to jog my memory:\n\n\nGetting full resolution over HDMI\n\nWhen I first booted the Pi attached to the display, there was a large white area on the right, and only the left portion of the screen was being used by the Pi (it was only using 640x480 of the 800x480 display). To fix this, you have to set a few display options in the configuration file the Raspberry Pi reads during startup to switch certain hardware settings.\n\nEdit /boot/config.txt (either while booted into Raspbian, or on another computer directly on the microSD card), making sure the following values are set:\n\n# uncomment if you get no picture on HDMI for a # default 'safe' mode#hdmi_safe=1# uncomment this if your display has a black border of unused # pixels visible and your display can output without overscandisable_overscan=0# uncomment if hdmi display is not detected and composite # is being output#hdmi_force_hotplug=1# uncomment to force a specific HDMI mode (this will force VGA)hdmi_group=2hdmi_mode=1hdmi_mode=87hdmi_cvt=800 480 60 6 0 0 0\n\nReboot the Pi either via the UI or by entering sudo reboot in the Terminal. Once rebooted, the Pi should fill up the full 800x480 display.\n\nNote: If the Pi boots up to a funny-looking screen and you canâ€™t see anything, you can either reformat the microSD card, or pull it, edit the /boot/config.txt file from another computer to fix it, and put it back in the Pi.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:03.000Z",
            "updated_at": "2023-04-02T03:49:54.000Z",
            "published_at": "2021-02-05T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57883",
            "uuid": "916ec881-a46b-4bf5-abf4-bca76be55d77",
            "title": "My Photos Workflow",
            "slug": "my-photos-workflow",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>I recently returned from vacation in Norway with a few hundred photos and a handful of videos, taken mostly using my iPhone 8.  I find that the Apple Photos app does a pretty nice job of cataloging photos and videos into <code>Moments</code>.  Each <code>Moment</code> includes all the images taken in a single day, and sometimes in a particular location, if photos are taken on the same day, but a great distance apart.</p><p>Moment names from my Norway vacation were nicely descriptive, like:</p><ul><li>Minneapolis-Saint Paul International Airport - Minneapolis, MN, June 11, 2019</li><li>Paris Charles de Gaulle Airport - Mauregard, ÃŽle-de-France, June 12, 2019</li><li>Jessheim - Akershus, June 12, 2019</li><li>Kirkenes, Finnmark - Johan Knudtzens gate, June 12, 2019</li><li>Kirkenes, Finnmark - Dr. Wessels gate, June 13, 2019</li><li>Kirkenes, Finnmark - Johan Knudtzens gate, June 14, 2019</li><li>SkarsvÃ¥g - Finnmark, June 14, 2019</li><li>ArnÃ¸yhamn - Norway, June 15, 2019</li></ul><h2 id='exporting-the-photos'>Exporting the Photos</h2><p>I found <a href='https://support.apple.com/guide/photos/export-photos-videos-and-slideshows-pht6e157c5f/mac'>this resource</a> on the web and followed it for the export portion of my process.</p><p>So, I opened <code>Photos</code> on my Mac Mini, selected the <code>Moments</code> view/tab, culled some of the duplicates out, then selected all 359 remaining images using my mouse.  With the images highlighted I selected menu options: <code>File</code>, <code>Export</code>, and <code>Export 359 Photos...</code>. I subsequently filled in the following dialog like so:</p><p><figure><img alt='Photos Export Dialog' src='https://images.summittdweller.com/Norway-Photos-2019/PhotosExportDialog.png'/><figcaption></figcaption></figure></p><p>I choose a â€˜Photo Kindâ€™, or format, equal to <code>PNG</code> and a â€˜Sizeâ€™ equal to <code>Medium</code>, since most of the images are huge and would load very slowly in my blog if left at their original size.  I elected to save the exported PNG images into a new folder on my <code>~/Desktop</code> named <code>Norway-Medium-PNG-Export</code>.</p><h2 id='upload-to-digital-ocean-spaces'>Upload to Digital Ocean â€œSpacesâ€</h2><p>A few days ago I registered with <em>Digital Ocean</em> <a href='https://cloud.digitalocean.com/spaces?i=d7d6c7'>â€œSpacesâ€</a>, and created my first â€œbucketâ€ named <code>images-summittdweller</code>. <em>Spaces</em> provides me with up to 280 GB of REST-accessible object storage for a small monthly fee.  To host my photos there I simply created a â€œfolderâ€ named <a href='https://cloud.digitalocean.com/spaces/images-summittdweller?i=d7d6c7&amp;path=Norway-Photos-2019%2F'>Norway-Photos-2019</a> and did a drag-n-drop of each <code>~/Desktop/Norway-Medium-PNG-Export/</code> individual* folder directly into my browser window.  *Note that the drag-n-drop interface was unable to swallow the entire <code>Norway-Medium-PNG-Export</code> folder all at once. ðŸ˜ž</p><p>All of my uploads to the <code>images-summittdweller</code> bucket were declared as <code>Public</code> rather than <code>Private</code>, that way they can be accessed using simple URLs without authentication.</p><h2 id='additional-images'>Additional Images</h2><p>In addition to the aforementioned photos, I also parked a copy of the <code>PhotosExportDialog.png</code> screen capture there in the root folder.  Itâ€™s accessible as <a href='https://images.summittdweller.com/Norway-Photos-2019/PhotosExportDialog.png'>https://images.summittdweller.com/Norway-Photos-2019/PhotosExportDialog.png</a> and thatâ€™s what I used above to embed the image you see in this document.</p><p>In the future, more images, perhaps some taken by Deb, Doug, or Mark McCune, can be added to this photo blog in a similar manner.</p><h2 id='object-structure-and-urls'>Object Structure and URLs</h2><p>A sampling of the bucket/object/filenames and URLs from <code>images-summittdweller</code> are tabulated below.  From this small sample the URL structure is easy to infer.</p><table><thead><tr><th>images-summittdweller Bucket Path</th><th>URL</th></tr></thead><tbody><tr><td>./Norway-Photos-2019/PhotosExportDialog.png</td><td><a href='https://images.summittdweller.com/Norway-Photos-2019/PhotosExportDialog.png'>https://images.summittdweller.com/Norway-Photos-2019/PhotosExportDialog.png</a></td></tr><tr><td>./Norway-Photos-2019/Minneapolis-Saint Paul International Airport - Minneapolis, MN, June 11, 2019/IMG_0352.png</td><td><a href='https://images.summittdweller.com/Norway-Photos-2019/Minneapolis-Saint%20Paul%20International%20Airport%20-%20Minneapolis,%20MN,%20June%2011,%202019/IMG_0352.png'>https://images.summittdweller.com/Norway-Photos-2019/Minneapolis-Saint%20Paul%20International%20Airport%20-%20Minneapolis,%20MN,%20June%2011,%202019/IMG_0352.png</a></td></tr><tr><td>./Norway-Photos-2019/TromsÃ¸ - Troms, June 15, 2019/IMG_0527.png</td><td><a href='https://images.summittdweller.com/Norway-Photos-2019/Troms%C3%B8%20-%20Troms,%20June%2015,%202019/IMG_0527.png'>https://images.summittdweller.com/Norway-Photos-2019/Troms%C3%B8%20-%20Troms,%20June%2015,%202019/IMG_0527.png</a></td></tr></tbody></table><h2 id='generating-markdown-for-blog-photos'>Generating Markdown for Blog Photos</h2><p>So the intent of all this is to populate the photo blogs that you see <a href='http://localhost:1313/posts/2019/07/my-photo-workflow/content/photos'>here</a>. To that end Iâ€™ve created a simple <a href='https://www.digitalocean.com/docs/api/'>API</a> Python3 script based on guidance provided in <a href='https://www.digitalocean.com/community/questions/how-to-access-all-the-files-stored-in-a-spaces-folder'>this article</a>.</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>I recently returned from vacation in Norway with a few hundred photos and a handful of videos, taken mostly using my iPhone 8.  I find that the Apple Photos app does a pretty nice job of cataloging photos and videos into <code>Moments</code>.  Each <code>Moment</code> includes all the images taken in a single day, and sometimes in a particular location, if photos are taken on the same day, but a great distance apart.</p><p>Moment names from my Norway vacation were nicely descriptive, like:</p><ul><li>Minneapolis-Saint Paul International Airport - Minneapolis, MN, June 11, 2019</li><li>Paris Charles de Gaulle Airport - Mauregard, ÃŽle-de-France, June 12, 2019</li><li>Jessheim - Akershus, June 12, 2019</li><li>Kirkenes, Finnmark - Johan Knudtzens gate, June 12, 2019</li><li>Kirkenes, Finnmark - Dr. Wessels gate, June 13, 2019</li><li>Kirkenes, Finnmark - Johan Knudtzens gate, June 14, 2019</li><li>SkarsvÃ¥g - Finnmark, June 14, 2019</li><li>ArnÃ¸yhamn - Norway, June 15, 2019</li></ul><h2 id='exporting-the-photos'>Exporting the Photos</h2><p>I found <a href='https://support.apple.com/guide/photos/export-photos-videos-and-slideshows-pht6e157c5f/mac'>this resource</a> on the web and followed it for the export portion of my process.</p><p>So, I opened <code>Photos</code> on my Mac Mini, selected the <code>Moments</code> view/tab, culled some of the duplicates out, then selected all 359 remaining images using my mouse.  With the images highlighted I selected menu options: <code>File</code>, <code>Export</code>, and <code>Export 359 Photos...</code>. I subsequently filled in the following dialog like so:</p><p><figure><img alt='Photos Export Dialog' src='https://images.summittdweller.com/Norway-Photos-2019/PhotosExportDialog.png'/><figcaption></figcaption></figure></p><p>I choose a â€˜Photo Kindâ€™, or format, equal to <code>PNG</code> and a â€˜Sizeâ€™ equal to <code>Medium</code>, since most of the images are huge and would load very slowly in my blog if left at their original size.  I elected to save the exported PNG images into a new folder on my <code>~/Desktop</code> named <code>Norway-Medium-PNG-Export</code>.</p><h2 id='upload-to-digital-ocean-spaces'>Upload to Digital Ocean â€œSpacesâ€</h2><p>A few days ago I registered with <em>Digital Ocean</em> <a href='https://cloud.digitalocean.com/spaces?i=d7d6c7'>â€œSpacesâ€</a>, and created my first â€œbucketâ€ named <code>images-summittdweller</code>. <em>Spaces</em> provides me with up to 280 GB of REST-accessible object storage for a small monthly fee.  To host my photos there I simply created a â€œfolderâ€ named <a href='https://cloud.digitalocean.com/spaces/images-summittdweller?i=d7d6c7&amp;path=Norway-Photos-2019%2F'>Norway-Photos-2019</a> and did a drag-n-drop of each <code>~/Desktop/Norway-Medium-PNG-Export/</code> individual* folder directly into my browser window.  *Note that the drag-n-drop interface was unable to swallow the entire <code>Norway-Medium-PNG-Export</code> folder all at once. ðŸ˜ž</p><p>All of my uploads to the <code>images-summittdweller</code> bucket were declared as <code>Public</code> rather than <code>Private</code>, that way they can be accessed using simple URLs without authentication.</p><h2 id='additional-images'>Additional Images</h2><p>In addition to the aforementioned photos, I also parked a copy of the <code>PhotosExportDialog.png</code> screen capture there in the root folder.  Itâ€™s accessible as <a href='https://images.summittdweller.com/Norway-Photos-2019/PhotosExportDialog.png'>https://images.summittdweller.com/Norway-Photos-2019/PhotosExportDialog.png</a> and thatâ€™s what I used above to embed the image you see in this document.</p><p>In the future, more images, perhaps some taken by Deb, Doug, or Mark McCune, can be added to this photo blog in a similar manner.</p><h2 id='object-structure-and-urls'>Object Structure and URLs</h2><p>A sampling of the bucket/object/filenames and URLs from <code>images-summittdweller</code> are tabulated below.  From this small sample the URL structure is easy to infer.</p><table><thead><tr><th>images-summittdweller Bucket Path</th><th>URL</th></tr></thead><tbody><tr><td>./Norway-Photos-2019/PhotosExportDialog.png</td><td><a href='https://images.summittdweller.com/Norway-Photos-2019/PhotosExportDialog.png'>https://images.summittdweller.com/Norway-Photos-2019/PhotosExportDialog.png</a></td></tr><tr><td>./Norway-Photos-2019/Minneapolis-Saint Paul International Airport - Minneapolis, MN, June 11, 2019/IMG_0352.png</td><td><a href='https://images.summittdweller.com/Norway-Photos-2019/Minneapolis-Saint%20Paul%20International%20Airport%20-%20Minneapolis,%20MN,%20June%2011,%202019/IMG_0352.png'>https://images.summittdweller.com/Norway-Photos-2019/Minneapolis-Saint%20Paul%20International%20Airport%20-%20Minneapolis,%20MN,%20June%2011,%202019/IMG_0352.png</a></td></tr><tr><td>./Norway-Photos-2019/TromsÃ¸ - Troms, June 15, 2019/IMG_0527.png</td><td><a href='https://images.summittdweller.com/Norway-Photos-2019/Troms%C3%B8%20-%20Troms,%20June%2015,%202019/IMG_0527.png'>https://images.summittdweller.com/Norway-Photos-2019/Troms%C3%B8%20-%20Troms,%20June%2015,%202019/IMG_0527.png</a></td></tr></tbody></table><h2 id='generating-markdown-for-blog-photos'>Generating Markdown for Blog Photos</h2><p>So the intent of all this is to populate the photo blogs that you see <a href='http://localhost:1313/posts/2019/07/my-photo-workflow/content/photos'>here</a>. To that end Iâ€™ve created a simple <a href='https://www.digitalocean.com/docs/api/'>API</a> Python3 script based on guidance provided in <a href='https://www.digitalocean.com/community/questions/how-to-access-all-the-files-stored-in-a-spaces-folder'>this article</a>.</p></p></article><!--kg-card-end: html-->",
            "comment_id": "21",
            "plaintext": "I recently returned from vacation in Norway with a few hundred photos and a handful of videos, taken mostly using my iPhone 8. I find that the Apple Photos app does a pretty nice job of cataloging photos and videos into Moments. Each Moment includes all the images taken in a single day, and sometimes in a particular location, if photos are taken on the same day, but a great distance apart.\n\nMoment names from my Norway vacation were nicely descriptive, like:\n\n * Minneapolis-Saint Paul International Airport - Minneapolis, MN, June 11, 2019\n * Paris Charles de Gaulle Airport - Mauregard, ÃŽle-de-France, June 12, 2019\n * Jessheim - Akershus, June 12, 2019\n * Kirkenes, Finnmark - Johan Knudtzens gate, June 12, 2019\n * Kirkenes, Finnmark - Dr. Wessels gate, June 13, 2019\n * Kirkenes, Finnmark - Johan Knudtzens gate, June 14, 2019\n * SkarsvÃ¥g - Finnmark, June 14, 2019\n * ArnÃ¸yhamn - Norway, June 15, 2019\n\n\nExporting the Photos\n\nI found this resource on the web and followed it for the export portion of my process.\n\nSo, I opened Photos on my Mac Mini, selected the Moments view/tab, culled some of the duplicates out, then selected all 359 remaining images using my mouse. With the images highlighted I selected menu options: File, Export, and Export 359 Photos.... I subsequently filled in the following dialog like so:\n\n\n\n\n\nI choose a â€˜Photo Kindâ€™, or format, equal to PNG and a â€˜Sizeâ€™ equal to Medium, since most of the images are huge and would load very slowly in my blog if left at their original size. I elected to save the exported PNG images into a new folder on my ~/Desktop named Norway-Medium-PNG-Export.\n\n\nUpload to Digital Ocean â€œSpacesâ€\n\nA few days ago I registered with Digital Ocean â€œSpacesâ€, and created my first â€œbucketâ€ named images-summittdweller. Spaces provides me with up to 280 GB of REST-accessible object storage for a small monthly fee. To host my photos there I simply created a â€œfolderâ€ named Norway-Photos-2019 and did a drag-n-drop of each ~/Desktop/Norway-Medium-PNG-Export/ individual* folder directly into my browser window. *Note that the drag-n-drop interface was unable to swallow the entire Norway-Medium-PNG-Export folder all at once. ðŸ˜ž\n\nAll of my uploads to the images-summittdweller bucket were declared as Public rather than Private, that way they can be accessed using simple URLs without authentication.\n\n\nAdditional Images\n\nIn addition to the aforementioned photos, I also parked a copy of the PhotosExportDialog.png screen capture there in the root folder. Itâ€™s accessible as https://images.summittdweller.com/Norway-Photos-2019/PhotosExportDialog.png and thatâ€™s what I used above to embed the image you see in this document.\n\nIn the future, more images, perhaps some taken by Deb, Doug, or Mark McCune, can be added to this photo blog in a similar manner.\n\n\nObject Structure and URLs\n\nA sampling of the bucket/object/filenames and URLs from images-summittdweller are tabulated below. From this small sample the URL structure is easy to infer.\n\nimages-summittdweller Bucket PathURL./Norway-Photos-2019/PhotosExportDialog.pnghttps://images.summittdweller.com/Norway-Photos-2019/PhotosExportDialog.png./Norway-Photos-2019/Minneapolis-Saint Paul International Airport - Minneapolis, MN, June 11, 2019/IMG_0352.pnghttps://images.summittdweller.com/Norway-Photos-2019/Minneapolis-Saint%20Paul%20International%20Airport%20-%20Minneapolis,%20MN,%20June%2011,%202019/IMG_0352.png./Norway-Photos-2019/TromsÃ¸ - Troms, June 15, 2019/IMG_0527.pnghttps://images.summittdweller.com/Norway-Photos-2019/Troms%C3%B8%20-%20Troms,%20June%2015,%202019/IMG_0527.png\n\n\nGenerating Markdown for Blog Photos\n\nSo the intent of all this is to populate the photo blogs that you see here. To that end Iâ€™ve created a simple API Python3 script based on guidance provided in this article.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:03.000Z",
            "updated_at": "2023-04-02T03:51:06.000Z",
            "published_at": "2019-07-04T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57884",
            "uuid": "31cffa92-4ee3-4413-af45-8061da24af23",
            "title": "Adding 'Remote Atom' to My DigitalOcean Server",
            "slug": "adding-remote-atom-to-my-digitalocean-server",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>Last evening and early this morning I completed the addition of a new (to me) package to <em>Atom</em> on my Mac Mini.  The package is <a href='https://atom.io/packages/remote-atom'>Remote Atom</a> and I found the configuration to be a little confusing, but in the end it was worth the work.</p><h2 id='use'>Use</h2><p>The addition and configuration of this package allows me to open an <em>SSH</em> terminal/session from my Mac Mini to my <em>summitt-dweller-DO-docker</em> droplet and, with <em>Atom</em> open locally on my Mac I can issue a command like</p><pre tabindex='0'><code>ratom /opt/README.md</code></pre><p>in the terminal connected to <em>summitt-dweller-DO-docker</em>, and the specified â€œremoteâ€ file will open in my local <em>Atom</em>.  Better still, if I make changes to the file and save them, the remote copy is automatically updated as saved.</p><h2 id='configuration'>Configuration</h2><p>As I said, configuration was a little dicey.  Mine followed exactly whatâ€™s documented in <a href='https://atom.io/packages/remote-atom'>the project site</a>, complete with renaming <code>rmate</code> to <code>ratom</code> as suggested.  The real key to configuration has two parts:</p><ul><li><p>First, <em>Atom</em> has to be open locally. This is necessary to get the package running so that it can accept connections from the remote, and that also requires that the package is auto-started along with <em>Atom</em>.</p></li><li><p>Next, I added the following specs to <code>~/.ssh/config</code> on my Mac Mini:</p><pre tabindex='0'><code>Host 104.248.237.235  RemoteForward 52698 localhost:52698</code></pre></li></ul><p>That addition to <code>~/.ssh/config</code> allows me to run my usual <em>ssh</em> connection commands without having to specify any remote/reverse tunnelingâ€¦the config does it for me automatically when the â€œHostâ€ or target is <em>summitt-dweller-DO-docker</em>.  Without that spec Iâ€™d have to configure each <em>ssh</em> connection I open, like so:</p><pre tabindex='0'><code>ssh -R 52698:localhost:52698 administrator@104.248.237.235</code></pre><p>Thatâ€™s a wrap. Until next timeâ€¦</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>Last evening and early this morning I completed the addition of a new (to me) package to <em>Atom</em> on my Mac Mini.  The package is <a href='https://atom.io/packages/remote-atom'>Remote Atom</a> and I found the configuration to be a little confusing, but in the end it was worth the work.</p><h2 id='use'>Use</h2><p>The addition and configuration of this package allows me to open an <em>SSH</em> terminal/session from my Mac Mini to my <em>summitt-dweller-DO-docker</em> droplet and, with <em>Atom</em> open locally on my Mac I can issue a command like</p><pre tabindex='0'><code>ratom /opt/README.md</code></pre><p>in the terminal connected to <em>summitt-dweller-DO-docker</em>, and the specified â€œremoteâ€ file will open in my local <em>Atom</em>.  Better still, if I make changes to the file and save them, the remote copy is automatically updated as saved.</p><h2 id='configuration'>Configuration</h2><p>As I said, configuration was a little dicey.  Mine followed exactly whatâ€™s documented in <a href='https://atom.io/packages/remote-atom'>the project site</a>, complete with renaming <code>rmate</code> to <code>ratom</code> as suggested.  The real key to configuration has two parts:</p><ul><li><p>First, <em>Atom</em> has to be open locally. This is necessary to get the package running so that it can accept connections from the remote, and that also requires that the package is auto-started along with <em>Atom</em>.</p></li><li><p>Next, I added the following specs to <code>~/.ssh/config</code> on my Mac Mini:</p><pre tabindex='0'><code>Host 104.248.237.235  RemoteForward 52698 localhost:52698</code></pre></li></ul><p>That addition to <code>~/.ssh/config</code> allows me to run my usual <em>ssh</em> connection commands without having to specify any remote/reverse tunnelingâ€¦the config does it for me automatically when the â€œHostâ€ or target is <em>summitt-dweller-DO-docker</em>.  Without that spec Iâ€™d have to configure each <em>ssh</em> connection I open, like so:</p><pre tabindex='0'><code>ssh -R 52698:localhost:52698 administrator@104.248.237.235</code></pre><p>Thatâ€™s a wrap. Until next timeâ€¦</p></p></article><!--kg-card-end: html-->",
            "comment_id": "22",
            "plaintext": "Last evening and early this morning I completed the addition of a new (to me) package to Atom on my Mac Mini. The package is Remote Atom and I found the configuration to be a little confusing, but in the end it was worth the work.\n\n\nUse\n\nThe addition and configuration of this package allows me to open an SSH terminal/session from my Mac Mini to my summitt-dweller-DO-docker droplet and, with Atom open locally on my Mac I can issue a command like\n\nratom /opt/README.md\n\nin the terminal connected to summitt-dweller-DO-docker, and the specified â€œremoteâ€ file will open in my local Atom. Better still, if I make changes to the file and save them, the remote copy is automatically updated as saved.\n\n\nConfiguration\n\nAs I said, configuration was a little dicey. Mine followed exactly whatâ€™s documented in the project site, complete with renaming rmate to ratom as suggested. The real key to configuration has two parts:\n\n * First, Atom has to be open locally. This is necessary to get the package running so that it can accept connections from the remote, and that also requires that the package is auto-started along with Atom.\n\n * Next, I added the following specs to ~/.ssh/config on my Mac Mini:\n   \n   Host 104.248.237.235  RemoteForward 52698 localhost:52698\n\nThat addition to ~/.ssh/config allows me to run my usual ssh connection commands without having to specify any remote/reverse tunnelingâ€¦the config does it for me automatically when the â€œHostâ€ or target is summitt-dweller-DO-docker. Without that spec Iâ€™d have to configure each ssh connection I open, like so:\n\nssh -R 52698:localhost:52698 administrator@104.248.237.235\n\nThatâ€™s a wrap. Until next timeâ€¦\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:03.000Z",
            "updated_at": "2023-04-02T03:50:50.000Z",
            "published_at": "2020-03-15T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57885",
            "uuid": "6353a4a6-b768-4dd1-8844-b4aaa130efae",
            "title": "Launching MacDown from a Terminal",
            "slug": "launching-macdown-from-a-terminal",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>Lately I find that I like to open <em>Markdown</em> documents in <em>MacDown</em> rather than <em>Atom</em>.  This is espeically true of things like â€œREADME.mdâ€ documents that I intend to read, but not edit. This can be done without any special configuration, assuming <em>MacDown</em> is installed and working.  To do that use a syntax like this:</p><pre tabindex='0'><code>open -b com.uranusjr.macdown path/to/document.md</code></pre><p>A command Iâ€™ve been using quite often today is: <code>open -b com.uranusjr.macdown ~/GitHub/dg-isle/docs/install/install-local-migrate.md</code>.</p><p>Thatâ€™s a wrap. Until next timeâ€¦</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>Lately I find that I like to open <em>Markdown</em> documents in <em>MacDown</em> rather than <em>Atom</em>.  This is espeically true of things like â€œREADME.mdâ€ documents that I intend to read, but not edit. This can be done without any special configuration, assuming <em>MacDown</em> is installed and working.  To do that use a syntax like this:</p><pre tabindex='0'><code>open -b com.uranusjr.macdown path/to/document.md</code></pre><p>A command Iâ€™ve been using quite often today is: <code>open -b com.uranusjr.macdown ~/GitHub/dg-isle/docs/install/install-local-migrate.md</code>.</p><p>Thatâ€™s a wrap. Until next timeâ€¦</p></p></article><!--kg-card-end: html-->",
            "comment_id": "23",
            "plaintext": "Lately I find that I like to open Markdown documents in MacDown rather than Atom. This is espeically true of things like â€œREADME.mdâ€ documents that I intend to read, but not edit. This can be done without any special configuration, assuming MacDown is installed and working. To do that use a syntax like this:\n\nopen -b com.uranusjr.macdown path/to/document.md\n\nA command Iâ€™ve been using quite often today is: open -b com.uranusjr.macdown ~/GitHub/dg-isle/docs/install/install-local-migrate.md.\n\nThatâ€™s a wrap. Until next timeâ€¦\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:03.000Z",
            "updated_at": "2023-04-02T03:50:44.000Z",
            "published_at": "2020-03-15T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428e16565e54c1436c57886",
            "uuid": "057cfef8-8400-4646-a92e-91caf29a93a9",
            "title": "â†’ Testing My ExternalURL Feature",
            "slug": "--testing-my-externalurl-feature",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"<article class='post'><p><p>Really just testing out this blogâ€™s <code>externalurl</code> feature here.  Click on the <a href='https://static.grinnell.edu/blogs/McFateM/posts/036-building-grocy-in-docksal/'><code>--&gt;</code></a> at the head of this post to see my â€œprofessionalâ€ post about building <a href='https://grocy.info/'>Grocy</a> in Docker and <a href='https://docksal.io'>Docksal</a>.</p></p></article>\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html--><article class='post'><p><p>Really just testing out this blogâ€™s <code>externalurl</code> feature here.  Click on the <a href='https://static.grinnell.edu/blogs/McFateM/posts/036-building-grocy-in-docksal/'><code>--&gt;</code></a> at the head of this post to see my â€œprofessionalâ€ post about building <a href='https://grocy.info/'>Grocy</a> in Docker and <a href='https://docksal.io'>Docksal</a>.</p></p></article><!--kg-card-end: html-->",
            "comment_id": "24",
            "plaintext": "Really just testing out this blogâ€™s externalurl feature here. Click on the --> at the head of this post to see my â€œprofessionalâ€ post about building Grocy in Docker and Docksal.\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T01:59:03.000Z",
            "updated_at": "2023-04-02T03:51:01.000Z",
            "published_at": "2019-08-11T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f2e965e54c1436c578c1",
            "uuid": "54beff53-947b-4b92-9009-aa577820a620",
            "title": "bbbike.html",
            "slug": "bbbike-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"Need to remember this address: https://garmin3.bbbike.org/\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html-->Need to remember this address: https://garmin3.bbbike.org/<!--kg-card-end: html-->",
            "comment_id": "0",
            "plaintext": "Need to remember this address: https://garmin3.bbbike.org/",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:13:45.000Z",
            "updated_at": "2023-04-05T01:33:56.000Z",
            "published_at": "2022-10-15T19:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f2e965e54c1436c578c2",
            "uuid": "042383ae-8539-4083-b5f1-5602897d794d",
            "title": "mcd.html",
            "slug": "mcd-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"Grabbing a quick lunch at McDonald's.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Madras, OR\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html-->Grabbing a quick lunch at McDonald's.<!--kg-card-end: html--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Madras, OR</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "1",
            "plaintext": "Grabbing a quick lunch at McDonald's.\n\n-/-/-/\n\nlocation: Madras, OR\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:13:45.000Z",
            "updated_at": "2023-04-05T01:26:23.000Z",
            "published_at": "2022-08-20T19:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f615bb6891164b1d4c59",
            "uuid": "d18c6744-683b-4eb7-9c5a-d786e1825ffb",
            "title": "nv.html",
            "slug": "nv-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"Winnemucca ETA is 11:35pm. Never have I seen so many stars.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Denico Junction, NV\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html-->Winnemucca ETA is 11:35pm. Never have I seen so many stars.<!--kg-card-end: html--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Denico Junction, NV</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "2",
            "plaintext": "Winnemucca ETA is 11:35pm. Never have I seen so many stars.\n\n-/-/-/\n\nlocation: Denico Junction, NV\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:27:17.000Z",
            "updated_at": "2023-04-05T01:40:02.000Z",
            "published_at": "2022-08-20T19:00:00.000Z",
            "custom_excerpt": "\n",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f615bb6891164b1d4c5a",
            "uuid": "eb296049-b97f-4e8d-a81e-8db02bad5982",
            "title": "tornado-warning-3-31.html",
            "slug": "tornado-warning-3-31-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Just came up from the basement after a Tama Co. tornado warning, and the wind is picking up again. ðŸŒª Â No visible damage outside, but I did find a puddle of pea size hail about 10 minutes after the storm.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Just came up from the basement after a Tama Co. tornado warning, and the wind is picking up again. ðŸŒª Â No visible damage outside, but I did find a puddle of pea size hail about 10 minutes after the storm.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "3",
            "plaintext": "Just came up from the basement after a Tama Co. tornado warning, and the wind is picking up again. ðŸŒª Â No visible damage outside, but I did find a puddle of pea size hail about 10 minutes after the storm.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:27:17.000Z",
            "updated_at": "2023-04-05T02:55:05.000Z",
            "published_at": "2023-03-31T16:56:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c6a",
            "uuid": "065975c0-f036-403d-8b3f-78d6c27a94c3",
            "title": "salt.html",
            "slug": "salt-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"Tom's reaction when we popped over the hill to see the Bonneville salt flats was holy shit.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: West Wendover, NV\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html-->Tom's reaction when we popped over the hill to see the Bonneville salt flats was holy shit.<!--kg-card-end: html--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: West Wendover, NV</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "4",
            "plaintext": "Tom's reaction when we popped over the hill to see the Bonneville salt flats was holy shit.\n\n-/-/-/\n\nlocation: West Wendover, NV\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:41.000Z",
            "updated_at": "2023-04-05T01:38:04.000Z",
            "published_at": "2022-08-21T19:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c6c",
            "uuid": "9896d76c-fc38-470a-976d-54031b6f167b",
            "title": "hugo-mod-local.html",
            "slug": "hugo-mod-local-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"Today I discovered a slick trick for local development of my first Hugo Module. The guidance I used was found in Working with Hugo Module Locally and it was spot-on! In my case the key was the additon of one line, two if you include the comment, to my project's config.yml file:<br/>// Innocent line below!<br/>replace github.com/SummittDweller/hugo-timeline => /Users/mark/GitHub/hugo-timeline<br/>\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html-->Today I discovered a slick trick for local development of my first Hugo Module. The guidance I used was found in Working with Hugo Module Locally and it was spot-on! In my case the key was the additon of one line, two if you include the comment, to my project's config.yml file:<br/>// Innocent line below!<br/>replace github.com/SummittDweller/hugo-timeline => /Users/mark/GitHub/hugo-timeline<br/><!--kg-card-end: html--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "6",
            "plaintext": "Today I discovered a slick trick for local development of my first Hugo Module. The guidance I used was found in Working with Hugo Module Locally and it was spot-on! In my case the key was the additon of one line, two if you include the comment, to my project's config.yml file:\n// Innocent line below!\nreplace github.com/SummittDweller/hugo-timeline => /Users/mark/GitHub/hugo-timeline\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:41.000Z",
            "updated_at": "2023-04-05T01:29:15.000Z",
            "published_at": "2022-12-18T18:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c6d",
            "uuid": "65639584-e8cb-4bf7-95c3-7d4d0b07e79a",
            "title": "relearning-11ty.html",
            "slug": "relearning-11ty-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"As I started to follow-up on Gating My Content & More - Parts 1 and 2 I quickly realized that I've already forgotten most of what I learned about eleventy back in December. So, since I already have years of Hugo experience, I elected to begin again with Migrating from Hugo to Eleventy and that article makes an early reference to A Deep Dive Into Eleventy Static Site Generator. If those fail there's Let's Learn Eleventy. In case it's needed later, I captured all of the sites listed above in a OneTab page.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>As I started to follow-up on Gating My Content &amp; More - Parts 1 and 2 I quickly realized that I've already forgotten most of what I learned about eleventy back in December. So, since I already have years of Hugo experience, I elected to begin again with Migrating from Hugo to Eleventy and that article makes an early reference to A Deep Dive Into Eleventy Static Site Generator. If those fail there's Let's Learn Eleventy. In case it's needed later, I captured all of the sites listed above in a OneTab page.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "7",
            "plaintext": "As I started to follow-up on Gating My Content & More - Parts 1 and 2 I quickly realized that I've already forgotten most of what I learned about eleventy back in December. So, since I already have years of Hugo experience, I elected to begin again with Migrating from Hugo to Eleventy and that article makes an early reference to A Deep Dive Into Eleventy Static Site Generator. If those fail there's Let's Learn Eleventy. In case it's needed later, I captured all of the sites listed above in a OneTab page.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:41.000Z",
            "updated_at": "2023-04-05T03:28:28.000Z",
            "published_at": "2023-02-06T18:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c6e",
            "uuid": "8937986a-5fe8-407b-a8f6-b539bdbb524a",
            "title": "how-to-adjust-a-bike-helmet.html",
            "slug": "how-to-adjust-a-bike-helmet-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Found Video - How to Adjust a Bicycle ðŸš´ðŸ½ Helmet a short time ago. ðŸ™‚\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Toledo, IA\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Found Video - How to Adjust a Bicycle ðŸš´ðŸ½ Helmet a short time ago. ðŸ™‚</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "8",
            "plaintext": "Found Video - How to Adjust a Bicycle ðŸš´ðŸ½ Helmet a short time ago. ðŸ™‚\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:41.000Z",
            "updated_at": "2023-04-05T03:26:02.000Z",
            "published_at": "2023-03-06T18:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c6f",
            "uuid": "ea984416-01bb-4514-ae94-229d779817d0",
            "title": "removed-title-display-from-microposts-like-this-one.html",
            "slug": "removed-title-display-from-microposts-like-this-one-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"This morning I modified .eleventy.js to remove post.title display from all micropost ðŸ”¬ type posts, like this one. ðŸ™‚ Now, maybe I'll also add the little microscope icon automatically?\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>This morning I modified .eleventy.js to remove post.title display from all micropost ðŸ”¬ type posts, like this one. ðŸ™‚ Now, maybe I'll also add the little microscope icon automatically?</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "9",
            "plaintext": "This morning I modified .eleventy.js to remove post.title display from all micropost ðŸ”¬ type posts, like this one. ðŸ™‚ Now, maybe I'll also add the little microscope icon automatically?\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:41.000Z",
            "updated_at": "2023-04-05T02:56:28.000Z",
            "published_at": "2023-03-31T07:55:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c70",
            "uuid": "2a054d5b-e305-47d7-8bc7-3440e40560f8",
            "title": "21pilots.html",
            "slug": "21pilots-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"T-Mobile Arena downtown Kansas City for Twenty-one Pilots. And I am probably not the oldest person here after all.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Kansas City, MO\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html-->T-Mobile Arena downtown Kansas City for Twenty-one Pilots. And I am probably not the oldest person here after all.<!--kg-card-end: html--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Kansas City, MO</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "10",
            "plaintext": "T-Mobile Arena downtown Kansas City for Twenty-one Pilots. And I am probably not the oldest person here after all.\n\n-/-/-/\n\nlocation: Kansas City, MO\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:41.000Z",
            "updated_at": "2023-04-05T01:36:19.000Z",
            "published_at": "2022-09-08T19:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c71",
            "uuid": "a9884614-21fc-4719-a850-d3819fdb585d",
            "title": "testing-my-new-publisher-for-ghost-app-on-iphone.html",
            "slug": "testing-my-new-publisher-for-ghost-app-on-iphone-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Testing my new 'Publisher for Ghost' app on iPhone... yup, it worked!\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Toledo, IA\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Testing my new 'Publisher for Ghost' app on iPhone... yup, it worked!</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "12",
            "plaintext": "Testing my new 'Publisher for Ghost' app on iPhone... yup, it worked!\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:41.000Z",
            "updated_at": "2023-04-05T02:57:02.000Z",
            "published_at": "2023-03-22T14:42:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c72",
            "uuid": "9f5fe593-22c9-4378-924f-37d8ef694d56",
            "title": "azure-extensions-for-vscode.html",
            "slug": "azure-extensions-for-vscode-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"Web Nirvana? It dawned on me this morning that both VSCode and Azure are Microsoft things. So, there should be some handy Azure extensions for VSCode, right? Yes, yes indeed there are! I'm installing them now!\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html-->Web Nirvana? It dawned on me this morning that both VSCode and Azure are Microsoft things. So, there should be some handy Azure extensions for VSCode, right? Yes, yes indeed there are! I'm installing them now!<!--kg-card-end: html-->",
            "comment_id": "13",
            "plaintext": "Web Nirvana? It dawned on me this morning that both VSCode and Azure are Microsoft things. So, there should be some handy Azure extensions for VSCode, right? Yes, yes indeed there are! I'm installing them now!",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:41.000Z",
            "updated_at": "2023-04-05T01:30:03.000Z",
            "published_at": "2022-11-19T18:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c73",
            "uuid": "eed494bc-20c1-48c5-8c94-44bccad6ff3e",
            "title": "gotta-love-hugo.html",
            "slug": "gotta-love-hugo-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"Ya' gotta love Hugo! I just completed my first Jekyll-to-Hugo conversion, and made it a Hugo module. It's taken me a couple of years to realize the power of Hugo modules, and I have to say it's AWESOME, and perfectly implemented.The process of conversion briefly is documented in the README.md file at SummittDweller/hugo-timeline, and the first use of it as a module appears elsewhere in this blog at My Hugo Timeline, A New Hugo Module. The timeline itself can be seen at https://blog.SummittDweller.com/timeline. Check it out!\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html-->Ya' gotta love Hugo! I just completed my first Jekyll-to-Hugo conversion, and made it a Hugo module. It's taken me a couple of years to realize the power of Hugo modules, and I have to say it's AWESOME, and perfectly implemented.The process of conversion briefly is documented in the README.md file at SummittDweller/hugo-timeline, and the first use of it as a module appears elsewhere in this blog at My Hugo Timeline, A New Hugo Module. The timeline itself can be seen at https://blog.SummittDweller.com/timeline. Check it out!<!--kg-card-end: html-->",
            "comment_id": "14",
            "plaintext": "Ya' gotta love Hugo! I just completed my first Jekyll-to-Hugo conversion, and made it a Hugo module. It's taken me a couple of years to realize the power of Hugo modules, and I have to say it's AWESOME, and perfectly implemented.The process of conversion briefly is documented in the README.md file at SummittDweller/hugo-timeline, and the first use of it as a module appears elsewhere in this blog at My Hugo Timeline, A New Hugo Module. The timeline itself can be seen at https://blog.SummittDweller.com/timeline. Check it out!",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:41.000Z",
            "updated_at": "2023-04-05T01:29:44.000Z",
            "published_at": "2022-12-05T18:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c74",
            "uuid": "be3b4b96-404a-4a62-b337-d6c955370b4a",
            "title": "tama-walkingaudit.html",
            "slug": "tama-walkingaudit-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"Tama walking audit...downtown and to Cherry Lake.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Tama, IA\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html-->Tama walking audit...downtown and to Cherry Lake.<!--kg-card-end: html--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Tama, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "15",
            "plaintext": "Tama walking audit...downtown and to Cherry Lake.\n\n-/-/-/\n\nlocation: Tama, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:41.000Z",
            "updated_at": "2023-04-05T01:34:58.000Z",
            "published_at": "2022-09-14T19:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c75",
            "uuid": "505d349b-0157-47ce-ba5f-8bac30dff4c2",
            "title": "dns-and-azure-email-changes.html",
            "slug": "dns-and-azure-email-changes-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Last evening I successfully completed a move of ItalianoWoods.com from a defunct presence on DigitalOcean to a landing site and working email via Azure and Azure DNS. Details can be found in a few places, including:\\n  - https://github.com/SummittDweller/how-MY-web-works/blob/main/docs/05-italianowoods.com.md- https://github.com/SummittDweller/how-MY-web-works/blob/main/docs/101-DigitalOcean.md\\n  - https://github.com/SummittDweller/italiano-woods-11ty-landing-page\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Toledo, IA\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Last evening I successfully completed a move of ItalianoWoods.com from a defunct presence on DigitalOcean to a landing site and working email via Azure and Azure DNS. Details can be found in a few places, including:</p>\n<ul>\n<li><a href=\"https://github.com/SummittDweller/how-MY-web-works/blob/main/docs/05-italianowoods.com.md-\">https://github.com/SummittDweller/how-MY-web-works/blob/main/docs/05-italianowoods.com.md-</a> <a href=\"https://github.com/SummittDweller/how-MY-web-works/blob/main/docs/101-DigitalOcean.md\">https://github.com/SummittDweller/how-MY-web-works/blob/main/docs/101-DigitalOcean.md</a></li>\n<li><a href=\"https://github.com/SummittDweller/italiano-woods-11ty-landing-page\">https://github.com/SummittDweller/italiano-woods-11ty-landing-page</a></li>\n</ul>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "16",
            "plaintext": "Last evening I successfully completed a move of ItalianoWoods.com from a defunct presence on DigitalOcean to a landing site and working email via Azure and Azure DNS. Details can be found in a few places, including:\n\n\n * https://github.com/SummittDweller/how-MY-web-works/blob/main/docs/05-italianowoods.com.md- https://github.com/SummittDweller/how-MY-web-works/blob/main/docs/101-DigitalOcean.md\n * https://github.com/SummittDweller/italiano-woods-11ty-landing-page\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:41.000Z",
            "updated_at": "2023-04-05T03:27:14.000Z",
            "published_at": "2023-03-01T18:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c76",
            "uuid": "cbeec327-f3e3-49f1-ac6a-69898daa5e51",
            "title": "adding-fontawesome-to-wieting-site.html",
            "slug": "adding-fontawesome-to-wieting-site-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Applied Inline FontAwesome SVGs in Hugo to the Hugo theme for the Wieting web site.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Toledo, IA\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Applied Inline FontAwesome SVGs in Hugo to the Hugo theme for the Wieting web site.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "17",
            "plaintext": "Applied Inline FontAwesome SVGs in Hugo to the Hugo theme for the Wieting web site.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:42.000Z",
            "updated_at": "2023-04-05T03:25:29.000Z",
            "published_at": "2023-03-07T18:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c77",
            "uuid": "9d20cb9f-ed48-40d8-a029-1f4e49192f04",
            "title": "rawlins.html",
            "slug": "rawlins-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"Posting an updated itinerary for eastbound day 3.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Rawlins, WY\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html-->Posting an updated itinerary for eastbound day 3.<!--kg-card-end: html--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Rawlins, WY</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "18",
            "plaintext": "Posting an updated itinerary for eastbound day 3.\n\n-/-/-/\n\nlocation: Rawlins, WY\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:42.000Z",
            "updated_at": "2023-04-05T01:39:02.000Z",
            "published_at": "2022-08-21T19:00:00.000Z",
            "custom_excerpt": "\n",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c78",
            "uuid": "d2ebc627-d942-4d3b-845f-bf03dad1c425",
            "title": "dick.html",
            "slug": "dick-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"Planning a lunch stop in Grand Island with Heartland Cacher and then on home to Iowa so Reviewer Smith can get back to Illinois this evening.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: North Platte, NE\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html-->Planning a lunch stop in Grand Island with Heartland Cacher and then on home to Iowa so Reviewer Smith can get back to Illinois this evening.<!--kg-card-end: html--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: North Platte, NE</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "20",
            "plaintext": "Planning a lunch stop in Grand Island with Heartland Cacher and then on home to Iowa so Reviewer Smith can get back to Illinois this evening.\n\n-/-/-/\n\nlocation: North Platte, NE\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:42.000Z",
            "updated_at": "2023-04-05T01:37:11.000Z",
            "published_at": "2022-08-22T19:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c79",
            "uuid": "4b7a8f96-96bf-4e3f-a873-0f52e1dad57e",
            "title": "turned-hot-water-recirc-off.html",
            "slug": "turned-hot-water-recirc-off-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Turned off the hot water recirc at home, and treated one plant for mites.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Toledo, IA\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Turned off the hot water recirc at home, and treated one plant for mites.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "21",
            "plaintext": "Turned off the hot water recirc at home, and treated one plant for mites.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:42.000Z",
            "updated_at": "2023-04-05T03:24:42.000Z",
            "published_at": "2023-03-11T18:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c7a",
            "uuid": "b7f97ffc-024f-4ffa-83b7-9989438a3469",
            "title": "rename-azure-subscription.html",
            "slug": "rename-azure-subscription-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Today I plan to follow the guidance found in Rename Azure Subscriptions and Find Your Environments Faster to fix the name of my personal Azure subscription 1, and maybe more. That's a horrible name, I know! Done! The new subscription name is SummittDweller Pay-As-You-Go. Much better!\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Toledo, IA\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Today I plan to follow the guidance found in Rename Azure Subscriptions and Find Your Environments Faster to fix the name of my personal Azure subscription 1, and maybe more. That's a horrible name, I know! Done! The new subscription name is SummittDweller Pay-As-You-Go. Much better!</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "22",
            "plaintext": "Today I plan to follow the guidance found in Rename Azure Subscriptions and Find Your Environments Faster to fix the name of my personal Azure subscription 1, and maybe more. That's a horrible name, I know! Done! The new subscription name is SummittDweller Pay-As-You-Go. Much better!\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:42.000Z",
            "updated_at": "2023-04-05T03:29:22.000Z",
            "published_at": "2023-02-03T18:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c7b",
            "uuid": "d0e9d090-dfd1-4e36-9145-18450981effe",
            "title": "ghost-this-weekend.html",
            "slug": "ghost-this-weekend-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Last weekend Mackenzie and I created a new Matomo analytics server on a DigitalOcean droplet w/ 2G of RAM. This weekend we created a new headless Ghost CMS droplet to support her portfolio site, and more.This evening I'm taking steps to begin rewriting this blog as a Ghost + 11ty reincarnation of what you see here now. The story of the underlying Ghost development and maintenance is told in Ghost Notes and its admin dashboard is available at https://ghost.summittservices.com/ghost.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Last weekend Mackenzie and I created a new Matomo analytics server on a DigitalOcean droplet w/ 2G of RAM. This weekend we created a new headless Ghost CMS droplet to support her portfolio site, and more.This evening I'm taking steps to begin rewriting this blog as a Ghost + 11ty reincarnation of what you see here now. The story of the underlying Ghost development and maintenance is told in Ghost Notes and its admin dashboard is available at <a href=\"https://ghost.summittservices.com/ghost\">https://ghost.summittservices.com/ghost</a>.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "23",
            "plaintext": "Last weekend Mackenzie and I created a new Matomo analytics server on a DigitalOcean droplet w/ 2G of RAM. This weekend we created a new headless Ghost CMS droplet to support her portfolio site, and more.This evening I'm taking steps to begin rewriting this blog as a Ghost + 11ty reincarnation of what you see here now. The story of the underlying Ghost development and maintenance is told in Ghost Notes and its admin dashboard is available at https://ghost.summittservices.com/ghost.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:42.000Z",
            "updated_at": "2023-04-05T03:23:25.000Z",
            "published_at": "2023-03-17T19:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6428f795bb6891164b1d4c7c",
            "uuid": "40dc758a-9697-450c-92b9-d195e7922605",
            "title": "reset-python.html",
            "slug": "reset-python-html",
            "mobiledoc": "{\"version\":\"0.3.1\",\"markups\":[],\"atoms\":[],\"cards\":[[\"html\",{\"cardName\":\"html\",\"html\":\"Reset Python environment on my Mac Mini using: https://dev.to/aditya005/right-way-to-uninstall-clean-python-on-a-mac-4jfo\"}]],\"sections\":[[10,0]],\"ghostVersion\":\"3.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: html-->Reset Python environment on my Mac Mini using: https://dev.to/aditya005/right-way-to-uninstall-clean-python-on-a-mac-4jfo<!--kg-card-end: html-->",
            "comment_id": "24",
            "plaintext": "Reset Python environment on my Mac Mini using: https://dev.to/aditya005/right-way-to-uninstall-clean-python-on-a-mac-4jfo",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T03:33:42.000Z",
            "updated_at": "2023-04-05T01:33:32.000Z",
            "published_at": "2022-10-19T19:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "642991a1bb6891164b1d4d8c",
            "uuid": "f28aabb5-65ce-4078-a161-2b55d18e9c96",
            "title": "adding-a-ghost-micropost-collection",
            "slug": "adding-a-ghost-micropost-collection",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"This morning's Ghost/11ty adventure will hopefully find me adding a new collection to both ends of this blog.  See [Building content collections](https://ghost.org/tutorials/content-collections/). \"}],[\"markdown\",{\"markdown\":\"Note: Using an internal tag, `#micropost`, for this did NOT work, at least it did not change the slug as expected.  Using `micropost` does work! \"}],[\"markdown\",{\"markdown\":\"-/-/-/\\ntype: micropost\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>This morning's Ghost/11ty adventure will hopefully find me adding a new collection to both ends of this blog.  See <a href=\"https://ghost.org/tutorials/content-collections/\">Building content collections</a>.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Note: Using an internal tag, <code>#micropost</code>, for this did NOT work, at least it did not change the slug as expected.  Using <code>micropost</code> does work!</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\ntype: micropost<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "642991a1bb6891164b1d4d8c",
            "plaintext": "This morning's Ghost/11ty adventure will hopefully find me adding a new collection to both ends of this blog. See Building content collections.\n\n\nNote: Using an internal tag, #micropost, for this did NOT work, at least it did not change the slug as expected. Using micropost does work!\n\n\n-/-/-/\n\ntype: micropost\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-02T14:30:57.000Z",
            "updated_at": "2023-04-05T00:29:46.000Z",
            "published_at": "2023-04-02T14:33:58.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "642a2915ddadd63e1863b36b",
            "uuid": "d6b0ea16-f096-453b-b6b1-0b6ae4186fd7",
            "title": "show-last-two-microposts-at-top-of-front-page",
            "slug": "show-last-two-microposts-at-top-of-front-page",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Now that microposts are off the front page, and have a page of their own as a new collection, let's see if we can modify the home page, that's `index.njk` by the way, to show the last micropost across the full-width at the top of the content.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\ntype: micropost\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Now that microposts are off the front page, and have a page of their own as a new collection, let's see if we can modify the home page, that's <code>index.njk</code> by the way, to show the last micropost across the full-width at the top of the content.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\ntype: micropost<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "642a2915ddadd63e1863b36b",
            "plaintext": "Now that microposts are off the front page, and have a page of their own as a new collection, let's see if we can modify the home page, that's index.njk by the way, to show the last micropost across the full-width at the top of the content.\n\n\n-/-/-/\n\ntype: micropost\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-03T01:17:09.000Z",
            "updated_at": "2023-04-05T00:29:25.000Z",
            "published_at": "2023-04-03T01:18:50.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "642af68bddadd63e1863b37d",
            "uuid": "5278910c-2502-479b-8e17-f3859fe29260",
            "title": "moved-gc-azure-billing",
            "slug": "moved-gc-azure-billing",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Took steps this morning to move billing for my GC/library Azure services to the library's credit card.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Grinnell, IA\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Took steps this morning to move billing for my GC/library Azure services to the library's credit card.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Grinnell, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "642af68bddadd63e1863b37d",
            "plaintext": "Took steps this morning to move billing for my GC/library Azure services to the library's credit card.\n\n\n-/-/-/\n\nlocation: Grinnell, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-03T15:53:47.000Z",
            "updated_at": "2023-04-05T03:22:18.000Z",
            "published_at": "2023-04-03T15:53:47.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "642c492bddadd63e1863b389",
            "uuid": "4622dbe0-29d5-4653-a7eb-099c1a583490",
            "title": "Moving Front Matter to the Rear",
            "slug": "moving-front-matter-to-the-rear",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"I've been using an iOS app called _Publisher for Ghost_ to craft and post new microposts from my iPhone.  Just one problem so far... I can't seem to successfully edit and save `excerpt` content so my current scheme of populating the `excerpt` with \\\"front matter\\\" isn't working well.  So, it's time to move that front matter out of the `excerpt` and to the end of the content body.  \\n\\nUpdate: _Publisher for Ghost_ just isn't cutting it so I did a little research and am on the cusp of making a switch... to [Ulysses](https://ulysses.app/), because it has a great little piece of _Ghost_ integration built-in.\"}],[\"markdown\",{\"markdown\":\"Note that in the remainder of this article there are references to the delimiter I use to set my \\\"rear matter\\\" apart from other content.  That delimiter is a series of three consecutive `-/` pairs, for a total of 6 characters.  These 6 characters actually form two 3-character delimiters, the first `dash-slash-dash` marks the end of the \\\"content\\\" while the second `slash-dash-slash` marks the beginning of the \\\"rear matter\\\" data.  \\n\\nSo, my example format (from this very post) for \\\"rear matter\\\" data looks a little like this, but with NO spaces:\\n\\n```\\n-/ -/ -/\\nlocation: Toledo, IA\\nexplanation: There's a reason why I choose an odd delimiter.  Read on.\\n```\"}],[\"markdown\",{\"markdown\":\"## Code\\n\\nThe code responsible for parsing this \\\"rear matter\\\" is from my `custom.js` and it reads like this:  \\n\\n```js\\n     // Set post.data defaults\\n    post.data = '';\\n    post.data.type = 'post'\\n    post.data.location = 'Toledo, IA';\\n\\n    // Looking for -/ -/ -/ to define end of content and start of our front matter\\n    // Replace post.html with everything above the last -/ -/ -/ delimiter\\n    let parts = post.html.replace(/<!--.*-->/gi, '').split('-/ -');\\n    let len = parts.length;\\n    if (len > 1) {\\n      let frontmatter = parts[len-1].replace(/<.*>/gi, '\\\\n');\\n      let parsed = matter(frontmatter, {delims: '/- /'});\\n      post.data = parsed.data;\\n      post.html = parts.slice(0, -1).join('')\\n      post.excerpt = post.html.replace(/(<([^>]+)>)/gi, \\\"\\\")\\n    } \\n\\n```\"}],[\"markdown\",{\"markdown\":\"## Why the Odd Delimiter?\\nWell, because I said so.  Since my code pulls from `post.html` I found it necessary to first `split` the post, then remove any/all HTML tags from the \\\"rear matter\\\" portion before passing that into the _gray-matter_ package and the `matter` function for parsing.\\n\\nSo, the `dash-slash-dash` is used to split the `post.html` and the `slash-dash-slash` after it becomes the opening delimiter for the `matter` function.  Using `------` or anything beginning with `---` wasn't ideal because the Markdown editors I use frequently convert those into `<hr>` tags.\\n\\nAnother factor, I find the `-/` combination is easy to type on my iPhone because both characters appear on the same \\\"special characters\\\" keyboard, so I don't have to switch keyboard in between, and they are positioned side-by-side.  \"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Toledo, IA\\nexplanation: There's a reason why I choose an odd looking delimiter.  Read on.\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[10,3],[10,4],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>I've been using an iOS app called <em>Publisher for Ghost</em> to craft and post new microposts from my iPhone.  Just one problem so far... I can't seem to successfully edit and save <code>excerpt</code> content so my current scheme of populating the <code>excerpt</code> with &quot;front matter&quot; isn't working well.  So, it's time to move that front matter out of the <code>excerpt</code> and to the end of the content body.</p>\n<p>Update: <em>Publisher for Ghost</em> just isn't cutting it so I did a little research and am on the cusp of making a switch... to <a href=\"https://ulysses.app/\">Ulysses</a>, because it has a great little piece of <em>Ghost</em> integration built-in.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Note that in the remainder of this article there are references to the delimiter I use to set my &quot;rear matter&quot; apart from other content.  That delimiter is a series of three consecutive <code>-/</code> pairs, for a total of 6 characters.  These 6 characters actually form two 3-character delimiters, the first <code>dash-slash-dash</code> marks the end of the &quot;content&quot; while the second <code>slash-dash-slash</code> marks the beginning of the &quot;rear matter&quot; data.</p>\n<p>So, my example format (from this very post) for &quot;rear matter&quot; data looks a little like this, but with NO spaces:</p>\n<pre><code>-/ -/ -/\nlocation: Toledo, IA\nexplanation: There's a reason why I choose an odd delimiter.  Read on.\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"code\">Code</h2>\n<p>The code responsible for parsing this &quot;rear matter&quot; is from my <code>custom.js</code> and it reads like this:</p>\n<pre><code class=\"language-js\">     // Set post.data defaults\n    post.data = '';\n    post.data.type = 'post'\n    post.data.location = 'Toledo, IA';\n\n    // Looking for -/ -/ -/ to define end of content and start of our front matter\n    // Replace post.html with everything above the last -/ -/ -/ delimiter\n    let parts = post.html.replace(/&lt;!--.*--&gt;/gi, '').split('-/ -');\n    let len = parts.length;\n    if (len &gt; 1) {\n      let frontmatter = parts[len-1].replace(/&lt;.*&gt;/gi, '\\n');\n      let parsed = matter(frontmatter, {delims: '/- /'});\n      post.data = parsed.data;\n      post.html = parts.slice(0, -1).join('')\n      post.excerpt = post.html.replace(/(&lt;([^&gt;]+)&gt;)/gi, &quot;&quot;)\n    } \n\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"why-the-odd-delimiter\">Why the Odd Delimiter?</h2>\n<p>Well, because I said so.  Since my code pulls from <code>post.html</code> I found it necessary to first <code>split</code> the post, then remove any/all HTML tags from the &quot;rear matter&quot; portion before passing that into the <em>gray-matter</em> package and the <code>matter</code> function for parsing.</p>\n<p>So, the <code>dash-slash-dash</code> is used to split the <code>post.html</code> and the <code>slash-dash-slash</code> after it becomes the opening delimiter for the <code>matter</code> function.  Using <code>------</code> or anything beginning with <code>---</code> wasn't ideal because the Markdown editors I use frequently convert those into <code>&lt;hr&gt;</code> tags.</p>\n<p>Another factor, I find the <code>-/</code> combination is easy to type on my iPhone because both characters appear on the same &quot;special characters&quot; keyboard, so I don't have to switch keyboard in between, and they are positioned side-by-side.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Toledo, IA<br>\nexplanation: There's a reason why I choose an odd looking delimiter.  Read on.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "642c492bddadd63e1863b389",
            "plaintext": "I've been using an iOS app called Publisher for Ghost to craft and post new microposts from my iPhone. Just one problem so far... I can't seem to successfully edit and save excerpt content so my current scheme of populating the excerpt with \"front matter\" isn't working well. So, it's time to move that front matter out of the excerpt and to the end of the content body.\n\n\nUpdate: Publisher for Ghost just isn't cutting it so I did a little research and am on the cusp of making a switch... to Ulysses, because it has a great little piece of Ghost integration built-in.\n\n\nNote that in the remainder of this article there are references to the delimiter I use to set my \"rear matter\" apart from other content. That delimiter is a series of three consecutive -/ pairs, for a total of 6 characters. These 6 characters actually form two 3-character delimiters, the first dash-slash-dash marks the end of the \"content\" while the second slash-dash-slash marks the beginning of the \"rear matter\" data.\n\n\nSo, my example format (from this very post) for \"rear matter\" data looks a little like this, but with NO spaces:\n\n\n-/ -/ -/\nlocation: Toledo, IA\nexplanation: There's a reason why I choose an odd delimiter.  Read on.\n\n\n\n\nCode\n\n\nThe code responsible for parsing this \"rear matter\" is from my custom.js and it reads like this:\n\n\n     // Set post.data defaults\n    post.data = '';\n    post.data.type = 'post'\n    post.data.location = 'Toledo, IA';\n\n    // Looking for -/ -/ -/ to define end of content and start of our front matter\n    // Replace post.html with everything above the last -/ -/ -/ delimiter\n    let parts = post.html.replace(/<!--.*-->/gi, '').split('-/ -');\n    let len = parts.length;\n    if (len > 1) {\n      let frontmatter = parts[len-1].replace(/<.*>/gi, '\\n');\n      let parsed = matter(frontmatter, {delims: '/- /'});\n      post.data = parsed.data;\n      post.html = parts.slice(0, -1).join('')\n      post.excerpt = post.html.replace(/(<([^>]+)>)/gi, \"\")\n    } \n\n\n\n\n\nWhy the Odd Delimiter?\n\n\nWell, because I said so. Since my code pulls from post.html I found it necessary to first split the post, then remove any/all HTML tags from the \"rear matter\" portion before passing that into the gray-matter package and the matter function for parsing.\n\n\nSo, the dash-slash-dash is used to split the post.html and the slash-dash-slash after it becomes the opening delimiter for the matter function. Using ------ or anything beginning with --- wasn't ideal because the Markdown editors I use frequently convert those into <hr> tags.\n\n\nAnother factor, I find the -/ combination is easy to type on my iPhone because both characters appear on the same \"special characters\" keyboard, so I don't have to switch keyboard in between, and they are positioned side-by-side.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n\nexplanation: There's a reason why I choose an odd looking delimiter. Read on.\n",
            "feature_image": "https://images.unsplash.com/photo-1567972787460-5b9f5f23f514?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDd8fHJlYXJ8ZW58MHx8fHwxNjgwNjMyMjMx&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-04T15:58:35.000Z",
            "updated_at": "2023-04-05T13:35:45.000Z",
            "published_at": "2023-04-04T18:17:54.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "642c4b82ddadd63e1863b39f",
            "uuid": "03c0a15e-a93c-4ca8-93d0-cb10963aafba",
            "title": "Debugging This Blog with VSCode",
            "slug": "debugging-this-blog-with-_vscode_",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"I'm making some significant changes to the code behind this blog today.  Specifically, I'm going to move my micropost \\\"front matter\\\" from the `post.excerpt` or `post.custom_excerpt` field to the \\\"body\\\" of the post where it might look like this example (taken from this very post):  \\n\\n```\\n-+-+-+\\nlocation: Toledo, IA\\nprice: $50.00\\nnote: This is just some sample \\\"front matter\\\". My parser removed the \\\"split\\\" characters from the delimiter you see here.\\n```\"}],[\"markdown\",{\"markdown\":\"# I Need VSCode Debugging!\\nTo do this effectively I really need live dev debugging in _VSCode_, but how can I do that?  \\n\\nWell, I turned first to [Tips for debugging in 11ty](https://griffadev.medium.com/tips-for-debugging-in-11ty-aca887d2c66e) by [George Griffiths](https://griffadev.medium.com) because it looked very promising.  In the second half of that post under the heading of **Debugging with VS Code** there are instructions for creating a `.vscode/lanuch.json` to do this, and I did.  But how does one \\\"attach\\\" their debugger to the script I use to launch/test this blog locally?  That command by the way is `yarn start`.  \\n\\n\"}],[\"markdown\",{\"markdown\":\"## My Debugger Configuration\\nSo, I found that the stock `launch.json` prescribed by George didn't quite work in my situation, I had to add a configuration AND with a small change, and turn off `Auto Attach` debugging. \\n\\nI clicked on the debugger icon in the left-hand pane of my _VSCode_ window and there I had the option to add a configuration.  I clicked that and was presented with several choices.  After incorrectly trying a few options I settled on one labeled `Run Script&colon; start` and it almost worked.  \\n\\nThe configuration added to my `launch.json` file included `\\\"command\\\"&colon; \\\"yarn run start\\\"`, but that's not quite right for me.  I simply use `yarn start` to launch my local dev instance of this blog, so I made that change to `lanuch.json` so that file now reads:  \\n\\n```json\\n{\\n  \\\"name\\\": \\\"11ty\\\",\\n  \\\"type\\\": \\\"node\\\",\\n  \\\"request\\\": \\\"launch\\\",\\n  \\\"program\\\": \\\"${workspaceRoot}/node_modules/.bin/eleventy\\\",\\n  \\\"stopOnEntry\\\": false,\\n  \\\"args\\\": [],\\n  \\\"cwd\\\": \\\"${workspaceRoot}\\\",\\n  \\\"console\\\": \\\"internalConsole\\\",\\n  \\\"configurations\\\": [\\n    {\\n      \\\"type\\\": \\\"node-terminal\\\",\\n      \\\"name\\\": \\\"Run Script: start\\\",\\n      \\\"request\\\": \\\"launch\\\",\\n      \\\"command\\\": \\\"yarn start\\\",\\n      \\\"cwd\\\": \\\"${workspaceFolder}\\\"\\n    }\\n  ]\\n}\\n```\"}],[\"markdown\",{\"markdown\":\"# It Works!\\nNow when I open the debugger and click the green start arrow beside `Run Script: start` I can see `.eleventy.js` begin running and it stops at any breakpoints I have set.  It even works when stepping into my `custom.js` script, all the while showing me the call stack and variables that are in-scope at the time.  Yay! \"}],[\"markdown\",{\"markdown\":\"Thank You [George](https://griffadev.medium.com)!\"}],[\"markdown\",{\"markdown\":\"## Wait, There's More\\nEven better news is that I can still run `yarn start` locally without involving the debugger.  Nice.\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Toledo, IA\\nprice: $50.00\\nnote: This is just some sample \\\"front matter\\\".\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[10,3],[10,4],[10,5],[10,6],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>I'm making some significant changes to the code behind this blog today.  Specifically, I'm going to move my micropost &quot;front matter&quot; from the <code>post.excerpt</code> or <code>post.custom_excerpt</code> field to the &quot;body&quot; of the post where it might look like this example (taken from this very post):</p>\n<pre><code>-+-+-+\nlocation: Toledo, IA\nprice: $50.00\nnote: This is just some sample &quot;front matter&quot;. My parser removed the &quot;split&quot; characters from the delimiter you see here.\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h1 id=\"i-need-vscode-debugging\">I Need VSCode Debugging!</h1>\n<p>To do this effectively I really need live dev debugging in <em>VSCode</em>, but how can I do that?</p>\n<p>Well, I turned first to <a href=\"https://griffadev.medium.com/tips-for-debugging-in-11ty-aca887d2c66e\">Tips for debugging in 11ty</a> by <a href=\"https://griffadev.medium.com\">George Griffiths</a> because it looked very promising.  In the second half of that post under the heading of <strong>Debugging with VS Code</strong> there are instructions for creating a <code>.vscode/lanuch.json</code> to do this, and I did.  But how does one &quot;attach&quot; their debugger to the script I use to launch/test this blog locally?  That command by the way is <code>yarn start</code>.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"my-debugger-configuration\">My Debugger Configuration</h2>\n<p>So, I found that the stock <code>launch.json</code> prescribed by George didn't quite work in my situation, I had to add a configuration AND with a small change, and turn off <code>Auto Attach</code> debugging.</p>\n<p>I clicked on the debugger icon in the left-hand pane of my <em>VSCode</em> window and there I had the option to add a configuration.  I clicked that and was presented with several choices.  After incorrectly trying a few options I settled on one labeled <code>Run Script&amp;colon; start</code> and it almost worked.</p>\n<p>The configuration added to my <code>launch.json</code> file included <code>&quot;command&quot;&amp;colon; &quot;yarn run start&quot;</code>, but that's not quite right for me.  I simply use <code>yarn start</code> to launch my local dev instance of this blog, so I made that change to <code>lanuch.json</code> so that file now reads:</p>\n<pre><code class=\"language-json\">{\n  &quot;name&quot;: &quot;11ty&quot;,\n  &quot;type&quot;: &quot;node&quot;,\n  &quot;request&quot;: &quot;launch&quot;,\n  &quot;program&quot;: &quot;${workspaceRoot}/node_modules/.bin/eleventy&quot;,\n  &quot;stopOnEntry&quot;: false,\n  &quot;args&quot;: [],\n  &quot;cwd&quot;: &quot;${workspaceRoot}&quot;,\n  &quot;console&quot;: &quot;internalConsole&quot;,\n  &quot;configurations&quot;: [\n    {\n      &quot;type&quot;: &quot;node-terminal&quot;,\n      &quot;name&quot;: &quot;Run Script: start&quot;,\n      &quot;request&quot;: &quot;launch&quot;,\n      &quot;command&quot;: &quot;yarn start&quot;,\n      &quot;cwd&quot;: &quot;${workspaceFolder}&quot;\n    }\n  ]\n}\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h1 id=\"it-works\">It Works!</h1>\n<p>Now when I open the debugger and click the green start arrow beside <code>Run Script: start</code> I can see <code>.eleventy.js</code> begin running and it stops at any breakpoints I have set.  It even works when stepping into my <code>custom.js</code> script, all the while showing me the call stack and variables that are in-scope at the time.  Yay!</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>Thank You <a href=\"https://griffadev.medium.com\">George</a>!</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"wait-theres-more\">Wait, There's More</h2>\n<p>Even better news is that I can still run <code>yarn start</code> locally without involving the debugger.  Nice.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Toledo, IA<br>\nprice: $50.00<br>\nnote: This is just some sample &quot;front matter&quot;.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "642c4b82ddadd63e1863b39f",
            "plaintext": "I'm making some significant changes to the code behind this blog today. Specifically, I'm going to move my micropost \"front matter\" from the post.excerpt or post.custom_excerpt field to the \"body\" of the post where it might look like this example (taken from this very post):\n\n\n-+-+-+\nlocation: Toledo, IA\nprice: $50.00\nnote: This is just some sample \"front matter\". My parser removed the \"split\" characters from the delimiter you see here.\n\n\n\n\nI Need VSCode Debugging!\n\n\nTo do this effectively I really need live dev debugging in VSCode, but how can I do that?\n\n\nWell, I turned first to Tips for debugging in 11ty by George Griffiths because it looked very promising. In the second half of that post under the heading of Debugging with VS Code there are instructions for creating a .vscode/lanuch.json to do this, and I did. But how does one \"attach\" their debugger to the script I use to launch/test this blog locally? That command by the way is yarn start.\n\n\n\nMy Debugger Configuration\n\n\nSo, I found that the stock launch.json prescribed by George didn't quite work in my situation, I had to add a configuration AND with a small change, and turn off Auto Attach debugging.\n\n\nI clicked on the debugger icon in the left-hand pane of my VSCode window and there I had the option to add a configuration. I clicked that and was presented with several choices. After incorrectly trying a few options I settled on one labeled Run Script&colon; start and it almost worked.\n\n\nThe configuration added to my launch.json file included \"command\"&colon; \"yarn run start\", but that's not quite right for me. I simply use yarn start to launch my local dev instance of this blog, so I made that change to lanuch.json so that file now reads:\n\n\n{\n  \"name\": \"11ty\",\n  \"type\": \"node\",\n  \"request\": \"launch\",\n  \"program\": \"${workspaceRoot}/node_modules/.bin/eleventy\",\n  \"stopOnEntry\": false,\n  \"args\": [],\n  \"cwd\": \"${workspaceRoot}\",\n  \"console\": \"internalConsole\",\n  \"configurations\": [\n    {\n      \"type\": \"node-terminal\",\n      \"name\": \"Run Script: start\",\n      \"request\": \"launch\",\n      \"command\": \"yarn start\",\n      \"cwd\": \"${workspaceFolder}\"\n    }\n  ]\n}\n\n\n\n\nIt Works!\n\n\nNow when I open the debugger and click the green start arrow beside Run Script: start I can see .eleventy.js begin running and it stops at any breakpoints I have set. It even works when stepping into my custom.js script, all the while showing me the call stack and variables that are in-scope at the time. Yay!\n\n\nThank You George!\n\n\n\nWait, There's More\n\n\nEven better news is that I can still run yarn start locally without involving the debugger. Nice.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n\nprice: $50.00\n\nnote: This is just some sample \"front matter\".\n",
            "feature_image": "https://images.unsplash.com/photo-1592609931041-40265b692757?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDR8fHZzY29kZXxlbnwwfHx8fDE2ODA2MzI0NjM&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-04T16:08:34.000Z",
            "updated_at": "2023-04-05T00:28:44.000Z",
            "published_at": "2023-04-04T16:31:07.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "642e8437ddadd63e1863b585",
            "uuid": "37f01abf-5c2e-4ccd-aaeb-b2b8e029e546",
            "title": "Testing ghost publisher again",
            "slug": "testing-ghost-publisher-again",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}]],\"cards\":[],\"markups\":[[\"a\",[\"href\",\"https://github.com/willowsokora/Ghost-Publisher\"]],[\"em\"],[\"a\",[\"href\",\"https://ghost.org/docs/admin-api/?_ga=2.258407498.1118611505.1680637422-1629315755.1679183141\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"I am back on my iPhone testing the Ghost Publisher app once more.  The problem here is that the \\\"tags\\\" feature doesn't appear to work at all?  I could fork the code (\"],[0,[0],1,\"https://github.com/willowsokora/Ghost-Publisher\"],[0,[],0,\") and try to \\\"fix\\\" it... nah.  Maybe Mackenzie wants to learn some \"],[0,[1],1,\"Swift\"],[0,[],0,\" programming?  Or, more likely, let's see what she can do with \"],[0,[1],1,\"Apple Shortcuts\"],[0,[],0,\" and the [Ghost Admin API](\"],[0,[2],1,\"https://ghost.org/docs/admin-api/?_ga=2.258407498.1118611505.1680637422-1629315755.1679183141\"],[0,[],0,\").\"]]],[1,\"p\",[[0,[],0,\"-/-/-/\"],[1,[],0,0],[0,[],0,\"location: Toledo, IA\"]]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>I am back on my iPhone testing the Ghost Publisher app once more. Â The problem here is that the \"tags\" feature doesn't appear to work at all? Â I could fork the code (<a href=\"https://github.com/willowsokora/Ghost-Publisher\">https://github.com/willowsokora/Ghost-Publisher</a>) and try to \"fix\" it... nah. Â Maybe Mackenzie wants to learn some <em>Swift</em> programming? Â Or, more likely, let's see what she can do with <em>Apple Shortcuts</em> and the [Ghost Admin API](<a href=\"https://ghost.org/docs/admin-api/?_ga=2.258407498.1118611505.1680637422-1629315755.1679183141\">https://ghost.org/docs/admin-api/?_ga=2.258407498.1118611505.1680637422-1629315755.1679183141</a>).</p><p>-/-/-/<br>location: Toledo, IA</p>",
            "comment_id": "642e8437ddadd63e1863b585",
            "plaintext": "I am back on my iPhone testing the Ghost Publisher app once more. Â The problem here is that the \"tags\" feature doesn't appear to work at all? Â I could fork the code (https://github.com/willowsokora/Ghost-Publisher) and try to \"fix\" it... nah. Â Maybe Mackenzie wants to learn some Swift programming? Â Or, more likely, let's see what she can do with Apple Shortcuts and the [Ghost Admin API](https://ghost.org/docs/admin-api/?_ga=2.258407498.1118611505.1680637422-1629315755.1679183141).\n\n-/-/-/\nlocation: Toledo, IA",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-06T08:35:03.000Z",
            "updated_at": "2023-04-06T14:49:26.000Z",
            "published_at": "2023-04-06T08:35:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64316124ddadd63e1863b59d",
            "uuid": "225bce0b-ebc8-4cab-842d-bb2c838f16e6",
            "title": "How I Added a Collection to This Blog",
            "slug": "how-i-added-a-collection-to-this-blog",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"What follows is an excerpt taken directly from this project's `README.md` file.  \"}],[\"markdown\",{\"markdown\":\"## Adding a 'micropost' Collection\\n\\nI'm following the guidance at [Building content collections](https://ghost.org/tutorials/content-collections/) to turn my new `micropost` tag into a new Ghost collection.  I've downloaded the `routes.yml` file from my Ghost installation as suggested in the guidance, and it's now part of this project with initial contents of:  \\n\\n```yaml\\nroutes:\\n\\ncollections:\\n  /micropost/:\\n    permalink: /micropost/{slug}/\\n    template: index\\n    filter: tag:micropost\\n  /:\\n    permalink: /{slug}/\\n    template: index\\n    filter: tag:-micropost\\n\\ntaxonomies:\\n  tag: /tag/{slug}/\\n  author: /author/{slug}/\\n  ```  \\n\\nThis change allowed me to swap this first line of template logic for the second:    \\n\\n```njk\\n  {% if post.data.type != \\\"micropost\\\" %}\\n```\\n\\n```njk\\n  {% if '/micropost/' not in post.url %}\\n```\\n\\nThe reverse logic in javascript now calls for:  \\n\\n```js\\n  if (post.url.includes(`/micropost/`)) {\\n```    \\n\\n## Completing the Addition of the 'micropost' Collection\\n\\nHaving added a `micropost` collection (see above) I made a copy of `src/index.njk` named `src/microposts.njk` and set the template front matter to:  \\n\\n```\\n---\\npagination:\\n  data: collections.microposts\\n  size: 9\\n  alias: microposts\\n---\\n```\\n\\nThe key logic also changed to:  \\n\\n```\\n    <section class=\\\"post-feed\\\">\\n        {% for post in microposts %}\\n          {# post.url | debugger #}\\n          {{ card(post) }}\\n        {% endfor %}\\n    </section>\\n```\\n\\nAll of this successfully created the new `/microposts/` path and I explicitly added it to the `site.navigation` in `src/_data/site.js`.  I also removed `About` from the `site.navigation` in the same source code.  \\n\\n## Don't Forget...\\n\\nRemember to upload any changes to `routes.yml` back to Ghost via the [Settings | Labs](__GHOST_URL__/ghost/#/settings/labs) menu!  \\n\\n## Subsequent Changes in `.eleventy.js` Where Filtering is Key!\\n\\n\\nI recently found that \\\"hiding\\\" mircorposts from the home page was seriously fouling up my pagination, when I asked for 9 posts per page I would sometimes only see 5 or fewer posts spread across 3 pages.  The system was properly positioning 9 posts, but those that were tagged as `micropost` were hidden from view.\\n\\nSo, I revamped my `.eleventy.js` to do a better job of filtering (that IS the keyword here!) my _Ghost_ content up-front, like this:\\n\\n```js\\n  // Get all posts, but NO microposts here!\\n  config.addCollection(\\\"posts\\\", async function(collection) {\\n\\n    collection = await api.posts\\n      .browse({\\n        include: \\\"tags,authors\\\",\\n        limit: \\\"all\\\",\\n        filter: \\\"tag:-micropost\\\" \\n      })\\n      .catch(err => {\\n        console.error(err);\\n      });\\n\\n    collection.forEach(post => {\\n\\n      post.url = stripDomain(post.url);\\n      post.primary_author.url = stripDomain(post.primary_author.url);\\n      post.tags.map(tag => (tag.url = stripDomain(tag.url)));\\n      // Convert publish date into a Date object\\n      post.published_at = new Date(post.published_at);\\n      // Call custom MAM javascript\\n      var custom = require(\\\"./custom.js\\\");\\n      post = custom.modify_post(post);\\n\\n    });\\n\\n    // Bring featured post to the top of the list\\n    collection.sort((post, nextPost) => nextPost.featured - post.featured);\\n\\n    return collection;\\n  });\\n\\n  // Get all posts AGAIN, but this time return only the microposts as a new collection\\n  // See https://11ty.rocks/posts/creating-and-using-11ty-collections/#more-ways-to-create-collections-with-addcollection\\n  config.addCollection(\\\"micropost\\\", async function(collection) {\\n\\n    collection = await api.posts\\n      .browse({\\n        include: \\\"tags,authors\\\",\\n        limit: \\\"all\\\",\\n        filter: \\\"tag:micropost\\\"\\n      })\\n      .catch(err => {\\n        console.error(err);\\n      });\\n\\n    const new_collection = [];  \\n    collection.forEach(post => {\\n      post.url = stripDomain(post.url);\\n      post.primary_author.url = stripDomain(post.primary_author.url);\\n      post.tags.map(tag => (tag.url = stripDomain(tag.url)));\\n      // Convert publish date into a Date object\\n      post.published_at = new Date(post.published_at);\\n      // Call custom MAM javascript\\n      var custom = require(\\\"./custom.js\\\");\\n      post = custom.modify_post(post);\\n      new_collection.push(post);\\n    });\\n\\n    // console.log(\\\"Micropost collection:\\\", new_collection);  // Dump what we hath created\\n    return new_collection;\\n  });\\n```\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>What follows is an excerpt taken directly from this project's <code>README.md</code> file.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"adding-a-micropost-collection\">Adding a 'micropost' Collection</h2>\n<p>I'm following the guidance at <a href=\"https://ghost.org/tutorials/content-collections/\">Building content collections</a> to turn my new <code>micropost</code> tag into a new Ghost collection.  I've downloaded the <code>routes.yml</code> file from my Ghost installation as suggested in the guidance, and it's now part of this project with initial contents of:</p>\n<pre><code class=\"language-yaml\">routes:\n\ncollections:\n  /micropost/:\n    permalink: /micropost/{slug}/\n    template: index\n    filter: tag:micropost\n  /:\n    permalink: /{slug}/\n    template: index\n    filter: tag:-micropost\n\ntaxonomies:\n  tag: /tag/{slug}/\n  author: /author/{slug}/\n</code></pre>\n<p>This change allowed me to swap this first line of template logic for the second:</p>\n<pre><code class=\"language-njk\">  {% if post.data.type != &quot;micropost&quot; %}\n</code></pre>\n<pre><code class=\"language-njk\">  {% if '/micropost/' not in post.url %}\n</code></pre>\n<p>The reverse logic in javascript now calls for:</p>\n<pre><code class=\"language-js\">  if (post.url.includes(`/micropost/`)) {\n</code></pre>\n<h2 id=\"completing-the-addition-of-the-micropost-collection\">Completing the Addition of the 'micropost' Collection</h2>\n<p>Having added a <code>micropost</code> collection (see above) I made a copy of <code>src/index.njk</code> named <code>src/microposts.njk</code> and set the template front matter to:</p>\n<pre><code>---\npagination:\n  data: collections.microposts\n  size: 9\n  alias: microposts\n---\n</code></pre>\n<p>The key logic also changed to:</p>\n<pre><code>    &lt;section class=&quot;post-feed&quot;&gt;\n        {% for post in microposts %}\n          {# post.url | debugger #}\n          {{ card(post) }}\n        {% endfor %}\n    &lt;/section&gt;\n</code></pre>\n<p>All of this successfully created the new <code>/microposts/</code> path and I explicitly added it to the <code>site.navigation</code> in <code>src/_data/site.js</code>.  I also removed <code>About</code> from the <code>site.navigation</code> in the same source code.</p>\n<h2 id=\"dont-forget\">Don't Forget...</h2>\n<p>Remember to upload any changes to <code>routes.yml</code> back to Ghost via the <a href=\"__GHOST_URL__/ghost/#/settings/labs\">Settings | Labs</a> menu!</p>\n<h2 id=\"subsequent-changes-in-eleventyjs-where-filtering-is-key\">Subsequent Changes in <code>.eleventy.js</code> Where Filtering is Key!</h2>\n<p>I recently found that &quot;hiding&quot; mircorposts from the home page was seriously fouling up my pagination, when I asked for 9 posts per page I would sometimes only see 5 or fewer posts spread across 3 pages.  The system was properly positioning 9 posts, but those that were tagged as <code>micropost</code> were hidden from view.</p>\n<p>So, I revamped my <code>.eleventy.js</code> to do a better job of filtering (that IS the keyword here!) my <em>Ghost</em> content up-front, like this:</p>\n<pre><code class=\"language-js\">  // Get all posts, but NO microposts here!\n  config.addCollection(&quot;posts&quot;, async function(collection) {\n\n    collection = await api.posts\n      .browse({\n        include: &quot;tags,authors&quot;,\n        limit: &quot;all&quot;,\n        filter: &quot;tag:-micropost&quot; \n      })\n      .catch(err =&gt; {\n        console.error(err);\n      });\n\n    collection.forEach(post =&gt; {\n\n      post.url = stripDomain(post.url);\n      post.primary_author.url = stripDomain(post.primary_author.url);\n      post.tags.map(tag =&gt; (tag.url = stripDomain(tag.url)));\n      // Convert publish date into a Date object\n      post.published_at = new Date(post.published_at);\n      // Call custom MAM javascript\n      var custom = require(&quot;./custom.js&quot;);\n      post = custom.modify_post(post);\n\n    });\n\n    // Bring featured post to the top of the list\n    collection.sort((post, nextPost) =&gt; nextPost.featured - post.featured);\n\n    return collection;\n  });\n\n  // Get all posts AGAIN, but this time return only the microposts as a new collection\n  // See https://11ty.rocks/posts/creating-and-using-11ty-collections/#more-ways-to-create-collections-with-addcollection\n  config.addCollection(&quot;micropost&quot;, async function(collection) {\n\n    collection = await api.posts\n      .browse({\n        include: &quot;tags,authors&quot;,\n        limit: &quot;all&quot;,\n        filter: &quot;tag:micropost&quot;\n      })\n      .catch(err =&gt; {\n        console.error(err);\n      });\n\n    const new_collection = [];  \n    collection.forEach(post =&gt; {\n      post.url = stripDomain(post.url);\n      post.primary_author.url = stripDomain(post.primary_author.url);\n      post.tags.map(tag =&gt; (tag.url = stripDomain(tag.url)));\n      // Convert publish date into a Date object\n      post.published_at = new Date(post.published_at);\n      // Call custom MAM javascript\n      var custom = require(&quot;./custom.js&quot;);\n      post = custom.modify_post(post);\n      new_collection.push(post);\n    });\n\n    // console.log(&quot;Micropost collection:&quot;, new_collection);  // Dump what we hath created\n    return new_collection;\n  });\n</code></pre>\n<!--kg-card-end: markdown-->",
            "comment_id": "64316124ddadd63e1863b59d",
            "plaintext": "What follows is an excerpt taken directly from this project's README.md file.\n\n\n\nAdding a 'micropost' Collection\n\n\nI'm following the guidance at Building content collections to turn my new micropost tag into a new Ghost collection. I've downloaded the routes.yml file from my Ghost installation as suggested in the guidance, and it's now part of this project with initial contents of:\n\n\nroutes:\n\ncollections:\n  /micropost/:\n    permalink: /micropost/{slug}/\n    template: index\n    filter: tag:micropost\n  /:\n    permalink: /{slug}/\n    template: index\n    filter: tag:-micropost\n\ntaxonomies:\n  tag: /tag/{slug}/\n  author: /author/{slug}/\n\n\n\nThis change allowed me to swap this first line of template logic for the second:\n\n\n  {% if post.data.type != \"micropost\" %}\n\n\n\n  {% if '/micropost/' not in post.url %}\n\n\n\nThe reverse logic in javascript now calls for:\n\n\n  if (post.url.includes(`/micropost/`)) {\n\n\n\n\nCompleting the Addition of the 'micropost' Collection\n\n\nHaving added a micropost collection (see above) I made a copy of src/index.njk named src/microposts.njk and set the template front matter to:\n\n\n---\npagination:\n  data: collections.microposts\n  size: 9\n  alias: microposts\n---\n\n\n\nThe key logic also changed to:\n\n\n    <section class=\"post-feed\">\n        {% for post in microposts %}\n          {# post.url | debugger #}\n          {{ card(post) }}\n        {% endfor %}\n    </section>\n\n\n\nAll of this successfully created the new /microposts/ path and I explicitly added it to the site.navigation in src/_data/site.js. I also removed About from the site.navigation in the same source code.\n\n\n\nDon't Forget...\n\n\nRemember to upload any changes to routes.yml back to Ghost via the Settings | Labs menu!\n\n\n\nSubsequent Changes in .eleventy.js Where Filtering is Key!\n\n\nI recently found that \"hiding\" mircorposts from the home page was seriously fouling up my pagination, when I asked for 9 posts per page I would sometimes only see 5 or fewer posts spread across 3 pages. The system was properly positioning 9 posts, but those that were tagged as micropost were hidden from view.\n\n\nSo, I revamped my .eleventy.js to do a better job of filtering (that IS the keyword here!) my Ghost content up-front, like this:\n\n\n  // Get all posts, but NO microposts here!\n  config.addCollection(\"posts\", async function(collection) {\n\n    collection = await api.posts\n      .browse({\n        include: \"tags,authors\",\n        limit: \"all\",\n        filter: \"tag:-micropost\" \n      })\n      .catch(err => {\n        console.error(err);\n      });\n\n    collection.forEach(post => {\n\n      post.url = stripDomain(post.url);\n      post.primary_author.url = stripDomain(post.primary_author.url);\n      post.tags.map(tag => (tag.url = stripDomain(tag.url)));\n      // Convert publish date into a Date object\n      post.published_at = new Date(post.published_at);\n      // Call custom MAM javascript\n      var custom = require(\"./custom.js\");\n      post = custom.modify_post(post);\n\n    });\n\n    // Bring featured post to the top of the list\n    collection.sort((post, nextPost) => nextPost.featured - post.featured);\n\n    return collection;\n  });\n\n  // Get all posts AGAIN, but this time return only the microposts as a new collection\n  // See https://11ty.rocks/posts/creating-and-using-11ty-collections/#more-ways-to-create-collections-with-addcollection\n  config.addCollection(\"micropost\", async function(collection) {\n\n    collection = await api.posts\n      .browse({\n        include: \"tags,authors\",\n        limit: \"all\",\n        filter: \"tag:micropost\"\n      })\n      .catch(err => {\n        console.error(err);\n      });\n\n    const new_collection = [];  \n    collection.forEach(post => {\n      post.url = stripDomain(post.url);\n      post.primary_author.url = stripDomain(post.primary_author.url);\n      post.tags.map(tag => (tag.url = stripDomain(tag.url)));\n      // Convert publish date into a Date object\n      post.published_at = new Date(post.published_at);\n      // Call custom MAM javascript\n      var custom = require(\"./custom.js\");\n      post = custom.modify_post(post);\n      new_collection.push(post);\n    });\n\n    // console.log(\"Micropost collection:\", new_collection);  // Dump what we hath created\n    return new_collection;\n  });\n\n",
            "feature_image": "https://images.unsplash.com/photo-1591961172040-ee974a422616?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDEwMnx8Y29sbGVjdGlvbnxlbnwwfHx8fDE2ODA5NTc5ODI&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-08T12:42:12.000Z",
            "updated_at": "2023-04-13T00:53:35.000Z",
            "published_at": "2023-04-08T12:47:15.000Z",
            "custom_excerpt": "What follows is an excerpt taken directly from this project's `README.md` file.  ",
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6433103dddadd63e1863b636",
            "uuid": "d000bc35-5871-4cd3-b3ec-0fb502444c87",
            "title": "Easter Nap Time",
            "slug": "easter-nap-time",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}]],\"cards\":[],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"Time for an Easter Sunday post-feast nap!  Nice dinner here with me, Chris, Mackenzie, Morgan, Justin, Leonard, Barb, Deb, Doug, Mason and Michael.  \"]]],[1,\"p\",[[0,[],0,\"-/-/-/\"],[1,[],0,0],[0,[],0,\"location: Toledo, IA\"]]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Time for an Easter Sunday post-feast nap! Â Nice dinner here with me, Chris, Mackenzie, Morgan, Justin, Leonard, Barb, Deb, Doug, Mason and Michael. Â </p><p>-/-/-/<br>location: Toledo, IA</p>",
            "comment_id": "6433103dddadd63e1863b636",
            "plaintext": "Time for an Easter Sunday post-feast nap! Â Nice dinner here with me, Chris, Mackenzie, Morgan, Justin, Leonard, Barb, Deb, Doug, Mason and Michael. Â \n\n-/-/-/\nlocation: Toledo, IA",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-09T19:21:33.000Z",
            "updated_at": "2023-04-09T19:23:54.000Z",
            "published_at": "2023-04-09T19:23:54.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "643367d3ddadd63e1863b650",
            "uuid": "a16c3f9b-00b0-4f00-9d0b-09789198a3c1",
            "title": "Hot Spring Spa is Gone",
            "slug": "hot-spring-spa-is-gone",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[[\"soft-return\",\"\",{}]],\"cards\":[],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"My old Hot Spring spa is gone! Listed it at about noon and by 4 PM I had 15 interested parties, most of them very serious. It went to a young couple who came very well prepared to haul it away... flatbed truck with a lift, and an extra set of muscles. It departed shortly after 8 PM. Well done!\"]]],[1,\"p\",[[0,[],0,\"-/-/-/\"],[1,[],0,0],[0,[],0,\"location: Toledo, IA\"]]],[1,\"p\",[]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>My old Hot Spring spa is gone! Listed it at about noon and by 4 PM I had 15 interested parties, most of them very serious. It went to a young couple who came very well prepared to haul it away... flatbed truck with a lift, and an extra set of muscles. It departed shortly after 8 PM. Well done!</p><p>-/-/-/<br>location: Toledo, IA</p><p></p>",
            "comment_id": "643367d3ddadd63e1863b650",
            "plaintext": "My old Hot Spring spa is gone! Listed it at about noon and by 4 PM I had 15 interested parties, most of them very serious. It went to a young couple who came very well prepared to haul it away... flatbed truck with a lift, and an extra set of muscles. It departed shortly after 8 PM. Well done!\n\n-/-/-/\nlocation: Toledo, IA\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-10T01:35:15.000Z",
            "updated_at": "2023-04-10T01:36:38.000Z",
            "published_at": "2023-04-09T01:35:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64343fedddadd63e1863b666",
            "uuid": "b4fdb2c3-5dd5-4a9a-b1cb-e6ea8a40bfb0",
            "title": "Updated-Rootstalk-with-landscape-orientation-message",
            "slug": "updated-rootstalk-with-landscape-orientation-message",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"I pushed some _Rootstalk_ updates into production (https://Rootstalk.Grinnell.edu) this morning and am making note of that here since I don't have this slick `micropost` capability on my professional blog. ðŸ™ƒ\"}],[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Grinnell, IA\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>I pushed some <em>Rootstalk</em> updates into production (<a href=\"https://Rootstalk.Grinnell.edu\">https://Rootstalk.Grinnell.edu</a>) this morning and am making note of that here since I don't have this slick <code>micropost</code> capability on my professional blog. ðŸ™ƒ</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Grinnell, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "64343fedddadd63e1863b666",
            "plaintext": "I pushed some Rootstalk updates into production (https://Rootstalk.Grinnell.edu) this morning and am making note of that here since I don't have this slick micropost capability on my professional blog. ðŸ™ƒ\n\n\n-/-/-/\n\nlocation: Grinnell, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-10T16:57:17.000Z",
            "updated_at": "2023-04-10T16:59:19.000Z",
            "published_at": "2023-04-10T16:59:19.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6434c995ddadd63e1863b677",
            "uuid": "f7a7a10b-4864-4ca0-ba1b-af13458fcb24",
            "title": "survived-first-soccer-officiating",
            "slug": "survived-first-soccer-officiating",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"Completed my first soccer officiating assignment tonight...  STC middle school girls and boys doubleheader, plus two B-games, vs. Mt. Vernon.  2.5 hours total play, but not too bad.  I still have a LOT to learn!  \"]]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Completed my first soccer officiating assignment tonight... Â STC middle school girls and boys doubleheader, plus two B-games, vs. Mt. Vernon. Â 2.5 hours total play, but not too bad. Â I still have a LOT to learn! Â </p>",
            "comment_id": "6434c995ddadd63e1863b677",
            "plaintext": "Completed my first soccer officiating assignment tonight... Â STC middle school girls and boys doubleheader, plus two B-games, vs. Mt. Vernon. Â 2.5 hours total play, but not too bad. Â I still have a LOT to learn! Â ",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-11T02:44:37.000Z",
            "updated_at": "2023-04-11T02:47:40.000Z",
            "published_at": "2023-04-11T00:36:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "643627dcddadd63e1863b68c",
            "uuid": "bd3877ff-4bd0-43fa-9cff-3f6d798507da",
            "title": "maybe-paperless-ngx",
            "slug": "maybe-paperless-ngx",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Today's income tax prep adventures has me believing that I need a new instance of [Paperless, maybe Paperless-NGX](https://docs.paperless-ngx.com/setup/#bare_metal) this time?  Now if I can just get Mackenzie to stand up and configure a new bare-metal Linux server. ðŸ™ƒ\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Today's income tax prep adventures has me believing that I need a new instance of <a href=\"https://docs.paperless-ngx.com/setup/#bare_metal\">Paperless, maybe Paperless-NGX</a> this time?  Now if I can just get Mackenzie to stand up and configure a new bare-metal Linux server. ðŸ™ƒ</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "643627dcddadd63e1863b68c",
            "plaintext": "Today's income tax prep adventures has me believing that I need a new instance of Paperless, maybe Paperless-NGX this time? Now if I can just get Mackenzie to stand up and configure a new bare-metal Linux server. ðŸ™ƒ\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-12T03:39:08.000Z",
            "updated_at": "2023-04-12T03:42:01.000Z",
            "published_at": "2023-04-12T03:42:01.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "643685f7ddadd63e1863b6a3",
            "uuid": "fd30169a-f80b-423a-8f74-8fe90d9cf3d9",
            "title": "hiding-microposts-breaks-pagination",
            "slug": "hiding-micrposts-breaks-pagination",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"So, since I could not get back to sleep this morning I started looking at this blog and wondering why my home page pagination isn't right?  After a little sleuthing I found that my custom logic to \\\"hide all microposts from the home page\\\" is working just as one might expect, except that this screws up the number of visible posts per page.  Hmmm, this needs some work. Guess I need to legitimately funnel microposts into an entirely separate collection!  \\n\\n**Done!**\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>So, since I could not get back to sleep this morning I started looking at this blog and wondering why my home page pagination isn't right?  After a little sleuthing I found that my custom logic to &quot;hide all microposts from the home page&quot; is working just as one might expect, except that this screws up the number of visible posts per page.  Hmmm, this needs some work. Guess I need to legitimately funnel microposts into an entirely separate collection!</p>\n<p><strong>Done!</strong></p>\n<!--kg-card-end: markdown-->",
            "comment_id": "643685f7ddadd63e1863b6a3",
            "plaintext": "So, since I could not get back to sleep this morning I started looking at this blog and wondering why my home page pagination isn't right? After a little sleuthing I found that my custom logic to \"hide all microposts from the home page\" is working just as one might expect, except that this screws up the number of visible posts per page. Hmmm, this needs some work. Guess I need to legitimately funnel microposts into an entirely separate collection!\n\n\nDone!\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-12T10:20:39.000Z",
            "updated_at": "2023-04-12T11:21:31.000Z",
            "published_at": "2023-04-12T10:23:48.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "643752e8ddadd63e1863b6c1",
            "uuid": "c0554478-0971-4526-bdd9-bc7d68b9763a",
            "title": "filing-2022-income-taxes",
            "slug": "filing-2022-income-taxes",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"Tonight is the night we file our 2022 income taxes.  Got nice little refunds from both Federal and Iowa, but all of my Fed refund is going toward first quarter estimated payments for 2023.  ðŸ˜•\"]]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Tonight is the night we file our 2022 income taxes. Â Got nice little refunds from both Federal and Iowa, but all of my Fed refund is going toward first quarter estimated payments for 2023. Â ðŸ˜•</p>",
            "comment_id": "643752e8ddadd63e1863b6c1",
            "plaintext": "Tonight is the night we file our 2022 income taxes. Â Got nice little refunds from both Federal and Iowa, but all of my Fed refund is going toward first quarter estimated payments for 2023. Â ðŸ˜•",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-13T00:55:04.000Z",
            "updated_at": "2023-04-13T00:56:49.000Z",
            "published_at": "2023-04-13T00:56:49.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6438784dddadd63e1863b6d6",
            "uuid": "29262b07-6ed1-4605-b5e5-5cbf930f8ae9",
            "title": "fixed-missing-individual-microposts",
            "slug": "fixed-missing-individual-microposts",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Ok, I now have the missing individual `micropost` issue resolved.  The fix required introducing a `microposts/microposts.njk` template patterned after `posts/posts.njk`, and linking that new template to a new `layouts/micropost.njk` template. \\n\\n-/-/-/\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Ok, I now have the missing individual <code>micropost</code> issue resolved.  The fix required introducing a <code>microposts/microposts.njk</code> template patterned after <code>posts/posts.njk</code>, and linking that new template to a new <code>layouts/micropost.njk</code> template.</p>\n<p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "6438784dddadd63e1863b6d6",
            "plaintext": "Ok, I now have the missing individual micropost issue resolved. The fix required introducing a microposts/microposts.njk template patterned after posts/posts.njk, and linking that new template to a new layouts/micropost.njk template.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-13T21:46:53.000Z",
            "updated_at": "2023-04-14T01:45:06.000Z",
            "published_at": "2023-04-14T00:46:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "643a1077ddadd63e1863b6eb",
            "uuid": "e61c08f1-3432-4c1b-aea8-59c86cbb6814",
            "title": "first-varsity-soccer-officiating",
            "slug": "first-varsity-soccer-officiating",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"My knees and back are definitely feeling better than 2 weeks ago.  Tonight I was AR2 for a varsity women's match with Independence at STC.  Final score was 11-2 on a very windy night, and it showed.  The crew of TJ and Dustin did a great job and I feel like I learned a lot from them tonight.  Thank you, gentlemen.\"]]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>My knees and back are definitely feeling better than 2 weeks ago. Â Tonight I was AR2 for a varsity women's match with Independence at STC. Â Final score was 11-2 on a very windy night, and it showed. Â The crew of TJ and Dustin did a great job and I feel like I learned a lot from them tonight. Â Thank you, gentlemen.</p>",
            "comment_id": "643a1077ddadd63e1863b6eb",
            "plaintext": "My knees and back are definitely feeling better than 2 weeks ago. Â Tonight I was AR2 for a varsity women's match with Independence at STC. Â Final score was 11-2 on a very windy night, and it showed. Â The crew of TJ and Dustin did a great job and I feel like I learned a lot from them tonight. Â Thank you, gentlemen.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-15T02:48:23.000Z",
            "updated_at": "2023-04-15T02:50:58.000Z",
            "published_at": "2023-04-15T02:50:58.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "643aa81eddadd63e1863b705",
            "uuid": "e4d2128d-7f29-4570-9522-68cc1af644d1",
            "title": "new-gpx-merge",
            "slug": "new-gpx-merge",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Last evening I rode my bike to/from soccer so this morning I wanted to \\\"merge\\\" those two track logs before publishing them to https://hikes.SummittDweller.com.  So, I found and forked https://github.com/locked-fg/gpxmerger to https://github.com/SummittDweller/gpxmerger and after tweaking my own code IT WORKS!  \\n\\nThe command I ran to make my first \\\"merge\\\" was: `python3 gpxmerger.py \\\"/Users/mark/Downloads/2023-04-14 16:32 - 3m 11s.gpx\\\" \\\"/Users/mark/Downloads/2023-04-14 20:40 - 3m 27s.gpx\\\"`.  I think I might tweak the script soon to just pull all of the `.gpx` files from a specified directory. \\n\\n**Update**: My fork of the project now accepts a single `target_directory` argument and uses \\\"glob\\\" to grab all the `.gpx` files in that directory.\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Last evening I rode my bike to/from soccer so this morning I wanted to &quot;merge&quot; those two track logs before publishing them to <a href=\"https://hikes.SummittDweller.com\">https://hikes.SummittDweller.com</a>.  So, I found and forked <a href=\"https://github.com/locked-fg/gpxmerger\">https://github.com/locked-fg/gpxmerger</a> to <a href=\"https://github.com/SummittDweller/gpxmerger\">https://github.com/SummittDweller/gpxmerger</a> and after tweaking my own code IT WORKS!</p>\n<p>The command I ran to make my first &quot;merge&quot; was: <code>python3 gpxmerger.py &quot;/Users/mark/Downloads/2023-04-14 16:32 - 3m 11s.gpx&quot; &quot;/Users/mark/Downloads/2023-04-14 20:40 - 3m 27s.gpx&quot;</code>.  I think I might tweak the script soon to just pull all of the <code>.gpx</code> files from a specified directory.</p>\n<p><strong>Update</strong>: My fork of the project now accepts a single <code>target_directory</code> argument and uses &quot;glob&quot; to grab all the <code>.gpx</code> files in that directory.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "643aa81eddadd63e1863b705",
            "plaintext": "Last evening I rode my bike to/from soccer so this morning I wanted to \"merge\" those two track logs before publishing them to https://hikes.SummittDweller.com. So, I found and forked https://github.com/locked-fg/gpxmerger to https://github.com/SummittDweller/gpxmerger and after tweaking my own code IT WORKS!\n\n\nThe command I ran to make my first \"merge\" was: python3 gpxmerger.py \"/Users/mark/Downloads/2023-04-14 16:32 - 3m 11s.gpx\" \"/Users/mark/Downloads/2023-04-14 20:40 - 3m 27s.gpx\". I think I might tweak the script soon to just pull all of the .gpx files from a specified directory.\n\n\nUpdate: My fork of the project now accepts a single target_directory argument and uses \"glob\" to grab all the .gpx files in that directory.\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-15T13:35:26.000Z",
            "updated_at": "2023-04-15T15:04:49.000Z",
            "published_at": "2023-04-15T13:42:58.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "643bf72fddadd63e1863b738",
            "uuid": "890c8811-2fd5-4b3e-a473-c62e99dcaade",
            "title": "reduce-spaces-stored-image-sizes",
            "slug": "reduce-azure-stored-image-sizes",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Ok, I get the sense that constantly pulling enormous digital images from _DigitalOcean Spaces_ to rebuild this blog is unnecessarily chewing up lots of bandwidth.  Today I'd like to begin fixing that by creating a utility, probably in _Python_, to grab all those images one-by-one, make a smaller copy of each, and put those copies back into a `web-ready` subdirectory in _Spaces_, or something like that.\\n\\nThere's a wealth of probably pertinent information to be had in https://docs.digitalocean.com/reference/api/spaces-api/.  Unfortunately, _Spaces_ isn't compatible with DO's own command line utility, [doctl](https://github.com/digitalocean/doctl), but it is compatible with [s3cmd](https://docs.digitalocean.com/products/spaces/reference/s3cmd/) and the link I've provided documents how to get started with that.  ðŸ™‚\\n\\n**Update:** See [Engaging `s3cmd` to Download and Resize Images from DO Spaces](https://blog.summittdweller.com/engaging-s3cmd-to-download-and-resize-images-from-do-spaces/) for my solution.\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Ok, I get the sense that constantly pulling enormous digital images from <em>DigitalOcean Spaces</em> to rebuild this blog is unnecessarily chewing up lots of bandwidth.  Today I'd like to begin fixing that by creating a utility, probably in <em>Python</em>, to grab all those images one-by-one, make a smaller copy of each, and put those copies back into a <code>web-ready</code> subdirectory in <em>Spaces</em>, or something like that.</p>\n<p>There's a wealth of probably pertinent information to be had in <a href=\"https://docs.digitalocean.com/reference/api/spaces-api/\">https://docs.digitalocean.com/reference/api/spaces-api/</a>.  Unfortunately, <em>Spaces</em> isn't compatible with DO's own command line utility, <a href=\"https://github.com/digitalocean/doctl\">doctl</a>, but it is compatible with <a href=\"https://docs.digitalocean.com/products/spaces/reference/s3cmd/\">s3cmd</a> and the link I've provided documents how to get started with that.  ðŸ™‚</p>\n<p><strong>Update:</strong> See <a href=\"https://blog.summittdweller.com/engaging-s3cmd-to-download-and-resize-images-from-do-spaces/\">Engaging <code>s3cmd</code> to Download and Resize Images from DO Spaces</a> for my solution.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "643bf72fddadd63e1863b738",
            "plaintext": "Ok, I get the sense that constantly pulling enormous digital images from DigitalOcean Spaces to rebuild this blog is unnecessarily chewing up lots of bandwidth. Today I'd like to begin fixing that by creating a utility, probably in Python, to grab all those images one-by-one, make a smaller copy of each, and put those copies back into a web-ready subdirectory in Spaces, or something like that.\n\n\nThere's a wealth of probably pertinent information to be had in https://docs.digitalocean.com/reference/api/spaces-api/. Unfortunately, Spaces isn't compatible with DO's own command line utility, doctl, but it is compatible with s3cmd and the link I've provided documents how to get started with that. ðŸ™‚\n\n\nUpdate: See Engaging s3cmd to Download and Resize Images from DO Spaces for my solution.\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-16T13:25:03.000Z",
            "updated_at": "2023-04-16T19:40:37.000Z",
            "published_at": "2023-04-16T13:28:11.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "643c0304ddadd63e1863b751",
            "uuid": "6e416562-0c04-4f46-8f1c-3dc529c221cc",
            "title": "Engaging `s3cmd` to Download and Resize Images from DO Spaces",
            "slug": "engaging-s3cmd-to-download-and-resize-images-from-do-spaces",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Earlier in this blog there's a `micropost` that lays out the problem at hand.  In a nutshell, most of the photos I saved in _DigitalOcean Spaces_ are too big to be effective in this blog.  They suck up lots of time and bandwidth every time this blog gets rebuilt, and then they are rendered at a fraction of their original size. This is exceptionall wasteful and unnecessary. \\n\\nSo, my task this morning is to install, configure, and engage the [s3cmd](https://s3tools.org/s3cmd) tools to help get this done.  There's _DigitalOcean_-specific guidance provided in [Setting Up s3cmd 2.x with DigitalOcean Spaces](https://docs.digitalocean.com/products/spaces/reference/s3cmd/) so that's where I will begin.  Here goes...\"}],[\"markdown\",{\"markdown\":\"## Installing `s3cmd`\\nThis looks to be very simple and straightforward, `brew install s3cmd` should do the trick. In a substantially abridged form, that looked like this:\\n\\n```bash\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blog-eleventy-ghost â€¹mainâ€º\\nâ•°â”€$ brew install s3cmd\\nRunning `brew update --auto-update`...\\n==> Auto-updated Homebrew!\\n==> Updated Homebrew from 4.0.10 (931327df1) to 4.0.13 (ac0663ae5).\\nUpdated 4 taps (dart-lang/dart, sass/sass, homebrew/core and homebrew/cask).\\n...\\nYou have 55 outdated formulae and 1 outdated cask installed.\\n...\\n==> Installing s3cmd\\n==> Pouring s3cmd--2.3.0.ventura.bottle.1.tar.gz\\nðŸº  /usr/local/Cellar/s3cmd/2.3.0: 837 files, 11.4MB\\n==> Running `brew cleanup s3cmd`...\\nDisable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\\nHide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\\n...\\n```\\n\\nThat took about 10 minutes, but should be worth it. \\n\\n## Configuration\\nNext, to begin configuration I need to fetch the access key:value pair for `images-summittdweller` that I created 4 years ago. I have the credentials necessary to view that information at https://cloud.digitalocean.com/account/api/spaces so that's what I've done.\\n\\nWhoa, that didn't work! I tried to use old access keys but apparently they are in the wrong format?  So, I created a new key named `key-for-s3cmd` and applied that (see below) and it works.\\n\\n```\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blog-eleventy-ghost â€¹mainâ€º\\nâ•°â”€$ s3cmd --configure\\n\\nEnter new values or accept defaults in brackets with Enter.\\nRefer to user manual for detailed description of all options.\\n\\nAccess key and Secret key are your identifiers for Amazon S3. Leave them empty for using the env variables.\\nAccess Key [images-summittdweller]: ***This is a secret***\\nSecret Key [4YPWYNXZZXFDIR6CRPHG]: ***An even bigger secret***\\nDefault Region [US]:\\n\\nUse \\\"s3.amazonaws.com\\\" for S3 Endpoint and not modify it to the target Amazon S3.\\nS3 Endpoint [nyc3.digitaloceanspaces.com]:\\n\\nUse \\\"%(bucket)s.s3.amazonaws.com\\\" to the target Amazon S3. \\\"%(bucket)s\\\" and \\\"%(location)s\\\" vars can be used\\nif the target S3 system supports dns based buckets.\\nDNS-style bucket+hostname:port template for accessing a bucket [%(bucket)s.nyc3.digitaloceanspaces.com]:\\n\\nEncryption password is used to protect your files from reading\\nby unauthorized persons while in transfer to S3\\nEncryption password [SummittDweller]:\\nPath to GPG program [/usr/local/bin/gpg]:\\n\\nWhen using secure HTTPS protocol all communication with Amazon S3\\nservers is protected from 3rd party eavesdropping. This method is\\nslower than plain HTTP, and can only be proxied with Python 2.7 or newer\\nUse HTTPS protocol [Yes]:\\n\\nOn some networks all internet access must go through a HTTP proxy.\\nTry setting it here if you can't connect to S3 directly\\nHTTP Proxy server name:\\n\\nNew settings:\\n  Access Key: ***This is a secret***\\n  Secret Key: ***An even bigger secret***\\n  Default Region: US\\n  S3 Endpoint: nyc3.digitaloceanspaces.com\\n  DNS-style bucket+hostname:port template for accessing a bucket: %(bucket)s.nyc3.digitaloceanspaces.com\\n  Encryption password: SummittDweller\\n  Path to GPG program: /usr/local/bin/gpg\\n  Use HTTPS protocol: True\\n  HTTP Proxy server name:\\n  HTTP Proxy server port: 0\\n\\nTest access with supplied credentials? [Y/n] Y\\nPlease wait, attempting to list all buckets...\\nSuccess. Your access key and secret key worked fine :-)\\n\\nNow verifying that encryption works...\\nSuccess. Encryption and decryption worked fine :-)\\n\\nSave settings? [y/N] y\\nConfiguration saved to '/Users/mark/.s3cfg'\\n```\"}],[\"markdown\",{\"markdown\":\"## Using `s3cwd`\\nThe \\\"More Information\\\" section at the end of the document I used above says that... \\\"You can use our [quick reference on s3cmd usage](https://docs.digitalocean.com/products/spaces/reference/s3cmd-usage/) to get started.\\\"  Ok, let's have a look... very nice!  I'm moving immediately to the [Save files to your local computer](https://docs.digitalocean.com/products/spaces/reference/s3cmd-usage/#save-files-to-your-local-computer) bits.\\n\"}],[\"markdown\",{\"markdown\":\"### Fetching Files of the August 2020 Derecho\\n\\nThe photos I saved of damage from our August 2020 Derecho, in a `images-summittdweller/2020-Aug-10-Derecho` bucket, are rather depressing and certainly don't need to be super high-res for the web, so let's retrieve those and practice this workflow there first.\\n\\nThe quick reference linked above says to use a command of the form `s3cmd get s3://spacename/path/ --recursive` to get all files from a particular folder.  In my case, that's...\\n\\n```\\nâ•­â”€mark@Marks-Mac-Mini ~/Downloads/2020-derecho-photos\\nâ•°â”€$ s3cmd get s3://images-summittdweller/2020-Aug-10-Derecho/ --recursive\\n\\nWARNING: Empty object name on S3 found, ignoring.\\ndownload: 's3://images-summittdweller/2020-Aug-10-Derecho/Derecho - 1.png' -> './Derecho - 1.png'  [1 of 82]\\n 23486944 of 23486944   100% in    1s    21.04 MB/s  done\\ndownload: 's3://images-summittdweller/2020-Aug-10-Derecho/Derecho - 10.png' -> './Derecho - 10.png'  [2 of 82]\\n 20861132 of 20861132   100% in    0s    23.45 MB/s  done\\n...\\ndownload: 's3://images-summittdweller/2020-Aug-10-Derecho/Photo-2020-08-20-19-51.jpeg' -> './Photo-2020-08-20-19-51.jpeg'  [81 of 82]\\n 6277783 of 6277783   100% in    0s    16.86 MB/s  done\\nERROR: Creation of file './for-the-web/' failed (Reason: Is a directory)\\n```\\n\\nOk, 81 images downloaded.  That was sooooooooo much better than the 1000-or-so clicks it would have taken to do that manually!  The only gottcha... that last error message about not downloading the `for-the-web` directory, which is currently empty anyway.  Before I go farther, I'm going to open that _DigitalOcean Spaces_ bucket and change the errant directory name to `web-ready`; that's where my \\\"thumbnail\\\" copies of all these images will be uploaded shortly.\"}],[\"markdown\",{\"markdown\":\"## Next Step, Resize Those Images\\nI found some concise and timely advice in the first web post I Googled: [How to quickly resize multiple images at once on Mac](https://www.idownloadblog.com/2013/10/19/how-to-resize-multiple-images-mac/). It uses exactly the tool I had in mind, the Mac-native `Preview` app.\\n\\nBefore begining that process I wanted to see just how much space my 81 images occupy, like so:\\n\\n```zsh\\nâ•­â”€mark@Marks-Mac-Mini ~/Downloads/2020-derecho-photos\\nâ•°â”€$ du -sh\\n2.7G\\t.\\n```\\n\\n2.7G isn't all that much, but it's still much bigger than it needs to be.  I'm firing up `Preview` now to see if I can reduce all images proportionally to a maximum width of 800 pixels.  Be back in a couple of minutes...\\n\\nDrum roll please...\\n```zsh\\nâ•­â”€mark@Marks-Mac-Mini ~/Downloads/2020-derecho-photos\\nâ•°â”€$ du -sh\\n163M\\t.\\n```\\n\\nNot bad at all.  Only took a couple of minutes and it reduced the total image size from 2.7G down to 163M. Not too shabby.\"}],[\"markdown\",{\"markdown\":\"## Uploads Complete... Next?\\nIn order to upload the resized images back to _DigitalOcean Spaces_, I simply used the nice graphical interface available to me at https://cloud.digitalocean.com/spaces/images-summittdweller?path=2020-Aug-10-Derecho%2Fweb-ready and the `Upload` option there.  It worked nicely, but for whatever reason two of the images failed to upload: `Derecho - 38.png` and `Derecho - 39.png`.  After a little review, and retries, I could not figure out why these wouldn't upload but that's OK because they are both largely redundant with `Derecho - 40.png`, so we'll just stick with that one.\\n\\nSo, in the original folder image `Derecho - 1.png` has an endpoint of `https://images.summittdweller.com/2020-Aug-10-Derecho/Derecho%20-%201.png`.  Makes sense.  In my new `web-ready` directory the reduced-size copy of the same image naturally has an endpoint of `https://images.summittdweller.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%201.png`.  Fortunately, that's a \\\"match\\\" except for the addition of the `web-ready` subdirectory in the path.  Exactly what I hoped would happen.\\n\\nThis means the next step is to...\"}],[\"markdown\",{\"markdown\":\"## Alter Content to Include the `web-ready` Path\\nI used the admin search (magnifying glass) feature of the _Ghost_ instance behind [this blog](__GHOST_URL__/ghost/#/dashboard) to find all references to `https://images.summittdweller.com/2020-Aug-10-Derecho` and it found: NOTHING.  Yikes.  Turns out all of the references were in one post, and it was draft.  So I edited the draft \\\"manually\\\" and published it.  Now let's try that search again... NOPE.  So, the text inside those `figure` tags evidently isn't discoverable.  â˜¹ï¸  Just as well since I think a different approach is needed.\"}],[\"markdown\",{\"markdown\":\"## Not `web-ready`, `originals`\\nSince editing the content (posts) to pick up the new `web-ready` directory is a royal pain, what I'm going to do now is create a new `originals` sub-directory in each bucket, download all the images, resize them locally as I did above, but replace the existing high-resolution images with the smaller copies AFTER I make a backup the original images in a new `originals` directory.  That way I don't have to edit any of my posts in order to get the smaller web-ready images, but I won't lose the originals either.  **Beautimous**.\\n\\n## Belay That Order!\\nWhile I'm confident this approach (above) will work, it may not be necessary.  I looked, for example, in `images-summittdweller/Norway-Photos-2019/Bergen - Hordaland, June 19, 2019` expecting to find some large images, but there were none over 800px in width.  In fact, I believe they are all under 640px wide, so nothing to do there, and that's a good thing.\"}],[\"markdown\",{\"markdown\":\"## That's All Folks\\nA detailed search of `images-summittdweller` didn't turn up any more enromous images that might get pushed to the web, so... \\\"That's All Folks\\\", for now at least.\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[10,3],[10,4],[10,5],[10,6],[10,7],[10,8],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Earlier in this blog there's a <code>micropost</code> that lays out the problem at hand.  In a nutshell, most of the photos I saved in <em>DigitalOcean Spaces</em> are too big to be effective in this blog.  They suck up lots of time and bandwidth every time this blog gets rebuilt, and then they are rendered at a fraction of their original size. This is exceptionall wasteful and unnecessary.</p>\n<p>So, my task this morning is to install, configure, and engage the <a href=\"https://s3tools.org/s3cmd\">s3cmd</a> tools to help get this done.  There's <em>DigitalOcean</em>-specific guidance provided in <a href=\"https://docs.digitalocean.com/products/spaces/reference/s3cmd/\">Setting Up s3cmd 2.x with DigitalOcean Spaces</a> so that's where I will begin.  Here goes...</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"installing-s3cmd\">Installing <code>s3cmd</code></h2>\n<p>This looks to be very simple and straightforward, <code>brew install s3cmd</code> should do the trick. In a substantially abridged form, that looked like this:</p>\n<pre><code class=\"language-bash\">â•­â”€mark@Marks-Mac-Mini ~/GitHub/blog-eleventy-ghost â€¹mainâ€º\nâ•°â”€$ brew install s3cmd\nRunning `brew update --auto-update`...\n==&gt; Auto-updated Homebrew!\n==&gt; Updated Homebrew from 4.0.10 (931327df1) to 4.0.13 (ac0663ae5).\nUpdated 4 taps (dart-lang/dart, sass/sass, homebrew/core and homebrew/cask).\n...\nYou have 55 outdated formulae and 1 outdated cask installed.\n...\n==&gt; Installing s3cmd\n==&gt; Pouring s3cmd--2.3.0.ventura.bottle.1.tar.gz\nðŸº  /usr/local/Cellar/s3cmd/2.3.0: 837 files, 11.4MB\n==&gt; Running `brew cleanup s3cmd`...\nDisable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\nHide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n...\n</code></pre>\n<p>That took about 10 minutes, but should be worth it.</p>\n<h2 id=\"configuration\">Configuration</h2>\n<p>Next, to begin configuration I need to fetch the access key:value pair for <code>images-summittdweller</code> that I created 4 years ago. I have the credentials necessary to view that information at <a href=\"https://cloud.digitalocean.com/account/api/spaces\">https://cloud.digitalocean.com/account/api/spaces</a> so that's what I've done.</p>\n<p>Whoa, that didn't work! I tried to use old access keys but apparently they are in the wrong format?  So, I created a new key named <code>key-for-s3cmd</code> and applied that (see below) and it works.</p>\n<pre><code>â•­â”€mark@Marks-Mac-Mini ~/GitHub/blog-eleventy-ghost â€¹mainâ€º\nâ•°â”€$ s3cmd --configure\n\nEnter new values or accept defaults in brackets with Enter.\nRefer to user manual for detailed description of all options.\n\nAccess key and Secret key are your identifiers for Amazon S3. Leave them empty for using the env variables.\nAccess Key [images-summittdweller]: ***This is a secret***\nSecret Key [4YPWYNXZZXFDIR6CRPHG]: ***An even bigger secret***\nDefault Region [US]:\n\nUse &quot;s3.amazonaws.com&quot; for S3 Endpoint and not modify it to the target Amazon S3.\nS3 Endpoint [nyc3.digitaloceanspaces.com]:\n\nUse &quot;%(bucket)s.s3.amazonaws.com&quot; to the target Amazon S3. &quot;%(bucket)s&quot; and &quot;%(location)s&quot; vars can be used\nif the target S3 system supports dns based buckets.\nDNS-style bucket+hostname:port template for accessing a bucket [%(bucket)s.nyc3.digitaloceanspaces.com]:\n\nEncryption password is used to protect your files from reading\nby unauthorized persons while in transfer to S3\nEncryption password [SummittDweller]:\nPath to GPG program [/usr/local/bin/gpg]:\n\nWhen using secure HTTPS protocol all communication with Amazon S3\nservers is protected from 3rd party eavesdropping. This method is\nslower than plain HTTP, and can only be proxied with Python 2.7 or newer\nUse HTTPS protocol [Yes]:\n\nOn some networks all internet access must go through a HTTP proxy.\nTry setting it here if you can't connect to S3 directly\nHTTP Proxy server name:\n\nNew settings:\n  Access Key: ***This is a secret***\n  Secret Key: ***An even bigger secret***\n  Default Region: US\n  S3 Endpoint: nyc3.digitaloceanspaces.com\n  DNS-style bucket+hostname:port template for accessing a bucket: %(bucket)s.nyc3.digitaloceanspaces.com\n  Encryption password: SummittDweller\n  Path to GPG program: /usr/local/bin/gpg\n  Use HTTPS protocol: True\n  HTTP Proxy server name:\n  HTTP Proxy server port: 0\n\nTest access with supplied credentials? [Y/n] Y\nPlease wait, attempting to list all buckets...\nSuccess. Your access key and secret key worked fine :-)\n\nNow verifying that encryption works...\nSuccess. Encryption and decryption worked fine :-)\n\nSave settings? [y/N] y\nConfiguration saved to '/Users/mark/.s3cfg'\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"using-s3cwd\">Using <code>s3cwd</code></h2>\n<p>The &quot;More Information&quot; section at the end of the document I used above says that... &quot;You can use our <a href=\"https://docs.digitalocean.com/products/spaces/reference/s3cmd-usage/\">quick reference on s3cmd usage</a> to get started.&quot;  Ok, let's have a look... very nice!  I'm moving immediately to the <a href=\"https://docs.digitalocean.com/products/spaces/reference/s3cmd-usage/#save-files-to-your-local-computer\">Save files to your local computer</a> bits.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h3 id=\"fetching-files-of-the-august-2020-derecho\">Fetching Files of the August 2020 Derecho</h3>\n<p>The photos I saved of damage from our August 2020 Derecho, in a <code>images-summittdweller/2020-Aug-10-Derecho</code> bucket, are rather depressing and certainly don't need to be super high-res for the web, so let's retrieve those and practice this workflow there first.</p>\n<p>The quick reference linked above says to use a command of the form <code>s3cmd get s3://spacename/path/ --recursive</code> to get all files from a particular folder.  In my case, that's...</p>\n<pre><code>â•­â”€mark@Marks-Mac-Mini ~/Downloads/2020-derecho-photos\nâ•°â”€$ s3cmd get s3://images-summittdweller/2020-Aug-10-Derecho/ --recursive\n\nWARNING: Empty object name on S3 found, ignoring.\ndownload: 's3://images-summittdweller/2020-Aug-10-Derecho/Derecho - 1.png' -&gt; './Derecho - 1.png'  [1 of 82]\n 23486944 of 23486944   100% in    1s    21.04 MB/s  done\ndownload: 's3://images-summittdweller/2020-Aug-10-Derecho/Derecho - 10.png' -&gt; './Derecho - 10.png'  [2 of 82]\n 20861132 of 20861132   100% in    0s    23.45 MB/s  done\n...\ndownload: 's3://images-summittdweller/2020-Aug-10-Derecho/Photo-2020-08-20-19-51.jpeg' -&gt; './Photo-2020-08-20-19-51.jpeg'  [81 of 82]\n 6277783 of 6277783   100% in    0s    16.86 MB/s  done\nERROR: Creation of file './for-the-web/' failed (Reason: Is a directory)\n</code></pre>\n<p>Ok, 81 images downloaded.  That was sooooooooo much better than the 1000-or-so clicks it would have taken to do that manually!  The only gottcha... that last error message about not downloading the <code>for-the-web</code> directory, which is currently empty anyway.  Before I go farther, I'm going to open that <em>DigitalOcean Spaces</em> bucket and change the errant directory name to <code>web-ready</code>; that's where my &quot;thumbnail&quot; copies of all these images will be uploaded shortly.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"next-step-resize-those-images\">Next Step, Resize Those Images</h2>\n<p>I found some concise and timely advice in the first web post I Googled: <a href=\"https://www.idownloadblog.com/2013/10/19/how-to-resize-multiple-images-mac/\">How to quickly resize multiple images at once on Mac</a>. It uses exactly the tool I had in mind, the Mac-native <code>Preview</code> app.</p>\n<p>Before begining that process I wanted to see just how much space my 81 images occupy, like so:</p>\n<pre><code class=\"language-zsh\">â•­â”€mark@Marks-Mac-Mini ~/Downloads/2020-derecho-photos\nâ•°â”€$ du -sh\n2.7G\t.\n</code></pre>\n<p>2.7G isn't all that much, but it's still much bigger than it needs to be.  I'm firing up <code>Preview</code> now to see if I can reduce all images proportionally to a maximum width of 800 pixels.  Be back in a couple of minutes...</p>\n<p>Drum roll please...</p>\n<pre><code class=\"language-zsh\">â•­â”€mark@Marks-Mac-Mini ~/Downloads/2020-derecho-photos\nâ•°â”€$ du -sh\n163M\t.\n</code></pre>\n<p>Not bad at all.  Only took a couple of minutes and it reduced the total image size from 2.7G down to 163M. Not too shabby.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"uploads-complete-next\">Uploads Complete... Next?</h2>\n<p>In order to upload the resized images back to <em>DigitalOcean Spaces</em>, I simply used the nice graphical interface available to me at <a href=\"https://cloud.digitalocean.com/spaces/images-summittdweller?path=2020-Aug-10-Derecho%2Fweb-ready\">https://cloud.digitalocean.com/spaces/images-summittdweller?path=2020-Aug-10-Derecho%2Fweb-ready</a> and the <code>Upload</code> option there.  It worked nicely, but for whatever reason two of the images failed to upload: <code>Derecho - 38.png</code> and <code>Derecho - 39.png</code>.  After a little review, and retries, I could not figure out why these wouldn't upload but that's OK because they are both largely redundant with <code>Derecho - 40.png</code>, so we'll just stick with that one.</p>\n<p>So, in the original folder image <code>Derecho - 1.png</code> has an endpoint of <code>https://images.summittdweller.com/2020-Aug-10-Derecho/Derecho%20-%201.png</code>.  Makes sense.  In my new <code>web-ready</code> directory the reduced-size copy of the same image naturally has an endpoint of <code>https://images.summittdweller.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%201.png</code>.  Fortunately, that's a &quot;match&quot; except for the addition of the <code>web-ready</code> subdirectory in the path.  Exactly what I hoped would happen.</p>\n<p>This means the next step is to...</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"alter-content-to-include-the-web-ready-path\">Alter Content to Include the <code>web-ready</code> Path</h2>\n<p>I used the admin search (magnifying glass) feature of the <em>Ghost</em> instance behind <a href=\"__GHOST_URL__/ghost/#/dashboard\">this blog</a> to find all references to <code>https://images.summittdweller.com/2020-Aug-10-Derecho</code> and it found: NOTHING.  Yikes.  Turns out all of the references were in one post, and it was draft.  So I edited the draft &quot;manually&quot; and published it.  Now let's try that search again... NOPE.  So, the text inside those <code>figure</code> tags evidently isn't discoverable.  â˜¹ï¸  Just as well since I think a different approach is needed.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"not-web-ready-originals\">Not <code>web-ready</code>, <code>originals</code></h2>\n<p>Since editing the content (posts) to pick up the new <code>web-ready</code> directory is a royal pain, what I'm going to do now is create a new <code>originals</code> sub-directory in each bucket, download all the images, resize them locally as I did above, but replace the existing high-resolution images with the smaller copies AFTER I make a backup the original images in a new <code>originals</code> directory.  That way I don't have to edit any of my posts in order to get the smaller web-ready images, but I won't lose the originals either.  <strong>Beautimous</strong>.</p>\n<h2 id=\"belay-that-order\">Belay That Order!</h2>\n<p>While I'm confident this approach (above) will work, it may not be necessary.  I looked, for example, in <code>images-summittdweller/Norway-Photos-2019/Bergen - Hordaland, June 19, 2019</code> expecting to find some large images, but there were none over 800px in width.  In fact, I believe they are all under 640px wide, so nothing to do there, and that's a good thing.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"thats-all-folks\">That's All Folks</h2>\n<p>A detailed search of <code>images-summittdweller</code> didn't turn up any more enromous images that might get pushed to the web, so... &quot;That's All Folks&quot;, for now at least.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "643c0304ddadd63e1863b751",
            "plaintext": "Earlier in this blog there's a micropost that lays out the problem at hand. In a nutshell, most of the photos I saved in DigitalOcean Spaces are too big to be effective in this blog. They suck up lots of time and bandwidth every time this blog gets rebuilt, and then they are rendered at a fraction of their original size. This is exceptionall wasteful and unnecessary.\n\n\nSo, my task this morning is to install, configure, and engage the s3cmd tools to help get this done. There's DigitalOcean-specific guidance provided in Setting Up s3cmd 2.x with DigitalOcean Spaces so that's where I will begin. Here goes...\n\n\n\nInstalling s3cmd\n\n\nThis looks to be very simple and straightforward, brew install s3cmd should do the trick. In a substantially abridged form, that looked like this:\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blog-eleventy-ghost â€¹mainâ€º\nâ•°â”€$ brew install s3cmd\nRunning `brew update --auto-update`...\n==> Auto-updated Homebrew!\n==> Updated Homebrew from 4.0.10 (931327df1) to 4.0.13 (ac0663ae5).\nUpdated 4 taps (dart-lang/dart, sass/sass, homebrew/core and homebrew/cask).\n...\nYou have 55 outdated formulae and 1 outdated cask installed.\n...\n==> Installing s3cmd\n==> Pouring s3cmd--2.3.0.ventura.bottle.1.tar.gz\nðŸº  /usr/local/Cellar/s3cmd/2.3.0: 837 files, 11.4MB\n==> Running `brew cleanup s3cmd`...\nDisable this behaviour by setting HOMEBREW_NO_INSTALL_CLEANUP.\nHide these hints with HOMEBREW_NO_ENV_HINTS (see `man brew`).\n...\n\n\n\nThat took about 10 minutes, but should be worth it.\n\n\n\nConfiguration\n\n\nNext, to begin configuration I need to fetch the access key:value pair for images-summittdweller that I created 4 years ago. I have the credentials necessary to view that information at https://cloud.digitalocean.com/account/api/spaces so that's what I've done.\n\n\nWhoa, that didn't work! I tried to use old access keys but apparently they are in the wrong format? So, I created a new key named key-for-s3cmd and applied that (see below) and it works.\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/blog-eleventy-ghost â€¹mainâ€º\nâ•°â”€$ s3cmd --configure\n\nEnter new values or accept defaults in brackets with Enter.\nRefer to user manual for detailed description of all options.\n\nAccess key and Secret key are your identifiers for Amazon S3. Leave them empty for using the env variables.\nAccess Key [images-summittdweller]: ***This is a secret***\nSecret Key [4YPWYNXZZXFDIR6CRPHG]: ***An even bigger secret***\nDefault Region [US]:\n\nUse \"s3.amazonaws.com\" for S3 Endpoint and not modify it to the target Amazon S3.\nS3 Endpoint [nyc3.digitaloceanspaces.com]:\n\nUse \"%(bucket)s.s3.amazonaws.com\" to the target Amazon S3. \"%(bucket)s\" and \"%(location)s\" vars can be used\nif the target S3 system supports dns based buckets.\nDNS-style bucket+hostname:port template for accessing a bucket [%(bucket)s.nyc3.digitaloceanspaces.com]:\n\nEncryption password is used to protect your files from reading\nby unauthorized persons while in transfer to S3\nEncryption password [SummittDweller]:\nPath to GPG program [__GHOST_URL__/usr/local/bin/gpg]:\n\nWhen using secure HTTPS protocol all communication with Amazon S3\nservers is protected from 3rd party eavesdropping. This method is\nslower than plain HTTP, and can only be proxied with Python 2.7 or newer\nUse HTTPS protocol [Yes]:\n\nOn some networks all internet access must go through a HTTP proxy.\nTry setting it here if you can't connect to S3 directly\nHTTP Proxy server name:\n\nNew settings:\n  Access Key: ***This is a secret***\n  Secret Key: ***An even bigger secret***\n  Default Region: US\n  S3 Endpoint: nyc3.digitaloceanspaces.com\n  DNS-style bucket+hostname:port template for accessing a bucket: %(bucket)s.nyc3.digitaloceanspaces.com\n  Encryption password: SummittDweller\n  Path to GPG program: /usr/local/bin/gpg\n  Use HTTPS protocol: True\n  HTTP Proxy server name:\n  HTTP Proxy server port: 0\n\nTest access with supplied credentials? [Y/n] Y\nPlease wait, attempting to list all buckets...\nSuccess. Your access key and secret key worked fine :-)\n\nNow verifying that encryption works...\nSuccess. Encryption and decryption worked fine :-)\n\nSave settings? [y/N] y\nConfiguration saved to '/Users/mark/.s3cfg'\n\n\n\n\nUsing s3cwd\n\n\nThe \"More Information\" section at the end of the document I used above says that... \"You can use our quick reference on s3cmd usage to get started.\" Ok, let's have a look... very nice! I'm moving immediately to the Save files to your local computer bits.\n\n\n\nFetching Files of the August 2020 Derecho\n\n\nThe photos I saved of damage from our August 2020 Derecho, in a images-summittdweller/2020-Aug-10-Derecho bucket, are rather depressing and certainly don't need to be super high-res for the web, so let's retrieve those and practice this workflow there first.\n\n\nThe quick reference linked above says to use a command of the form s3cmd get s3://spacename/path/ --recursive to get all files from a particular folder. In my case, that's...\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/Downloads/2020-derecho-photos\nâ•°â”€$ s3cmd get s3://images-summittdweller/2020-Aug-10-Derecho/ --recursive\n\nWARNING: Empty object name on S3 found, ignoring.\ndownload: 's3://images-summittdweller/2020-Aug-10-Derecho/Derecho - 1.png' -> './Derecho - 1.png'  [1 of 82]\n 23486944 of 23486944   100% in    1s    21.04 MB/s  done\ndownload: 's3://images-summittdweller/2020-Aug-10-Derecho/Derecho - 10.png' -> './Derecho - 10.png'  [2 of 82]\n 20861132 of 20861132   100% in    0s    23.45 MB/s  done\n...\ndownload: 's3://images-summittdweller/2020-Aug-10-Derecho/Photo-2020-08-20-19-51.jpeg' -> './Photo-2020-08-20-19-51.jpeg'  [81 of 82]\n 6277783 of 6277783   100% in    0s    16.86 MB/s  done\nERROR: Creation of file './for-the-web/' failed (Reason: Is a directory)\n\n\n\nOk, 81 images downloaded. That was sooooooooo much better than the 1000-or-so clicks it would have taken to do that manually! The only gottcha... that last error message about not downloading the for-the-web directory, which is currently empty anyway. Before I go farther, I'm going to open that DigitalOcean Spaces bucket and change the errant directory name to web-ready; that's where my \"thumbnail\" copies of all these images will be uploaded shortly.\n\n\n\nNext Step, Resize Those Images\n\n\nI found some concise and timely advice in the first web post I Googled: How to quickly resize multiple images at once on Mac. It uses exactly the tool I had in mind, the Mac-native Preview app.\n\n\nBefore begining that process I wanted to see just how much space my 81 images occupy, like so:\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/Downloads/2020-derecho-photos\nâ•°â”€$ du -sh\n2.7G\t.\n\n\n\n2.7G isn't all that much, but it's still much bigger than it needs to be. I'm firing up Preview now to see if I can reduce all images proportionally to a maximum width of 800 pixels. Be back in a couple of minutes...\n\n\nDrum roll please...\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/Downloads/2020-derecho-photos\nâ•°â”€$ du -sh\n163M\t.\n\n\n\nNot bad at all. Only took a couple of minutes and it reduced the total image size from 2.7G down to 163M. Not too shabby.\n\n\n\nUploads Complete... Next?\n\n\nIn order to upload the resized images back to DigitalOcean Spaces, I simply used the nice graphical interface available to me at https://cloud.digitalocean.com/spaces/images-summittdweller?path=2020-Aug-10-Derecho%2Fweb-ready and the Upload option there. It worked nicely, but for whatever reason two of the images failed to upload: Derecho - 38.png and Derecho - 39.png. After a little review, and retries, I could not figure out why these wouldn't upload but that's OK because they are both largely redundant with Derecho - 40.png, so we'll just stick with that one.\n\n\nSo, in the original folder image Derecho - 1.png has an endpoint of https://images.summittdweller.com/2020-Aug-10-Derecho/Derecho%20-%201.png. Makes sense. In my new web-ready directory the reduced-size copy of the same image naturally has an endpoint of https://images.summittdweller.com/2020-Aug-10-Derecho/web-ready/Derecho%20-%201.png. Fortunately, that's a \"match\" except for the addition of the web-ready subdirectory in the path. Exactly what I hoped would happen.\n\n\nThis means the next step is to...\n\n\n\nAlter Content to Include the web-ready Path\n\n\nI used the admin search (magnifying glass) feature of the Ghost instance behind this blog to find all references to https://images.summittdweller.com/2020-Aug-10-Derecho and it found: NOTHING. Yikes. Turns out all of the references were in one post, and it was draft. So I edited the draft \"manually\" and published it. Now let's try that search again... NOPE. So, the text inside those figure tags evidently isn't discoverable. â˜¹ï¸ Just as well since I think a different approach is needed.\n\n\n\nNot web-ready, originals\n\n\nSince editing the content (posts) to pick up the new web-ready directory is a royal pain, what I'm going to do now is create a new originals sub-directory in each bucket, download all the images, resize them locally as I did above, but replace the existing high-resolution images with the smaller copies AFTER I make a backup the original images in a new originals directory. That way I don't have to edit any of my posts in order to get the smaller web-ready images, but I won't lose the originals either. Beautimous.\n\n\n\nBelay That Order!\n\n\nWhile I'm confident this approach (above) will work, it may not be necessary. I looked, for example, in images-summittdweller/Norway-Photos-2019/Bergen - Hordaland, June 19, 2019 expecting to find some large images, but there were none over 800px in width. In fact, I believe they are all under 640px wide, so nothing to do there, and that's a good thing.\n\n\n\nThat's All Folks\n\n\nA detailed search of images-summittdweller didn't turn up any more enromous images that might get pushed to the web, so... \"That's All Folks\", for now at least.\n",
            "feature_image": "__GHOST_URL__/content/images/2023/04/Screenshot-2023-04-16-at-14.37.02.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-16T14:15:32.000Z",
            "updated_at": "2023-04-16T19:38:25.000Z",
            "published_at": "2023-04-16T14:57:16.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "643e0a98ddadd63e1863b838",
            "uuid": "6fdc7ed9-ac36-41a2-98c2-1895481ff297",
            "title": "another-ms-soccer-in-the-books",
            "slug": "another-ms-soccer-in-the-books",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Completed my third soccer officiating assignment tonight...  STC middle school girls and boys doubleheader, plus two B-games, vs. Williamsburg.  Another 2.5 hours total play, but again, not too bad.  I still have so much to learn! \"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Completed my third soccer officiating assignment tonight...  STC middle school girls and boys doubleheader, plus two B-games, vs. Williamsburg.  Another 2.5 hours total play, but again, not too bad.  I still have so much to learn!</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "643e0a98ddadd63e1863b838",
            "plaintext": "Completed my third soccer officiating assignment tonight... STC middle school girls and boys doubleheader, plus two B-games, vs. Williamsburg. Another 2.5 hours total play, but again, not too bad. I still have so much to learn!\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-18T03:12:24.000Z",
            "updated_at": "2023-04-18T03:14:04.000Z",
            "published_at": "2023-04-18T01:13:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "643e9a8bddadd63e1863b84c",
            "uuid": "debd2dd5-6918-463f-a711-3266072b4800",
            "title": "early-start-fixed-small-micropost-display",
            "slug": "early-start-fixed-small-micropost-display",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"I got an early start this morning (awake at 5:30 so what the heck) and had to restart my Grinnell College MacBook (which is still rebooting!) so I took a few minutes to debug the `micropost` content in this blog.  Turns out I had a regex expression that was a little too aggressive.  Removed that (it wasn't entirely necessary) and all is well now.  \\n\\n-/-/-/\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>I got an early start this morning (awake at 5:30 so what the heck) and had to restart my Grinnell College MacBook (which is still rebooting!) so I took a few minutes to debug the <code>micropost</code> content in this blog.  Turns out I had a regex expression that was a little too aggressive.  Removed that (it wasn't entirely necessary) and all is well now.</p>\n<p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "643e9a8bddadd63e1863b84c",
            "plaintext": "I got an early start this morning (awake at 5:30 so what the heck) and had to restart my Grinnell College MacBook (which is still rebooting!) so I took a few minutes to debug the micropost content in this blog. Turns out I had a regex expression that was a little too aggressive. Removed that (it wasn't entirely necessary) and all is well now.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-18T13:26:35.000Z",
            "updated_at": "2023-04-18T13:29:13.000Z",
            "published_at": "2023-04-18T11:28:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "643f30f7ddadd63e1863b860",
            "uuid": "357556f8-640b-4ee9-92e3-83faaf56d67e",
            "title": "barb-sprayed-the-snow-on-the-mountain",
            "slug": "barb-sprayed-the-snow-on-the-mountain",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Barb came in this afternoon and sprayed broadleaf control on the out-of-control \\\"Snow on the Mountain\\\" around the house.\\n\\n-/-/-/\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Barb came in this afternoon and sprayed broadleaf control on the out-of-control &quot;Snow on the Mountain&quot; around the house.</p>\n<p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "643f30f7ddadd63e1863b860",
            "plaintext": "Barb came in this afternoon and sprayed broadleaf control on the out-of-control \"Snow on the Mountain\" around the house.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-19T00:08:23.000Z",
            "updated_at": "2023-04-19T00:10:04.000Z",
            "published_at": "2023-04-18T19:09:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "643f378dddadd63e1863b874",
            "uuid": "cf2f4873-c7ca-4110-9cf8-7978c460e366",
            "title": "implementing-pagefind-here",
            "slug": "implementing-pagefind-here",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Last evening I followed [Using PageFind with Eleventy for Search](https://rknight.me/using-pagefind-with-eleventy-for-search/) to try and implement robust search capability in this blog.  I'm working in a new `pagefind` branch of the code to pull this off.\\n\\n-/-/-/\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Last evening I followed <a href=\"https://rknight.me/using-pagefind-with-eleventy-for-search/\">Using PageFind with Eleventy for Search</a> to try and implement robust search capability in this blog.  I'm working in a new <code>pagefind</code> branch of the code to pull this off.</p>\n<p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "643f378dddadd63e1863b874",
            "plaintext": "Last evening I followed Using PageFind with Eleventy for Search to try and implement robust search capability in this blog. I'm working in a new pagefind branch of the code to pull this off.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-19T00:36:29.000Z",
            "updated_at": "2023-04-20T15:00:56.000Z",
            "published_at": "2023-04-19T05:38:32.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "644153c5ddadd63e1863b89c",
            "uuid": "ad852665-e132-4b05-98ed-642a4b8f7de7",
            "title": "Searching for a Search Solution",
            "slug": "glad-i-found-pagefind",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"A few months ago I sat in on a [CFE.dev webinar](https://cfe.dev/sessions/static-search-with-pagefind/) and I was really impressed with what I saw.  I made a note to come back and look closer at [Pagefind](https://pagefind.app/), and my new blog -- this blog that you're presumably reading right now -- really needed a search feature, so the \\\"Search\\\" box on this page (I hope it's there) is the outcome.  \"}],[\"markdown\",{\"markdown\":\"## Glad I Found Pagefind\\n\\nSo, I started looking closely at search options and considered things like [Lunr](https://lunrjs.com/), which I've used before, and [Solr](https://solr.apache.org/), which I both love and hate (because of its JAVA roots).  Pagefind was, of course, also on that short list and it quickly solidified its position at the top of the list when I found [Adding search to an Eleventy site](https://mikefallows.com/posts/adding-search-to-eleventy-site/) by [Mike](https://mikefallows.com/about/). \\n\\nMike doesn't explain the setup in detail, but this comment really resonated with me so I decided to follow the same path: \\n\\n> Weirdly, I've found that I seem to read the posts on this site more than I write them. I say read, but I just mean referring to the stuff I've written because it has left my head.\\n\\nMike does provide a link to the reference he used, namely [Using PageFind with Eleventy for Search](https://rknight.me/using-pagefind-with-eleventy-for-search/) by [Robb Knight](https://rknight.me/).  I found Robb's guidance and experience to be VERY helpful.  Thank you, Robb!\"}],[\"markdown\",{\"markdown\":\"## Implementing Robb's Approach\\n\\nI won't bother duplicating what Robb explains quite well, but this wasn't a 10-minute solution for me, probably because I'm really still learning _Javascript_ and _Eleventy_, and also because I'm using a _Ghost_ back-end with packages managed via _Yarn_ rather than _npm_.   \\n\\nSo, in the few sections that follow I'll try to briefly described what's different about my approach versus Robb's, along with what didn't, and what ultimately did work.\"}],[\"markdown\",{\"markdown\":\"## `yarn`, Not `npm`\\n\\nThe first significant difference I encountered was the requirement that this blog project uses `yarn`, not `npm` for package management.  Eventually I found that I just needed to replace Robb's `npm install pagefind` command with a `yarn add pagefind` equivalent.  I don't really understand the details of that difference, but it worked. \"}],[\"markdown\",{\"markdown\":\"## eleventy.after Never Fires?\\n\\nThe biggest hurdle for me was trying to get this bit of Robb's code to work.\\n\\n```js\\nconst { execSync } = require('child_process')\\n\\nmodule.exports = function(eleventyConfig) {\\n  eleventyConfig.on('eleventy.after', () => {\\n    execSync(`npx pagefind --source _site --glob \\\\\\\"**/*.html\\\\\\\"`, { encoding: 'utf-8' })\\n  })\\n}\\n```\\n\\nIn my case the `--source` parameter needed to be `dist` since this blog is generated into a directory by that name, and my configuration object is simply `config` rather than `eleventyConfig`.  I made those simple changes and added my snippet to the `.eleventy.js` file, but found that it never triggered.  I even replaced the `execSync` function call with a simple `console.log` statement and still got nothing.  And still to this day, I have no idea why that didn't work.\\n\\nThat snippet of code is supposed to be responsible for indexing all of the `.html` files after _Eleventy_ has generated them.  Well, I found out that everything else was working properly, but the `_pagefind` bundle generated by that indexing operation was just \\\"missing\\\", since the index never was created.  That made me wonder what would happen if I \\\"forced\\\" the system to index my content in a different manner...and that wonder ultimately worked.\"}],[\"markdown\",{\"markdown\":\"## Using `npx pagefind...` to Index Content\\n\\nHaving studied some of the [Pagefind documentation](https://pagefind.app/docs/) I wondered what adding some post-processing to my build workflow might do, something like `npx pagefind --source dist`?  That ultimately worked, but not in that original form.\\n\\nI found that when I ran `yarn start` to locally rebuild the site, there was no generated `./dist/_pagefind` bundle present, so I got no \\\"Search\\\" user interface elements, but there was an empty `<div>` where that belonged.  So, with my localhost instance still running I opened a new terminal and ran `npx pagefind --source dist` in the project directory. Voila! The `./dist/_pagefind` bundle magically appeared and the \\\"Search\\\" control was instantly visible in my localhost window!  It was working, and it was beautiful.    \"}],[\"markdown\",{\"markdown\":\"## Added a `pagefind` Script... Didn't Work\\n\\nOk, with the above breakthrough in-hand I made this addition to the `scripts:` key in my `package.json` file: \\n\\n```json\\n  \\\"pagefind\\\": \\\"npx pagefind --source dist\\\"\\n```\\n\\nThen I added the following to the end of my `steps:` key in `.github/workflows/build-and-deploy.yml`:\\n\\n```yml\\n  - run: yarn pagefind\\n```      \\n\\nThis worked to some extent, but wasn't reliable and absolutely didn't work when deployed to my _DigitalOcean_ app.  The inner-workings of `yarn` and build caching in these environments is still a DEEP mystery to me!\"}],[\"markdown\",{\"markdown\":\"## Extending My `encrypt` Script\\n\\nWhat does work, both locally and on _DigitalOcean_, is essentially an \\\"extension\\\" of my old `encrypt` script.  My old build workflow included these two elements of `package.json` and `build-and-deploy.yml`:\\n\\n```json\\n    \\\"encrypt\\\": \\\"staticrypt ./dist/rebuild.html '***hidden***' --short -o ./dist/rebuild.html -f ./src/auth/login.html -t 'Summitt Dweller Blog - Rebuild' -i 'Please enter the passphrase.<br/>Hint: gh0st' --label-error 'Sorry, Ella says no. Try again.'\\\"\\n```\\n\\n...and...\\n\\n```yml\\n  - run: yarn encrypt\\n```      \\n\\nI took note of the relative path spec for `./dist/rebuild.html` in the `encrypt` command, reasoned that I should run `pagefind` in a similar fashion -- but just before encryption -- and came up with this change in `package.json`:\\n\\n```json\\n    \\\"encrypt\\\": \\\"npx pagefind --source ./dist && staticrypt ./dist/rebuild.html '***hidden***' --short -o ./dist/rebuild.html -f ./src/auth/login.html -t 'Summitt Dweller Blog - Rebuild' -i 'Please enter the passphrase.<br/>Hint: gh0st' --label-error 'Sorry, Ella says no. Try again.'\\\"\\n```\\n\\n**It works!**  \\n\\nWhen I'm running locally my `build-and-deploy.yml` doesn't apply so in that case I typically will do this IF I want my search index (and encryption) updated:\\n\\n```bash\\nyarn start\\nyarn encrypt\\n```\\n\\nWhen I rebuild in production on _DigitalOcean_ my `build-and-deploy.yml` configuration IS run so including `npx pagefind...` as part of the `yarn encrypt` step does the trick.\\n\\n\"}],[\"markdown\",{\"markdown\":\"## Time to Test...\\n\\nI'm going to save this post now and rebuild this blog on _DigitalOcean_, where with any luck, a search for a term like \\\"DEEP\\\" should return this post, and maybe one or two others.  Drum roll please...  **Huzzah!**\"}],[\"markdown\",{\"markdown\":\"## Man, Do I Feel Stupid\\n\\nPreviously I mentioned that my additon of a `package.json` script named `pagefind` didn't work, and that my _DigitalOcean_ builds kept trying to do `yarn encrypt` after `yarn build`.  Well, turns out that's because `build-and-deploy.yml`, where I had inserted the `yarn pagefind` step IS NOT in control of building my _DigitalOcean_ app.  In fact, it's a `.github` workflow so I'm really not sure what role that file plays, if any?\\n\\nI went looking in my _DigitalOcean_ app configuration settings for `yarn encrypt` and found it, in the app's \\\"App Settings\\\" subsection titled \\\"App Spec\\\".  When I view that \\\"App Spec\\\" I see this:\\n\\n```\\nalerts:\\n- rule: DEPLOYMENT_FAILED\\n- rule: DOMAIN_FAILED\\ndomains:\\n- domain: blog.summittdweller.com\\n  type: PRIMARY\\n  zone: summittdweller.com\\nenvs:\\n- key: TZ\\n  scope: RUN_AND_BUILD_TIME\\n  value: America/Chicago\\nname: blog-summittdweller-11ty-ghost\\nregion: nyc\\nstatic_sites:\\n- build_command: |-\\n    yarn build\\n    yarn encrypt\\n  environment_slug: node-js\\n  github:\\n    branch: main\\n    deploy_on_push: true\\n    repo: SummittDweller/blog-eleventy-ghost\\n  name: blog-eleventy-ghost\\n  output_dir: dist\\n  routes:\\n  - path: /\\n  source_dir: /\\n```\\n\\nNote the two `build_command:` elements.  Let's change those two steps to three, like so:\\n\\n```\\n- build_command: |-\\n    yarn build\\n    yarn pagefind\\n    yarn encrypt\\n```\\n\\nNote that I captured the \\\"App Spec\\\" in a file named `blog-summittdweller-11ty-ghost.yaml` and I've saved that file in the project directory (where I hope it will do no harm).  **Attention: After making the aforementioned addition I almost forgot to upload this file back to _DigitalOcean_ to replace our existing App Spec!**  Don't be stupid like me!\\n\\nNext, I needed a corresponding change in `package.json`, specifically these two lines (like I had them before, duh):\\n\\n```\\n  \\\"pagefind\\\": \\\"npx pagefind --source ./dist\\\",\\n  \\\"encrypt\\\": \\\"staticrypt ./dist/rebuild.html '***hidden***' --short -o ./dist/rebuild.html -f ./src/auth/login.html -t 'Summitt Dweller Blog - Rebuild' -i 'Please enter the passphrase.<br/>Hint: gh0st' --label-error 'Sorry, Ella says no. Try again.'\\\"\\n```\\n\"}],[\"markdown\",{\"markdown\":\"## Push to Rebuild\\n\\nOk, having modified **and UPLOADED** `blog-summittdweller-11ty-ghost.yaml`, and having modified `package.json`, it came time to commit and push all my changes to see what happens.  Another drum roll, please... \"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[10,3],[10,4],[10,5],[10,6],[10,7],[10,8],[10,9],[10,10],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>A few months ago I sat in on a <a href=\"https://cfe.dev/sessions/static-search-with-pagefind/\">CFE.dev webinar</a> and I was really impressed with what I saw.  I made a note to come back and look closer at <a href=\"https://pagefind.app/\">Pagefind</a>, and my new blog -- this blog that you're presumably reading right now -- really needed a search feature, so the &quot;Search&quot; box on this page (I hope it's there) is the outcome.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"glad-i-found-pagefind\">Glad I Found Pagefind</h2>\n<p>So, I started looking closely at search options and considered things like <a href=\"https://lunrjs.com/\">Lunr</a>, which I've used before, and <a href=\"https://solr.apache.org/\">Solr</a>, which I both love and hate (because of its JAVA roots).  Pagefind was, of course, also on that short list and it quickly solidified its position at the top of the list when I found <a href=\"https://mikefallows.com/posts/adding-search-to-eleventy-site/\">Adding search to an Eleventy site</a> by <a href=\"https://mikefallows.com/about/\">Mike</a>.</p>\n<p>Mike doesn't explain the setup in detail, but this comment really resonated with me so I decided to follow the same path:</p>\n<blockquote>\n<p>Weirdly, I've found that I seem to read the posts on this site more than I write them. I say read, but I just mean referring to the stuff I've written because it has left my head.</p>\n</blockquote>\n<p>Mike does provide a link to the reference he used, namely <a href=\"https://rknight.me/using-pagefind-with-eleventy-for-search/\">Using PageFind with Eleventy for Search</a> by <a href=\"https://rknight.me/\">Robb Knight</a>.  I found Robb's guidance and experience to be VERY helpful.  Thank you, Robb!</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"implementing-robbs-approach\">Implementing Robb's Approach</h2>\n<p>I won't bother duplicating what Robb explains quite well, but this wasn't a 10-minute solution for me, probably because I'm really still learning <em>Javascript</em> and <em>Eleventy</em>, and also because I'm using a <em>Ghost</em> back-end with packages managed via <em>Yarn</em> rather than <em>npm</em>.</p>\n<p>So, in the few sections that follow I'll try to briefly described what's different about my approach versus Robb's, along with what didn't, and what ultimately did work.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"yarn-not-npm\"><code>yarn</code>, Not <code>npm</code></h2>\n<p>The first significant difference I encountered was the requirement that this blog project uses <code>yarn</code>, not <code>npm</code> for package management.  Eventually I found that I just needed to replace Robb's <code>npm install pagefind</code> command with a <code>yarn add pagefind</code> equivalent.  I don't really understand the details of that difference, but it worked.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"eleventyafter-never-fires\">eleventy.after Never Fires?</h2>\n<p>The biggest hurdle for me was trying to get this bit of Robb's code to work.</p>\n<pre><code class=\"language-js\">const { execSync } = require('child_process')\n\nmodule.exports = function(eleventyConfig) {\n  eleventyConfig.on('eleventy.after', () =&gt; {\n    execSync(`npx pagefind --source _site --glob \\&quot;**/*.html\\&quot;`, { encoding: 'utf-8' })\n  })\n}\n</code></pre>\n<p>In my case the <code>--source</code> parameter needed to be <code>dist</code> since this blog is generated into a directory by that name, and my configuration object is simply <code>config</code> rather than <code>eleventyConfig</code>.  I made those simple changes and added my snippet to the <code>.eleventy.js</code> file, but found that it never triggered.  I even replaced the <code>execSync</code> function call with a simple <code>console.log</code> statement and still got nothing.  And still to this day, I have no idea why that didn't work.</p>\n<p>That snippet of code is supposed to be responsible for indexing all of the <code>.html</code> files after <em>Eleventy</em> has generated them.  Well, I found out that everything else was working properly, but the <code>_pagefind</code> bundle generated by that indexing operation was just &quot;missing&quot;, since the index never was created.  That made me wonder what would happen if I &quot;forced&quot; the system to index my content in a different manner...and that wonder ultimately worked.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"using-npx-pagefind-to-index-content\">Using <code>npx pagefind...</code> to Index Content</h2>\n<p>Having studied some of the <a href=\"https://pagefind.app/docs/\">Pagefind documentation</a> I wondered what adding some post-processing to my build workflow might do, something like <code>npx pagefind --source dist</code>?  That ultimately worked, but not in that original form.</p>\n<p>I found that when I ran <code>yarn start</code> to locally rebuild the site, there was no generated <code>./dist/_pagefind</code> bundle present, so I got no &quot;Search&quot; user interface elements, but there was an empty <code>&lt;div&gt;</code> where that belonged.  So, with my localhost instance still running I opened a new terminal and ran <code>npx pagefind --source dist</code> in the project directory. Voila! The <code>./dist/_pagefind</code> bundle magically appeared and the &quot;Search&quot; control was instantly visible in my localhost window!  It was working, and it was beautiful.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"added-a-pagefind-script-didnt-work\">Added a <code>pagefind</code> Script... Didn't Work</h2>\n<p>Ok, with the above breakthrough in-hand I made this addition to the <code>scripts:</code> key in my <code>package.json</code> file:</p>\n<pre><code class=\"language-json\">  &quot;pagefind&quot;: &quot;npx pagefind --source dist&quot;\n</code></pre>\n<p>Then I added the following to the end of my <code>steps:</code> key in <code>.github/workflows/build-and-deploy.yml</code>:</p>\n<pre><code class=\"language-yml\">  - run: yarn pagefind\n</code></pre>\n<p>This worked to some extent, but wasn't reliable and absolutely didn't work when deployed to my <em>DigitalOcean</em> app.  The inner-workings of <code>yarn</code> and build caching in these environments is still a DEEP mystery to me!</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"extending-my-encrypt-script\">Extending My <code>encrypt</code> Script</h2>\n<p>What does work, both locally and on <em>DigitalOcean</em>, is essentially an &quot;extension&quot; of my old <code>encrypt</code> script.  My old build workflow included these two elements of <code>package.json</code> and <code>build-and-deploy.yml</code>:</p>\n<pre><code class=\"language-json\">    &quot;encrypt&quot;: &quot;staticrypt ./dist/rebuild.html '***hidden***' --short -o ./dist/rebuild.html -f ./src/auth/login.html -t 'Summitt Dweller Blog - Rebuild' -i 'Please enter the passphrase.&lt;br/&gt;Hint: gh0st' --label-error 'Sorry, Ella says no. Try again.'&quot;\n</code></pre>\n<p>...and...</p>\n<pre><code class=\"language-yml\">  - run: yarn encrypt\n</code></pre>\n<p>I took note of the relative path spec for <code>./dist/rebuild.html</code> in the <code>encrypt</code> command, reasoned that I should run <code>pagefind</code> in a similar fashion -- but just before encryption -- and came up with this change in <code>package.json</code>:</p>\n<pre><code class=\"language-json\">    &quot;encrypt&quot;: &quot;npx pagefind --source ./dist &amp;&amp; staticrypt ./dist/rebuild.html '***hidden***' --short -o ./dist/rebuild.html -f ./src/auth/login.html -t 'Summitt Dweller Blog - Rebuild' -i 'Please enter the passphrase.&lt;br/&gt;Hint: gh0st' --label-error 'Sorry, Ella says no. Try again.'&quot;\n</code></pre>\n<p><strong>It works!</strong></p>\n<p>When I'm running locally my <code>build-and-deploy.yml</code> doesn't apply so in that case I typically will do this IF I want my search index (and encryption) updated:</p>\n<pre><code class=\"language-bash\">yarn start\nyarn encrypt\n</code></pre>\n<p>When I rebuild in production on <em>DigitalOcean</em> my <code>build-and-deploy.yml</code> configuration IS run so including <code>npx pagefind...</code> as part of the <code>yarn encrypt</code> step does the trick.</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"time-to-test\">Time to Test...</h2>\n<p>I'm going to save this post now and rebuild this blog on <em>DigitalOcean</em>, where with any luck, a search for a term like &quot;DEEP&quot; should return this post, and maybe one or two others.  Drum roll please...  <strong>Huzzah!</strong></p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"man-do-i-feel-stupid\">Man, Do I Feel Stupid</h2>\n<p>Previously I mentioned that my additon of a <code>package.json</code> script named <code>pagefind</code> didn't work, and that my <em>DigitalOcean</em> builds kept trying to do <code>yarn encrypt</code> after <code>yarn build</code>.  Well, turns out that's because <code>build-and-deploy.yml</code>, where I had inserted the <code>yarn pagefind</code> step IS NOT in control of building my <em>DigitalOcean</em> app.  In fact, it's a <code>.github</code> workflow so I'm really not sure what role that file plays, if any?</p>\n<p>I went looking in my <em>DigitalOcean</em> app configuration settings for <code>yarn encrypt</code> and found it, in the app's &quot;App Settings&quot; subsection titled &quot;App Spec&quot;.  When I view that &quot;App Spec&quot; I see this:</p>\n<pre><code>alerts:\n- rule: DEPLOYMENT_FAILED\n- rule: DOMAIN_FAILED\ndomains:\n- domain: blog.summittdweller.com\n  type: PRIMARY\n  zone: summittdweller.com\nenvs:\n- key: TZ\n  scope: RUN_AND_BUILD_TIME\n  value: America/Chicago\nname: blog-summittdweller-11ty-ghost\nregion: nyc\nstatic_sites:\n- build_command: |-\n    yarn build\n    yarn encrypt\n  environment_slug: node-js\n  github:\n    branch: main\n    deploy_on_push: true\n    repo: SummittDweller/blog-eleventy-ghost\n  name: blog-eleventy-ghost\n  output_dir: dist\n  routes:\n  - path: /\n  source_dir: /\n</code></pre>\n<p>Note the two <code>build_command:</code> elements.  Let's change those two steps to three, like so:</p>\n<pre><code>- build_command: |-\n    yarn build\n    yarn pagefind\n    yarn encrypt\n</code></pre>\n<p>Note that I captured the &quot;App Spec&quot; in a file named <code>blog-summittdweller-11ty-ghost.yaml</code> and I've saved that file in the project directory (where I hope it will do no harm).  <strong>Attention: After making the aforementioned addition I almost forgot to upload this file back to <em>DigitalOcean</em> to replace our existing App Spec!</strong>  Don't be stupid like me!</p>\n<p>Next, I needed a corresponding change in <code>package.json</code>, specifically these two lines (like I had them before, duh):</p>\n<pre><code>  &quot;pagefind&quot;: &quot;npx pagefind --source ./dist&quot;,\n  &quot;encrypt&quot;: &quot;staticrypt ./dist/rebuild.html '***hidden***' --short -o ./dist/rebuild.html -f ./src/auth/login.html -t 'Summitt Dweller Blog - Rebuild' -i 'Please enter the passphrase.&lt;br/&gt;Hint: gh0st' --label-error 'Sorry, Ella says no. Try again.'&quot;\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"push-to-rebuild\">Push to Rebuild</h2>\n<p>Ok, having modified <strong>and UPLOADED</strong> <code>blog-summittdweller-11ty-ghost.yaml</code>, and having modified <code>package.json</code>, it came time to commit and push all my changes to see what happens.  Another drum roll, please...</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "644153c5ddadd63e1863b89c",
            "plaintext": "A few months ago I sat in on a CFE.dev webinar and I was really impressed with what I saw. I made a note to come back and look closer at Pagefind, and my new blog -- this blog that you're presumably reading right now -- really needed a search feature, so the \"Search\" box on this page (I hope it's there) is the outcome.\n\n\n\nGlad I Found Pagefind\n\n\nSo, I started looking closely at search options and considered things like Lunr, which I've used before, and Solr, which I both love and hate (because of its JAVA roots). Pagefind was, of course, also on that short list and it quickly solidified its position at the top of the list when I found Adding search to an Eleventy site by Mike.\n\n\nMike doesn't explain the setup in detail, but this comment really resonated with me so I decided to follow the same path:\n\n\n\n\n\nWeirdly, I've found that I seem to read the posts on this site more than I write them. I say read, but I just mean referring to the stuff I've written because it has left my head.\n\n\n\nMike does provide a link to the reference he used, namely Using PageFind with Eleventy for Search by Robb Knight. I found Robb's guidance and experience to be VERY helpful. Thank you, Robb!\n\n\n\nImplementing Robb's Approach\n\n\nI won't bother duplicating what Robb explains quite well, but this wasn't a 10-minute solution for me, probably because I'm really still learning Javascript and Eleventy, and also because I'm using a Ghost back-end with packages managed via Yarn rather than npm.\n\n\nSo, in the few sections that follow I'll try to briefly described what's different about my approach versus Robb's, along with what didn't, and what ultimately did work.\n\n\n\nyarn, Not npm\n\n\nThe first significant difference I encountered was the requirement that this blog project uses yarn, not npm for package management. Eventually I found that I just needed to replace Robb's npm install pagefind command with a yarn add pagefind equivalent. I don't really understand the details of that difference, but it worked.\n\n\n\neleventy.after Never Fires?\n\n\nThe biggest hurdle for me was trying to get this bit of Robb's code to work.\n\n\nconst { execSync } = require('child_process')\n\nmodule.exports = function(eleventyConfig) {\n  eleventyConfig.on('eleventy.after', () => {\n    execSync(`npx pagefind --source _site --glob \\\"**/*.html\\\"`, { encoding: 'utf-8' })\n  })\n}\n\n\n\nIn my case the --source parameter needed to be dist since this blog is generated into a directory by that name, and my configuration object is simply config rather than eleventyConfig. I made those simple changes and added my snippet to the .eleventy.js file, but found that it never triggered. I even replaced the execSync function call with a simple console.log statement and still got nothing. And still to this day, I have no idea why that didn't work.\n\n\nThat snippet of code is supposed to be responsible for indexing all of the .html files after Eleventy has generated them. Well, I found out that everything else was working properly, but the _pagefind bundle generated by that indexing operation was just \"missing\", since the index never was created. That made me wonder what would happen if I \"forced\" the system to index my content in a different manner...and that wonder ultimately worked.\n\n\n\nUsing npx pagefind... to Index Content\n\n\nHaving studied some of the Pagefind documentation I wondered what adding some post-processing to my build workflow might do, something like npx pagefind --source dist? That ultimately worked, but not in that original form.\n\n\nI found that when I ran yarn start to locally rebuild the site, there was no generated ./dist/_pagefind bundle present, so I got no \"Search\" user interface elements, but there was an empty <div> where that belonged. So, with my localhost instance still running I opened a new terminal and ran npx pagefind --source dist in the project directory. Voila! The ./dist/_pagefind bundle magically appeared and the \"Search\" control was instantly visible in my localhost window! It was working, and it was beautiful.\n\n\n\nAdded a pagefind Script... Didn't Work\n\n\nOk, with the above breakthrough in-hand I made this addition to the scripts: key in my package.json file:\n\n\n  \"pagefind\": \"npx pagefind --source dist\"\n\n\n\nThen I added the following to the end of my steps: key in .github/workflows/build-and-deploy.yml:\n\n\n  - run: yarn pagefind\n\n\n\nThis worked to some extent, but wasn't reliable and absolutely didn't work when deployed to my DigitalOcean app. The inner-workings of yarn and build caching in these environments is still a DEEP mystery to me!\n\n\n\nExtending My encrypt Script\n\n\nWhat does work, both locally and on DigitalOcean, is essentially an \"extension\" of my old encrypt script. My old build workflow included these two elements of package.json and build-and-deploy.yml:\n\n\n    \"encrypt\": \"staticrypt ./dist/rebuild.html '***hidden***' --short -o ./dist/rebuild.html -f ./src/auth/login.html -t 'Summitt Dweller Blog - Rebuild' -i 'Please enter the passphrase.<br/>Hint: gh0st' --label-error 'Sorry, Ella says no. Try again.'\"\n\n\n\n...and...\n\n\n  - run: yarn encrypt\n\n\n\nI took note of the relative path spec for ./dist/rebuild.html in the encrypt command, reasoned that I should run pagefind in a similar fashion -- but just before encryption -- and came up with this change in package.json:\n\n\n    \"encrypt\": \"npx pagefind --source ./dist && staticrypt ./dist/rebuild.html '***hidden***' --short -o ./dist/rebuild.html -f ./src/auth/login.html -t 'Summitt Dweller Blog - Rebuild' -i 'Please enter the passphrase.<br/>Hint: gh0st' --label-error 'Sorry, Ella says no. Try again.'\"\n\n\n\nIt works!\n\n\nWhen I'm running locally my build-and-deploy.yml doesn't apply so in that case I typically will do this IF I want my search index (and encryption) updated:\n\n\nyarn start\nyarn encrypt\n\n\n\nWhen I rebuild in production on DigitalOcean my build-and-deploy.yml configuration IS run so including npx pagefind... as part of the yarn encrypt step does the trick.\n\n\n\nTime to Test...\n\n\nI'm going to save this post now and rebuild this blog on DigitalOcean, where with any luck, a search for a term like \"DEEP\" should return this post, and maybe one or two others. Drum roll please... Huzzah!\n\n\n\nMan, Do I Feel Stupid\n\n\nPreviously I mentioned that my additon of a package.json script named pagefind didn't work, and that my DigitalOcean builds kept trying to do yarn encrypt after yarn build. Well, turns out that's because build-and-deploy.yml, where I had inserted the yarn pagefind step IS NOT in control of building my DigitalOcean app. In fact, it's a .github workflow so I'm really not sure what role that file plays, if any?\n\n\nI went looking in my DigitalOcean app configuration settings for yarn encrypt and found it, in the app's \"App Settings\" subsection titled \"App Spec\". When I view that \"App Spec\" I see this:\n\n\nalerts:\n- rule: DEPLOYMENT_FAILED\n- rule: DOMAIN_FAILED\ndomains:\n- domain: blog.summittdweller.com\n  type: PRIMARY\n  zone: summittdweller.com\nenvs:\n- key: TZ\n  scope: RUN_AND_BUILD_TIME\n  value: America/Chicago\nname: blog-summittdweller-11ty-ghost\nregion: nyc\nstatic_sites:\n- build_command: |-\n    yarn build\n    yarn encrypt\n  environment_slug: node-js\n  github:\n    branch: main\n    deploy_on_push: true\n    repo: SummittDweller/blog-eleventy-ghost\n  name: blog-eleventy-ghost\n  output_dir: dist\n  routes:\n  - path: /\n  source_dir: /\n\n\n\nNote the two build_command: elements. Let's change those two steps to three, like so:\n\n\n- build_command: |-\n    yarn build\n    yarn pagefind\n    yarn encrypt\n\n\n\nNote that I captured the \"App Spec\" in a file named blog-summittdweller-11ty-ghost.yaml and I've saved that file in the project directory (where I hope it will do no harm). Attention: After making the aforementioned addition I almost forgot to upload this file back to DigitalOcean to replace our existing App Spec! Don't be stupid like me!\n\n\nNext, I needed a corresponding change in package.json, specifically these two lines (like I had them before, duh):\n\n\n  \"pagefind\": \"npx pagefind --source ./dist\",\n  \"encrypt\": \"staticrypt ./dist/rebuild.html '***hidden***' --short -o ./dist/rebuild.html -f ./src/auth/login.html -t 'Summitt Dweller Blog - Rebuild' -i 'Please enter the passphrase.<br/>Hint: gh0st' --label-error 'Sorry, Ella says no. Try again.'\"\n\n\n\n\nPush to Rebuild\n\n\nOk, having modified and UPLOADED blog-summittdweller-11ty-ghost.yaml, and having modified package.json, it came time to commit and push all my changes to see what happens. Another drum roll, please...\n",
            "feature_image": "https://images.unsplash.com/photo-1496449903678-68ddcb189a24?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDIzfHxzZWFyY2h8ZW58MHx8fHwxNjgyMDAyODkw&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-20T15:01:25.000Z",
            "updated_at": "2023-04-20T20:41:53.000Z",
            "published_at": "2023-04-20T17:02:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64459332ddadd63e1863babf",
            "uuid": "16e69fae-76f5-4b55-8fbd-14333e72d071",
            "title": "sold-mower-and-bunk-bed",
            "slug": "sold-mower-and-bunk-bed",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Both my EGO self-propelled mower and old twin-over-full bunk bed sold and taken away today.  Yay!  Next up, The Rolling Stone camper and Ecotric eBike.\\n\\n-/-/-/\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Both my EGO self-propelled mower and old twin-over-full bunk bed sold and taken away today.  Yay!  Next up, The Rolling Stone camper and Ecotric eBike.</p>\n<p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "64459332ddadd63e1863babf",
            "plaintext": "Both my EGO self-propelled mower and old twin-over-full bunk bed sold and taken away today. Yay! Next up, The Rolling Stone camper and Ecotric eBike.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-23T20:21:06.000Z",
            "updated_at": "2023-04-23T20:23:43.000Z",
            "published_at": "2023-04-23T20:23:43.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "644c7b91ddadd63e1863bb93",
            "uuid": "7c41ad77-ffec-4ab7-848c-84d11ed0c7e5",
            "title": "pca-weekend",
            "slug": "pca-weekend",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Departing for the PCA (Peoples' Choice Awards) weekend in Clear Lake / Mason City.  Got The Some IT in tow.  First camping of the season.\\n\\n-/-/-/\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Departing for the PCA (Peoples' Choice Awards) weekend in Clear Lake / Mason City.  Got The Some IT in tow.  First camping of the season.</p>\n<p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "644c7b91ddadd63e1863bb93",
            "plaintext": "Departing for the PCA (Peoples' Choice Awards) weekend in Clear Lake / Mason City. Got The Some IT in tow. First camping of the season.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-29T02:06:09.000Z",
            "updated_at": "2023-04-29T02:18:39.000Z",
            "published_at": "2023-04-28T18:31:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "644d0e1bddadd63e1863bbbf",
            "uuid": "fb52cb75-79e3-43dd-9570-f3f01fcd9c4a",
            "title": "cold-morning-clear-lake",
            "slug": "cold-morning-clear-lake",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Camping at Clear Lake State Park and I have to admit it's cold.  My phone says the temp is 37&deg;F and my little space heater appears to be broken.  It gets warm but the fan doesn't work so that's all.  Heading to the shower, then breakfast at TJs, then to Menards for a new space heater!\\n\\n-/-/-/\\nlocation: Clear Lake State Park\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Camping at Clear Lake State Park and I have to admit it's cold.  My phone says the temp is 37Â°F and my little space heater appears to be broken.  It gets warm but the fan doesn't work so that's all.  Heading to the shower, then breakfast at TJs, then to Menards for a new space heater!</p>\n<p>-/-/-/<br>\nlocation: Clear Lake State Park</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "644d0e1bddadd63e1863bbbf",
            "plaintext": "Camping at Clear Lake State Park and I have to admit it's cold. My phone says the temp is 37Â°F and my little space heater appears to be broken. It gets warm but the fan doesn't work so that's all. Heading to the shower, then breakfast at TJs, then to Menards for a new space heater!\n\n\n-/-/-/\n\nlocation: Clear Lake State Park\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-04-29T12:31:23.000Z",
            "updated_at": "2023-04-29T12:33:46.000Z",
            "published_at": "2023-04-29T12:33:46.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6451148eddadd63e1863bbd3",
            "uuid": "7d37eb05-ba14-4bf9-9557-013333ce6a7e",
            "title": "middle-school-soccer-dual",
            "slug": "middle-school-soccer",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"My back isn't as sore this morning as I expected it might be.  I did ref some middle school soccer matches last night on a VERY hard field at STC.  Managed to trip over a sprinkler head that I don't think has been \\\"used\\\" in years.\\n\\n-/-/-/\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>My back isn't as sore this morning as I expected it might be.  I did ref some middle school soccer matches last night on a VERY hard field at STC.  Managed to trip over a sprinkler head that I don't think has been &quot;used&quot; in years.</p>\n<p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "6451148eddadd63e1863bbd3",
            "plaintext": "My back isn't as sore this morning as I expected it might be. I did ref some middle school soccer matches last night on a VERY hard field at STC. Managed to trip over a sprinkler head that I don't think has been \"used\" in years.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-05-02T13:47:58.000Z",
            "updated_at": "2023-05-02T13:50:12.000Z",
            "published_at": "2023-05-02T11:49:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64553032ddadd63e1863bbed",
            "uuid": "1bc93eae-03a0-447c-acd0-12f93acdc72c",
            "title": "fathers-and-sons",
            "slug": "fathers-and-sons",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Traveled to Iowa City to see Luis A. perform in a production of \\\"Fathers and Sons\\\" at the University of Iowa, part of the annual New Plays Festival there.  Found a geocache outside the theatre after the show.\\n\\n-/-/-/\\nlocation: Iowa City, Iowa\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Traveled to Iowa City to see Luis A. perform in a production of &quot;Fathers and Sons&quot; at the University of Iowa, part of the annual New Plays Festival there.  Found a geocache outside the theatre after the show.</p>\n<p>-/-/-/<br>\nlocation: Iowa City, Iowa</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "64553032ddadd63e1863bbed",
            "plaintext": "Traveled to Iowa City to see Luis A. perform in a production of \"Fathers and Sons\" at the University of Iowa, part of the annual New Plays Festival there. Found a geocache outside the theatre after the show.\n\n\n-/-/-/\n\nlocation: Iowa City, Iowa\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-05-05T16:34:58.000Z",
            "updated_at": "2023-05-07T15:34:11.000Z",
            "published_at": "2023-05-05T01:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "645955f9ddadd63e1863bc07",
            "uuid": "ae2c9acd-ef5c-44e2-87c9-e198cb4f2c4e",
            "title": "applied-BioAdvanced-Concentrate-Season-Long-Weed-Killer",
            "slug": "applied-bioadvanced-concentrate-season-long-weed-killer",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Today I applied one bottle (29 oz.) of  BioAdvancedâ„¢ Concentrate Season Long Weed Killer to my entire lawn in 9 applications using my Ryobi 1-gallon chemical sprayer.  Mix was 3.5oz per tank with each application covering about 500 square feet. \\n\\nWe shall see how it performs.  See https://bioadvanced.com/season-long-weed-control-for-lawns.html for more details.\\n\\n-/-/-/\\nmixture: 704050A \\nMenardsSKU: 2634119\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Today I applied one bottle (29 oz.) of  BioAdvancedâ„¢ Concentrate Season Long Weed Killer to my entire lawn in 9 applications using my Ryobi 1-gallon chemical sprayer.  Mix was 3.5oz per tank with each application covering about 500 square feet.</p>\n<p>We shall see how it performs.  See <a href=\"https://bioadvanced.com/season-long-weed-control-for-lawns.html\">https://bioadvanced.com/season-long-weed-control-for-lawns.html</a> for more details.</p>\n<p>-/-/-/<br>\nmixture: 704050A<br>\nMenardsSKU: 2634119<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "645955f9ddadd63e1863bc07",
            "plaintext": "Today I applied one bottle (29 oz.) of BioAdvancedâ„¢ Concentrate Season Long Weed Killer to my entire lawn in 9 applications using my Ryobi 1-gallon chemical sprayer. Mix was 3.5oz per tank with each application covering about 500 square feet.\n\n\nWe shall see how it performs. See https://bioadvanced.com/season-long-weed-control-for-lawns.html for more details.\n\n\n-/-/-/\n\nmixture: 704050A\n\nMenardsSKU: 2634119\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-05-08T20:05:13.000Z",
            "updated_at": "2023-05-08T20:16:58.000Z",
            "published_at": "2023-05-07T20:12:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "645a6c49ddadd63e1863bc27",
            "uuid": "1626ddfc-6816-4b1f-b401-72507eee83fc",
            "title": "lawn-is-looking-better",
            "slug": "lawn-is-looking-better",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"Mowing the lawn this evening and I'm happy to report that most of the weeds I treated last evening have curling leaves.  As Young Frankenstein might say... This could work!\"]]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Mowing the lawn this evening and I'm happy to report that most of the weeds I treated last evening have curling leaves. Â As Young Frankenstein might say... This could work!</p>",
            "comment_id": "645a6c49ddadd63e1863bc27",
            "plaintext": "Mowing the lawn this evening and I'm happy to report that most of the weeds I treated last evening have curling leaves. Â As Young Frankenstein might say... This could work!",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-05-09T15:52:41.000Z",
            "updated_at": "2023-05-09T15:54:33.000Z",
            "published_at": "2023-05-08T23:52:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "645ad272ddadd63e1863bc36",
            "uuid": "4fbbe0de-00ec-48c0-a003-4d2c142b69ae",
            "title": "wrapping-hugo-in-npm",
            "slug": "wrapping-hugo-in-npm",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"I ran into a big road block with implementation of Pagefind in _Rootstalk_ today... everything works fine in development, but I can't easily deploy to _Azure_ because there's no way to \\\"inject\\\" Pagefind into an Azure Static Web App build before the \\\"public\\\" content gets deployed.  I can generate the Pagefind parts after deployment, but that does me no good.  \\n\\nTomorrow I need to have a look at my _Rootstalk_ DigitalOcean deployment to see if what I already have might work there (DO uses a build script that I can add an `npx...` command to).  If that fails I need to look back at https://www.blogtrack.io/blog/powerful-blog-setup-with-hugo-and-npm/ to see if there's a solution there for me.  \\n\\n-/-/-/\\nlocation: Toledo, IA\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>I ran into a big road block with implementation of Pagefind in <em>Rootstalk</em> today... everything works fine in development, but I can't easily deploy to <em>Azure</em> because there's no way to &quot;inject&quot; Pagefind into an Azure Static Web App build before the &quot;public&quot; content gets deployed.  I can generate the Pagefind parts after deployment, but that does me no good.</p>\n<p>Tomorrow I need to have a look at my <em>Rootstalk</em> DigitalOcean deployment to see if what I already have might work there (DO uses a build script that I can add an <code>npx...</code> command to).  If that fails I need to look back at <a href=\"https://www.blogtrack.io/blog/powerful-blog-setup-with-hugo-and-npm/\">https://www.blogtrack.io/blog/powerful-blog-setup-with-hugo-and-npm/</a> to see if there's a solution there for me.</p>\n<p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "645ad272ddadd63e1863bc36",
            "plaintext": "I ran into a big road block with implementation of Pagefind in Rootstalk today... everything works fine in development, but I can't easily deploy to Azure because there's no way to \"inject\" Pagefind into an Azure Static Web App build before the \"public\" content gets deployed. I can generate the Pagefind parts after deployment, but that does me no good.\n\n\nTomorrow I need to have a look at my Rootstalk DigitalOcean deployment to see if what I already have might work there (DO uses a build script that I can add an npx... command to). If that fails I need to look back at https://www.blogtrack.io/blog/powerful-blog-setup-with-hugo-and-npm/ to see if there's a solution there for me.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-05-09T23:08:34.000Z",
            "updated_at": "2023-05-10T14:56:55.000Z",
            "published_at": "2023-05-09T23:13:09.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "645baab7ddadd63e1863bc52",
            "uuid": "c04500f4-409c-4eab-b301-1151a715270d",
            "title": "A Pagefind Problem?",
            "slug": "a-pagefind-problem",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"# Not Just a Hugo Issue\\n\\nTake note of the question mark at the end of the title, otherwise it could be somewhat misleading.  This is not really a problem with Hugo, but one with cloud deployment of Hugo static apps, particularly as an Azure Static Web App.\\n\\n# The Nutshell\\n\\nAs you may know from [post 143](https://static.grinnell.edu/dlad-blog/posts/143-significant-rootstalk-retooling/), I have successfully installed and configured [Pagefind](https://pagefind.app/) in [Rootstalk](https://rootstalk.grinnell.edu), but thus far it only works locally.  When I try to deploy Pagefind to the cloud, specifically as an Azure Static Web App, I can't make it work because there's no apparent way to invoke the necessary `npx pagefind...` command AFTER Hugo compiles the site, but BEFORE the site gets deployed.  Azure leverages GitHub Actions to build Hugo sites, but that process also involves some custom/proprietary Azure scripts.  Therein lies the problem.  \\n\\nThe Azure script auto-detects the presence of a Hugo project, or any one of many other platforms.  That makes the process super-easy to use, but nearly impossible to \\\"customize\\\".  Azure does provide some configuration variables to influence the script behavior, most notably there's an `app_build_command` variable that looks promising, but it only works for `node` builds, and not for Hugo.\\n\\n# Three Possible Solutions\\n\\nI can reasonably see three possible solutions to this dilema.  In order of simplicity they are:\\n\\n## 1. Skip Azure and Deploy Only to DigitalOcean\\n\\nUltimately, Rootstalk's production instance is a DigitalOcean (DO) static web app, Azure is only used for \\\"staging\\\" of a locally viable Rootstalk instance.  DO doesn't use GitHub Actions, a drawback in my book, so its build script, called an \\\"App Spec\\\" in DO, is a little more \\\"open\\\".  The critical portion of the App Spec I use to deploy Rootstalk in DO reads like this:\\n\\n```\\nstatic_sites:\\n- build_command: hugo -d public\\n```\\n\\nThat's it, just a simple `hugo -d public` command.  So, in theory I should be able to just change that to read:\\n\\n```\\nstatic_sites:\\n- build_command: hugo -d public && npm_config_yes=true npx pagefind --source \\\"public\\\" --bundle-dir ../static/_pagefind\\n```\\n\\nIt's basically just a \\\"compound\\\" command to run `npx` immediately after `hugo` is done compiling.  \\n\\nThe problem with this very simple solution, assuming it even works, is that it's somewhat unique to Rootstalk which is already deployed to DigitalOcean.  Other Hugo projects, and I have many like [this blog](https://static.grinnell.edu/dlad-blog), that need Azure or another cloud provider other than DO, would not benefit from this fix.\\n\\n### Update 12-May-2023: Same Problem Exists in DigitalOcean\\n\\nWell, I tried.  I attempted to push my Pagefind additions to Rootstalk forward directly into production on DigitalOcean.  Unfortunately, that failed in similar fashion to what I saw in Azure.  It all works locally, but DigitalOcean, like Azure, has no way of \\\"detecting\\\" that my Hugo project has an NPM component, and therefore takes no steps to build NPM or Pagefind into my solution.  \\n\\nSo, I'm moving on to option #2 below.  Wish me luck.  \\n\\n## 2. Wrap Hugo in `npm`\\n\\nSo, `node` and `npm` seem to be all the rage these days, and perhaps for good reason.  I recently fell in love with [Eleventy/11ty](https://www.11ty.dev) because it's Javascript, not Go, and it's elegantly simple with tons of flexibility.  If my Azure Static Web App was framed in `node.js`, as both _Eleventy_ and _Pagefind_ are, there would be no problem.  The Azure scripts used to deploy those frameworks are far more customizable than Hugo, and there's documentation to prove it.  \\n\\nSo, how might I approach something like this?  Well, [A Powerful Blog Setup with Hugo and NPM](https://www.blogtrack.io/blog/powerful-blog-setup-with-hugo-and-npm/) by Tom Hombergs looks like a promising place to start.  The process that Tom advocates leverages a neat little package called [hugo-bin](https://www.npmjs.com/package/hugo-bin).  \\n\\nIf strategy #1 fails I'll certainly give this #2 a try.  Even if #1 works, I might give this strategy a spin if/when I re-tool [this blog](https://static.grinnell.edu/dlad-blog).  \\n\\n## Update 29-May-2023: NPM is GREAT!\\n\\nSince my first option (above) failed very quickly, I moved on to this option and I honestly think I might transition every static site that I have to be wrapped inside NPM, it works wonderfully and is a really attractive solution for so many ills!  \\n\\nI'm going to document my experience with NPM wrapped around Hugo and will post that document here soon, probably as [Wrap EVERYTHING in NPM!](https://blog.summittdweller.com/wrap-everything-in-npm/).  \\n\\n## 3. Transition from Hugo to Eleventy\\n\\nReasonable?  Yes.  A lot of work?  That's relative.  The right thing to do?  Probably.  \\n\\nSo, it's already been done, see [This Blog in Eleventy + Ghost](https://blog.summittdweller.com/this-blog-in-eleventy-ghost/) and [Searching for a Search Solution](https://blog.summittdweller.com/glad-i-found-pagefind/).  That's all I'm going to say about this option, a definite maybe.  \\n\\n---\\n\\nThat's all folks... for now.  \\n\\n\\n\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><h1 id=\"not-just-a-hugo-issue\">Not Just a Hugo Issue</h1>\n<p>Take note of the question mark at the end of the title, otherwise it could be somewhat misleading.  This is not really a problem with Hugo, but one with cloud deployment of Hugo static apps, particularly as an Azure Static Web App.</p>\n<h1 id=\"the-nutshell\">The Nutshell</h1>\n<p>As you may know from <a href=\"https://static.grinnell.edu/dlad-blog/posts/143-significant-rootstalk-retooling/\">post 143</a>, I have successfully installed and configured <a href=\"https://pagefind.app/\">Pagefind</a> in <a href=\"https://rootstalk.grinnell.edu\">Rootstalk</a>, but thus far it only works locally.  When I try to deploy Pagefind to the cloud, specifically as an Azure Static Web App, I can't make it work because there's no apparent way to invoke the necessary <code>npx pagefind...</code> command AFTER Hugo compiles the site, but BEFORE the site gets deployed.  Azure leverages GitHub Actions to build Hugo sites, but that process also involves some custom/proprietary Azure scripts.  Therein lies the problem.</p>\n<p>The Azure script auto-detects the presence of a Hugo project, or any one of many other platforms.  That makes the process super-easy to use, but nearly impossible to &quot;customize&quot;.  Azure does provide some configuration variables to influence the script behavior, most notably there's an <code>app_build_command</code> variable that looks promising, but it only works for <code>node</code> builds, and not for Hugo.</p>\n<h1 id=\"three-possible-solutions\">Three Possible Solutions</h1>\n<p>I can reasonably see three possible solutions to this dilema.  In order of simplicity they are:</p>\n<h2 id=\"1-skip-azure-and-deploy-only-to-digitalocean\">1. Skip Azure and Deploy Only to DigitalOcean</h2>\n<p>Ultimately, Rootstalk's production instance is a DigitalOcean (DO) static web app, Azure is only used for &quot;staging&quot; of a locally viable Rootstalk instance.  DO doesn't use GitHub Actions, a drawback in my book, so its build script, called an &quot;App Spec&quot; in DO, is a little more &quot;open&quot;.  The critical portion of the App Spec I use to deploy Rootstalk in DO reads like this:</p>\n<pre><code>static_sites:\n- build_command: hugo -d public\n</code></pre>\n<p>That's it, just a simple <code>hugo -d public</code> command.  So, in theory I should be able to just change that to read:</p>\n<pre><code>static_sites:\n- build_command: hugo -d public &amp;&amp; npm_config_yes=true npx pagefind --source &quot;public&quot; --bundle-dir ../static/_pagefind\n</code></pre>\n<p>It's basically just a &quot;compound&quot; command to run <code>npx</code> immediately after <code>hugo</code> is done compiling.</p>\n<p>The problem with this very simple solution, assuming it even works, is that it's somewhat unique to Rootstalk which is already deployed to DigitalOcean.  Other Hugo projects, and I have many like <a href=\"https://static.grinnell.edu/dlad-blog\">this blog</a>, that need Azure or another cloud provider other than DO, would not benefit from this fix.</p>\n<h3 id=\"update-12-may-2023-same-problem-exists-in-digitalocean\">Update 12-May-2023: Same Problem Exists in DigitalOcean</h3>\n<p>Well, I tried.  I attempted to push my Pagefind additions to Rootstalk forward directly into production on DigitalOcean.  Unfortunately, that failed in similar fashion to what I saw in Azure.  It all works locally, but DigitalOcean, like Azure, has no way of &quot;detecting&quot; that my Hugo project has an NPM component, and therefore takes no steps to build NPM or Pagefind into my solution.</p>\n<p>So, I'm moving on to option #2 below.  Wish me luck.</p>\n<h2 id=\"2-wrap-hugo-in-npm\">2. Wrap Hugo in <code>npm</code></h2>\n<p>So, <code>node</code> and <code>npm</code> seem to be all the rage these days, and perhaps for good reason.  I recently fell in love with <a href=\"https://www.11ty.dev\">Eleventy/11ty</a> because it's Javascript, not Go, and it's elegantly simple with tons of flexibility.  If my Azure Static Web App was framed in <code>node.js</code>, as both <em>Eleventy</em> and <em>Pagefind</em> are, there would be no problem.  The Azure scripts used to deploy those frameworks are far more customizable than Hugo, and there's documentation to prove it.</p>\n<p>So, how might I approach something like this?  Well, <a href=\"https://www.blogtrack.io/blog/powerful-blog-setup-with-hugo-and-npm/\">A Powerful Blog Setup with Hugo and NPM</a> by Tom Hombergs looks like a promising place to start.  The process that Tom advocates leverages a neat little package called <a href=\"https://www.npmjs.com/package/hugo-bin\">hugo-bin</a>.</p>\n<p>If strategy #1 fails I'll certainly give this #2 a try.  Even if #1 works, I might give this strategy a spin if/when I re-tool <a href=\"https://static.grinnell.edu/dlad-blog\">this blog</a>.</p>\n<h2 id=\"update-29-may-2023-npm-is-great\">Update 29-May-2023: NPM is GREAT!</h2>\n<p>Since my first option (above) failed very quickly, I moved on to this option and I honestly think I might transition every static site that I have to be wrapped inside NPM, it works wonderfully and is a really attractive solution for so many ills!</p>\n<p>I'm going to document my experience with NPM wrapped around Hugo and will post that document here soon, probably as <a href=\"https://blog.summittdweller.com/wrap-everything-in-npm/\">Wrap EVERYTHING in NPM!</a>.</p>\n<h2 id=\"3-transition-from-hugo-to-eleventy\">3. Transition from Hugo to Eleventy</h2>\n<p>Reasonable?  Yes.  A lot of work?  That's relative.  The right thing to do?  Probably.</p>\n<p>So, it's already been done, see <a href=\"https://blog.summittdweller.com/this-blog-in-eleventy-ghost/\">This Blog in Eleventy + Ghost</a> and <a href=\"https://blog.summittdweller.com/glad-i-found-pagefind/\">Searching for a Search Solution</a>.  That's all I'm going to say about this option, a definite maybe.</p>\n<hr>\n<p>That's all folks... for now.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "645baab7ddadd63e1863bc52",
            "plaintext": "Not Just a Hugo Issue\n\n\nTake note of the question mark at the end of the title, otherwise it could be somewhat misleading. This is not really a problem with Hugo, but one with cloud deployment of Hugo static apps, particularly as an Azure Static Web App.\n\n\n\nThe Nutshell\n\n\nAs you may know from post 143, I have successfully installed and configured Pagefind in Rootstalk, but thus far it only works locally. When I try to deploy Pagefind to the cloud, specifically as an Azure Static Web App, I can't make it work because there's no apparent way to invoke the necessary npx pagefind... command AFTER Hugo compiles the site, but BEFORE the site gets deployed. Azure leverages GitHub Actions to build Hugo sites, but that process also involves some custom/proprietary Azure scripts. Therein lies the problem.\n\n\nThe Azure script auto-detects the presence of a Hugo project, or any one of many other platforms. That makes the process super-easy to use, but nearly impossible to \"customize\". Azure does provide some configuration variables to influence the script behavior, most notably there's an app_build_command variable that looks promising, but it only works for node builds, and not for Hugo.\n\n\n\nThree Possible Solutions\n\n\nI can reasonably see three possible solutions to this dilema. In order of simplicity they are:\n\n\n\n1. Skip Azure and Deploy Only to DigitalOcean\n\n\nUltimately, Rootstalk's production instance is a DigitalOcean (DO) static web app, Azure is only used for \"staging\" of a locally viable Rootstalk instance. DO doesn't use GitHub Actions, a drawback in my book, so its build script, called an \"App Spec\" in DO, is a little more \"open\". The critical portion of the App Spec I use to deploy Rootstalk in DO reads like this:\n\n\nstatic_sites:\n- build_command: hugo -d public\n\n\n\nThat's it, just a simple hugo -d public command. So, in theory I should be able to just change that to read:\n\n\nstatic_sites:\n- build_command: hugo -d public && npm_config_yes=true npx pagefind --source \"public\" --bundle-dir ../static/_pagefind\n\n\n\nIt's basically just a \"compound\" command to run npx immediately after hugo is done compiling.\n\n\nThe problem with this very simple solution, assuming it even works, is that it's somewhat unique to Rootstalk which is already deployed to DigitalOcean. Other Hugo projects, and I have many like this blog, that need Azure or another cloud provider other than DO, would not benefit from this fix.\n\n\n\nUpdate 12-May-2023: Same Problem Exists in DigitalOcean\n\n\nWell, I tried. I attempted to push my Pagefind additions to Rootstalk forward directly into production on DigitalOcean. Unfortunately, that failed in similar fashion to what I saw in Azure. It all works locally, but DigitalOcean, like Azure, has no way of \"detecting\" that my Hugo project has an NPM component, and therefore takes no steps to build NPM or Pagefind into my solution.\n\n\nSo, I'm moving on to option #2 below. Wish me luck.\n\n\n\n2. Wrap Hugo in npm\n\n\nSo, node and npm seem to be all the rage these days, and perhaps for good reason. I recently fell in love with Eleventy/11ty because it's Javascript, not Go, and it's elegantly simple with tons of flexibility. If my Azure Static Web App was framed in node.js, as both Eleventy and Pagefind are, there would be no problem. The Azure scripts used to deploy those frameworks are far more customizable than Hugo, and there's documentation to prove it.\n\n\nSo, how might I approach something like this? Well, A Powerful Blog Setup with Hugo and NPM by Tom Hombergs looks like a promising place to start. The process that Tom advocates leverages a neat little package called hugo-bin.\n\n\nIf strategy #1 fails I'll certainly give this #2 a try. Even if #1 works, I might give this strategy a spin if/when I re-tool this blog.\n\n\n\nUpdate 29-May-2023: NPM is GREAT!\n\n\nSince my first option (above) failed very quickly, I moved on to this option and I honestly think I might transition every static site that I have to be wrapped inside NPM, it works wonderfully and is a really attractive solution for so many ills!\n\n\nI'm going to document my experience with NPM wrapped around Hugo and will post that document here soon, probably as Wrap EVERYTHING in NPM!.\n\n\n\n3. Transition from Hugo to Eleventy\n\n\nReasonable? Yes. A lot of work? That's relative. The right thing to do? Probably.\n\n\nSo, it's already been done, see This Blog in Eleventy + Ghost and Searching for a Search Solution. That's all I'm going to say about this option, a definite maybe.\n\n\n\nThat's all folks... for now.\n",
            "feature_image": "https://images.unsplash.com/photo-1561470508-fd4df1ed90b2?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=MnwxMTc3M3wwfDF8c2VhcmNofDE0fHxjbG91ZCUyMHN0b3JtfGVufDB8fHx8MTY4MzcyOTUzNg&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-05-10T14:31:19.000Z",
            "updated_at": "2023-05-19T21:05:02.000Z",
            "published_at": "2023-05-10T14:33:09.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64627a84ddadd63e1863bc67",
            "uuid": "6305edca-d674-4b13-9a92-fec93443fd7a",
            "title": "first-matomo-update",
            "slug": "first-matomo-update",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Been prompted to do this for a couple of weeks so I finally took-the-plunge.  https://analytics.summittservices.com/index.php?module=CoreUpdater&action=newVersionAvailable.\\n\\nWow, that was way too easy.  I wonder if it really worked?  \\n\\n-/-/-/\\nlocation: Toledo, IA  \"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Been prompted to do this for a couple of weeks so I finally took-the-plunge.  <a href=\"https://analytics.summittservices.com/index.php?module=CoreUpdater&amp;action=newVersionAvailable\">https://analytics.summittservices.com/index.php?module=CoreUpdater&amp;action=newVersionAvailable</a>.</p>\n<p>Wow, that was way too easy.  I wonder if it really worked?</p>\n<p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "64627a84ddadd63e1863bc67",
            "plaintext": "Been prompted to do this for a couple of weeks so I finally took-the-plunge. https://analytics.summittservices.com/index.php?module=CoreUpdater&action=newVersionAvailable.\n\n\nWow, that was way too easy. I wonder if it really worked?\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-05-15T18:31:32.000Z",
            "updated_at": "2023-05-15T18:33:16.000Z",
            "published_at": "2023-05-15T18:33:16.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6467e4a1ddadd63e1863bc80",
            "uuid": "57388bc9-8f8a-412b-be13-cbee3b2e2d15",
            "title": "Wrap EVERYTHING in NPM!",
            "slug": "wrap-everything-in-npm",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"So, `node` and `npm` seem to be all the rage these days, and perhaps for good reason.  I recently fell in love with [Eleventy/11ty](https://www.11ty.dev) over [Hugo](https://gohugo.io) because it's Javascript, not Go, and it's elegantly simple with tons of flexibility.  I recently tried to add _Pagefind_ search to a Hugo static web site (see https://static.grinnell.edu/dlad-blog/posts/143-significant-rootstalk-retooling/).  If _Rootstalk_, an Azure Static Web App was framed in `node.js`, as both _Eleventy_ and _Pagefind_ are, there would be no problem.  The Azure scripts used to deploy those frameworks are far more customizable than Hugo, and there's documentation to prove it.  \\n\\nSo, how might I approach combining Hugo with Pagefind in the cloud?  Well, [A Powerful Blog Setup with Hugo and NPM](https://web.archive.org/web/20220818082611/https://www.blogtrack.io/blog/powerful-blog-setup-with-hugo-and-npm/)* by Tom Hombergs looked like a promising place to start.  The process that Tom advocates leverages a neat little package called [hugo-bin](https://www.npmjs.com/package/hugo-bin).  \\n \\n*_The links provided above and below are to a Wayback Machine capture of the original post._   \"}],[\"markdown\",{\"markdown\":\"# That Was Too Easy!\\n\\nWrapping my Hugo site in an NPM package was so easy that I forgot to document it... and maybe I really didn't need too.  Time to catch up, so here's a brief sysnopsis of what I did...\\n\\n## Following Tom's Excellent Advice\\n\\nI started by studying [A Powerful Blog Setup with Hugo and NPM](https://web.archive.org/web/20220818082611/https://www.blogtrack.io/blog/powerful-blog-setup-with-hugo-and-npm/) and quickly found that I could easily follow it almost verbatim.  Since I already had `npm` and `Hugo` installed I skipped ahead to the section titled \\\"Setting Up a Hugo Project\\\" and then to the `npx` and `git` commands there.  My experience, mostly in commands, looked like this on my Mac Mini workstation.  \\n\\n```zsh\\ncd ~/GitHub/\\n# Named the new project npm-rootstalk so it would not confilct with any of my existing `rootstalk...` directories\\nmkdir npm-rootstalk      \\ncd npm-rootstalk\\nnpx hugo new site . --force\\n# Copied the contents of my old project into the new one and then removed whatever I no longer needed\\ncp -fr ~/GitHub/rootstalk/. .  \\n# Installed Pagefind...\\nnpm install pagefind\\ngit init\\n# I created a new empty repo in GitHub called npm-rootstalk, then...\\ngit remote add origin https://github.com/Digital-Grinnell/npm-rootstalk \\ngit add . \\ngit commit -m \\\"Initial commit of new npm-wrapped Hugo project\\\"\\ngit push\\n```\\n\\nHaving secured a new repo I moved to running Hugo locally, then polishing my `package.json` scripts as Tom did.  I now have a `package.json` that reads like this:\\n\\n```json\\n{\\n  \\\"name\\\": \\\"npm-rootstalk\\\",\\n  \\\"version\\\": \\\"1.0.0\\\",\\n  \\\"description\\\": \\\"Rootstalk website built with Hugo and the Lightbi theme inside an NPM package.  May 2023.\\\",\\n  \\\"main\\\": \\\"index.js\\\",\\n  \\\"scripts\\\": {\\n    \\\"test\\\": \\\"echo \\\\\\\"Error: no test specified\\\\\\\" && exit 1\\\",\\n    \\\"build\\\": \\\"npm run hugo:build && npx pagefind --source public\\\",\\n    \\\"do:build\\\": \\\"hugo -d public && npx pagefind --source public\\\",\\n    \\\"azure:build\\\": \\\"hugo -d public --baseURL=\\\\\\\"https://yellow-wave-0e513e510.3.azurestaticapps.net/\\\\\\\" && npx pagefind --source public\\\",\\n    \\\"clean\\\": \\\"npm run hugo:clean\\\",\\n    \\\"serve\\\": \\\"npm run hugo:build && npx pagefind --source public --bundle-dir ../static/_pagefind && npm run hugo:serve\\\",\\n    \\\"hugo:build\\\": \\\"hugo -d public\\\",\\n    \\\"hugo:serve\\\": \\\"hugo server\\\",\\n    \\\"hugo:clean\\\": \\\"rm -rf build resources public\\\"\\n  },\\n  \\\"author\\\": \\\"Mark A. McFate\\\",\\n  \\\"license\\\": \\\"ISC\\\",\\n  \\\"dependencies\\\": {\\n    \\\"hugo-bin\\\": \\\"^0.102.0\\\",\\n    \\\"pagefind\\\": \\\"^0.12.0\\\"\\n  }\\n}\\n```\\n\\n# It Works!\\n\\nNow I just use `npm run serve` to build the Hugo site, index it with Pagefind, and serve it locally at http://localhost:1313.   \\n\\n# A Staging Site in Azure\\n\\nI can simply push changes to the `main` branch of the `npm-rootstalk` repo to trigger an Azure (aka GitHub Actions) rebuild, indexing and deployment of the site to [this address](https://yellow-wave-0e513e510.3.azurestaticapps.net/).  \\n\\n# A New Production Branch\\n\\nPushing to production is just as simple, I just have to push changes to the new `production` branch of the code and my app spec at DigitalOcean (see below) takes care of building, indexing, and deploying to https://rootstalk.grinnell.edu.  \\n\\nThat DO app spec reads like this:\\n\\n```yaml\\nalerts:\\n- rule: DEPLOYMENT_FAILED\\n- rule: DOMAIN_FAILED\\ndomains:\\n- domain: rootstalk.grinnell.edu\\n  type: PRIMARY\\n- domain: prairiejournal.grinnell.edu\\n  type: ALIAS\\nenvs:\\n- key: TZ\\n  scope: RUN_AND_BUILD_TIME\\n  value: America/Chicago\\n- key: HUGO_MATOMO_ID\\n  scope: RUN_AND_BUILD_TIME\\n  value: \\\"15\\\"\\ningress:\\n  rules:\\n  - component:\\n      name: npm-rootstalk\\n    match:\\n      path:\\n        prefix: /\\nname: npm-rootstalk\\nregion: nyc\\nstatic_sites:\\n- build_command: npm run build\\n  environment_slug: node-js\\n  github:\\n    branch: production\\n    deploy_on_push: true\\n    repo: Digital-Grinnell/npm-rootstalk\\n  name: npm-rootstalk\\n  source_dir: /\\n```\\n\\n---   \\n\\nIt's heavenly!  And that's all for now.\\n\\n\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>So, <code>node</code> and <code>npm</code> seem to be all the rage these days, and perhaps for good reason.  I recently fell in love with <a href=\"https://www.11ty.dev\">Eleventy/11ty</a> over <a href=\"https://gohugo.io\">Hugo</a> because it's Javascript, not Go, and it's elegantly simple with tons of flexibility.  I recently tried to add <em>Pagefind</em> search to a Hugo static web site (see <a href=\"https://static.grinnell.edu/dlad-blog/posts/143-significant-rootstalk-retooling/\">https://static.grinnell.edu/dlad-blog/posts/143-significant-rootstalk-retooling/</a>).  If <em>Rootstalk</em>, an Azure Static Web App was framed in <code>node.js</code>, as both <em>Eleventy</em> and <em>Pagefind</em> are, there would be no problem.  The Azure scripts used to deploy those frameworks are far more customizable than Hugo, and there's documentation to prove it.</p>\n<p>So, how might I approach combining Hugo with Pagefind in the cloud?  Well, <a href=\"https://web.archive.org/web/20220818082611/https://www.blogtrack.io/blog/powerful-blog-setup-with-hugo-and-npm/\">A Powerful Blog Setup with Hugo and NPM</a>* by Tom Hombergs looked like a promising place to start.  The process that Tom advocates leverages a neat little package called <a href=\"https://www.npmjs.com/package/hugo-bin\">hugo-bin</a>.</p>\n<p>*<em>The links provided above and below are to a Wayback Machine capture of the original post.</em></p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h1 id=\"that-was-too-easy\">That Was Too Easy!</h1>\n<p>Wrapping my Hugo site in an NPM package was so easy that I forgot to document it... and maybe I really didn't need too.  Time to catch up, so here's a brief sysnopsis of what I did...</p>\n<h2 id=\"following-toms-excellent-advice\">Following Tom's Excellent Advice</h2>\n<p>I started by studying <a href=\"https://web.archive.org/web/20220818082611/https://www.blogtrack.io/blog/powerful-blog-setup-with-hugo-and-npm/\">A Powerful Blog Setup with Hugo and NPM</a> and quickly found that I could easily follow it almost verbatim.  Since I already had <code>npm</code> and <code>Hugo</code> installed I skipped ahead to the section titled &quot;Setting Up a Hugo Project&quot; and then to the <code>npx</code> and <code>git</code> commands there.  My experience, mostly in commands, looked like this on my Mac Mini workstation.</p>\n<pre><code class=\"language-zsh\">cd ~/GitHub/\n# Named the new project npm-rootstalk so it would not confilct with any of my existing `rootstalk...` directories\nmkdir npm-rootstalk      \ncd npm-rootstalk\nnpx hugo new site . --force\n# Copied the contents of my old project into the new one and then removed whatever I no longer needed\ncp -fr ~/GitHub/rootstalk/. .  \n# Installed Pagefind...\nnpm install pagefind\ngit init\n# I created a new empty repo in GitHub called npm-rootstalk, then...\ngit remote add origin https://github.com/Digital-Grinnell/npm-rootstalk \ngit add . \ngit commit -m &quot;Initial commit of new npm-wrapped Hugo project&quot;\ngit push\n</code></pre>\n<p>Having secured a new repo I moved to running Hugo locally, then polishing my <code>package.json</code> scripts as Tom did.  I now have a <code>package.json</code> that reads like this:</p>\n<pre><code class=\"language-json\">{\n  &quot;name&quot;: &quot;npm-rootstalk&quot;,\n  &quot;version&quot;: &quot;1.0.0&quot;,\n  &quot;description&quot;: &quot;Rootstalk website built with Hugo and the Lightbi theme inside an NPM package.  May 2023.&quot;,\n  &quot;main&quot;: &quot;index.js&quot;,\n  &quot;scripts&quot;: {\n    &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot;,\n    &quot;build&quot;: &quot;npm run hugo:build &amp;&amp; npx pagefind --source public&quot;,\n    &quot;do:build&quot;: &quot;hugo -d public &amp;&amp; npx pagefind --source public&quot;,\n    &quot;azure:build&quot;: &quot;hugo -d public --baseURL=\\&quot;https://yellow-wave-0e513e510.3.azurestaticapps.net/\\&quot; &amp;&amp; npx pagefind --source public&quot;,\n    &quot;clean&quot;: &quot;npm run hugo:clean&quot;,\n    &quot;serve&quot;: &quot;npm run hugo:build &amp;&amp; npx pagefind --source public --bundle-dir ../static/_pagefind &amp;&amp; npm run hugo:serve&quot;,\n    &quot;hugo:build&quot;: &quot;hugo -d public&quot;,\n    &quot;hugo:serve&quot;: &quot;hugo server&quot;,\n    &quot;hugo:clean&quot;: &quot;rm -rf build resources public&quot;\n  },\n  &quot;author&quot;: &quot;Mark A. McFate&quot;,\n  &quot;license&quot;: &quot;ISC&quot;,\n  &quot;dependencies&quot;: {\n    &quot;hugo-bin&quot;: &quot;^0.102.0&quot;,\n    &quot;pagefind&quot;: &quot;^0.12.0&quot;\n  }\n}\n</code></pre>\n<h1 id=\"it-works\">It Works!</h1>\n<p>Now I just use <code>npm run serve</code> to build the Hugo site, index it with Pagefind, and serve it locally at <a href=\"http://localhost:1313\">http://localhost:1313</a>.</p>\n<h1 id=\"a-staging-site-in-azure\">A Staging Site in Azure</h1>\n<p>I can simply push changes to the <code>main</code> branch of the <code>npm-rootstalk</code> repo to trigger an Azure (aka GitHub Actions) rebuild, indexing and deployment of the site to <a href=\"https://yellow-wave-0e513e510.3.azurestaticapps.net/\">this address</a>.</p>\n<h1 id=\"a-new-production-branch\">A New Production Branch</h1>\n<p>Pushing to production is just as simple, I just have to push changes to the new <code>production</code> branch of the code and my app spec at DigitalOcean (see below) takes care of building, indexing, and deploying to <a href=\"https://rootstalk.grinnell.edu\">https://rootstalk.grinnell.edu</a>.</p>\n<p>That DO app spec reads like this:</p>\n<pre><code class=\"language-yaml\">alerts:\n- rule: DEPLOYMENT_FAILED\n- rule: DOMAIN_FAILED\ndomains:\n- domain: rootstalk.grinnell.edu\n  type: PRIMARY\n- domain: prairiejournal.grinnell.edu\n  type: ALIAS\nenvs:\n- key: TZ\n  scope: RUN_AND_BUILD_TIME\n  value: America/Chicago\n- key: HUGO_MATOMO_ID\n  scope: RUN_AND_BUILD_TIME\n  value: &quot;15&quot;\ningress:\n  rules:\n  - component:\n      name: npm-rootstalk\n    match:\n      path:\n        prefix: /\nname: npm-rootstalk\nregion: nyc\nstatic_sites:\n- build_command: npm run build\n  environment_slug: node-js\n  github:\n    branch: production\n    deploy_on_push: true\n    repo: Digital-Grinnell/npm-rootstalk\n  name: npm-rootstalk\n  source_dir: /\n</code></pre>\n<hr>\n<p>It's heavenly!  And that's all for now.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "6467e4a1ddadd63e1863bc80",
            "plaintext": "So, node and npm seem to be all the rage these days, and perhaps for good reason. I recently fell in love with Eleventy/11ty over Hugo because it's Javascript, not Go, and it's elegantly simple with tons of flexibility. I recently tried to add Pagefind search to a Hugo static web site (see https://static.grinnell.edu/dlad-blog/posts/143-significant-rootstalk-retooling/). If Rootstalk, an Azure Static Web App was framed in node.js, as both Eleventy and Pagefind are, there would be no problem. The Azure scripts used to deploy those frameworks are far more customizable than Hugo, and there's documentation to prove it.\n\n\nSo, how might I approach combining Hugo with Pagefind in the cloud? Well, A Powerful Blog Setup with Hugo and NPM* by Tom Hombergs looked like a promising place to start. The process that Tom advocates leverages a neat little package called hugo-bin.\n\n\n*The links provided above and below are to a Wayback Machine capture of the original post.\n\n\n\nThat Was Too Easy!\n\n\nWrapping my Hugo site in an NPM package was so easy that I forgot to document it... and maybe I really didn't need too. Time to catch up, so here's a brief sysnopsis of what I did...\n\n\n\nFollowing Tom's Excellent Advice\n\n\nI started by studying A Powerful Blog Setup with Hugo and NPM and quickly found that I could easily follow it almost verbatim. Since I already had npm and Hugo installed I skipped ahead to the section titled \"Setting Up a Hugo Project\" and then to the npx and git commands there. My experience, mostly in commands, looked like this on my Mac Mini workstation.\n\n\ncd ~/GitHub/\n# Named the new project npm-rootstalk so it would not confilct with any of my existing `rootstalk...` directories\nmkdir npm-rootstalk      \ncd npm-rootstalk\nnpx hugo new site . --force\n# Copied the contents of my old project into the new one and then removed whatever I no longer needed\ncp -fr ~/GitHub/rootstalk/. .  \n# Installed Pagefind...\nnpm install pagefind\ngit init\n# I created a new empty repo in GitHub called npm-rootstalk, then...\ngit remote add origin https://github.com/Digital-Grinnell/npm-rootstalk \ngit add . \ngit commit -m \"Initial commit of new npm-wrapped Hugo project\"\ngit push\n\n\n\nHaving secured a new repo I moved to running Hugo locally, then polishing my package.json scripts as Tom did. I now have a package.json that reads like this:\n\n\n{\n  \"name\": \"npm-rootstalk\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Rootstalk website built with Hugo and the Lightbi theme inside an NPM package.  May 2023.\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\",\n    \"build\": \"npm run hugo:build && npx pagefind --source public\",\n    \"do:build\": \"hugo -d public && npx pagefind --source public\",\n    \"azure:build\": \"hugo -d public --baseURL=\\\"https://yellow-wave-0e513e510.3.azurestaticapps.net/\\\" && npx pagefind --source public\",\n    \"clean\": \"npm run hugo:clean\",\n    \"serve\": \"npm run hugo:build && npx pagefind --source public --bundle-dir ../static/_pagefind && npm run hugo:serve\",\n    \"hugo:build\": \"hugo -d public\",\n    \"hugo:serve\": \"hugo server\",\n    \"hugo:clean\": \"rm -rf build resources public\"\n  },\n  \"author\": \"Mark A. McFate\",\n  \"license\": \"ISC\",\n  \"dependencies\": {\n    \"hugo-bin\": \"^0.102.0\",\n    \"pagefind\": \"^0.12.0\"\n  }\n}\n\n\n\n\nIt Works!\n\n\nNow I just use npm run serve to build the Hugo site, index it with Pagefind, and serve it locally at http://localhost:1313.\n\n\n\nA Staging Site in Azure\n\n\nI can simply push changes to the main branch of the npm-rootstalk repo to trigger an Azure (aka GitHub Actions) rebuild, indexing and deployment of the site to this address.\n\n\n\nA New Production Branch\n\n\nPushing to production is just as simple, I just have to push changes to the new production branch of the code and my app spec at DigitalOcean (see below) takes care of building, indexing, and deploying to https://rootstalk.grinnell.edu.\n\n\nThat DO app spec reads like this:\n\n\nalerts:\n- rule: DEPLOYMENT_FAILED\n- rule: DOMAIN_FAILED\ndomains:\n- domain: rootstalk.grinnell.edu\n  type: PRIMARY\n- domain: prairiejournal.grinnell.edu\n  type: ALIAS\nenvs:\n- key: TZ\n  scope: RUN_AND_BUILD_TIME\n  value: America/Chicago\n- key: HUGO_MATOMO_ID\n  scope: RUN_AND_BUILD_TIME\n  value: \"15\"\ningress:\n  rules:\n  - component:\n      name: npm-rootstalk\n    match:\n      path:\n        prefix: /\nname: npm-rootstalk\nregion: nyc\nstatic_sites:\n- build_command: npm run build\n  environment_slug: node-js\n  github:\n    branch: production\n    deploy_on_push: true\n    repo: Digital-Grinnell/npm-rootstalk\n  name: npm-rootstalk\n  source_dir: /\n\n\n\n\nIt's heavenly! And that's all for now.\n",
            "feature_image": "https://images.unsplash.com/photo-1587539963986-8a74135821d4?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDQzfHx3cmFwfGVufDB8fHx8MTY4NDUzMDM1MXww&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 1,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-05-19T21:05:37.000Z",
            "updated_at": "2023-07-18T21:22:37.000Z",
            "published_at": "2023-05-19T22:27:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "646b8972ddadd63e1863bd3b",
            "uuid": "dfb207f2-5b54-45d8-ba8d-25f5b5621e64",
            "title": "Commencment-2023",
            "slug": "commencment-2023",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"-/-/-/\\nlocation: Grinnell College\\n\"}]],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"Beautiful day for commencment 2023 in Grinnell.  I just wish Alina were here.  8^(\"]]],[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Beautiful day for commencment 2023 in Grinnell. Â I just wish Alina were here. Â 8^(</p><!--kg-card-begin: markdown--><p>-/-/-/<br>\nlocation: Grinnell College</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "646b8972ddadd63e1863bd3b",
            "plaintext": "Beautiful day for commencment 2023 in Grinnell. Â I just wish Alina were here. Â 8^(\n\n-/-/-/\n\nlocation: Grinnell College\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-05-22T15:25:38.000Z",
            "updated_at": "2023-05-22T16:41:37.000Z",
            "published_at": "2023-05-22T15:28:17.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "646e5561ddadd63e1863bd5a",
            "uuid": "62b71aac-c9ba-4c6b-be4a-a0be9f5d2cb8",
            "title": "cyclone-1965-completed",
            "slug": "cyclone-1965-completed",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"This morning I was dealing with the 1965 edition of the Grinnell College yearbook, _Cyclone 1965_, in Digital.Grinnell.  That's a monster of a yearbook, 278 pages and a .pdf that's almost 1.4 GB in size.  \\nIn order to get the .pdf to upload I tried a number of tricks, the only one that worked was a modification of [Book Ingest in Digital.Grinnell](https://static.grinnell.edu/dlad-blog/posts/097-book-ingest-in-digital-grinnell/)   The key command was...  \\n\\n```\\ndocker cp \\\"/mnt/storage/Yearbooks/Cyclone 1965/lib_1965cycloneyearbook_0002.pdf\\\" isle-apache-dg:/var/www/sites/default/files/book.pdf\\n```\\n\\n-/-/-/\\nlocation: Grinnell College  \"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>This morning I was dealing with the 1965 edition of the Grinnell College yearbook, <em>Cyclone 1965</em>, in Digital.Grinnell.  That's a monster of a yearbook, 278 pages and a .pdf that's almost 1.4 GB in size.<br>\nIn order to get the .pdf to upload I tried a number of tricks, the only one that worked was a modification of <a href=\"https://static.grinnell.edu/dlad-blog/posts/097-book-ingest-in-digital-grinnell/\">Book Ingest in Digital.Grinnell</a>   The key command was...</p>\n<pre><code>docker cp &quot;/mnt/storage/Yearbooks/Cyclone 1965/lib_1965cycloneyearbook_0002.pdf&quot; isle-apache-dg:/var/www/sites/default/files/book.pdf\n</code></pre>\n<p>-/-/-/<br>\nlocation: Grinnell College</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "646e5561ddadd63e1863bd5a",
            "plaintext": "This morning I was dealing with the 1965 edition of the Grinnell College yearbook, Cyclone 1965, in Digital.Grinnell. That's a monster of a yearbook, 278 pages and a .pdf that's almost 1.4 GB in size.\n\nIn order to get the .pdf to upload I tried a number of tricks, the only one that worked was a modification of Book Ingest in Digital.Grinnell The key command was...\n\n\ndocker cp \"/mnt/storage/Yearbooks/Cyclone 1965/lib_1965cycloneyearbook_0002.pdf\" isle-apache-dg:/var/www/sites/default/files/book.pdf\n\n\n\n-/-/-/\n\nlocation: Grinnell College\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-05-24T18:20:17.000Z",
            "updated_at": "2023-05-24T18:23:56.000Z",
            "published_at": "2023-05-24T18:23:56.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64703d76ddadd63e1863bd72",
            "uuid": "68a8acd2-fc2e-445e-98f8-e71059ba3546",
            "title": "owensboro-ky",
            "slug": "owensboro-ky",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Staying this weekend in a Marriott in Owensboro, Kentucky, for GeoWoodstock 2023.  Headed to Louisville in the morning for some oldies.  \\n\\n-/-/-/\\nlocation: Owensboro, KY  \"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Staying this weekend in a Marriott in Owensboro, Kentucky, for GeoWoodstock 2023.  Headed to Louisville in the morning for some oldies.</p>\n<p>-/-/-/<br>\nlocation: Owensboro, KY</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "64703d76ddadd63e1863bd72",
            "plaintext": "Staying this weekend in a Marriott in Owensboro, Kentucky, for GeoWoodstock 2023. Headed to Louisville in the morning for some oldies.\n\n\n-/-/-/\n\nlocation: Owensboro, KY\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-05-26T05:02:46.000Z",
            "updated_at": "2023-05-26T05:06:43.000Z",
            "published_at": "2023-05-26T05:04:43.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6476ac01ddadd63e1863bd85",
            "uuid": "8390268f-2735-433a-ae37-aca85ee47d82",
            "title": "elementary-school-weed-control",
            "slug": "elementary-school-weed-control",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Went to the elementary early this evening and sprayed Weed-B-Gone around the bench and area.  I hope it knocks the remaining weeds there back.  There was no wind and no rain thus far, so I hope it works.  \\n\\n-/-/-/\\nlocation: Tama, Iowa\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Went to the elementary early this evening and sprayed Weed-B-Gone around the bench and area.  I hope it knocks the remaining weeds there back.  There was no wind and no rain thus far, so I hope it works.</p>\n<p>-/-/-/<br>\nlocation: Tama, Iowa</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "6476ac01ddadd63e1863bd85",
            "plaintext": "Went to the elementary early this evening and sprayed Weed-B-Gone around the bench and area. I hope it knocks the remaining weeds there back. There was no wind and no rain thus far, so I hope it works.\n\n\n-/-/-/\n\nlocation: Tama, Iowa\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-05-31T02:08:01.000Z",
            "updated_at": "2023-05-31T02:10:06.000Z",
            "published_at": "2023-05-31T02:10:06.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6477c94eddadd63e1863bd97",
            "uuid": "ffd52dcc-95e3-43b7-a45e-00b5177b8dfe",
            "title": "Roadtrip: Geowoodstock 2023",
            "slug": "roadtrip-geowoodstock-2023",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Geowoodstock 2023 ([GC89GMX](https://coord.info/GC89GMX)) and Kentucky's oldest surviving geocache ([GC39E](https://coord.info/GC39E)) were the intended destinations of another epic roadtrip with _gossamar_ on May 25-28, 2023. \\n\\nThe route and cache count looked something like this:\\n\\n![Geowoodstock-2023-Caches-Found](__GHOST_URL__/content/images/2023/05/Geowoodstock-2023-Caches-Found.png)\\n\\nThe green lines represent my \\\"outbound\\\" route while the red lines show my \\\"return\\\" route back from [GC39E](https://coord.info/GC39E).  The ordered list of caches and events found is available for download below.  \"}],[\"file\",{\"loop\":false,\"src\":\"__GHOST_URL__/content/files/2023/05/Geowoodstock-Caches-Found.pdf\",\"fileName\":\"Geowoodstock-Caches-Found.pdf\",\"fileTitle\":\"Geowoodstock Caches Found\",\"fileCaption\":\"The GPS Maze at the top of the list was not found first, but it's listed that way.\",\"fileSize\":198938}],[\"markdown\",{\"markdown\":\"By the numbers I show:\\n\\n  - 88 geocaches found + events attended\\n  - 108 Adventure Lab stages logged\\n  - a few DNFs\\n  - 985 miles traveled in Tom's car at 40+ mpg \\n    - 21.4 gallons of gas totaling $72.30\\n  - 520 miles traveled in my Honda Ridgeline at 24+ mpg\\n  \"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Geowoodstock 2023 (<a href=\"https://coord.info/GC89GMX\">GC89GMX</a>) and Kentucky's oldest surviving geocache (<a href=\"https://coord.info/GC39E\">GC39E</a>) were the intended destinations of another epic roadtrip with <em>gossamar</em> on May 25-28, 2023.</p>\n<p>The route and cache count looked something like this:</p>\n<p><img src=\"__GHOST_URL__/content/images/2023/05/Geowoodstock-2023-Caches-Found.png\" alt=\"Geowoodstock-2023-Caches-Found\" loading=\"lazy\"></p>\n<p>The green lines represent my &quot;outbound&quot; route while the red lines show my &quot;return&quot; route back from <a href=\"https://coord.info/GC39E\">GC39E</a>.  The ordered list of caches and events found is available for download below.</p>\n<!--kg-card-end: markdown-->\n        <div class=\"kg-card kg-file-card \">\n            <a class=\"kg-file-card-container\" href=\"__GHOST_URL__/content/files/2023/05/Geowoodstock-Caches-Found.pdf\" title=\"Download\" download>\n                <div class=\"kg-file-card-contents\">\n                    <div class=\"kg-file-card-title\">Geowoodstock Caches Found</div>\n                    <div class=\"kg-file-card-caption\">The GPS Maze at the top of the list was not found first, but it&apos;s listed that way.</div>\n                    <div class=\"kg-file-card-metadata\">\n                        <div class=\"kg-file-card-filename\">Geowoodstock-Caches-Found.pdf</div>\n                        <div class=\"kg-file-card-filesize\">194 KB</div>\n                    </div>\n                </div>\n                <div class=\"kg-file-card-icon\">\n                    <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\"><defs><style>.a{fill:none;stroke:currentColor;stroke-linecap:round;stroke-linejoin:round;stroke-width:1.5px;}</style></defs><title>download-circle</title><polyline class=\"a\" points=\"8.25 14.25 12 18 15.75 14.25\"/><line class=\"a\" x1=\"12\" y1=\"6.75\" x2=\"12\" y2=\"18\"/><circle class=\"a\" cx=\"12\" cy=\"12\" r=\"11.25\"/></svg>\n                </div>\n            </a>\n        </div>\n        <!--kg-card-begin: markdown--><p>By the numbers I show:</p>\n<ul>\n<li>88 geocaches found + events attended</li>\n<li>108 Adventure Lab stages logged</li>\n<li>a few DNFs</li>\n<li>985 miles traveled in Tom's car at 40+ mpg\n<ul>\n<li>21.4 gallons of gas totaling $72.30</li>\n</ul>\n</li>\n<li>520 miles traveled in my Honda Ridgeline at 24+ mpg</li>\n</ul>\n<!--kg-card-end: markdown-->",
            "comment_id": "6477c94eddadd63e1863bd97",
            "plaintext": "Geowoodstock 2023 (GC89GMX) and Kentucky's oldest surviving geocache (GC39E) were the intended destinations of another epic roadtrip with gossamar on May 25-28, 2023.\n\n\nThe route and cache count looked something like this:\n\n\n\n\n\nThe green lines represent my \"outbound\" route while the red lines show my \"return\" route back from GC39E. The ordered list of caches and events found is available for download below.\n\n\n\n\n\n\nGeowoodstock Caches Found\nThe GPS Maze at the top of the list was not found first, but it's listed that way.\n\nGeowoodstock-Caches-Found.pdf\n194 KB\n\n\n\ndownload-circle\n\n\n\n\n\nBy the numbers I show:\n\n\n * 88 geocaches found + events attended\n * 108 Adventure Lab stages logged\n * a few DNFs\n * 985 miles traveled in Tom's car at 40+ mpg\n   \n   * 21.4 gallons of gas totaling $72.30\n   \n * 520 miles traveled in my Honda Ridgeline at 24+ mpg\n",
            "feature_image": "https://images.unsplash.com/photo-1593115590389-076721aa1607?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDF8fGdlb2NhY2hpbmd8ZW58MHx8fHwxNjg1NTc2MDQyfDA&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-05-31T22:25:18.000Z",
            "updated_at": "2023-06-01T02:54:01.000Z",
            "published_at": "2023-05-29T22:32:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6478a08addadd63e1863bdfb",
            "uuid": "2ba6721f-4e6b-4d97-87df-dee7eb27e810",
            "title": "streamlit-ghost-azure-resources",
            "slug": "streamlit-ghost-azure-resources",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"I've got Mackenzie looking at Streamlit as a means of building a mobile-friendly app that I can use to create posts like this one.  That app will need to allow me to edit  a TITLE and Markdown BODY fields, capture location and time, and post all of that information to my personal blog... preferably from my cell phone.  I've captured some possible resources and guidance in [https://www.one-tab.com/page/71iaDADxT-eLEOx15qeVnQ](https://www.one-tab.com/page/71iaDADxT-eLEOx15qeVnQ).\\n\\n-/-/-/\\nlocation: Toledo, IA\\n\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>I've got Mackenzie looking at Streamlit as a means of building a mobile-friendly app that I can use to create posts like this one.  That app will need to allow me to edit  a TITLE and Markdown BODY fields, capture location and time, and post all of that information to my personal blog... preferably from my cell phone.  I've captured some possible resources and guidance in <a href=\"https://www.one-tab.com/page/71iaDADxT-eLEOx15qeVnQ\">https://www.one-tab.com/page/71iaDADxT-eLEOx15qeVnQ</a>.</p>\n<p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "6478a08addadd63e1863bdfb",
            "plaintext": "I've got Mackenzie looking at Streamlit as a means of building a mobile-friendly app that I can use to create posts like this one. That app will need to allow me to edit a TITLE and Markdown BODY fields, capture location and time, and post all of that information to my personal blog... preferably from my cell phone. I've captured some possible resources and guidance in https://www.one-tab.com/page/71iaDADxT-eLEOx15qeVnQ.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-06-01T13:43:38.000Z",
            "updated_at": "2023-06-05T17:20:28.000Z",
            "published_at": "2023-06-01T13:49:18.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "647bc916ddadd63e1863be1c",
            "uuid": "881f12f4-a78f-468e-b6cd-bb960da14af8",
            "title": "fixing-wieting-guild-pages",
            "slug": "fixing-wieting-guild-pages",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Just the other day I got an updated copy of the Wieting Theatre's volunteer roster and assignment schedule.  As I'm trying to post them to the [theatre's management website](https://wieting-guild.tamatoledo.com) (it's password protected) I keep having issues with `npm` and dependencies that won't compile.  The fix, thus far has included a local command stream like this:  \\n\\n```sh\\ncd wieting-guild-pages\\ngit pull\\ncode .\\nnpm run build\\nnpm run start \\n  --> failed\\nnpm update\\nnpm audit fix\\nnpm run build\\nnpm run start\\n  --> failed\\nnpm audit fix --force\\nnpm run build\\n  --> failed\\nnpm install axios\\nnpm run build\\n  --> failed\\nnpm update\\nnpm run build\\n```  \\n\\nThe last errors had this in common:  \\n\\n```\\n[11ty] Unhandled rejection in promise: (more in DEBUG output)\\n[11ty] connect ETIMEDOUT 54.243.162.8:443 (via Error)\\n[11ty] \\n[11ty] Original error stack trace: Error: connect ETIMEDOUT 54.243.162.8:443\\n[11ty]     at AxiosError.from (/Users/mark/GitHub/wieting-guild-pages/node_modules/axios/dist/node/axios.cjs:836:14)\\n```  \\n\\nOne explanation I found:  \\n\\n```\\nThe ETIMEDOUT error is thrown by the Node.js runtime when a connection or HTTP request is not closed properly after some time. You might encounter this error from time to time if you configured a timeout on your outgoing HTTP requests. The general solution to this issue is to catch the error and repeat the request, preferably using an exponential backoff strategy so that a waiting period is added between subsequent retries until the request eventually succeeds, or the maximum amount of retries is reached. If you encounter this error frequently, try to investigate your request timeout settings and choose a more appropriate value for the endpoint if possible.\\n```\\n\\nI also found a GitHub issues/bug report related to Axios and this error at https://github.com/SillyTavern/SillyTavern/issues/432.  So, maybe it's not just me?  \\n\\n\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Just the other day I got an updated copy of the Wieting Theatre's volunteer roster and assignment schedule.  As I'm trying to post them to the <a href=\"https://wieting-guild.tamatoledo.com\">theatre's management website</a> (it's password protected) I keep having issues with <code>npm</code> and dependencies that won't compile.  The fix, thus far has included a local command stream like this:</p>\n<pre><code class=\"language-sh\">cd wieting-guild-pages\ngit pull\ncode .\nnpm run build\nnpm run start \n  --&gt; failed\nnpm update\nnpm audit fix\nnpm run build\nnpm run start\n  --&gt; failed\nnpm audit fix --force\nnpm run build\n  --&gt; failed\nnpm install axios\nnpm run build\n  --&gt; failed\nnpm update\nnpm run build\n</code></pre>\n<p>The last errors had this in common:</p>\n<pre><code>[11ty] Unhandled rejection in promise: (more in DEBUG output)\n[11ty] connect ETIMEDOUT 54.243.162.8:443 (via Error)\n[11ty] \n[11ty] Original error stack trace: Error: connect ETIMEDOUT 54.243.162.8:443\n[11ty]     at AxiosError.from (/Users/mark/GitHub/wieting-guild-pages/node_modules/axios/dist/node/axios.cjs:836:14)\n</code></pre>\n<p>One explanation I found:</p>\n<pre><code>The ETIMEDOUT error is thrown by the Node.js runtime when a connection or HTTP request is not closed properly after some time. You might encounter this error from time to time if you configured a timeout on your outgoing HTTP requests. The general solution to this issue is to catch the error and repeat the request, preferably using an exponential backoff strategy so that a waiting period is added between subsequent retries until the request eventually succeeds, or the maximum amount of retries is reached. If you encounter this error frequently, try to investigate your request timeout settings and choose a more appropriate value for the endpoint if possible.\n</code></pre>\n<p>I also found a GitHub issues/bug report related to Axios and this error at <a href=\"https://github.com/SillyTavern/SillyTavern/issues/432\">https://github.com/SillyTavern/SillyTavern/issues/432</a>.  So, maybe it's not just me?</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "647bc916ddadd63e1863be1c",
            "plaintext": "Just the other day I got an updated copy of the Wieting Theatre's volunteer roster and assignment schedule. As I'm trying to post them to the theatre's management website (it's password protected) I keep having issues with npm and dependencies that won't compile. The fix, thus far has included a local command stream like this:\n\n\ncd wieting-guild-pages\ngit pull\ncode .\nnpm run build\nnpm run start \n  --> failed\nnpm update\nnpm audit fix\nnpm run build\nnpm run start\n  --> failed\nnpm audit fix --force\nnpm run build\n  --> failed\nnpm install axios\nnpm run build\n  --> failed\nnpm update\nnpm run build\n\n\n\nThe last errors had this in common:\n\n\n[11ty] Unhandled rejection in promise: (more in DEBUG output)\n[11ty] connect ETIMEDOUT 54.243.162.8:443 (via Error)\n[11ty] \n[11ty] Original error stack trace: Error: connect ETIMEDOUT 54.243.162.8:443\n[11ty]     at AxiosError.from (/Users/mark/GitHub/wieting-guild-pages/node_modules/axios/dist/node/axios.cjs:836:14)\n\n\n\nOne explanation I found:\n\n\nThe ETIMEDOUT error is thrown by the Node.js runtime when a connection or HTTP request is not closed properly after some time. You might encounter this error from time to time if you configured a timeout on your outgoing HTTP requests. The general solution to this issue is to catch the error and repeat the request, preferably using an exponential backoff strategy so that a waiting period is added between subsequent retries until the request eventually succeeds, or the maximum amount of retries is reached. If you encounter this error frequently, try to investigate your request timeout settings and choose a more appropriate value for the endpoint if possible.\n\n\n\nI also found a GitHub issues/bug report related to Axios and this error at https://github.com/SillyTavern/SillyTavern/issues/432. So, maybe it's not just me?\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-06-03T23:13:26.000Z",
            "updated_at": "2023-06-03T23:37:01.000Z",
            "published_at": "2023-06-03T23:20:26.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "647dd46cddadd63e1863be50",
            "uuid": "8a582700-dab9-4b59-aebe-4d959558fcb8",
            "title": "streamlit-apps-fork",
            "slug": "streamlit-apps-fork",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"This morning I found some new _Streamlit_ resources from developer **Jcharis**, and I forked his [Jcharis/Streamlit_DataScience_Apps](https://github.com/Jcharis/Streamlit_DataScience_Apps) to make my own copy at [SummittDweller/Streamlit_DataScience_Apps](https://github.com/SummittDweller/Streamlit_DataScience_Apps)  \\n\\nNow I'm going to try and get the component _Simple_CRuD_Blog_App_with_Streamlit_ working locally as a proof-of-concept.  Since I can't \\\"clone\\\" the single project repo, and a \\\"sparse checkout\\\" seems wasteful since I'll never push back to the original project, I'm going to `git init` an entirely new local named _simple-CRuD-blog-app-with-streamlit_ and just copy/paste the contents.\\n\\nIt works!  \"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>This morning I found some new <em>Streamlit</em> resources from developer <strong>Jcharis</strong>, and I forked his <a href=\"https://github.com/Jcharis/Streamlit_DataScience_Apps\">Jcharis/Streamlit_DataScience_Apps</a> to make my own copy at <a href=\"https://github.com/SummittDweller/Streamlit_DataScience_Apps\">SummittDweller/Streamlit_DataScience_Apps</a></p>\n<p>Now I'm going to try and get the component <em>Simple_CRuD_Blog_App_with_Streamlit</em> working locally as a proof-of-concept.  Since I can't &quot;clone&quot; the single project repo, and a &quot;sparse checkout&quot; seems wasteful since I'll never push back to the original project, I'm going to <code>git init</code> an entirely new local named <em>simple-CRuD-blog-app-with-streamlit</em> and just copy/paste the contents.</p>\n<p>It works!</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "647dd46cddadd63e1863be50",
            "plaintext": "This morning I found some new Streamlit resources from developer Jcharis, and I forked his Jcharis/Streamlit_DataScience_Apps to make my own copy at SummittDweller/Streamlit_DataScience_Apps\n\n\nNow I'm going to try and get the component Simple_CRuD_Blog_App_with_Streamlit working locally as a proof-of-concept. Since I can't \"clone\" the single project repo, and a \"sparse checkout\" seems wasteful since I'll never push back to the original project, I'm going to git init an entirely new local named simple-CRuD-blog-app-with-streamlit and just copy/paste the contents.\n\n\nIt works!\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-06-05T12:26:20.000Z",
            "updated_at": "2023-06-05T17:06:21.000Z",
            "published_at": "2023-06-05T12:31:46.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "647f65cfddadd63e1863be88",
            "uuid": "1625f68b-a65d-4046-a305-03b9866918f3",
            "title": "Planting Sempervivum tectorum (and More)",
            "slug": "planting-hens-and-chicks-and-more",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"This morning I started an experiment... clipping leaves (\\\"lobes\\\" might be a better term for these things) from a healthy, indoor _Sempervivum tectorum_.  What's that, you ask? The common name is **Hens and Chicks**.  \\n\\nA couple of weeks ago I bought an on-sale strawberry pot full of _Sempervivum tectorum_ and I have it growing on a little table on the front porch.  It's doing QUITE WELL there!  A couple of days ago I uprooted a 3 foot square patch of _Snow on the Mountain_ from a spot in my front flower beds (outside out southeast bedroom window), and that left a big bare patch of soil to be dealt with.  \\n\\nToday I clipped some vertical growth from the _Sempervivum tectorum_, stripped about two dozen of the \\\"lobes\\\" from the bottoms, and transplanted the \\\"stems\\\" into an indoor pot where I'm also trying to root some Jade plants.  That left me with a handful of detached \\\"lobes\\\" so I got out my cultivator, chewed up the bare spot left from the _Snow on the Mountain_, scattered the detached lobes there, and covered them gently with a little garden soil.  I have no idea if these might produce new plants... we shall see.  \\n\\nSince I had the cultivator out I also roughed up some spots where I'm having trougle getting grass to grow, and I'll be watering those spots for the coming week just as I have been watering the _Snow on the Mountain_ which was transplated to an area near STC Elementary where there's an Ian memorial rock and bench.  There's no longer a tree at that memorial location, the previous one died so we had it cut down. Our hope is to plant a new tree this Fall.   \\n\\n-/-/-/\\nlocation: Toledo, IA\\n\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>This morning I started an experiment... clipping leaves (&quot;lobes&quot; might be a better term for these things) from a healthy, indoor <em>Sempervivum tectorum</em>.  What's that, you ask? The common name is <strong>Hens and Chicks</strong>.</p>\n<p>A couple of weeks ago I bought an on-sale strawberry pot full of <em>Sempervivum tectorum</em> and I have it growing on a little table on the front porch.  It's doing QUITE WELL there!  A couple of days ago I uprooted a 3 foot square patch of <em>Snow on the Mountain</em> from a spot in my front flower beds (outside out southeast bedroom window), and that left a big bare patch of soil to be dealt with.</p>\n<p>Today I clipped some vertical growth from the <em>Sempervivum tectorum</em>, stripped about two dozen of the &quot;lobes&quot; from the bottoms, and transplanted the &quot;stems&quot; into an indoor pot where I'm also trying to root some Jade plants.  That left me with a handful of detached &quot;lobes&quot; so I got out my cultivator, chewed up the bare spot left from the <em>Snow on the Mountain</em>, scattered the detached lobes there, and covered them gently with a little garden soil.  I have no idea if these might produce new plants... we shall see.</p>\n<p>Since I had the cultivator out I also roughed up some spots where I'm having trougle getting grass to grow, and I'll be watering those spots for the coming week just as I have been watering the <em>Snow on the Mountain</em> which was transplated to an area near STC Elementary where there's an Ian memorial rock and bench.  There's no longer a tree at that memorial location, the previous one died so we had it cut down. Our hope is to plant a new tree this Fall.</p>\n<p>-/-/-/<br>\nlocation: Toledo, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "647f65cfddadd63e1863be88",
            "plaintext": "This morning I started an experiment... clipping leaves (\"lobes\" might be a better term for these things) from a healthy, indoor Sempervivum tectorum. What's that, you ask? The common name is Hens and Chicks.\n\n\nA couple of weeks ago I bought an on-sale strawberry pot full of Sempervivum tectorum and I have it growing on a little table on the front porch. It's doing QUITE WELL there! A couple of days ago I uprooted a 3 foot square patch of Snow on the Mountain from a spot in my front flower beds (outside out southeast bedroom window), and that left a big bare patch of soil to be dealt with.\n\n\nToday I clipped some vertical growth from the Sempervivum tectorum, stripped about two dozen of the \"lobes\" from the bottoms, and transplanted the \"stems\" into an indoor pot where I'm also trying to root some Jade plants. That left me with a handful of detached \"lobes\" so I got out my cultivator, chewed up the bare spot left from the Snow on the Mountain, scattered the detached lobes there, and covered them gently with a little garden soil. I have no idea if these might produce new plants... we shall see.\n\n\nSince I had the cultivator out I also roughed up some spots where I'm having trougle getting grass to grow, and I'll be watering those spots for the coming week just as I have been watering the Snow on the Mountain which was transplated to an area near STC Elementary where there's an Ian memorial rock and bench. There's no longer a tree at that memorial location, the previous one died so we had it cut down. Our hope is to plant a new tree this Fall.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n",
            "feature_image": "https://images.unsplash.com/photo-1642900282496-0ffb92c20adb?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDJ8fGhlbnMlMjBhbmQlMjBjaGlja3N8ZW58MHx8fHwxNjg2MDcxNjI4fDA&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-06-06T16:58:55.000Z",
            "updated_at": "2023-06-06T17:14:02.000Z",
            "published_at": "2023-06-06T17:14:02.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64845ff7ddadd63e1863bece",
            "uuid": "64515be2-f15d-4f65-9c16-82ebff06ff22",
            "title": "camping-at-fishermans-corner",
            "slug": "camping-at-fishermans-corner",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Arrived at Fisherman's Corner campground in Hampton, IL, on Thursday evening and went on my first Iowa.LandShark geo-bike ride yesterday.  Somewhere between 18-22 miles of geocaching along the Mississippi River from Moline to Davenport and Rock Island.  Open my [track log](https://hikes.summittdweller.com/hikes/2023/06/2023-06-09_5.47pm/) to see where Gossamar and I went.  \\n\\n-/-/-/\\nlocation: Hampton, IL\\n\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Arrived at Fisherman's Corner campground in Hampton, IL, on Thursday evening and went on my first Iowa.LandShark geo-bike ride yesterday.  Somewhere between 18-22 miles of geocaching along the Mississippi River from Moline to Davenport and Rock Island.  Open my <a href=\"https://hikes.summittdweller.com/hikes/2023/06/2023-06-09_5.47pm/\">track log</a> to see where Gossamar and I went.</p>\n<p>-/-/-/<br>\nlocation: Hampton, IL</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "64845ff7ddadd63e1863bece",
            "plaintext": "Arrived at Fisherman's Corner campground in Hampton, IL, on Thursday evening and went on my first Iowa.LandShark geo-bike ride yesterday. Somewhere between 18-22 miles of geocaching along the Mississippi River from Moline to Davenport and Rock Island. Open my track log to see where Gossamar and I went.\n\n\n-/-/-/\n\nlocation: Hampton, IL\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-06-10T11:35:19.000Z",
            "updated_at": "2023-06-10T12:21:23.000Z",
            "published_at": "2023-06-10T11:38:36.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6487716cddadd63e1863bee5",
            "uuid": "98dc0218-79c6-4d45-a2ac-8b99bf08c60a",
            "title": "upgrading-matomo-php",
            "slug": "upgrading-matomo-php",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"This afternoon I'm adding `https://digital.grinnell.edu` (site ID is 17) to my own Matomo instance and I'm prompted to upgrade PHP on that Matomo droplet (DigitalOcean).  I did so quite easily following [Upgrade PHP from 7.2 to 7.4 on CentOS 8 and Apache](https://www.digitalocean.com/community/questions/upgrade-php-from-7-2-to-7-4-on-centos-8-and-apache).  I've also updated my Drupal version, and some modules, in https://digital.grinnell.edu along with adding the `matomo` module, but that module is now reporting:  \\n\\n```\\n\\n    The validation of \\\"http://analytics.summittservices.com/matomo.php\\\" failed with error \\\"Error opening socket ssl://analytics.summittservices.com:443\\\" (HTTP code 0).\\n    The validation of \\\"https://analytics.summittservices.com/matomo.php\\\" failed with error \\\"Error opening socket ssl://analytics.summittservices.com:443\\\" (HTTP code 0).\\n```\\n\\nHmmm...wonder what's up with that?  \\n\\nSo, I tried this...  \\n```\\nLast login: Mon Jun 12 19:21:45 2023 from 162.243.190.66\\n[root@centos-s-1vcpu-1gb-nyc1-01 ~]# sudo certbot renew\\nSaving debug log to /var/log/letsencrypt/letsencrypt.log\\n\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\\nProcessing /etc/letsencrypt/renewal/summittservices.com-0001.conf\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\\nRenewing an existing certificate for summittservices.com and analytics.summittservices.com\\nReloading nginx server after certificate renewal\\n\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\\nProcessing /etc/letsencrypt/renewal/summittservices.com.conf\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\\nRenewing an existing certificate for summittservices.com and www.summittservices.com\\nReloading nginx server after certificate renewal\\n\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\\nCongratulations, all renewals succeeded: \\n  /etc/letsencrypt/live/summittservices.com-0001/fullchain.pem (success)\\n  /etc/letsencrypt/live/summittservices.com/fullchain.pem (success)\\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\\n```\\n\\n...and... NO more validation errors!  Yay!  \"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>This afternoon I'm adding <code>https://digital.grinnell.edu</code> (site ID is 17) to my own Matomo instance and I'm prompted to upgrade PHP on that Matomo droplet (DigitalOcean).  I did so quite easily following <a href=\"https://www.digitalocean.com/community/questions/upgrade-php-from-7-2-to-7-4-on-centos-8-and-apache\">Upgrade PHP from 7.2 to 7.4 on CentOS 8 and Apache</a>.  I've also updated my Drupal version, and some modules, in <a href=\"https://digital.grinnell.edu\">https://digital.grinnell.edu</a> along with adding the <code>matomo</code> module, but that module is now reporting:</p>\n<pre><code>\n    The validation of &quot;http://analytics.summittservices.com/matomo.php&quot; failed with error &quot;Error opening socket ssl://analytics.summittservices.com:443&quot; (HTTP code 0).\n    The validation of &quot;https://analytics.summittservices.com/matomo.php&quot; failed with error &quot;Error opening socket ssl://analytics.summittservices.com:443&quot; (HTTP code 0).\n</code></pre>\n<p>Hmmm...wonder what's up with that?</p>\n<p>So, I tried this...</p>\n<pre><code>Last login: Mon Jun 12 19:21:45 2023 from 162.243.190.66\n[root@centos-s-1vcpu-1gb-nyc1-01 ~]# sudo certbot renew\nSaving debug log to /var/log/letsencrypt/letsencrypt.log\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nProcessing /etc/letsencrypt/renewal/summittservices.com-0001.conf\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nRenewing an existing certificate for summittservices.com and analytics.summittservices.com\nReloading nginx server after certificate renewal\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nProcessing /etc/letsencrypt/renewal/summittservices.com.conf\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nRenewing an existing certificate for summittservices.com and www.summittservices.com\nReloading nginx server after certificate renewal\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nCongratulations, all renewals succeeded: \n  /etc/letsencrypt/live/summittservices.com-0001/fullchain.pem (success)\n  /etc/letsencrypt/live/summittservices.com/fullchain.pem (success)\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n</code></pre>\n<p>...and... NO more validation errors!  Yay!</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "6487716cddadd63e1863bee5",
            "plaintext": "This afternoon I'm adding https://digital.grinnell.edu (site ID is 17) to my own Matomo instance and I'm prompted to upgrade PHP on that Matomo droplet (DigitalOcean). I did so quite easily following Upgrade PHP from 7.2 to 7.4 on CentOS 8 and Apache. I've also updated my Drupal version, and some modules, in https://digital.grinnell.edu along with adding the matomo module, but that module is now reporting:\n\n\n\n    The validation of \"http://analytics.summittservices.com/matomo.php\" failed with error \"Error opening socket ssl://analytics.summittservices.com:443\" (HTTP code 0).\n    The validation of \"https://analytics.summittservices.com/matomo.php\" failed with error \"Error opening socket ssl://analytics.summittservices.com:443\" (HTTP code 0).\n\n\n\nHmmm...wonder what's up with that?\n\n\nSo, I tried this...\n\n\nLast login: Mon Jun 12 19:21:45 2023 from 162.243.190.66\n[root@centos-s-1vcpu-1gb-nyc1-01 ~]# sudo certbot renew\nSaving debug log to /var/log/letsencrypt/letsencrypt.log\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nProcessing /etc/letsencrypt/renewal/summittservices.com-0001.conf\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nRenewing an existing certificate for summittservices.com and analytics.summittservices.com\nReloading nginx server after certificate renewal\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nProcessing /etc/letsencrypt/renewal/summittservices.com.conf\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nRenewing an existing certificate for summittservices.com and www.summittservices.com\nReloading nginx server after certificate renewal\n\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\nCongratulations, all renewals succeeded: \n  /etc/letsencrypt/live/summittservices.com-0001/fullchain.pem (success)\n  /etc/letsencrypt/live/summittservices.com/fullchain.pem (success)\n- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n\n\n\n...and... NO more validation errors! Yay!\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-06-12T19:26:36.000Z",
            "updated_at": "2023-06-12T19:56:08.000Z",
            "published_at": "2023-06-12T19:30:18.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64931a30ddadd63e1863bf09",
            "uuid": "ed307f47-3650-430d-a7da-5888c49456a2",
            "title": "greetings-from-vermillion",
            "slug": "greetings-from-vermillion",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Arrived in Vermillion, South Dakota, last evening about 6:30 PM and went straight to dinner at the \\\"Old Lumber Company\\\" downtown.  Checked in to our hotel adjacent to the Univ. of South Dakota campus at about 7:15 PM and went to find the music department building (the fine arts center) where Christine will be taking classes for the rest of the week.\\n\\nWhile she's in class I'll be working from my hotel room here, or maybe from the USD library.\\n\\n-/-/-/\\nlocation: Vermillion, South Dakota\\n\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Arrived in Vermillion, South Dakota, last evening about 6:30 PM and went straight to dinner at the &quot;Old Lumber Company&quot; downtown.  Checked in to our hotel adjacent to the Univ. of South Dakota campus at about 7:15 PM and went to find the music department building (the fine arts center) where Christine will be taking classes for the rest of the week.</p>\n<p>While she's in class I'll be working from my hotel room here, or maybe from the USD library.</p>\n<p>-/-/-/<br>\nlocation: Vermillion, South Dakota</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "64931a30ddadd63e1863bf09",
            "plaintext": "Arrived in Vermillion, South Dakota, last evening about 6:30 PM and went straight to dinner at the \"Old Lumber Company\" downtown. Checked in to our hotel adjacent to the Univ. of South Dakota campus at about 7:15 PM and went to find the music department building (the fine arts center) where Christine will be taking classes for the rest of the week.\n\n\nWhile she's in class I'll be working from my hotel room here, or maybe from the USD library.\n\n\n-/-/-/\n\nlocation: Vermillion, South Dakota\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-06-21T15:41:36.000Z",
            "updated_at": "2023-06-21T15:45:01.000Z",
            "published_at": "2023-06-21T12:44:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6495a38bddadd63e1863bf22",
            "uuid": "595c4bf3-2de4-44a9-a41b-3cf67c3bfddb",
            "title": "fire-alarm-2-am",
            "slug": "fire-alarm-2-am",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Do we get extra IHG (Holiday Inn) bonus points for living through the 2 AM false fire alarm last night?  NOT FUN.  Hope I can drive home this afternoon without falling asleep.\\n\\n-/-/-/\\nlocation: Vermillion, SD\\n\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Do we get extra IHG (Holiday Inn) bonus points for living through the 2 AM false fire alarm last night?  NOT FUN.  Hope I can drive home this afternoon without falling asleep.</p>\n<p>-/-/-/<br>\nlocation: Vermillion, SD</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "6495a38bddadd63e1863bf22",
            "plaintext": "Do we get extra IHG (Holiday Inn) bonus points for living through the 2 AM false fire alarm last night? NOT FUN. Hope I can drive home this afternoon without falling asleep.\n\n\n-/-/-/\n\nlocation: Vermillion, SD\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-06-23T13:52:11.000Z",
            "updated_at": "2023-06-23T13:54:01.000Z",
            "published_at": "2023-06-23T12:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6496ff70ddadd63e1863bf33",
            "uuid": "38719519-49b7-40e9-ada1-05722d389f86",
            "title": "a-close-call-indeed",
            "slug": "a-close-call-indeed",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Driving home from a few days at Univ. of South Dakota in Vermillion last evening and stopped at Justin's house in M-town to meet his parents and grandmother, plus Deb & Doug.  We left there about 8:30 or so and I took the old Lincoln Highway into town to avoid deer along the road on the shorter rural route.  \\n\\nWe nearly got hit by an impaired driver (?) when turning on to Center Street just south of the Hy-Vee / Taco John's intersection.  Fortunately for us, a large SUV (Suburban?) took the force of the impact while vehicles and debris flew all around us.  Nobody was injured and there's not a scratch (that we can see) on the new Kia, but we didn't get home until a little after 10 PM.\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Driving home from a few days at Univ. of South Dakota in Vermillion last evening and stopped at Justin's house in M-town to meet his parents and grandmother, plus Deb &amp; Doug.  We left there about 8:30 or so and I took the old Lincoln Highway into town to avoid deer along the road on the shorter rural route.</p>\n<p>We nearly got hit by an impaired driver (?) when turning on to Center Street just south of the Hy-Vee / Taco John's intersection.  Fortunately for us, a large SUV (Suburban?) took the force of the impact while vehicles and debris flew all around us.  Nobody was injured and there's not a scratch (that we can see) on the new Kia, but we didn't get home until a little after 10 PM.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "6496ff70ddadd63e1863bf33",
            "plaintext": "Driving home from a few days at Univ. of South Dakota in Vermillion last evening and stopped at Justin's house in M-town to meet his parents and grandmother, plus Deb & Doug. We left there about 8:30 or so and I took the old Lincoln Highway into town to avoid deer along the road on the shorter rural route.\n\n\nWe nearly got hit by an impaired driver (?) when turning on to Center Street just south of the Hy-Vee / Taco John's intersection. Fortunately for us, a large SUV (Suburban?) took the force of the impact while vehicles and debris flew all around us. Nobody was injured and there's not a scratch (that we can see) on the new Kia, but we didn't get home until a little after 10 PM.\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-06-24T14:36:32.000Z",
            "updated_at": "2023-06-24T14:48:41.000Z",
            "published_at": "2023-06-24T14:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64a1a208ddadd63e1863bf5c",
            "uuid": "3065b6dc-8bb3-4392-bf41-3eb60625bc8b",
            "title": "Buzzard-billys",
            "slug": "buzzard-billys",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Trying breakfast at Buzzard Billy's before \\\"Ain't Too Proud\\\" this afternoon.\\n\\n-/-/-/\\nlocation: Des Moines, IA\\n\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Trying breakfast at Buzzard Billy's before &quot;Ain't Too Proud&quot; this afternoon.</p>\n<p>-/-/-/<br>\nlocation: Des Moines, IA</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "64a1a208ddadd63e1863bf5c",
            "plaintext": "Trying breakfast at Buzzard Billy's before \"Ain't Too Proud\" this afternoon.\n\n\n-/-/-/\n\nlocation: Des Moines, IA\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-07-02T16:12:56.000Z",
            "updated_at": "2023-07-02T16:15:59.000Z",
            "published_at": "2023-07-02T16:15:59.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64a6fb49ddadd63e1863bf77",
            "uuid": "4997464d-aca4-489f-aa5c-30d7e86d5753",
            "title": "Redefining an Azure Static Web App",
            "slug": "redefining-an-azure-static-web-app",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Today's burning question... Can I _easily_ \\\"redefine\\\" an Azure Static Web App?  \\n\\nSo, the source code for my password-protected [Wieting-Guild-Pages](https://wieting-guild.tamatoledo.com/) is broken and I can't update the stale old content that's currently there.  It's a long story.  Fortunately, I've rebuilt that code in a new GitHub repo and have it working again.  Yay!\\n\\nNow, can I take the deployment parts of the old/broken repo and apply them to the new repo and make it all work again?  \"}],[\"markdown\",{\"markdown\":\"## Worth a Try\\n\\nSo, I started this experiment by visiting the old project, https://github.com/SummittDweller/wieting-guild-pages, and copying the https://github.com/SummittDweller/wieting-guild-pages/blob/main/.github/workflows/azure-static-web-apps-lemon-mushroom-087d78210.yml file found there.  That GitHub workflow file contains nearly all the information required to deploy the old site, maybe it will work for the new site too?  Nope, at least not right out of the box.  \\n\\nI attched the `.yml` file to my new project by placing an unmodified copy of it in the new project's `.github/workflows` directory.  Then when I committed the change and pushed it to GitHub the workflow kicked in automatically.  Ultimately it looks like the \\\"build\\\" portion of the process worked as-expected, but the \\\"deployment\\\" failed with these messages:  \\n\\n```\\nDeploymentId: 86ab60d0-3abf-429c-9c17-405068c1ebcf\\n\\ndeployment_token was not provided.\\nThe deployment_token is required for deploying content. If you'd like to continue the run without deployment, add the configuration skip_deploy_on_missing_secrets set to true in your workflow file\\nAn unknown exception has occurred\\n\\nFor further information, please visit the Azure Static Web Apps documentation at https://docs.microsoft.com/en-us/azure/static-web-apps/\\nIf you believe this behavior is unexpected, please raise a GitHub issue at https://github.com/azure/static-web-apps/issues/\\nExiting\\n```\\n\\n## Something is Missing\\n\\nSince I'm not absolutely sure what's missing, and I don't know how to replace it even if I was sure of what it is, I'm going to just create a new instance of this web app following the guidance, yet again, in [Quickstart: Build your first static web app](https://learn.microsoft.com/en-us/azure/static-web-apps/get-started-portal?tabs=vanilla-javascript&pivots=github).\\n\"}]],\"markups\":[],\"sections\":[[10,0],[10,1],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Today's burning question... Can I <em>easily</em> &quot;redefine&quot; an Azure Static Web App?</p>\n<p>So, the source code for my password-protected <a href=\"https://wieting-guild.tamatoledo.com/\">Wieting-Guild-Pages</a> is broken and I can't update the stale old content that's currently there.  It's a long story.  Fortunately, I've rebuilt that code in a new GitHub repo and have it working again.  Yay!</p>\n<p>Now, can I take the deployment parts of the old/broken repo and apply them to the new repo and make it all work again?</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"worth-a-try\">Worth a Try</h2>\n<p>So, I started this experiment by visiting the old project, <a href=\"https://github.com/SummittDweller/wieting-guild-pages\">https://github.com/SummittDweller/wieting-guild-pages</a>, and copying the <a href=\"https://github.com/SummittDweller/wieting-guild-pages/blob/main/.github/workflows/azure-static-web-apps-lemon-mushroom-087d78210.yml\">https://github.com/SummittDweller/wieting-guild-pages/blob/main/.github/workflows/azure-static-web-apps-lemon-mushroom-087d78210.yml</a> file found there.  That GitHub workflow file contains nearly all the information required to deploy the old site, maybe it will work for the new site too?  Nope, at least not right out of the box.</p>\n<p>I attched the <code>.yml</code> file to my new project by placing an unmodified copy of it in the new project's <code>.github/workflows</code> directory.  Then when I committed the change and pushed it to GitHub the workflow kicked in automatically.  Ultimately it looks like the &quot;build&quot; portion of the process worked as-expected, but the &quot;deployment&quot; failed with these messages:</p>\n<pre><code>DeploymentId: 86ab60d0-3abf-429c-9c17-405068c1ebcf\n\ndeployment_token was not provided.\nThe deployment_token is required for deploying content. If you'd like to continue the run without deployment, add the configuration skip_deploy_on_missing_secrets set to true in your workflow file\nAn unknown exception has occurred\n\nFor further information, please visit the Azure Static Web Apps documentation at https://docs.microsoft.com/en-us/azure/static-web-apps/\nIf you believe this behavior is unexpected, please raise a GitHub issue at https://github.com/azure/static-web-apps/issues/\nExiting\n</code></pre>\n<h2 id=\"something-is-missing\">Something is Missing</h2>\n<p>Since I'm not absolutely sure what's missing, and I don't know how to replace it even if I was sure of what it is, I'm going to just create a new instance of this web app following the guidance, yet again, in <a href=\"https://learn.microsoft.com/en-us/azure/static-web-apps/get-started-portal?tabs=vanilla-javascript&amp;pivots=github\">Quickstart: Build your first static web app</a>.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "64a6fb49ddadd63e1863bf77",
            "plaintext": "Today's burning question... Can I easily \"redefine\" an Azure Static Web App?\n\n\nSo, the source code for my password-protected Wieting-Guild-Pages is broken and I can't update the stale old content that's currently there. It's a long story. Fortunately, I've rebuilt that code in a new GitHub repo and have it working again. Yay!\n\n\nNow, can I take the deployment parts of the old/broken repo and apply them to the new repo and make it all work again?\n\n\n\nWorth a Try\n\n\nSo, I started this experiment by visiting the old project, https://github.com/SummittDweller/wieting-guild-pages, and copying the https://github.com/SummittDweller/wieting-guild-pages/blob/main/.github/workflows/azure-static-web-apps-lemon-mushroom-087d78210.yml file found there. That GitHub workflow file contains nearly all the information required to deploy the old site, maybe it will work for the new site too? Nope, at least not right out of the box.\n\n\nI attched the .yml file to my new project by placing an unmodified copy of it in the new project's .github/workflows directory. Then when I committed the change and pushed it to GitHub the workflow kicked in automatically. Ultimately it looks like the \"build\" portion of the process worked as-expected, but the \"deployment\" failed with these messages:\n\n\nDeploymentId: 86ab60d0-3abf-429c-9c17-405068c1ebcf\n\ndeployment_token was not provided.\nThe deployment_token is required for deploying content. If you'd like to continue the run without deployment, add the configuration skip_deploy_on_missing_secrets set to true in your workflow file\nAn unknown exception has occurred\n\nFor further information, please visit the Azure Static Web Apps documentation at https://docs.microsoft.com/en-us/azure/static-web-apps/\nIf you believe this behavior is unexpected, please raise a GitHub issue at https://github.com/azure/static-web-apps/issues/\nExiting\n\n\n\n\nSomething is Missing\n\n\nSince I'm not absolutely sure what's missing, and I don't know how to replace it even if I was sure of what it is, I'm going to just create a new instance of this web app following the guidance, yet again, in Quickstart: Build your first static web app.\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-07-06T17:35:05.000Z",
            "updated_at": "2023-07-06T19:11:12.000Z",
            "published_at": "2023-07-06T19:11:12.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64b93ff9ddadd63e1863bfd7",
            "uuid": "af32956c-75b1-49ab-85f1-7b8290f38a78",
            "title": "3Dprinter-probe-z-offset",
            "slug": "3dprinter",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"So, the probe Z-offset on my printer seems to be wonky.  I noticed during bed leveling that my print head is contacting the bed of my printer just BEFORE the probe is triggered.  That's not good!  I'm going to have a look at [BLTouch / CR Touch Z Offset (Z Probe Offset) Calibration in Marlin Firmware](https://www.3dprintgorilla.com/bltouch-crtouch-z-probe-offset-calibration-in-marlin/) to see if I can correct that posthaste.  \"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>So, the probe Z-offset on my printer seems to be wonky.  I noticed during bed leveling that my print head is contacting the bed of my printer just BEFORE the probe is triggered.  That's not good!  I'm going to have a look at <a href=\"https://www.3dprintgorilla.com/bltouch-crtouch-z-probe-offset-calibration-in-marlin/\">BLTouch / CR Touch Z Offset (Z Probe Offset) Calibration in Marlin Firmware</a> to see if I can correct that posthaste.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "64b93ff9ddadd63e1863bfd7",
            "plaintext": "So, the probe Z-offset on my printer seems to be wonky. I noticed during bed leveling that my print head is contacting the bed of my printer just BEFORE the probe is triggered. That's not good! I'm going to have a look at BLTouch / CR Touch Z Offset (Z Probe Offset) Calibration in Marlin Firmware to see if I can correct that posthaste.\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-07-20T14:08:57.000Z",
            "updated_at": "2023-07-20T14:12:20.000Z",
            "published_at": "2023-07-20T12:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64bafd80ddadd63e1863bfef",
            "uuid": "dbe452de-4c07-40dd-a896-4fa2cfd3516f",
            "title": "3d-printer-z-adjustment",
            "slug": "3d-printer-z-adjustment",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"Not sure yet if it will solve my problems, but I had the same issue as posted in [SOLVED E3V2 Nozzle hitting bed during CR Touch ABL](https://www.reddit.com/r/ender3/comments/r862z9/solved_e3v2_nozzle_hitting_bed_during_cr_touch_abl/) so I applied the washer \\\"fix\\\".  We shall see.\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>Not sure yet if it will solve my problems, but I had the same issue as posted in <a href=\"https://www.reddit.com/r/ender3/comments/r862z9/solved_e3v2_nozzle_hitting_bed_during_cr_touch_abl/\">SOLVED E3V2 Nozzle hitting bed during CR Touch ABL</a> so I applied the washer &quot;fix&quot;.  We shall see.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "64bafd80ddadd63e1863bfef",
            "plaintext": "Not sure yet if it will solve my problems, but I had the same issue as posted in SOLVED E3V2 Nozzle hitting bed during CR Touch ABL so I applied the washer \"fix\". We shall see.\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-07-21T21:49:52.000Z",
            "updated_at": "2023-07-21T21:51:38.000Z",
            "published_at": "2023-07-21T21:51:38.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64bd82b3ddadd63e1863c001",
            "uuid": "fadf9fbb-1462-49c0-b842-722209b7cd18",
            "title": "u-post-cap-stl-file",
            "slug": "u-post-cap-stl-file",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"file\",{\"loop\":false,\"src\":\"__GHOST_URL__/content/files/2023/07/42-to-27x35-Trapezoid-UPost-Cap.stl\",\"fileName\":\"42-to-27x35-Trapezoid-UPost-Cap.stl\",\"fileTitle\":\"42 to 27x35 Trapezoid UPost Cap\",\"fileCaption\":\"\",\"fileSize\":67284}]],\"markups\":[[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Need to try something new here... I have a 3d print \"],[0,[0],1,\".stl\"],[0,[],0,\" model file that I want to share with others.  I wonder if I can do that here as an attachment?  Let's try... \"]]],[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Need to try something new here... I have a 3d print <code>.stl</code> model file that I want to share with others. Â I wonder if I can do that here as an attachment? Â Let's try... </p>\n        <div class=\"kg-card kg-file-card kg-file-card-medium\">\n            <a class=\"kg-file-card-container\" href=\"__GHOST_URL__/content/files/2023/07/42-to-27x35-Trapezoid-UPost-Cap.stl\" title=\"Download\" download>\n                <div class=\"kg-file-card-contents\">\n                    <div class=\"kg-file-card-title\">42 to 27x35 Trapezoid UPost Cap</div>\n                    \n                    <div class=\"kg-file-card-metadata\">\n                        <div class=\"kg-file-card-filename\">42-to-27x35-Trapezoid-UPost-Cap.stl</div>\n                        <div class=\"kg-file-card-filesize\">66 KB</div>\n                    </div>\n                </div>\n                <div class=\"kg-file-card-icon\">\n                    <svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 24 24\"><defs><style>.a{fill:none;stroke:currentColor;stroke-linecap:round;stroke-linejoin:round;stroke-width:1.5px;}</style></defs><title>download-circle</title><polyline class=\"a\" points=\"8.25 14.25 12 18 15.75 14.25\"/><line class=\"a\" x1=\"12\" y1=\"6.75\" x2=\"12\" y2=\"18\"/><circle class=\"a\" cx=\"12\" cy=\"12\" r=\"11.25\"/></svg>\n                </div>\n            </a>\n        </div>\n        ",
            "comment_id": "64bd82b3ddadd63e1863c001",
            "plaintext": "Need to try something new here... I have a 3d print .stl model file that I want to share with others. Â I wonder if I can do that here as an attachment? Â Let's try...\n\n\n\n\n\n42 to 27x35 Trapezoid UPost Cap\n\n\n42-to-27x35-Trapezoid-UPost-Cap.stl\n66 KB\n\n\n\ndownload-circle\n\n\n\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-07-23T19:42:43.000Z",
            "updated_at": "2023-07-23T19:45:05.000Z",
            "published_at": "2023-07-23T19:45:05.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "64bec538ddadd63e1863c015",
            "uuid": "8ee8a860-10c3-449c-9d2f-135a83a444e0",
            "title": "Building My First Steamlit App",
            "slug": "building-my-first-steamlit-app",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"I've been wanting to give [Streamlit](https://streamlit.io/) a try for some time now.  Recently, I found [Streamlit DataScience Apps](https://github.com/Jcharis/Streamlit_DataScience_Apps), a _GitHub_ repo full of _Streamlit_ apps, written by [Jcharis](https://github.com/Jcharis/Streamlit_DataScience_Apps/commits?author=Jcharis).  In particular, I thought I would take the [Job_Search_App_with_Streamlit_Forms_n_GithubAPI](https://github.com/Jcharis/Streamlit_DataScience_Apps/tree/master/Job_Search_App_with_Streamlit_Forms_n_GithubAPI) code for a spin.\\n\\nFirst step, I created a new `~/GitHub/` code directory on my Mac; I named my directory `~/GitHub/job-search-app-with-streamlit-forms`.  The plan was to work in that directory inside _VSCode_ with all the project requirements housed in a Python virtual environment (`.venv`) there. \\n\\nThe command stream in my terminal looked like this:\\n\\n```\\nâ•­â”€mark@Marks-Mac-Mini ~\\nâ•°â”€$ cd ~/GitHub\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\\nâ•°â”€$ mkdir job-search-app-with-streamlit-forms\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\\nâ•°â”€$ cd job-search-app-with-streamlit-forms\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms\\nâ•°â”€$ code .\\n```\\n\\nThat last command opened the new directory in _VSCode_ where I had all the tools I needed, including a new terminal window.  In that window I continued with...\\n\\n```\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \\nâ•°â”€$ python3 -m venv .venv\\n\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \\nâ•°â”€$ source .venv/bin/activate\\n\\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \\nâ•°â”€$ pip3 install streamlit\\n\\nCollecting streamlit\\n  Downloading streamlit-1.25.0-py2.py3-none-any.whl (8.1 MB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 8.1/8.1 MB 26.6 MB/s eta 0:00:00\\nCollecting altair<6,>=4.0\\n  Downloading altair-5.0.1-py3-none-any.whl (471 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 471.5/471.5 kB 13.9 MB/s eta 0:00:00\\nCollecting blinker<2,>=1.0.0\\n  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\\nCollecting cachetools<6,>=4.0\\n  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\\nCollecting click<9,>=7.0\\n  Downloading click-8.1.6-py3-none-any.whl (97 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 97.9/97.9 kB 3.7 MB/s eta 0:00:00\\nCollecting importlib-metadata<7,>=1.4\\n  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\\nCollecting numpy<2,>=1.19.3\\n  Downloading numpy-1.25.1-cp311-cp311-macosx_10_9_x86_64.whl (20.0 MB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20.0/20.0 MB 30.2 MB/s eta 0:00:00\\nCollecting packaging<24,>=16.8\\n  Downloading packaging-23.1-py3-none-any.whl (48 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 48.9/48.9 kB 1.6 MB/s eta 0:00:00\\nCollecting pandas<3,>=1.3.0\\n  Downloading pandas-2.0.3-cp311-cp311-macosx_10_9_x86_64.whl (11.6 MB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 11.6/11.6 MB 38.2 MB/s eta 0:00:00\\nCollecting pillow<10,>=7.1.0\\n  Downloading Pillow-9.5.0-cp311-cp311-macosx_10_10_x86_64.whl (3.4 MB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.4/3.4 MB 23.5 MB/s eta 0:00:00\\nCollecting protobuf<5,>=3.20\\n  Downloading protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 400.3/400.3 kB 12.9 MB/s eta 0:00:00\\nCollecting pyarrow>=6.0\\n  Downloading pyarrow-12.0.1-cp311-cp311-macosx_10_14_x86_64.whl (24.7 MB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24.7/24.7 MB 19.0 MB/s eta 0:00:00\\nCollecting pympler<2,>=0.9\\n  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 164.8/164.8 kB 5.9 MB/s eta 0:00:00\\nCollecting python-dateutil<3,>=2.7.3\\n  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 247.7/247.7 kB 7.9 MB/s eta 0:00:00\\nCollecting requests<3,>=2.18\\n  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.6/62.6 kB 2.3 MB/s eta 0:00:00\\nCollecting rich<14,>=10.14.0\\n  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 239.4/239.4 kB 8.8 MB/s eta 0:00:00\\nCollecting tenacity<9,>=8.1.0\\n  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\\nCollecting toml<2,>=0.10.1\\n  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\\nCollecting typing-extensions<5,>=4.1.0\\n  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\\nCollecting tzlocal<5,>=1.1\\n  Downloading tzlocal-4.3.1-py3-none-any.whl (20 kB)\\nCollecting validators<1,>=0.2\\n  Downloading validators-0.20.0.tar.gz (30 kB)\\n  Preparing metadata (setup.py) ... done\\nCollecting gitpython!=3.1.19,<4,>=3.0.7\\n  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 188.5/188.5 kB 6.9 MB/s eta 0:00:00\\nCollecting pydeck<1,>=0.8\\n  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.7/4.7 MB 28.7 MB/s eta 0:00:00\\nCollecting tornado<7,>=6.0.3\\n  Downloading tornado-6.3.2-cp38-abi3-macosx_10_9_x86_64.whl (422 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 422.6/422.6 kB 12.7 MB/s eta 0:00:00\\nCollecting jinja2\\n  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 133.1/133.1 kB 5.4 MB/s eta 0:00:00\\nCollecting jsonschema>=3.0\\n  Downloading jsonschema-4.18.4-py3-none-any.whl (80 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 81.0/81.0 kB 3.0 MB/s eta 0:00:00\\nCollecting toolz\\n  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 55.8/55.8 kB 2.1 MB/s eta 0:00:00\\nCollecting gitdb<5,>=4.0.1\\n  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.7/62.7 kB 2.1 MB/s eta 0:00:00\\nCollecting zipp>=0.5\\n  Downloading zipp-3.16.2-py3-none-any.whl (7.2 kB)\\nCollecting pytz>=2020.1\\n  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\\nCollecting tzdata>=2022.1\\n  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 341.8/341.8 kB 10.8 MB/s eta 0:00:00\\nCollecting six>=1.5\\n  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\\nCollecting charset-normalizer<4,>=2\\n  Downloading charset_normalizer-3.2.0-cp311-cp311-macosx_10_9_x86_64.whl (125 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 125.1/125.1 kB 4.5 MB/s eta 0:00:00\\nCollecting idna<4,>=2.5\\n  Downloading idna-3.4-py3-none-any.whl (61 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 61.5/61.5 kB 2.1 MB/s eta 0:00:00\\nCollecting urllib3<3,>=1.21.1\\n  Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 123.9/123.9 kB 4.5 MB/s eta 0:00:00\\nCollecting certifi>=2017.4.17\\n  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 158.3/158.3 kB 5.7 MB/s eta 0:00:00\\nCollecting markdown-it-py>=2.2.0\\n  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 87.5/87.5 kB 3.3 MB/s eta 0:00:00\\nCollecting pygments<3.0.0,>=2.13.0\\n  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.1/1.1 MB 23.0 MB/s eta 0:00:00\\nCollecting pytz-deprecation-shim\\n  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\\nCollecting decorator>=3.4.0\\n  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\\nCollecting smmap<6,>=3.0.1\\n  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\\nCollecting MarkupSafe>=2.0\\n  Downloading MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_x86_64.whl (13 kB)\\nCollecting attrs>=22.2.0\\n  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 61.2/61.2 kB 2.1 MB/s eta 0:00:00\\nCollecting jsonschema-specifications>=2023.03.6\\n  Downloading jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\\nCollecting referencing>=0.28.4\\n  Downloading referencing-0.30.0-py3-none-any.whl (25 kB)\\nCollecting rpds-py>=0.7.1\\n  Downloading rpds_py-0.9.2-cp311-cp311-macosx_10_7_x86_64.whl (311 kB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 311.9/311.9 kB 9.3 MB/s eta 0:00:00\\nCollecting mdurl~=0.1\\n  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\\nInstalling collected packages: pytz, zipp, urllib3, tzdata, typing-extensions, tornado, toolz, toml, tenacity, smmap, six, rpds-py, pympler, pygments, protobuf, pillow, packaging, numpy, mdurl, MarkupSafe, idna, decorator, click, charset-normalizer, certifi, cachetools, blinker, attrs, validators, requests, referencing, pytz-deprecation-shim, python-dateutil, pyarrow, markdown-it-py, jinja2, importlib-metadata, gitdb, tzlocal, rich, pydeck, pandas, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\\n  DEPRECATION: validators is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\\n  Running setup.py install for validators ... done\\nSuccessfully installed MarkupSafe-2.1.3 altair-5.0.1 attrs-23.1.0 blinker-1.6.2 cachetools-5.3.1 certifi-2023.7.22 charset-normalizer-3.2.0 click-8.1.6 decorator-5.1.1 gitdb-4.0.10 gitpython-3.1.32 idna-3.4 importlib-metadata-6.8.0 jinja2-3.1.2 jsonschema-4.18.4 jsonschema-specifications-2023.7.1 markdown-it-py-3.0.0 mdurl-0.1.2 numpy-1.25.1 packaging-23.1 pandas-2.0.3 pillow-9.5.0 protobuf-4.23.4 pyarrow-12.0.1 pydeck-0.8.0 pygments-2.15.1 pympler-1.0.1 python-dateutil-2.8.2 pytz-2023.3 pytz-deprecation-shim-0.1.0.post0 referencing-0.30.0 requests-2.31.0 rich-13.4.2 rpds-py-0.9.2 six-1.16.0 smmap-5.0.0 streamlit-1.25.0 tenacity-8.2.2 toml-0.10.2 toolz-0.12.0 tornado-6.3.2 typing-extensions-4.7.1 tzdata-2023.3 tzlocal-4.3.1 urllib3-2.0.4 validators-0.20.0 zipp-3.16.2\\n\\n[notice] A new release of pip is available: 23.0.1 -> 23.2.1\\n[notice] To update, run: pip install --upgrade pip\\n\\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \\nâ•°â”€$ pip install --upgrade pip\\n\\nRequirement already satisfied: pip in ./.venv/lib/python3.11/site-packages (23.0.1)\\nCollecting pip\\n  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.1/2.1 MB 12.6 MB/s eta 0:00:00\\nInstalling collected packages: pip\\n  Attempting uninstall: pip\\n    Found existing installation: pip 23.0.1\\n    Uninstalling pip-23.0.1:\\n      Successfully uninstalled pip-23.0.1\\nSuccessfully installed pip-23.2.1\\n\\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \\nâ•°â”€$ pip3 install requests\\n\\nRequirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (2.31.0)\\nRequirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests) (3.2.0)\\nRequirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests) (3.4)\\nRequirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests) (2.0.4)\\nRequirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests) (2023.7.22)\\n\\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \\nâ•°â”€$ streamlit app\\nUsage: streamlit [OPTIONS] COMMAND [ARGS]...\\nTry 'streamlit --help' for help.\\n\\nError: No such command 'app'.\\n\\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \\nâ•°â”€$ streamlit run app.py\\n\\n  You can now view your Streamlit app in your browser.\\n\\n  Local URL: http://localhost:8501\\n  Network URL: http://192.168.0.183:8501\\n\\n  For better performance, install the Watchdog module:\\n\\n  $ xcode-select --install\\n  $ pip install watchdog\\n            \\n2023-07-24 20:58:17.240 Uncaught app exception\\nTraceback (most recent call last):\\n  File \\\"/Users/mark/GitHub/job-search-app-with-streamlit-forms/.venv/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py\\\", line 552, in _run_script\\n    exec(code, module.__dict__)\\n  File \\\"/Users/mark/GitHub/job-search-app-with-streamlit-forms/app.py\\\", line 116, in <module>\\n    main()\\n  File \\\"/Users/mark/GitHub/job-search-app-with-streamlit-forms/app.py\\\", line 43, in main\\n    nav1,nav2,nav3 = st.beta_columns([3,2,1])\\n                     ^^^^^^^^^^^^^^^\\nAttributeError: module 'streamlit' has no attribute 'beta_columns'\\n```\\n\\nMackenzie says I need to remove the `beta_` in two places in the code... Done.\\n\\nLaunching the app again with `streamlit run app.py` after a moment or two it works!  \\n\\n\\n\\n\\n\\n\\n\\n\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]],[1,\"p\",[[0,[],0,\" \"]]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>I've been wanting to give <a href=\"https://streamlit.io/\">Streamlit</a> a try for some time now.  Recently, I found <a href=\"https://github.com/Jcharis/Streamlit_DataScience_Apps\">Streamlit DataScience Apps</a>, a <em>GitHub</em> repo full of <em>Streamlit</em> apps, written by <a href=\"https://github.com/Jcharis/Streamlit_DataScience_Apps/commits?author=Jcharis\">Jcharis</a>.  In particular, I thought I would take the <a href=\"https://github.com/Jcharis/Streamlit_DataScience_Apps/tree/master/Job_Search_App_with_Streamlit_Forms_n_GithubAPI\">Job_Search_App_with_Streamlit_Forms_n_GithubAPI</a> code for a spin.</p>\n<p>First step, I created a new <code>~/GitHub/</code> code directory on my Mac; I named my directory <code>~/GitHub/job-search-app-with-streamlit-forms</code>.  The plan was to work in that directory inside <em>VSCode</em> with all the project requirements housed in a Python virtual environment (<code>.venv</code>) there.</p>\n<p>The command stream in my terminal looked like this:</p>\n<pre><code>â•­â”€mark@Marks-Mac-Mini ~\nâ•°â”€$ cd ~/GitHub\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\nâ•°â”€$ mkdir job-search-app-with-streamlit-forms\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\nâ•°â”€$ cd job-search-app-with-streamlit-forms\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms\nâ•°â”€$ code .\n</code></pre>\n<p>That last command opened the new directory in <em>VSCode</em> where I had all the tools I needed, including a new terminal window.  In that window I continued with...</p>\n<pre><code>â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \nâ•°â”€$ python3 -m venv .venv\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \nâ•°â”€$ source .venv/bin/activate\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \nâ•°â”€$ pip3 install streamlit\n\nCollecting streamlit\n  Downloading streamlit-1.25.0-py2.py3-none-any.whl (8.1 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 8.1/8.1 MB 26.6 MB/s eta 0:00:00\nCollecting altair&lt;6,&gt;=4.0\n  Downloading altair-5.0.1-py3-none-any.whl (471 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 471.5/471.5 kB 13.9 MB/s eta 0:00:00\nCollecting blinker&lt;2,&gt;=1.0.0\n  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\nCollecting cachetools&lt;6,&gt;=4.0\n  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\nCollecting click&lt;9,&gt;=7.0\n  Downloading click-8.1.6-py3-none-any.whl (97 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 97.9/97.9 kB 3.7 MB/s eta 0:00:00\nCollecting importlib-metadata&lt;7,&gt;=1.4\n  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\nCollecting numpy&lt;2,&gt;=1.19.3\n  Downloading numpy-1.25.1-cp311-cp311-macosx_10_9_x86_64.whl (20.0 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20.0/20.0 MB 30.2 MB/s eta 0:00:00\nCollecting packaging&lt;24,&gt;=16.8\n  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 48.9/48.9 kB 1.6 MB/s eta 0:00:00\nCollecting pandas&lt;3,&gt;=1.3.0\n  Downloading pandas-2.0.3-cp311-cp311-macosx_10_9_x86_64.whl (11.6 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 11.6/11.6 MB 38.2 MB/s eta 0:00:00\nCollecting pillow&lt;10,&gt;=7.1.0\n  Downloading Pillow-9.5.0-cp311-cp311-macosx_10_10_x86_64.whl (3.4 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.4/3.4 MB 23.5 MB/s eta 0:00:00\nCollecting protobuf&lt;5,&gt;=3.20\n  Downloading protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 400.3/400.3 kB 12.9 MB/s eta 0:00:00\nCollecting pyarrow&gt;=6.0\n  Downloading pyarrow-12.0.1-cp311-cp311-macosx_10_14_x86_64.whl (24.7 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24.7/24.7 MB 19.0 MB/s eta 0:00:00\nCollecting pympler&lt;2,&gt;=0.9\n  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 164.8/164.8 kB 5.9 MB/s eta 0:00:00\nCollecting python-dateutil&lt;3,&gt;=2.7.3\n  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 247.7/247.7 kB 7.9 MB/s eta 0:00:00\nCollecting requests&lt;3,&gt;=2.18\n  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.6/62.6 kB 2.3 MB/s eta 0:00:00\nCollecting rich&lt;14,&gt;=10.14.0\n  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 239.4/239.4 kB 8.8 MB/s eta 0:00:00\nCollecting tenacity&lt;9,&gt;=8.1.0\n  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\nCollecting toml&lt;2,&gt;=0.10.1\n  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\nCollecting typing-extensions&lt;5,&gt;=4.1.0\n  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\nCollecting tzlocal&lt;5,&gt;=1.1\n  Downloading tzlocal-4.3.1-py3-none-any.whl (20 kB)\nCollecting validators&lt;1,&gt;=0.2\n  Downloading validators-0.20.0.tar.gz (30 kB)\n  Preparing metadata (setup.py) ... done\nCollecting gitpython!=3.1.19,&lt;4,&gt;=3.0.7\n  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 188.5/188.5 kB 6.9 MB/s eta 0:00:00\nCollecting pydeck&lt;1,&gt;=0.8\n  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.7/4.7 MB 28.7 MB/s eta 0:00:00\nCollecting tornado&lt;7,&gt;=6.0.3\n  Downloading tornado-6.3.2-cp38-abi3-macosx_10_9_x86_64.whl (422 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 422.6/422.6 kB 12.7 MB/s eta 0:00:00\nCollecting jinja2\n  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 133.1/133.1 kB 5.4 MB/s eta 0:00:00\nCollecting jsonschema&gt;=3.0\n  Downloading jsonschema-4.18.4-py3-none-any.whl (80 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 81.0/81.0 kB 3.0 MB/s eta 0:00:00\nCollecting toolz\n  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 55.8/55.8 kB 2.1 MB/s eta 0:00:00\nCollecting gitdb&lt;5,&gt;=4.0.1\n  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.7/62.7 kB 2.1 MB/s eta 0:00:00\nCollecting zipp&gt;=0.5\n  Downloading zipp-3.16.2-py3-none-any.whl (7.2 kB)\nCollecting pytz&gt;=2020.1\n  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\nCollecting tzdata&gt;=2022.1\n  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 341.8/341.8 kB 10.8 MB/s eta 0:00:00\nCollecting six&gt;=1.5\n  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\nCollecting charset-normalizer&lt;4,&gt;=2\n  Downloading charset_normalizer-3.2.0-cp311-cp311-macosx_10_9_x86_64.whl (125 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 125.1/125.1 kB 4.5 MB/s eta 0:00:00\nCollecting idna&lt;4,&gt;=2.5\n  Downloading idna-3.4-py3-none-any.whl (61 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 61.5/61.5 kB 2.1 MB/s eta 0:00:00\nCollecting urllib3&lt;3,&gt;=1.21.1\n  Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 123.9/123.9 kB 4.5 MB/s eta 0:00:00\nCollecting certifi&gt;=2017.4.17\n  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 158.3/158.3 kB 5.7 MB/s eta 0:00:00\nCollecting markdown-it-py&gt;=2.2.0\n  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 87.5/87.5 kB 3.3 MB/s eta 0:00:00\nCollecting pygments&lt;3.0.0,&gt;=2.13.0\n  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.1/1.1 MB 23.0 MB/s eta 0:00:00\nCollecting pytz-deprecation-shim\n  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\nCollecting decorator&gt;=3.4.0\n  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\nCollecting smmap&lt;6,&gt;=3.0.1\n  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\nCollecting MarkupSafe&gt;=2.0\n  Downloading MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_x86_64.whl (13 kB)\nCollecting attrs&gt;=22.2.0\n  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 61.2/61.2 kB 2.1 MB/s eta 0:00:00\nCollecting jsonschema-specifications&gt;=2023.03.6\n  Downloading jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\nCollecting referencing&gt;=0.28.4\n  Downloading referencing-0.30.0-py3-none-any.whl (25 kB)\nCollecting rpds-py&gt;=0.7.1\n  Downloading rpds_py-0.9.2-cp311-cp311-macosx_10_7_x86_64.whl (311 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 311.9/311.9 kB 9.3 MB/s eta 0:00:00\nCollecting mdurl~=0.1\n  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\nInstalling collected packages: pytz, zipp, urllib3, tzdata, typing-extensions, tornado, toolz, toml, tenacity, smmap, six, rpds-py, pympler, pygments, protobuf, pillow, packaging, numpy, mdurl, MarkupSafe, idna, decorator, click, charset-normalizer, certifi, cachetools, blinker, attrs, validators, requests, referencing, pytz-deprecation-shim, python-dateutil, pyarrow, markdown-it-py, jinja2, importlib-metadata, gitdb, tzlocal, rich, pydeck, pandas, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n  DEPRECATION: validators is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n  Running setup.py install for validators ... done\nSuccessfully installed MarkupSafe-2.1.3 altair-5.0.1 attrs-23.1.0 blinker-1.6.2 cachetools-5.3.1 certifi-2023.7.22 charset-normalizer-3.2.0 click-8.1.6 decorator-5.1.1 gitdb-4.0.10 gitpython-3.1.32 idna-3.4 importlib-metadata-6.8.0 jinja2-3.1.2 jsonschema-4.18.4 jsonschema-specifications-2023.7.1 markdown-it-py-3.0.0 mdurl-0.1.2 numpy-1.25.1 packaging-23.1 pandas-2.0.3 pillow-9.5.0 protobuf-4.23.4 pyarrow-12.0.1 pydeck-0.8.0 pygments-2.15.1 pympler-1.0.1 python-dateutil-2.8.2 pytz-2023.3 pytz-deprecation-shim-0.1.0.post0 referencing-0.30.0 requests-2.31.0 rich-13.4.2 rpds-py-0.9.2 six-1.16.0 smmap-5.0.0 streamlit-1.25.0 tenacity-8.2.2 toml-0.10.2 toolz-0.12.0 tornado-6.3.2 typing-extensions-4.7.1 tzdata-2023.3 tzlocal-4.3.1 urllib3-2.0.4 validators-0.20.0 zipp-3.16.2\n\n[notice] A new release of pip is available: 23.0.1 -&gt; 23.2.1\n[notice] To update, run: pip install --upgrade pip\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \nâ•°â”€$ pip install --upgrade pip\n\nRequirement already satisfied: pip in ./.venv/lib/python3.11/site-packages (23.0.1)\nCollecting pip\n  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.1/2.1 MB 12.6 MB/s eta 0:00:00\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.0.1\n    Uninstalling pip-23.0.1:\n      Successfully uninstalled pip-23.0.1\nSuccessfully installed pip-23.2.1\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \nâ•°â”€$ pip3 install requests\n\nRequirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (2.31.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in ./.venv/lib/python3.11/site-packages (from requests) (3.2.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in ./.venv/lib/python3.11/site-packages (from requests) (3.4)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests) (2.0.4)\nRequirement already satisfied: certifi&gt;=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests) (2023.7.22)\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \nâ•°â”€$ streamlit app\nUsage: streamlit [OPTIONS] COMMAND [ARGS]...\nTry 'streamlit --help' for help.\n\nError: No such command 'app'.\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \nâ•°â”€$ streamlit run app.py\n\n  You can now view your Streamlit app in your browser.\n\n  Local URL: http://localhost:8501\n  Network URL: http://192.168.0.183:8501\n\n  For better performance, install the Watchdog module:\n\n  $ xcode-select --install\n  $ pip install watchdog\n            \n2023-07-24 20:58:17.240 Uncaught app exception\nTraceback (most recent call last):\n  File &quot;/Users/mark/GitHub/job-search-app-with-streamlit-forms/.venv/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py&quot;, line 552, in _run_script\n    exec(code, module.__dict__)\n  File &quot;/Users/mark/GitHub/job-search-app-with-streamlit-forms/app.py&quot;, line 116, in &lt;module&gt;\n    main()\n  File &quot;/Users/mark/GitHub/job-search-app-with-streamlit-forms/app.py&quot;, line 43, in main\n    nav1,nav2,nav3 = st.beta_columns([3,2,1])\n                     ^^^^^^^^^^^^^^^\nAttributeError: module 'streamlit' has no attribute 'beta_columns'\n</code></pre>\n<p>Mackenzie says I need to remove the <code>beta_</code> in two places in the code... Done.</p>\n<p>Launching the app again with <code>streamlit run app.py</code> after a moment or two it works!</p>\n<!--kg-card-end: markdown--><p></p><p> </p>",
            "comment_id": "64bec538ddadd63e1863c015",
            "plaintext": "I've been wanting to give Streamlit a try for some time now. Recently, I found Streamlit DataScience Apps, a GitHub repo full of Streamlit apps, written by Jcharis. In particular, I thought I would take the Job_Search_App_with_Streamlit_Forms_n_GithubAPI code for a spin.\n\n\nFirst step, I created a new ~/GitHub/ code directory on my Mac; I named my directory ~/GitHub/job-search-app-with-streamlit-forms. The plan was to work in that directory inside VSCode with all the project requirements housed in a Python virtual environment (.venv) there.\n\n\nThe command stream in my terminal looked like this:\n\n\nâ•­â”€mark@Marks-Mac-Mini ~\nâ•°â”€$ cd ~/GitHub\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\nâ•°â”€$ mkdir job-search-app-with-streamlit-forms\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\nâ•°â”€$ cd job-search-app-with-streamlit-forms\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms\nâ•°â”€$ code .\n\n\n\nThat last command opened the new directory in VSCode where I had all the tools I needed, including a new terminal window. In that window I continued with...\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \nâ•°â”€$ python3 -m venv .venv\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \nâ•°â”€$ source .venv/bin/activate\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \nâ•°â”€$ pip3 install streamlit\n\nCollecting streamlit\n  Downloading streamlit-1.25.0-py2.py3-none-any.whl (8.1 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 8.1/8.1 MB 26.6 MB/s eta 0:00:00\nCollecting altair<6,>=4.0\n  Downloading altair-5.0.1-py3-none-any.whl (471 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 471.5/471.5 kB 13.9 MB/s eta 0:00:00\nCollecting blinker<2,>=1.0.0\n  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\nCollecting cachetools<6,>=4.0\n  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\nCollecting click<9,>=7.0\n  Downloading click-8.1.6-py3-none-any.whl (97 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 97.9/97.9 kB 3.7 MB/s eta 0:00:00\nCollecting importlib-metadata<7,>=1.4\n  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\nCollecting numpy<2,>=1.19.3\n  Downloading numpy-1.25.1-cp311-cp311-macosx_10_9_x86_64.whl (20.0 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 20.0/20.0 MB 30.2 MB/s eta 0:00:00\nCollecting packaging<24,>=16.8\n  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 48.9/48.9 kB 1.6 MB/s eta 0:00:00\nCollecting pandas<3,>=1.3.0\n  Downloading pandas-2.0.3-cp311-cp311-macosx_10_9_x86_64.whl (11.6 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 11.6/11.6 MB 38.2 MB/s eta 0:00:00\nCollecting pillow<10,>=7.1.0\n  Downloading Pillow-9.5.0-cp311-cp311-macosx_10_10_x86_64.whl (3.4 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.4/3.4 MB 23.5 MB/s eta 0:00:00\nCollecting protobuf<5,>=3.20\n  Downloading protobuf-4.23.4-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 400.3/400.3 kB 12.9 MB/s eta 0:00:00\nCollecting pyarrow>=6.0\n  Downloading pyarrow-12.0.1-cp311-cp311-macosx_10_14_x86_64.whl (24.7 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24.7/24.7 MB 19.0 MB/s eta 0:00:00\nCollecting pympler<2,>=0.9\n  Downloading Pympler-1.0.1-py3-none-any.whl (164 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 164.8/164.8 kB 5.9 MB/s eta 0:00:00\nCollecting python-dateutil<3,>=2.7.3\n  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 247.7/247.7 kB 7.9 MB/s eta 0:00:00\nCollecting requests<3,>=2.18\n  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.6/62.6 kB 2.3 MB/s eta 0:00:00\nCollecting rich<14,>=10.14.0\n  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 239.4/239.4 kB 8.8 MB/s eta 0:00:00\nCollecting tenacity<9,>=8.1.0\n  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\nCollecting toml<2,>=0.10.1\n  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\nCollecting typing-extensions<5,>=4.1.0\n  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\nCollecting tzlocal<5,>=1.1\n  Downloading tzlocal-4.3.1-py3-none-any.whl (20 kB)\nCollecting validators<1,>=0.2\n  Downloading validators-0.20.0.tar.gz (30 kB)\n  Preparing metadata (setup.py) ... done\nCollecting gitpython!=3.1.19,<4,>=3.0.7\n  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 188.5/188.5 kB 6.9 MB/s eta 0:00:00\nCollecting pydeck<1,>=0.8\n  Downloading pydeck-0.8.0-py2.py3-none-any.whl (4.7 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 4.7/4.7 MB 28.7 MB/s eta 0:00:00\nCollecting tornado<7,>=6.0.3\n  Downloading tornado-6.3.2-cp38-abi3-macosx_10_9_x86_64.whl (422 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 422.6/422.6 kB 12.7 MB/s eta 0:00:00\nCollecting jinja2\n  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 133.1/133.1 kB 5.4 MB/s eta 0:00:00\nCollecting jsonschema>=3.0\n  Downloading jsonschema-4.18.4-py3-none-any.whl (80 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 81.0/81.0 kB 3.0 MB/s eta 0:00:00\nCollecting toolz\n  Downloading toolz-0.12.0-py3-none-any.whl (55 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 55.8/55.8 kB 2.1 MB/s eta 0:00:00\nCollecting gitdb<5,>=4.0.1\n  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.7/62.7 kB 2.1 MB/s eta 0:00:00\nCollecting zipp>=0.5\n  Downloading zipp-3.16.2-py3-none-any.whl (7.2 kB)\nCollecting pytz>=2020.1\n  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)\nCollecting tzdata>=2022.1\n  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 341.8/341.8 kB 10.8 MB/s eta 0:00:00\nCollecting six>=1.5\n  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\nCollecting charset-normalizer<4,>=2\n  Downloading charset_normalizer-3.2.0-cp311-cp311-macosx_10_9_x86_64.whl (125 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 125.1/125.1 kB 4.5 MB/s eta 0:00:00\nCollecting idna<4,>=2.5\n  Downloading idna-3.4-py3-none-any.whl (61 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 61.5/61.5 kB 2.1 MB/s eta 0:00:00\nCollecting urllib3<3,>=1.21.1\n  Downloading urllib3-2.0.4-py3-none-any.whl (123 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 123.9/123.9 kB 4.5 MB/s eta 0:00:00\nCollecting certifi>=2017.4.17\n  Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 158.3/158.3 kB 5.7 MB/s eta 0:00:00\nCollecting markdown-it-py>=2.2.0\n  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 87.5/87.5 kB 3.3 MB/s eta 0:00:00\nCollecting pygments<3.0.0,>=2.13.0\n  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.1/1.1 MB 23.0 MB/s eta 0:00:00\nCollecting pytz-deprecation-shim\n  Downloading pytz_deprecation_shim-0.1.0.post0-py2.py3-none-any.whl (15 kB)\nCollecting decorator>=3.4.0\n  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\nCollecting smmap<6,>=3.0.1\n  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\nCollecting MarkupSafe>=2.0\n  Downloading MarkupSafe-2.1.3-cp311-cp311-macosx_10_9_x86_64.whl (13 kB)\nCollecting attrs>=22.2.0\n  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 61.2/61.2 kB 2.1 MB/s eta 0:00:00\nCollecting jsonschema-specifications>=2023.03.6\n  Downloading jsonschema_specifications-2023.7.1-py3-none-any.whl (17 kB)\nCollecting referencing>=0.28.4\n  Downloading referencing-0.30.0-py3-none-any.whl (25 kB)\nCollecting rpds-py>=0.7.1\n  Downloading rpds_py-0.9.2-cp311-cp311-macosx_10_7_x86_64.whl (311 kB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 311.9/311.9 kB 9.3 MB/s eta 0:00:00\nCollecting mdurl~=0.1\n  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\nInstalling collected packages: pytz, zipp, urllib3, tzdata, typing-extensions, tornado, toolz, toml, tenacity, smmap, six, rpds-py, pympler, pygments, protobuf, pillow, packaging, numpy, mdurl, MarkupSafe, idna, decorator, click, charset-normalizer, certifi, cachetools, blinker, attrs, validators, requests, referencing, pytz-deprecation-shim, python-dateutil, pyarrow, markdown-it-py, jinja2, importlib-metadata, gitdb, tzlocal, rich, pydeck, pandas, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n  DEPRECATION: validators is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n  Running setup.py install for validators ... done\nSuccessfully installed MarkupSafe-2.1.3 altair-5.0.1 attrs-23.1.0 blinker-1.6.2 cachetools-5.3.1 certifi-2023.7.22 charset-normalizer-3.2.0 click-8.1.6 decorator-5.1.1 gitdb-4.0.10 gitpython-3.1.32 idna-3.4 importlib-metadata-6.8.0 jinja2-3.1.2 jsonschema-4.18.4 jsonschema-specifications-2023.7.1 markdown-it-py-3.0.0 mdurl-0.1.2 numpy-1.25.1 packaging-23.1 pandas-2.0.3 pillow-9.5.0 protobuf-4.23.4 pyarrow-12.0.1 pydeck-0.8.0 pygments-2.15.1 pympler-1.0.1 python-dateutil-2.8.2 pytz-2023.3 pytz-deprecation-shim-0.1.0.post0 referencing-0.30.0 requests-2.31.0 rich-13.4.2 rpds-py-0.9.2 six-1.16.0 smmap-5.0.0 streamlit-1.25.0 tenacity-8.2.2 toml-0.10.2 toolz-0.12.0 tornado-6.3.2 typing-extensions-4.7.1 tzdata-2023.3 tzlocal-4.3.1 urllib3-2.0.4 validators-0.20.0 zipp-3.16.2\n\n[notice] A new release of pip is available: 23.0.1 -> 23.2.1\n[notice] To update, run: pip install --upgrade pip\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \nâ•°â”€$ pip install --upgrade pip\n\nRequirement already satisfied: pip in ./.venv/lib/python3.11/site-packages (23.0.1)\nCollecting pip\n  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.1/2.1 MB 12.6 MB/s eta 0:00:00\nInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 23.0.1\n    Uninstalling pip-23.0.1:\n      Successfully uninstalled pip-23.0.1\nSuccessfully installed pip-23.2.1\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \nâ•°â”€$ pip3 install requests\n\nRequirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests) (2023.7.22)\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \nâ•°â”€$ streamlit app\nUsage: streamlit [OPTIONS] COMMAND [ARGS]...\nTry 'streamlit --help' for help.\n\nError: No such command 'app'.\n\n(.venv) â•­â”€mark@Marks-Mac-Mini ~/GitHub/job-search-app-with-streamlit-forms \nâ•°â”€$ streamlit run app.py\n\n  You can now view your Streamlit app in your browser.\n\n  Local URL: http://localhost:8501\n  Network URL: http://192.168.0.183:8501\n\n  For better performance, install the Watchdog module:\n\n  $ xcode-select --install\n  $ pip install watchdog\n            \n2023-07-24 20:58:17.240 Uncaught app exception\nTraceback (most recent call last):\n  File \"/Users/mark/GitHub/job-search-app-with-streamlit-forms/.venv/lib/python3.11/site-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 552, in _run_script\n    exec(code, module.__dict__)\n  File \"/Users/mark/GitHub/job-search-app-with-streamlit-forms/app.py\", line 116, in <module>\n    main()\n  File \"/Users/mark/GitHub/job-search-app-with-streamlit-forms/app.py\", line 43, in main\n    nav1,nav2,nav3 = st.beta_columns([3,2,1])\n                     ^^^^^^^^^^^^^^^\nAttributeError: module 'streamlit' has no attribute 'beta_columns'\n\n\n\nMackenzie says I need to remove the beta_ in two places in the code... Done.\n\n\nLaunching the app again with streamlit run app.py after a moment or two it works!\n\n\n\n\n",
            "feature_image": "https://images.unsplash.com/photo-1600682322637-95c40966e79f?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDM2fHxweXRob258ZW58MHx8fHwxNjkwMjIzOTUxfDA&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-07-24T18:38:48.000Z",
            "updated_at": "2023-07-25T02:15:43.000Z",
            "published_at": "2023-07-24T18:44:51.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6519787cddadd63e1863c05f",
            "uuid": "e975e0f7-4fc7-407f-83d5-7c4d3db52c39",
            "title": "Tested Positive for COVID",
            "slug": "tested-positive-for-covid",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"Finally got to see the doctor today after starting to feel ill on September 3, and to my surprise I tested positive for COVID.  Symptoms were mild so I didn't need or receive any treatment.\"]]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Finally got to see the doctor today after starting to feel ill on September 3, and to my surprise I tested positive for COVID. Â Symptoms were mild so I didn't need or receive any treatment.</p>",
            "comment_id": "6519787cddadd63e1863c05f",
            "plaintext": "Finally got to see the doctor today after starting to feel ill on September 3, and to my surprise I tested positive for COVID. Â Symptoms were mild so I didn't need or receive any treatment.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-10-01T13:47:40.000Z",
            "updated_at": "2023-10-01T13:49:47.000Z",
            "published_at": "2023-09-05T13:47:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "65198336ddadd63e1863c06f",
            "uuid": "0caf5780-0b84-4a34-8f83-5ece681e9081",
            "title": "For Sale: The Rolling Stone, a Home-Built Teardrop Foamie",
            "slug": "for-sale-the-rolling-stone-a-home-built-teardrop-foamie",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"About 18 months ago I bought a new-to-me Aliner Scout camper and \\\"The Rolling Stone\\\", my home-built teardrop foamie has been in storage ever since.  I don't want to store it again this winter so it's finally time to sell it.  \\n\\nThe unit is road-ready and super lite (I used to tow it with a Toyota RAV4), and dry as ever in the interior after more than 7 years of use.  Search \\\"teardrop foamie\\\" on the web and you'll get a sense of what this is and how one is built.\\n\\nThis unit is built to accomodate a queen size mattress, but I've installed a small room air conditioning unit and marine battery with a full-size mattress instead.  It's made mostly of foam insulation so it's easy to cool in the summer and I kept it warm in the winter using a small electric space heater.  It does have a 110v shore power connection that works nicely.  There's a ceiling-mounted, thermostat-controlled DC exhaust fan and built-in DC interior lights too.  \\n\\nI'm **asking $1500 or make an offer** for the unit.  \\n\\nGoing to post some photos of the exterior and interior here but you need to see this thing in-person to really appreciate it.  \\n\\nI also plan to link to this listing from a Facebook Marketplace post.  \\n\\n![photo](https://summittservices.blob.core.windows.net/blog-eleventy-ghost/Rolling-Stone/IMG_1254.png)\\n\\n![photo](https://summittservices.blob.core.windows.net/blog-eleventy-ghost/Rolling-Stone/IMG_1262.png)\\n\\n![photo](https://summittservices.blob.core.windows.net/blog-eleventy-ghost/Rolling-Stone/IMG_1264.png)\\n\\n![photo](https://summittservices.blob.core.windows.net/blog-eleventy-ghost/Rolling-Stone/IMG_1269.png)\\n\\n![photo](https://summittservices.blob.core.windows.net/blog-eleventy-ghost/Rolling-Stone/IMG_1257.png)\\n\\n![photo](https://summittservices.blob.core.windows.net/blog-eleventy-ghost/Rolling-Stone/IMG_1258.png)\\n\\n![photo](https://summittservices.blob.core.windows.net/blog-eleventy-ghost/Rolling-Stone/IMG_1267.png)\\n\\nThe unit is available to view in Toledo, Iowa.  Please contact me via email to [mark@tamatoledo.net](mail://mark@tamatoledo.net) to discuss and arrange a visit.  I also plan to link to this listing from a Facebook Marketplace post where you can contact me via Messenger, although I prefer email.  \\n\\nIf there's lots of interest I can take some measurements and probably add dimensions to this listing.  Towing requires a 2\\\" ball. \\n\\n-/-/-/\\nlocation: Toledo, IA\\nasking: $1500\\n\\n\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>About 18 months ago I bought a new-to-me Aliner Scout camper and &quot;The Rolling Stone&quot;, my home-built teardrop foamie has been in storage ever since.  I don't want to store it again this winter so it's finally time to sell it.</p>\n<p>The unit is road-ready and super lite (I used to tow it with a Toyota RAV4), and dry as ever in the interior after more than 7 years of use.  Search &quot;teardrop foamie&quot; on the web and you'll get a sense of what this is and how one is built.</p>\n<p>This unit is built to accomodate a queen size mattress, but I've installed a small room air conditioning unit and marine battery with a full-size mattress instead.  It's made mostly of foam insulation so it's easy to cool in the summer and I kept it warm in the winter using a small electric space heater.  It does have a 110v shore power connection that works nicely.  There's a ceiling-mounted, thermostat-controlled DC exhaust fan and built-in DC interior lights too.</p>\n<p>I'm <strong>asking $1500 or make an offer</strong> for the unit.</p>\n<p>Going to post some photos of the exterior and interior here but you need to see this thing in-person to really appreciate it.</p>\n<p>I also plan to link to this listing from a Facebook Marketplace post.</p>\n<p><img src=\"https://summittservices.blob.core.windows.net/blog-eleventy-ghost/Rolling-Stone/IMG_1254.png\" alt=\"photo\" loading=\"lazy\"></p>\n<p><img src=\"https://summittservices.blob.core.windows.net/blog-eleventy-ghost/Rolling-Stone/IMG_1262.png\" alt=\"photo\" loading=\"lazy\"></p>\n<p><img src=\"https://summittservices.blob.core.windows.net/blog-eleventy-ghost/Rolling-Stone/IMG_1264.png\" alt=\"photo\" loading=\"lazy\"></p>\n<p><img src=\"https://summittservices.blob.core.windows.net/blog-eleventy-ghost/Rolling-Stone/IMG_1269.png\" alt=\"photo\" loading=\"lazy\"></p>\n<p><img src=\"https://summittservices.blob.core.windows.net/blog-eleventy-ghost/Rolling-Stone/IMG_1257.png\" alt=\"photo\" loading=\"lazy\"></p>\n<p><img src=\"https://summittservices.blob.core.windows.net/blog-eleventy-ghost/Rolling-Stone/IMG_1258.png\" alt=\"photo\" loading=\"lazy\"></p>\n<p><img src=\"https://summittservices.blob.core.windows.net/blog-eleventy-ghost/Rolling-Stone/IMG_1267.png\" alt=\"photo\" loading=\"lazy\"></p>\n<p>The unit is available to view in Toledo, Iowa.  Please contact me via email to <a href=\"mail://mark@tamatoledo.net\">mark@tamatoledo.net</a> to discuss and arrange a visit.  I also plan to link to this listing from a Facebook Marketplace post where you can contact me via Messenger, although I prefer email.</p>\n<p>If there's lots of interest I can take some measurements and probably add dimensions to this listing.  Towing requires a 2&quot; ball.</p>\n<p>-/-/-/<br>\nlocation: Toledo, IA<br>\nasking: $1500</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "65198336ddadd63e1863c06f",
            "plaintext": "About 18 months ago I bought a new-to-me Aliner Scout camper and \"The Rolling Stone\", my home-built teardrop foamie has been in storage ever since. I don't want to store it again this winter so it's finally time to sell it.\n\n\nThe unit is road-ready and super lite (I used to tow it with a Toyota RAV4), and dry as ever in the interior after more than 7 years of use. Search \"teardrop foamie\" on the web and you'll get a sense of what this is and how one is built.\n\n\nThis unit is built to accomodate a queen size mattress, but I've installed a small room air conditioning unit and marine battery with a full-size mattress instead. It's made mostly of foam insulation so it's easy to cool in the summer and I kept it warm in the winter using a small electric space heater. It does have a 110v shore power connection that works nicely. There's a ceiling-mounted, thermostat-controlled DC exhaust fan and built-in DC interior lights too.\n\n\nI'm asking $1500 or make an offer for the unit.\n\n\nGoing to post some photos of the exterior and interior here but you need to see this thing in-person to really appreciate it.\n\n\nI also plan to link to this listing from a Facebook Marketplace post.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe unit is available to view in Toledo, Iowa. Please contact me via email to mark@tamatoledo.net to discuss and arrange a visit. I also plan to link to this listing from a Facebook Marketplace post where you can contact me via Messenger, although I prefer email.\n\n\nIf there's lots of interest I can take some measurements and probably add dimensions to this listing. Towing requires a 2\" ball.\n\n\n-/-/-/\n\nlocation: Toledo, IA\n\nasking: $1500\n",
            "feature_image": "__GHOST_URL__/content/images/2023/10/IMG_1260.png",
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-10-01T14:33:26.000Z",
            "updated_at": "2023-11-20T18:55:56.000Z",
            "published_at": "2023-10-01T15:00:39.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6537090cddadd63e1863c288",
            "uuid": "b4dc769a-6437-4c20-98b4-dce7f1aa96a5",
            "title": "Garmin GPSMAP 67 Experience",
            "slug": "garmin-gpsmap-67-experience",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"I generally go geocaching with my iPhone and _Cachly_, and it's a great combination because I can find caches AND log them live once found.  However, there are times when I'm on a geocaching hike and I'd prefer to have a \\\"real\\\" GPS to use.  I also frequently fear that I'll drop and destroy my iPhone while caching, and be left with no GPS and NO way to call for help.  \\n\\nSo, on a recent cross-country geocaching adventure I loaded my trusty old Garmin Oregon 450 to assist, but once on the road I quickly found that the rubber cover on the power button had crumbled from age.  The unit worked but it was certainly not waterproof, not even close, and to be honest, I never really liked the Oregon's touchscreen experience.  The screen frequently needed calibration, was difficult to see at times, and I just didn't use it much.  The old USB mini interface and inability to log finds \\\"live\\\" was also a big drawback.  \\n\\nWhen I got home from that trip I decided it was time for a new GPS and I wanted one with USB rechargable batteries, preferably USB-c, live logging, and NO touchscreen.  That's a pretty good description of the Garmin GPSMAP 67 that I purchased.  \\n\\nMy GPSMAP 67 was delivered about 10 AM yesterday, and the weather was perfect so I made plans to load it up with geocaches and go hunting late that afternoon.  I'm disappointed to report that I never got out of the house, spending several hours trying to load the device. \\n\\n# Initial Problems\\nMy first inclination after reading some of the documentation was to use the \\\"live\\\" feature and my home wi-fi to download some geocaches and go hunting.  I did manage to get some loaded, but the results were not suitable for heading outside.  There were two major issues...  \\n\\n## 5-Mile Search Radius\\n\\nThe first issue is that in this mode the unit apparently searches for up to 25 geocaches that are within a 5-mile radius of the map center, initially the device's location, but this can be changed by panning the map.    \\n\\nThat's all well and good, but all of the geocaches within about 15 miles of home are MINE.  I don't really care to download my own geocaches when I want to go hunting, and the \\\"solution\\\" pointed out another flaw.  \\n\\n## Flawed Filtering\\n\\nOk, so I thought there must be a \\\"filter\\\" feature so that I can be selective about the \\\"live\\\" geocaches my map-center search returns, and there is.  I don't recall all of the filter options, there are a few, but I do remember selecting only caches I have not previously found.  Fine, but the one key filter criteria I really needed is missing...  I am unable to exclude the caches that I OWN.  So, even with filtering turned on my map-center search still returned only caches that I own, and for whatever reason, only 3 of the 60 or so nearby were returned.  \\n\\nClearly this was not going to work.  \\n\\n## Panning the Map\\n\\nSo, I thought I'd better get away from \\\"home\\\" and I had in mind two unfound (by me) geocahes about 20-miles away.  I don't exactly recall the buttons I used but I panned the map center to roughly the location I had in mind and managed to get some geocaches on the map there, but only three caches were shown and none of them was the one I wanted.  Apparently the map center was not quite where it needed to be?  In any event, I deemed this \\\"feature\\\" virtually useless because a 5-mile radius isn't enough when the map center is NOT your current location, and the promise of displaying 25 caches aslo was not fulfilled since I was shown only 3 caches... and I know there were more than that within 5-miles of the map center I had set.  \\n\\n## Conclusions Thus Far\\n\\nThe unit is solid and the buttons make sense so I give the hardware a solid `A`.  The software kind'a sucks, so far it's a `D`, as in dud. It appears the software was written with the device current location in mind, but geocachers don't use GPS units that way, we want to fetch intended targets (with the option to NOT include our own hides) miles from home while we have internet access at home, or at the hotel, or in the campground.  That's the target for 99% of the geocachers I know.  \\n\\n# A Pocket Query + USB Approach\\n\\nI turned from trying to fetch data for caches miles from me using the device, back to the old tried-and-true method, via a Geocahing.com \\\"pocket query\\\".  With pocket queries (PQ) I can control the filtering and the search center location in a number of ways.  Once the PQ is downloaded (a GPX file) I can move it to the device via a USB connection and off I go.  Nope, not with this unit and any of my Mac computers.  \\n\\nI spent the better part of 4 hours trying to transfer a GPX file to the unit to give me geocaches to search for.  I chatted with Garmin support a couple of times and tried dozens of settings and sequences.  Nope.  During one chat session the tech help suggested I try using Windows.  WRONG ANSWER.  That suggestion nearly broke my spirit, so I gave up on USB entirely and ultimately found another way, but it's flawed too.\\n\\n# What Works\\n\\nPress `Menu` twice, select `Setup`, then `Geocaching` and scroll down to `Geocache Lists`.  A list of my downloadable pocket queries (PQs) appears and I select the one I'd like to load, for example, \\\"Local - Not Found\\\" with a count of 500 and status of \\\"Not Synced\\\".  Download of 500 caches took less than 2 minutes, not bad, but I got NOTHING.  Trying that again...  status message says \\\"Basic geocache details downloaded.  Descriptions, Hints and Logs will now be downloaded in the background.\\\"  \\n\\nI go to `Menu` then `Geocaching` (not `Setup`) and still... NOTHING.  \\n\\nSo, what worked somewhat last evening, isn't working anymore.  Rather frustrating.  \\n\\n\\n\\n\\n\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>I generally go geocaching with my iPhone and <em>Cachly</em>, and it's a great combination because I can find caches AND log them live once found.  However, there are times when I'm on a geocaching hike and I'd prefer to have a &quot;real&quot; GPS to use.  I also frequently fear that I'll drop and destroy my iPhone while caching, and be left with no GPS and NO way to call for help.</p>\n<p>So, on a recent cross-country geocaching adventure I loaded my trusty old Garmin Oregon 450 to assist, but once on the road I quickly found that the rubber cover on the power button had crumbled from age.  The unit worked but it was certainly not waterproof, not even close, and to be honest, I never really liked the Oregon's touchscreen experience.  The screen frequently needed calibration, was difficult to see at times, and I just didn't use it much.  The old USB mini interface and inability to log finds &quot;live&quot; was also a big drawback.</p>\n<p>When I got home from that trip I decided it was time for a new GPS and I wanted one with USB rechargable batteries, preferably USB-c, live logging, and NO touchscreen.  That's a pretty good description of the Garmin GPSMAP 67 that I purchased.</p>\n<p>My GPSMAP 67 was delivered about 10 AM yesterday, and the weather was perfect so I made plans to load it up with geocaches and go hunting late that afternoon.  I'm disappointed to report that I never got out of the house, spending several hours trying to load the device.</p>\n<h1 id=\"initial-problems\">Initial Problems</h1>\n<p>My first inclination after reading some of the documentation was to use the &quot;live&quot; feature and my home wi-fi to download some geocaches and go hunting.  I did manage to get some loaded, but the results were not suitable for heading outside.  There were two major issues...</p>\n<h2 id=\"5-mile-search-radius\">5-Mile Search Radius</h2>\n<p>The first issue is that in this mode the unit apparently searches for up to 25 geocaches that are within a 5-mile radius of the map center, initially the device's location, but this can be changed by panning the map.</p>\n<p>That's all well and good, but all of the geocaches within about 15 miles of home are MINE.  I don't really care to download my own geocaches when I want to go hunting, and the &quot;solution&quot; pointed out another flaw.</p>\n<h2 id=\"flawed-filtering\">Flawed Filtering</h2>\n<p>Ok, so I thought there must be a &quot;filter&quot; feature so that I can be selective about the &quot;live&quot; geocaches my map-center search returns, and there is.  I don't recall all of the filter options, there are a few, but I do remember selecting only caches I have not previously found.  Fine, but the one key filter criteria I really needed is missing...  I am unable to exclude the caches that I OWN.  So, even with filtering turned on my map-center search still returned only caches that I own, and for whatever reason, only 3 of the 60 or so nearby were returned.</p>\n<p>Clearly this was not going to work.</p>\n<h2 id=\"panning-the-map\">Panning the Map</h2>\n<p>So, I thought I'd better get away from &quot;home&quot; and I had in mind two unfound (by me) geocahes about 20-miles away.  I don't exactly recall the buttons I used but I panned the map center to roughly the location I had in mind and managed to get some geocaches on the map there, but only three caches were shown and none of them was the one I wanted.  Apparently the map center was not quite where it needed to be?  In any event, I deemed this &quot;feature&quot; virtually useless because a 5-mile radius isn't enough when the map center is NOT your current location, and the promise of displaying 25 caches aslo was not fulfilled since I was shown only 3 caches... and I know there were more than that within 5-miles of the map center I had set.</p>\n<h2 id=\"conclusions-thus-far\">Conclusions Thus Far</h2>\n<p>The unit is solid and the buttons make sense so I give the hardware a solid <code>A</code>.  The software kind'a sucks, so far it's a <code>D</code>, as in dud. It appears the software was written with the device current location in mind, but geocachers don't use GPS units that way, we want to fetch intended targets (with the option to NOT include our own hides) miles from home while we have internet access at home, or at the hotel, or in the campground.  That's the target for 99% of the geocachers I know.</p>\n<h1 id=\"a-pocket-query-usb-approach\">A Pocket Query + USB Approach</h1>\n<p>I turned from trying to fetch data for caches miles from me using the device, back to the old tried-and-true method, via a Geocahing.com &quot;pocket query&quot;.  With pocket queries (PQ) I can control the filtering and the search center location in a number of ways.  Once the PQ is downloaded (a GPX file) I can move it to the device via a USB connection and off I go.  Nope, not with this unit and any of my Mac computers.</p>\n<p>I spent the better part of 4 hours trying to transfer a GPX file to the unit to give me geocaches to search for.  I chatted with Garmin support a couple of times and tried dozens of settings and sequences.  Nope.  During one chat session the tech help suggested I try using Windows.  WRONG ANSWER.  That suggestion nearly broke my spirit, so I gave up on USB entirely and ultimately found another way, but it's flawed too.</p>\n<h1 id=\"what-works\">What Works</h1>\n<p>Press <code>Menu</code> twice, select <code>Setup</code>, then <code>Geocaching</code> and scroll down to <code>Geocache Lists</code>.  A list of my downloadable pocket queries (PQs) appears and I select the one I'd like to load, for example, &quot;Local - Not Found&quot; with a count of 500 and status of &quot;Not Synced&quot;.  Download of 500 caches took less than 2 minutes, not bad, but I got NOTHING.  Trying that again...  status message says &quot;Basic geocache details downloaded.  Descriptions, Hints and Logs will now be downloaded in the background.&quot;</p>\n<p>I go to <code>Menu</code> then <code>Geocaching</code> (not <code>Setup</code>) and still... NOTHING.</p>\n<p>So, what worked somewhat last evening, isn't working anymore.  Rather frustrating.</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "6537090cddadd63e1863c288",
            "plaintext": "I generally go geocaching with my iPhone and Cachly, and it's a great combination because I can find caches AND log them live once found. However, there are times when I'm on a geocaching hike and I'd prefer to have a \"real\" GPS to use. I also frequently fear that I'll drop and destroy my iPhone while caching, and be left with no GPS and NO way to call for help.\n\n\nSo, on a recent cross-country geocaching adventure I loaded my trusty old Garmin Oregon 450 to assist, but once on the road I quickly found that the rubber cover on the power button had crumbled from age. The unit worked but it was certainly not waterproof, not even close, and to be honest, I never really liked the Oregon's touchscreen experience. The screen frequently needed calibration, was difficult to see at times, and I just didn't use it much. The old USB mini interface and inability to log finds \"live\" was also a big drawback.\n\n\nWhen I got home from that trip I decided it was time for a new GPS and I wanted one with USB rechargable batteries, preferably USB-c, live logging, and NO touchscreen. That's a pretty good description of the Garmin GPSMAP 67 that I purchased.\n\n\nMy GPSMAP 67 was delivered about 10 AM yesterday, and the weather was perfect so I made plans to load it up with geocaches and go hunting late that afternoon. I'm disappointed to report that I never got out of the house, spending several hours trying to load the device.\n\n\n\nInitial Problems\n\n\nMy first inclination after reading some of the documentation was to use the \"live\" feature and my home wi-fi to download some geocaches and go hunting. I did manage to get some loaded, but the results were not suitable for heading outside. There were two major issues...\n\n\n\n5-Mile Search Radius\n\n\nThe first issue is that in this mode the unit apparently searches for up to 25 geocaches that are within a 5-mile radius of the map center, initially the device's location, but this can be changed by panning the map.\n\n\nThat's all well and good, but all of the geocaches within about 15 miles of home are MINE. I don't really care to download my own geocaches when I want to go hunting, and the \"solution\" pointed out another flaw.\n\n\n\nFlawed Filtering\n\n\nOk, so I thought there must be a \"filter\" feature so that I can be selective about the \"live\" geocaches my map-center search returns, and there is. I don't recall all of the filter options, there are a few, but I do remember selecting only caches I have not previously found. Fine, but the one key filter criteria I really needed is missing... I am unable to exclude the caches that I OWN. So, even with filtering turned on my map-center search still returned only caches that I own, and for whatever reason, only 3 of the 60 or so nearby were returned.\n\n\nClearly this was not going to work.\n\n\n\nPanning the Map\n\n\nSo, I thought I'd better get away from \"home\" and I had in mind two unfound (by me) geocahes about 20-miles away. I don't exactly recall the buttons I used but I panned the map center to roughly the location I had in mind and managed to get some geocaches on the map there, but only three caches were shown and none of them was the one I wanted. Apparently the map center was not quite where it needed to be? In any event, I deemed this \"feature\" virtually useless because a 5-mile radius isn't enough when the map center is NOT your current location, and the promise of displaying 25 caches aslo was not fulfilled since I was shown only 3 caches... and I know there were more than that within 5-miles of the map center I had set.\n\n\n\nConclusions Thus Far\n\n\nThe unit is solid and the buttons make sense so I give the hardware a solid A. The software kind'a sucks, so far it's a D, as in dud. It appears the software was written with the device current location in mind, but geocachers don't use GPS units that way, we want to fetch intended targets (with the option to NOT include our own hides) miles from home while we have internet access at home, or at the hotel, or in the campground. That's the target for 99% of the geocachers I know.\n\n\n\nA Pocket Query + USB Approach\n\n\nI turned from trying to fetch data for caches miles from me using the device, back to the old tried-and-true method, via a Geocahing.com \"pocket query\". With pocket queries (PQ) I can control the filtering and the search center location in a number of ways. Once the PQ is downloaded (a GPX file) I can move it to the device via a USB connection and off I go. Nope, not with this unit and any of my Mac computers.\n\n\nI spent the better part of 4 hours trying to transfer a GPX file to the unit to give me geocaches to search for. I chatted with Garmin support a couple of times and tried dozens of settings and sequences. Nope. During one chat session the tech help suggested I try using Windows. WRONG ANSWER. That suggestion nearly broke my spirit, so I gave up on USB entirely and ultimately found another way, but it's flawed too.\n\n\n\nWhat Works\n\n\nPress Menu twice, select Setup, then Geocaching and scroll down to Geocache Lists. A list of my downloadable pocket queries (PQs) appears and I select the one I'd like to load, for example, \"Local - Not Found\" with a count of 500 and status of \"Not Synced\". Download of 500 caches took less than 2 minutes, not bad, but I got NOTHING. Trying that again... status message says \"Basic geocache details downloaded. Descriptions, Hints and Logs will now be downloaded in the background.\"\n\n\nI go to Menu then Geocaching (not Setup) and still... NOTHING.\n\n\nSo, what worked somewhat last evening, isn't working anymore. Rather frustrating.\n",
            "feature_image": "https://images.unsplash.com/photo-1593115590389-076721aa1607?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDF8fGdlb2NhY2hlfGVufDB8fHx8MTY5ODEwNTk2NXww&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "draft",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-10-24T00:00:12.000Z",
            "updated_at": "2023-10-24T02:12:57.000Z",
            "published_at": null,
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "655bac21ddadd63e1863c395",
            "uuid": "74eebc2f-f9d4-4c0a-b627-7380393f980f",
            "title": "Improving My Azure Blob Storage",
            "slug": "improving-my-azure-blob-storage",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"I use Azure Blob Storage quite a bit these days, at work and here at home.  Recently a student I've been working with turned my attention to [this post from Microsoft](https://learn.microsoft.com/en-us/training/modules/blob-storage-image-upload-static-web-apps/1-introduction) and this week I'm going to take a crack at putting it to use, perhaps in association with this blog.  \\n-/-/-/\\nlocation: Toledo, Iowa\"}]],\"markups\":[],\"sections\":[[10,0],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<!--kg-card-begin: markdown--><p>I use Azure Blob Storage quite a bit these days, at work and here at home.  Recently a student I've been working with turned my attention to <a href=\"https://learn.microsoft.com/en-us/training/modules/blob-storage-image-upload-static-web-apps/1-introduction\">this post from Microsoft</a> and this week I'm going to take a crack at putting it to use, perhaps in association with this blog.<br>\n-/-/-/<br>\nlocation: Toledo, Iowa</p>\n<!--kg-card-end: markdown-->",
            "comment_id": "655bac21ddadd63e1863c395",
            "plaintext": "I use Azure Blob Storage quite a bit these days, at work and here at home. Recently a student I've been working with turned my attention to this post from Microsoft and this week I'm going to take a crack at putting it to use, perhaps in association with this blog.\n\n-/-/-/\n\nlocation: Toledo, Iowa\n",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-11-20T18:57:37.000Z",
            "updated_at": "2023-12-23T12:06:05.000Z",
            "published_at": "2023-11-20T19:00:04.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "6586cbd4ddadd63e1863c3b0",
            "uuid": "14fbb190-606e-466f-a20f-bd2f14e29e46",
            "title": "Time for a New Static CMS Approach",
            "slug": "time-for-a-new-static-cms-approach",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[[\"a\",[\"href\",\"https://wieting.TamaToledo.com\"]],[\"a\",[\"href\",\"https://www.npmjs.com/package/@staticcms/core\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Wow, it's been way too long since I posted here.  So much has happened, and been missed along the way.  Time to fix that and I'm going to start with a re-write of the \"],[0,[0],1,\"Wieting Theatre website\"],[0,[],0,\" using \"],[0,[1],1,\"staticcms/core\"],[0,[],0,\".  Watch for a full blog post coming soon!\"]]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Wow, it's been way too long since I posted here. Â So much has happened, and been missed along the way. Â Time to fix that and I'm going to start with a re-write of the <a href=\"https://wieting.TamaToledo.com\">Wieting Theatre website</a> using <a href=\"https://www.npmjs.com/package/@staticcms/core\">staticcms/core</a>. Â Watch for a full blog post coming soon!</p>",
            "comment_id": "6586cbd4ddadd63e1863c3b0",
            "plaintext": "Wow, it's been way too long since I posted here. Â So much has happened, and been missed along the way. Â Time to fix that and I'm going to start with a re-write of the Wieting Theatre website using staticcms/core. Â Watch for a full blog post coming soon!",
            "feature_image": null,
            "featured": 1,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-12-23T12:00:20.000Z",
            "updated_at": "2023-12-23T12:04:41.000Z",
            "published_at": "2023-12-23T12:04:41.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "658e2900ddadd63e1863c3e1",
            "uuid": "0196933d-9a3b-4966-af52-35052766e620",
            "title": "First Dose of Wegovy",
            "slug": "first-dose-of-wegovy",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"Got my first 0.25 dose of Wegovy started (finally) this evening at 8 PM.  Not difficult or painful at all.  Injection site was in my right leg, upper thigh.\"]]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Got my first 0.25 dose of Wegovy started (finally) this evening at 8 PM. Â Not difficult or painful at all. Â Injection site was in my right leg, upper thigh.</p>",
            "comment_id": "658e2900ddadd63e1863c3e1",
            "plaintext": "Got my first 0.25 dose of Wegovy started (finally) this evening at 8 PM. Â Not difficult or painful at all. Â Injection site was in my right leg, upper thigh.",
            "feature_image": null,
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-12-29T02:03:44.000Z",
            "updated_at": "2023-12-29T14:11:21.000Z",
            "published_at": "2023-12-29T02:05:25.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "658ed79eddadd63e1863c3f3",
            "uuid": "74ad3c0d-661c-4aa1-aacf-ca189ddc3b3e",
            "title": "On-prem Servers with StaticCMS and Remote Access for the Wieting",
            "slug": "on-prem-servers-with-staticcms-and-remote-access-for-the-wieting",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[[\"em\"],[\"a\",[\"href\",\"https://code.visualstudio.com/\"]],[\"a\",[\"href\",\"https://en.wikipedia.org/wiki/Content_management_system\"]],[\"a\",[\"href\",\"gohugo.io\"]],[\"a\",[\"href\",\"https://wieting.TamaToledo.com\"]],[\"a\",[\"href\",\"https://github.com\"]],[\"a\",[\"href\",\"https://www.staticcms.org/\"]],[\"a\",[\"href\",\"https://edovia.com/en/screens/\"]],[\"strong\"],[\"a\",[\"href\",\"https://www.windstream.com/high-speed-internet\"]],[\"a\",[\"href\",\"https://www.sonicequipment.com/\"]],[\"a\",[\"href\",\"https://getscreen.me\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"It's no secret that I love building ridiculously inexpensive but secure and reliable static web sites.  Unfortunately, adding and maintaining content can be a pain.  \"],[0,[0],1,\"I'd rather write code than content! \"],[0,[],0,\"  So, I also want to pawn that content responsibility off on others, but that means teaching them to use \"],[0,[1],1,\"VSCode\"],[0,[],0,\" â€“ my means of editing static content â€“ or providing a \"],[0,[2],1,\"CMS (content management system)\"],[0,[],0,\" they can work with.  There's no such thing as a static CMS so now I need some \\\"dynamic\\\" components.  Unfortunately my \\\"dynamic\\\" CMS requires user authentication because \"],[0,[0],1,\"we want SOMEONE editing our content, not EVERYONE! \"],[0,[],0,\"That always seems to be pricey, at least by comparison to our $5/month static website.    \"]]],[1,\"h1\",[[0,[],0,\"Currently...\"]]],[1,\"p\",[[0,[],0,\"The Wieting already has an inexpensive \"],[0,[3],1,\"Hugo\"],[0,[],0,\" static website at \"],[0,[4],1,\"https://Wieting.TamaToledo.com\"],[0,[],0,\".   The site code and content both reside in \"],[0,[5],1,\"GitHub\"],[0,[],0,\" free-of-charge.  The site is currently hosted on \"],[0,[0],1,\"Netlify\"],[0,[],0,\" and that costs very little, but also provides meager and dimishing features with virtually no support.  So all of that is good, but could be much better in the near future.  \"]]],[1,\"p\",[[0,[],0,\"Right now the CMS portion of the puzzle uses \"],[0,[0],1,\"NetlifyCMS\"],[0,[],0,\" which demands either running on \"],[0,[0],1,\"Netlify, \"],[0,[],0,\"as it does,\"],[0,[0],1,\" \"],[0,[],0,\"or tediously implementing a relatively complex editor authentication scheme elsewhere.  I chose the simple approach of using the \"],[0,[0],1,\"Netlify\"],[0,[],0,\" host with it's built-in \"],[0,[0],1,\"Netlify Identity\"],[0,[],0,\" features for authentication.  Again, not bad, but not optimal and certainly not sustainable.    \"]]],[1,\"p\",[[0,[],0,\"The other problem with \"],[0,[0],1,\"NetlifyCMS\"],[0,[],0,\" is that every change/addition triggers a new automatic deployment of the site.  When the editors make more than one or two changes in rapid succession, which they like to do, the CMS queues up multiple concureent re-builds of the site and those almost always exceed API quota and crash.   So the changes get saved, but not deployed.   \"]]],[1,\"h1\",[[0,[],0,\"The Future...\"]]],[1,\"p\",[[0,[],0,\"So, what if I could give my \\\"editors\\\" access to a free, aka \\\"open\\\" CMS, one that doesn't require \"],[0,[0],1,\"Netlify \"],[0,[],0,\"or\"],[0,[0],1,\" Netlify Identity\"],[0,[],0,\"?  Sounds promising.  I've been looking at \"],[0,[6],1,\"StaticCMS\"],[0,[],0,\", but if I run that CMS in the cloud we still have an \\\"expensive\\\" authentication requirement in some form.  Hmmmm, what if that CMS were running locally on my own server so that no cloud authentication is needed?  That could work, right?  Editors could sit down at the server, which is really just a workstation at the theatre, and edit content until the cows come home, with no cloud authentication needed.  Perfect!  \"]]],[1,\"p\",[[0,[],0,\"Yes, but...  I can't imagine anyone wanting to sit at a workstation in the projection booth to enter content, that place is difficult to access (lots of stairs), way too noisy with the projector running, frequently either too hot or too cold, and it's just not convenient in the least.  \"]]],[1,\"h1\",[[0,[],0,\"Remote Access to the Rescue\"]]],[1,\"p\",[[0,[],0,\"To avoid working in the projection booth, where the noisy projector and computer workstations are, we currently take advantage of remote desktop access using a program I purchased several years ago: \"],[0,[7],1,\"Screens\"],[0,[],0,\".  I have a \"],[0,[0],1,\"Screens 4\"],[0,[],0,\" license that I obtained with a one-time-fee and it works from any of my Macs (or iOS devices) to give me control of the Mac Mini in the booth.  But \"],[0,[0],1,\"Screens\"],[0,[],0,\" is Mac-only software.  It has a remote component called \"],[0,[0],1,\"Screens Connect \"],[0,[],0,\"that runs on each remote device to make connections super-easy, but \"],[0,[0],1,\"Screens Connect \"],[0,[],0,\"doesn't work on Linux systems which require tedios manual configuration instead.  \"],[0,[8],0,\"I've spent many hours but have never been able to make the manual configuration work with the Wieting's networking and \"],[0,[9],1,\"Kinetic\"],[0,[],0,\" internet connection from \"],[0,[0],1,\"Windstream\"],[0,[],1,\".  \"],[0,[],0,\"     \"]]],[1,\"p\",[[0,[],0,\"In addition to \"],[0,[0],1,\"Screens,\"],[0,[],0,\" the Wieting has used \"],[0,[0],1,\"TeamViewer\"],[0,[],0,\" with our technical service provider, \"],[0,[10],1,\"Sonic Equipment Company\"],[0,[],0,\", for remote connections into the projection booth.  We've never owned a license and purchasing one is cost-prohibitive.   \"]]],[1,\"h1\",[[0,[],0,\"Reasonable Remote Access?\"]]],[1,\"p\",[[0,[0],1,\"Screens\"],[0,[],0,\" just released a new version, \"],[0,[0],1,\"Screens 5\"],[0,[],0,\", and the upgrade costs $$$ but it's still Mac-only and there's still no Linux version of their wonderful \"],[0,[0],1,\"Screens Connect\"],[0,[],0,\" app.  So, no thank you.  There must be a reasonable alternative, right?   \"]]],[1,\"p\",[[0,[],0,\"Yup.  I've signed up for a 30-day trial (I love software that comes with a reasonable trial version and period) of \"],[0,[11],1,\"Getscreen.me\"],[0,[],0,\".   So far it rocks!  Even with my Linux workstations!   Best of all, I believe the Wieting's use case would cost between $60 to $150 per year.  Not too shabby.\"]]],[1,\"h1\",[[0,[],0,\"Summary... the Plan\"]]],[1,\"p\",[[0,[],0,\"So, my plan/proposal is to park a Linux workstation (a PC repurposed with the \"],[0,[0],1,\"Ubuntu \"],[0,[],0,\"OS) in the projection booth to support an instance of \"],[0,[6],1,\"StaticCMS\"],[0,[],0,\".  That workstation will be remotely accessible using \"],[0,[11],1,\"Getscreen.me\"],[0,[],0,\" and it will be home to a local copy of the Wieting's website.  It will be configured such that \"],[0,[0],1,\"StaticCMS\"],[0,[],0,\" can be used to update the local website content, with a link that can be used to push changes to \"],[0,[0],1,\"GitHub\"],[0,[],0,\" where changes are deployed to \"],[0,[4],1,\"https://wieting.TamaToledo.com\"],[0,[],0,\" hosted in either \"],[0,[0],1,\"DigitalOcean\"],[0,[],0,\" or \"],[0,[0],1,\"Azure\"],[0,[],0,\" static apps.  \"]]],[1,\"h1\",[[0,[],0,\"Bonus!\"]]],[1,\"p\",[[0,[],0,\"Without too much extra effort, the Linux workstation with remote access should also be able to support playback of the Wieting's pre-show content (currently running from an unreliable Raspberry Pi) as well as projector and audio rack controls (currently supplied by our Mac Mini).   \"]]],[1,\"p\",[[0,[],0,\"  \"]]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>It's no secret that I love building ridiculously inexpensive but secure and reliable static web sites. Â Unfortunately, adding and maintaining content can be a pain. Â <em>I'd rather write code than content! </em> Â So, I also want to pawn that content responsibility off on others, but that means teaching them to use <a href=\"https://code.visualstudio.com/\">VSCode</a> â€“ my means of editing static content â€“ or providing a <a href=\"https://en.wikipedia.org/wiki/Content_management_system\">CMS (content management system)</a> they can work with. Â There's no such thing as a static CMS so now I need some \"dynamic\" components. Â Unfortunately my \"dynamic\" CMS requires user authentication because <em>we want SOMEONE editing our content, not EVERYONE! </em>That always seems to be pricey, at least by comparison to our $5/month static website. Â  Â </p><h1 id=\"currently\">Currently...</h1><p>The Wieting already has an inexpensive <a href=\"gohugo.io\">Hugo</a> static website at <a href=\"https://wieting.TamaToledo.com\">https://Wieting.TamaToledo.com</a>. Â  The site code and content both reside in <a href=\"https://github.com\">GitHub</a> free-of-charge. Â The site is currently hosted on <em>Netlify</em> and that costs very little, but also provides meager and dimishing features with virtually no support. Â So all of that is good, but could be much better in the near future. Â </p><p>Right now the CMS portion of the puzzle uses <em>NetlifyCMS</em> which demands either running on <em>Netlify, </em>as it does,<em> </em>or tediously implementing a relatively complex editor authentication scheme elsewhere. Â I chose the simple approach of using the <em>Netlify</em> host with it's built-in <em>Netlify Identity</em> features for authentication. Â Again, not bad, but not optimal and certainly not sustainable. Â  Â </p><p>The other problem with <em>NetlifyCMS</em> is that every change/addition triggers a new automatic deployment of the site. Â When the editors make more than one or two changes in rapid succession, which they like to do, the CMS queues up multiple concureent re-builds of the site and those almost always exceed API quota and crash. Â  So the changes get saved, but not deployed. Â  </p><h1 id=\"the-future\">The Future...</h1><p>So, what if I could give my \"editors\" access to a free, aka \"open\" CMS, one that doesn't require <em>Netlify </em>or<em> Netlify Identity</em>? Â Sounds promising. Â I've been looking at <a href=\"https://www.staticcms.org/\">StaticCMS</a>, but if I run that CMS in the cloud we still have an \"expensive\" authentication requirement in some form. Â Hmmmm, what if that CMS were running locally on my own server so that no cloud authentication is needed? Â That could work, right? Â Editors could sit down at the server, which is really just a workstation at the theatre, and edit content until the cows come home, with no cloud authentication needed. Â Perfect! Â </p><p>Yes, but... Â I can't imagine anyone wanting to sit at a workstation in the projection booth to enter content, that place is difficult to access (lots of stairs), way too noisy with the projector running, frequently either too hot or too cold, and it's just not convenient in the least. Â </p><h1 id=\"remote-access-to-the-rescue\">Remote Access to the Rescue</h1><p>To avoid working in the projection booth, where the noisy projector and computer workstations are, we currently take advantage of remote desktop access using a program I purchased several years ago: <a href=\"https://edovia.com/en/screens/\">Screens</a>. Â I have a <em>Screens 4</em> license that I obtained with a one-time-fee and it works from any of my Macs (or iOS devices) to give me control of the Mac Mini in the booth. Â But <em>Screens</em> is Mac-only software. Â It has a remote component called <em>Screens Connect </em>that runs on each remote device to make connections super-easy, but <em>Screens Connect </em>doesn't work on Linux systems which require tedios manual configuration instead. Â <strong>I've spent many hours but have never been able to make the manual configuration work with the Wieting's networking and <a href=\"https://www.windstream.com/high-speed-internet\">Kinetic</a> internet connection from <em>Windstream</em>. Â </strong> Â  Â  </p><p>In addition to <em>Screens,</em> the Wieting has used <em>TeamViewer</em> with our technical service provider, <a href=\"https://www.sonicequipment.com/\">Sonic Equipment Company</a>, for remote connections into the projection booth. Â We've never owned a license and purchasing one is cost-prohibitive. Â  </p><h1 id=\"reasonable-remote-access\">Reasonable Remote Access?</h1><p><em>Screens</em> just released a new version, <em>Screens 5</em>, and the upgrade costs $$$ but it's still Mac-only and there's still no Linux version of their wonderful <em>Screens Connect</em> app. Â So, no thank you. Â There must be a reasonable alternative, right? Â  </p><p>Yup. Â I've signed up for a 30-day trial (I love software that comes with a reasonable trial version and period) of <a href=\"https://getscreen.me\">Getscreen.me</a>. Â  So far it rocks! Â Even with my Linux workstations! Â  Best of all, I believe the Wieting's use case would cost between $60 to $150 per year. Â Not too shabby.</p><h1 id=\"summary-the-plan\">Summary... the Plan</h1><p>So, my plan/proposal is to park a Linux workstation (a PC repurposed with the <em>Ubuntu </em>OS) in the projection booth to support an instance of <a href=\"https://www.staticcms.org/\">StaticCMS</a>. Â That workstation will be remotely accessible using <a href=\"https://getscreen.me\">Getscreen.me</a> and it will be home to a local copy of the Wieting's website. Â It will be configured such that <em>StaticCMS</em> can be used to update the local website content, with a link that can be used to push changes to <em>GitHub</em> where changes are deployed to <a href=\"https://wieting.TamaToledo.com\">https://wieting.TamaToledo.com</a> hosted in either <em>DigitalOcean</em> or <em>Azure</em> static apps. Â </p><h1 id=\"bonus\">Bonus!</h1><p>Without too much extra effort, the Linux workstation with remote access should also be able to support playback of the Wieting's pre-show content (currently running from an unreliable Raspberry Pi) as well as projector and audio rack controls (currently supplied by our Mac Mini). Â  </p><p> Â </p>",
            "comment_id": "658ed79eddadd63e1863c3f3",
            "plaintext": "It's no secret that I love building ridiculously inexpensive but secure and reliable static web sites. Â Unfortunately, adding and maintaining content can be a pain. Â I'd rather write code than content! Â So, I also want to pawn that content responsibility off on others, but that means teaching them to use VSCode â€“ my means of editing static content â€“ or providing a CMS (content management system) they can work with. Â There's no such thing as a static CMS so now I need some \"dynamic\" components. Â Unfortunately my \"dynamic\" CMS requires user authentication because we want SOMEONE editing our content, not EVERYONE! That always seems to be pricey, at least by comparison to our $5/month static website. Â  Â \n\n\nCurrently...\n\nThe Wieting already has an inexpensive Hugo static website at https://Wieting.TamaToledo.com. Â  The site code and content both reside in GitHub free-of-charge. Â The site is currently hosted on Netlify and that costs very little, but also provides meager and dimishing features with virtually no support. Â So all of that is good, but could be much better in the near future. Â \n\nRight now the CMS portion of the puzzle uses NetlifyCMS which demands either running on Netlify, as it does, or tediously implementing a relatively complex editor authentication scheme elsewhere. Â I chose the simple approach of using the Netlify host with it's built-in Netlify Identity features for authentication. Â Again, not bad, but not optimal and certainly not sustainable. Â  Â \n\nThe other problem with NetlifyCMS is that every change/addition triggers a new automatic deployment of the site. Â When the editors make more than one or two changes in rapid succession, which they like to do, the CMS queues up multiple concureent re-builds of the site and those almost always exceed API quota and crash. Â  So the changes get saved, but not deployed. Â \n\n\nThe Future...\n\nSo, what if I could give my \"editors\" access to a free, aka \"open\" CMS, one that doesn't require Netlify or Netlify Identity? Â Sounds promising. Â I've been looking at StaticCMS, but if I run that CMS in the cloud we still have an \"expensive\" authentication requirement in some form. Â Hmmmm, what if that CMS were running locally on my own server so that no cloud authentication is needed? Â That could work, right? Â Editors could sit down at the server, which is really just a workstation at the theatre, and edit content until the cows come home, with no cloud authentication needed. Â Perfect! Â \n\nYes, but... Â I can't imagine anyone wanting to sit at a workstation in the projection booth to enter content, that place is difficult to access (lots of stairs), way too noisy with the projector running, frequently either too hot or too cold, and it's just not convenient in the least. Â \n\n\nRemote Access to the Rescue\n\nTo avoid working in the projection booth, where the noisy projector and computer workstations are, we currently take advantage of remote desktop access using a program I purchased several years ago: Screens. Â I have a Screens 4 license that I obtained with a one-time-fee and it works from any of my Macs (or iOS devices) to give me control of the Mac Mini in the booth. Â But Screens is Mac-only software. Â It has a remote component called Screens Connect that runs on each remote device to make connections super-easy, but Screens Connect doesn't work on Linux systems which require tedios manual configuration instead. Â I've spent many hours but have never been able to make the manual configuration work with the Wieting's networking and Kinetic internet connection from Windstream. Â  Â  Â \n\nIn addition to Screens, the Wieting has used TeamViewer with our technical service provider, Sonic Equipment Company, for remote connections into the projection booth. Â We've never owned a license and purchasing one is cost-prohibitive. Â \n\n\nReasonable Remote Access?\n\nScreens just released a new version, Screens 5, and the upgrade costs $$$ but it's still Mac-only and there's still no Linux version of their wonderful Screens Connect app. Â So, no thank you. Â There must be a reasonable alternative, right? Â \n\nYup. Â I've signed up for a 30-day trial (I love software that comes with a reasonable trial version and period) of Getscreen.me. Â  So far it rocks! Â Even with my Linux workstations! Â  Best of all, I believe the Wieting's use case would cost between $60 to $150 per year. Â Not too shabby.\n\n\nSummary... the Plan\n\nSo, my plan/proposal is to park a Linux workstation (a PC repurposed with the Ubuntu OS) in the projection booth to support an instance of StaticCMS. Â That workstation will be remotely accessible using Getscreen.me and it will be home to a local copy of the Wieting's website. Â It will be configured such that StaticCMS can be used to update the local website content, with a link that can be used to push changes to GitHub where changes are deployed to https://wieting.TamaToledo.com hosted in either DigitalOcean or Azure static apps. Â \n\n\nBonus!\n\nWithout too much extra effort, the Linux workstation with remote access should also be able to support playback of the Wieting's pre-show content (currently running from an unreliable Raspberry Pi) as well as projector and audio rack controls (currently supplied by our Mac Mini). Â \n\nÂ ",
            "feature_image": "https://images.unsplash.com/photo-1515413741792-b5900ade941f?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDE4fHxyZW1vdGV8ZW58MHx8fHwxNzAzODYwMTU1fDA&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2023-12-29T14:28:46.000Z",
            "updated_at": "2023-12-29T17:19:09.000Z",
            "published_at": "2023-12-29T16:41:14.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "659ea83addadd63e1863c59d",
            "uuid": "a68a90ec-dded-48dd-b2c6-e898b5f92dfd",
            "title": "Snowpocalypse 2024?",
            "slug": "snowpocalypse-2024",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2024/01/IMG_2070.png\",\"width\":907,\"height\":1210,\"caption\":\"Probably 6\\\" - 7\\\" of wet snow but near the house and street it was 14\\\" - 16\\\" deep.\"}],[\"markdown\",{\"markdown\":\"## Update: 10-01-2024 @ 10 AM\"}],[\"image\",{\"src\":\"__GHOST_URL__/content/images/2024/01/IMG_2072.png\",\"width\":907,\"height\":1210,\"caption\":\"Not quite done yet, but at least the drive is clear and the front door is reachable.\"}]],\"markups\":[[\"a\",[\"href\",\"http://localhost:1313/hikes/2024/01/2024-01-09_0430pm/\"]]],\"sections\":[[1,\"p\",[[0,[],0,\"Maybe not as bad as predicted (at least per some predictions) but it was enough wet snow for me.  Took almost an hour to clear using my EGO cordless snow-thrower (love it) and there's more to be done before Mackenzie and I can leave for work in the morning.  \"]]],[1,\"p\",[[0,[],0,\"Fortunately both Grinnell College and South Tama County schools were closed today.  GC re-opens at noon tomorrow and STC just announced that they will be closed on Wednesday too.  \"]]],[1,\"p\",[[0,[],0,\"The captioned photo above is where I left it this evening at about 5:30 PM.  The photo below shows the first 1-minute of my progress at about 4:30 PM.  I posted a track-log of the \\\"walk\\\" at \"],[0,[0],1,\"https://hikes.summittdweller.com/hikes/2024/01/2024-01-09_0430pm/\"],[0,[],0,\".\"]]],[10,0],[1,\"p\",[[0,[],0,\"Ultimately I burned through 4 large EGO batteries.  Clearing the drive in the past would typically take only 2 with some capacity to spare.  \"]]],[1,\"p\",[[0,[],0,\"I still have more to do before going to work tomorrow.  Got another storm heading this way on Wednesday evening so I better get at it in the morning.  Wish me luck.\"]]],[10,1],[1,\"p\",[[0,[],0,\"Managed to get the snow-thrower out again to finish up last evening's work before heading back to Grinnell in a bit.   34 minutes of effort covering about 3/4 of a mile.  I'll post another track log at https://hikes.summittdweller.com soon.  I did take one more photo to give some perspective to the front porch situation.  \"]]],[1,\"p\",[[0,[],0,\"I really should have taken a photo before I started.  The snow shelf extending down off the roof was easily 2' deep/tall x 8' long x 16\\\" thick...before I knocked it down, an effort that took 12 pokes with my shovel.   Went through another two EGO batteries in the effort.  \"]]],[10,2],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Maybe not as bad as predicted (at least per some predictions) but it was enough wet snow for me. Â Took almost an hour to clear using my EGO cordless snow-thrower (love it) and there's more to be done before Mackenzie and I can leave for work in the morning. Â </p><p>Fortunately both Grinnell College and South Tama County schools were closed today. Â GC re-opens at noon tomorrow and STC just announced that they will be closed on Wednesday too. Â </p><p>The captioned photo above is where I left it this evening at about 5:30 PM. Â The photo below shows the first 1-minute of my progress at about 4:30 PM. Â I posted a track-log of the \"walk\" at <a href=\"http://localhost:1313/hikes/2024/01/2024-01-09_0430pm/\">https://hikes.summittdweller.com/hikes/2024/01/2024-01-09_0430pm/</a>.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2024/01/IMG_2070.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"907\" height=\"1210\" srcset=\"__GHOST_URL__/content/images/size/w600/2024/01/IMG_2070.png 600w, __GHOST_URL__/content/images/2024/01/IMG_2070.png 907w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Probably 6\" - 7\" of wet snow but near the house and street it was 14\" - 16\" deep.</figcaption></figure><p>Ultimately I burned through 4 large EGO batteries. Â Clearing the drive in the past would typically take only 2 with some capacity to spare. Â </p><p>I still have more to do before going to work tomorrow. Â Got another storm heading this way on Wednesday evening so I better get at it in the morning. Â Wish me luck.</p><!--kg-card-begin: markdown--><h2 id=\"update-10-01-2024-10-am\">Update: 10-01-2024 @ 10 AM</h2>\n<!--kg-card-end: markdown--><p>Managed to get the snow-thrower out again to finish up last evening's work before heading back to Grinnell in a bit. Â  34 minutes of effort covering about 3/4 of a mile. Â I'll post another track log at https://hikes.summittdweller.com soon. Â I did take one more photo to give some perspective to the front porch situation. Â </p><p>I really should have taken a photo before I started. Â The snow shelf extending down off the roof was easily 2' deep/tall x 8' long x 16\" thick...before I knocked it down, an effort that took 12 pokes with my shovel. Â  Went through another two EGO batteries in the effort. Â </p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2024/01/IMG_2072.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"907\" height=\"1210\" srcset=\"__GHOST_URL__/content/images/size/w600/2024/01/IMG_2072.png 600w, __GHOST_URL__/content/images/2024/01/IMG_2072.png 907w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Not quite done yet, but at least the drive is clear and the front door is reachable.</figcaption></figure>",
            "comment_id": "659ea83addadd63e1863c59d",
            "plaintext": "Maybe not as bad as predicted (at least per some predictions) but it was enough wet snow for me. Â Took almost an hour to clear using my EGO cordless snow-thrower (love it) and there's more to be done before Mackenzie and I can leave for work in the morning. Â \n\nFortunately both Grinnell College and South Tama County schools were closed today. Â GC re-opens at noon tomorrow and STC just announced that they will be closed on Wednesday too. Â \n\nThe captioned photo above is where I left it this evening at about 5:30 PM. Â The photo below shows the first 1-minute of my progress at about 4:30 PM. Â I posted a track-log of the \"walk\" at https://hikes.summittdweller.com/hikes/2024/01/2024-01-09_0430pm/.\n\nUltimately I burned through 4 large EGO batteries. Â Clearing the drive in the past would typically take only 2 with some capacity to spare. Â \n\nI still have more to do before going to work tomorrow. Â Got another storm heading this way on Wednesday evening so I better get at it in the morning. Â Wish me luck.\n\n\nUpdate: 10-01-2024 @ 10 AM\n\n\nManaged to get the snow-thrower out again to finish up last evening's work before heading back to Grinnell in a bit. Â  34 minutes of effort covering about 3/4 of a mile. Â I'll post another track log at https://hikes.summittdweller.com soon. Â I did take one more photo to give some perspective to the front porch situation. Â \n\nI really should have taken a photo before I started. Â The snow shelf extending down off the roof was easily 2' deep/tall x 8' long x 16\" thick...before I knocked it down, an effort that took 12 pokes with my shovel. Â  Went through another two EGO batteries in the effort. Â ",
            "feature_image": "__GHOST_URL__/content/images/2024/01/IMG_2071.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2024-01-10T14:22:50.000Z",
            "updated_at": "2024-01-10T15:55:56.000Z",
            "published_at": "2024-01-10T00:00:00.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "65a2aadbddadd63e1863c630",
            "uuid": "0ea55fc1-0742-4fe1-9ba1-7abb334b1b0c",
            "title": "Snowpocalypse 2024 - Round 2",
            "slug": "snowpocalypse-2024-round-2",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"image\",{\"src\":\"__GHOST_URL__/content/images/2024/01/IMG_1552.png\",\"width\":907,\"height\":1210,\"caption\":\"There are steps and a deck under there somewhere.\"}]],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"Just thought I would post a couple more photos, with a probable update later today.  Took these photos yesterday (Friday, January 12) at about noon when I ventured outside to clear the driveway.  Didn't quite get it all done because it was just too cold and windy, and the snow was still falling.  I didn't even attempt to clear the front porch... ain't nobody coming to visit today anyway.  8^)\"]]],[10,0],[1,\"p\",[[0,[],0,\"I love my EGO snow thrower, but pushing through drifts that are taller than the intake (about 18\\\") is NO FUN.  \"]]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Just thought I would post a couple more photos, with a probable update later today. Â Took these photos yesterday (Friday, January 12) at about noon when I ventured outside to clear the driveway. Â Didn't quite get it all done because it was just too cold and windy, and the snow was still falling. Â I didn't even attempt to clear the front porch... ain't nobody coming to visit today anyway. Â 8^)</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"__GHOST_URL__/content/images/2024/01/IMG_1552.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"907\" height=\"1210\" srcset=\"__GHOST_URL__/content/images/size/w600/2024/01/IMG_1552.png 600w, __GHOST_URL__/content/images/2024/01/IMG_1552.png 907w\" sizes=\"(min-width: 720px) 720px\"><figcaption>There are steps and a deck under there somewhere.</figcaption></figure><p>I love my EGO snow thrower, but pushing through drifts that are taller than the intake (about 18\") is NO FUN. Â </p>",
            "comment_id": "65a2aadbddadd63e1863c630",
            "plaintext": "Just thought I would post a couple more photos, with a probable update later today. Â Took these photos yesterday (Friday, January 12) at about noon when I ventured outside to clear the driveway. Â Didn't quite get it all done because it was just too cold and windy, and the snow was still falling. Â I didn't even attempt to clear the front porch... ain't nobody coming to visit today anyway. Â 8^)\n\nI love my EGO snow thrower, but pushing through drifts that are taller than the intake (about 18\") is NO FUN. Â ",
            "feature_image": "__GHOST_URL__/content/images/2024/01/IMG_1551.png",
            "featured": 0,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2024-01-13T15:23:07.000Z",
            "updated_at": "2024-01-13T15:28:12.000Z",
            "published_at": "2024-01-13T15:28:12.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "65a2adb6ddadd63e1863c691",
            "uuid": "5b88f3cb-429c-4220-9136-cb8854cd3d2f",
            "title": "Spinning Up StaticCMS",
            "slug": "spinning-up-staticcms",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[[\"markdown\",{\"markdown\":\"## The Plan  \\nSo, the plan here involves establishing a \\\"local-only\\\" CMS for the [Wieting Theatre website](https://Wieting.TamaToledo.com) and running it on the new Ubuntu server in the Wieting's projection booth.  Editors should will be given login credentials to that server where they can run a local copy of the website (it's a Hugo static site) AND a local copy of the CMS editor, make changes, preview them, and commit the changes to the project's GitHub repo.  The website, hosted with _AWS Amplify_ is then automatically updated based on the updated content.  \\n\\n### Along the Way  \\nIt's worth noting that while looking at [StaticCMS](https://www.staticcms.org) I also stumbled upon [tabcms - A CMS that runs in your browser tab](https://mortenson.coffee/work/tabcms/) which might be of interest if \\\"The Plan\\\" doesn't work. \\n\\n## First Steps - Start with a Template\\nI choose the guidance at [Start with a Template](https://www.staticcms.org/docs/start-with-a-template) to get started.  My aim is to clone that repo and build it locally \\\"as-is\\\", then see if I can drop my existing [wieting-ss](https://github.com/SummittServices/wieting-ss) repo into the `site` directory and continue to make it work locally.  \\n\\nIf that works, I'll repeat the same on the Wieting's Ubuntu server and keep pushing forward.  Wish me luck?  \\n\\n### Getting Started\\n\\nFollowing the [Local Development](https://github.com/StaticJsCMS/static-cms-hugo-netlify-template#local-development) guidance found me cloning this [template]( https://github.com/StaticJsCMS/static-cms-hugo-netlify-template) then...  \\n\\n```zsh\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-netlify-template â€¹mainâ€º \\nâ•°â”€$ npm install \\nnpm WARN deprecated querystring@0.2.0: The querystring API is considered Legacy. new code should use the URLSearchParams API instead.\\n\\nadded 1567 packages, and audited 1568 packages in 2m\\n\\n426 packages are looking for funding\\n  run `npm fund` for details\\n\\n2 moderate severity vulnerabilities\\n\\nTo address all issues, run:\\n  npm audit fix\\n\\nRun `npm audit` for details.\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-netlify-template â€¹main*â€º \\nâ•°â”€$ npm start\\n\\n> static-cms-hugo-netlify-template@1.0.0 start\\n> run-p start:**\\n\\n\\n> static-cms-hugo-netlify-template@1.0.0 start:webpack\\n> webpack-dev-server --config webpack.dev.js --hot --stats-error-details\\n\\n\\n> static-cms-hugo-netlify-template@1.0.0 start:hugo\\n> hugo -d ../dist -s site -vw\\n\\nWARN  --verbose was deprecated in Hugo v0.114.0 and will be removed in a future release. use --logLevel info\\nStart building sites â€¦ \\nhugo v0.120.1-16fb2cae88eb6add7d12e9fbfcf01d8670e60a35 darwin/amd64 BuildDate=2023-10-30T16:44:31Z VendorInfo=gohugoio\\n\\nINFO  copy static: syncing static files to /\\nINFO  build: running step process duration 962.376Âµs\\nINFO  build: running step assemble duration 4.712758ms\\nINFO  build: running step render duration 16.982673ms\\nINFO  build: running step postProcess duration 8.3Âµs\\n\\n                   | EN  \\n-------------------+-----\\n  Pages            | 10  \\n  Paginator pages  |  0  \\n  Non-page files   |  0  \\n  Static files     | 43  \\n  Processed images |  0  \\n  Aliases          |  1  \\n  Sitemaps         |  1  \\n  Cleaned          |  0  \\n\\nBuilt in 68 ms\\nWatching for changes in /Users/mark/GitHub/static-cms-hugo-netlify-template/site/{content,data,layouts,static}\\nWatching for config changes in /Users/mark/GitHub/static-cms-hugo-netlify-template/site/config.toml\\nPress Ctrl+C to stop\\n<i> [webpack-dev-server] Project is running at:\\n<i> [webpack-dev-server] Loopback: http://localhost:3000/\\n<i> [webpack-dev-server] On Your Network (IPv4): http://192.168.0.183:3000/\\n<i> [webpack-dev-server] On Your Network (IPv6): http://[fe80::1]:3000/\\n<i> [webpack-dev-server] Content not from webpack is served from '/Users/mark/GitHub/static-cms-hugo-netlify-template/dist' directory\\n<i> [webpack-dev-server] 404s will fallback to '/index.html'\\n<i> [webpack-dev-middleware] wait until bundle finished: /\\nassets by path *.js 18.3 MiB\\n  asset cms.js 18 MiB [emitted] (name: cms)\\n  asset main.js 300 KiB [emitted] (name: main)\\nasset main.css 113 KiB [emitted] (name: main)\\nasset admin/index.html 521 bytes [emitted]\\nasset fonts/.keep 0 bytes [emitted] [from: src/fonts/.keep] [copied]\\nEntrypoint main 413 KiB = main.css 113 KiB main.js 300 KiB\\nEntrypoint cms 18 MiB = cms.js\\nruntime modules 72.3 KiB 38 modules\\nmodules by path ./node_modules/ 16.9 MiB 82 modules\\nmodules by path ./src/ 133 KiB (javascript) 113 KiB (css/mini-extract)\\n  modules by path ./src/js/ 15.2 KiB 9 modules\\n  modules by path ./src/css/*.scss 118 KiB (javascript) 113 KiB (css/mini-extract)\\n    ./src/css/main.scss 2.78 KiB [built] [code generated]\\n    ./node_modules/to-string-loader/src/to-string.js!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 429 bytes [built] [code generated]\\n    ./node_modules/mini-css-extract-plugin/dist/loader.js??ruleSet[1].rules[2].use[1]!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 332 bytes [built] [code generated]\\n    + 2 modules\\n  ./src/index.js 124 bytes [built] [code generated]\\nasset modules 5.46 KiB\\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.28 KiB [built] [code generated] [build time executed]\\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.33 KiB [built] [code generated] [build time executed]\\n  data:image/jpeg;base64,/9j/4QAYRXhpZgAA.. 1.55 KiB [built] [code generated] [build time executed]\\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.3 KiB [built] [code generated] [build time executed]\\nwebpack 5.89.0 compiled successfully in 6191 ms\\nINFO  Received System Events: [CREATE        \\\"/Users/mark/GitHub/static-cms-hugo-netlify-template/site/data/webpack.json\\\" WRITE         \\\"/Users/mark/GitHub/static-cms-hugo-netlify-template/site/data/webpack.json\\\"]\\n\\nChange detected, rebuilding site.\\n2024-01-13 10:55:38.259 -0600\\nData changed WRITE         \\\"/Users/mark/GitHub/static-cms-hugo-netlify-template/site/data/webpack.json\\\"\\nData changed WRITE         \\\"/Users/mark/GitHub/static-cms-hugo-netlify-template/site/data/webpack.json\\\"\\nINFO  build: running step process duration 114.033Âµs\\nINFO  build: running step assemble duration 277ns\\nINFO  build: running step render duration 6.244639ms\\nINFO  build: running step postProcess duration 1.831Âµs\\nTotal in 6 ms\\n```\\n\\nThe demo site is indeed working at `http://localhost:3000/` and a vist to `http://localhost:3000/admin` does indeed open a _StaticCMS_ login that's prompting me with the following image.\\n\\n![Screenshot-2024-01-13-at-11.00.45](__GHOST_URL__/content/images/2024/01/Screenshot-2024-01-13-at-11.00.45.png)\\n\\n### Let's Go Local!\\n\\nNext, I'm going to try and switch what we have above to \\\"go local\\\" using [this guidance](https://www.staticcms.org/docs/local-backend) provided in the _StaticCMS_ documenation.  Fingers crossed for good luck...  \\n\\n### Eureka! It Works!\\n\\nSo, I made the `local_backend` config changes as prescribed in `site/static/admin/config.yml` and that file now looks like this:\\n\\n```\\nlocal_backend: \\n  # when using a custom proxy server port\\n  url: http://localhost:8082/api/v1\\n  # when accessing the local site from a host other than 'localhost' or '127.0.0.1'\\n  allowed_hosts: ['192.168.0.1']\\n```  \\n\\nI also added a new `.env` file in the project root directory with a single line reading `PORT=8082`, matching the port number specified in the `url:` value from `config.yml`.  \\n\\nNow, with `npx @staticcms/proxy-server` running in a local terminal I'm able to run `npm start` (in my _VSCode_ terminal) to launch the site at `localhost:3000`.  Having done that I'm able to visit `http://localhost:3000/admin` where I get a new _StaticCMS_ splash screen with a simple `Login` button, not a _Netlify_ button.  Yay! \\n\\n### Even Better News?  \\n\\n_StaticCMS_ was built from _NetlifyCMS_ so the `site/static/admin/config.yml`.  I think I'll be able to use the `collections:` portion of my old `admin/config.yml` file from [wieting-one-click-hugo-cms](https://github.com/SummittDweller/wieting-one-click-hugo-cms) to get a headstart on setting that up!  \\n\\nNext step... let's see if I can drop the `site` directory from [wieting-ss](https://github.com/SummittServices/wieting-ss) into this local project and still have a functioning local site.  Again, fingers crossed for luck.  \\n\\n# Fresh Restart\\nIn order to start fresh I went back to the [StaticJsCMS/static-cms-hugo-netlify-template](https://github.com/StaticJsCMS/static-cms-hugo-netlify-template) repo and created a new fork (not a clone) in my `Summitt-Services` team space at [https://github.com/Summitt-Services/static-cms-hugo-local-template](https://github.com/Summitt-Services/static-cms-hugo-local-template).  In the new fork I changed the `-netlify-` portion of the name to `-local-` as this new project is intended to have no _Netlify_ association, only a \\\"local\\\" CMS will be supported.  \\n\\nNext, I cloned the new fork to my workstation and got it working locally again using the same steps I had taken above.  \\n\\n## Copying `wieting-ss` to `static-cms-hugo-local-template`  \\n\\nFor safe-keeping I created a new branch named `wieting` in `~/GitHub/static-cms-hugo-local-template` where I did this:  \\n\\n```zsh\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹wieting*â€º \\nâ•°â”€$ rsync -aruvi ../wieting-ss/. site/.\\n...\\n>f++++++++++ themes/vanilla-bootstrap-hugo-theme/static/js/checkTweetDate.js\\n>f++++++++++ themes/vanilla-bootstrap-hugo-theme/static/js/feather.min.js\\n>f++++++++++ themes/vanilla-bootstrap-hugo-theme/static/js/jquery-3.3.1.slim.min.js\\n\\nsent 282,877,469 bytes  received 470,944 bytes  9,605,030.95 bytes/sec\\ntotal size is 470,527,158  speedup is 1.66\\n```\\n\\nWill it work?  Let's see... NOPE.  It does produce a site but the old \\\"Kaldi\\\" content is still all I see.  I even changed the `backend.branch:` value from `main` to `wieting`, but that did nothing.  So, I've captured the output here so that I can have a look at what's happening.  \\n\\n```zsh\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹wieting*â€º \\nâ•°â”€$ npm start                               \\n\\n> static-cms-hugo-netlify-template@1.0.0 start\\n> run-p start:**\\n\\n\\n> static-cms-hugo-netlify-template@1.0.0 start:webpack\\n> webpack-dev-server --config webpack.dev.js --hot --stats-error-details\\n\\n\\n> static-cms-hugo-netlify-template@1.0.0 start:hugo\\n> hugo -d ../dist -s site -vw\\n\\nWARN  --verbose was deprecated in Hugo v0.114.0 and will be removed in a future release. use --logLevel info\\nStart building sites â€¦ \\nhugo v0.120.1-16fb2cae88eb6add7d12e9fbfcf01d8670e60a35 darwin/amd64 BuildDate=2023-10-30T16:44:31Z VendorInfo=gohugoio\\n\\nINFO  copy static: syncing static files to /\\nINFO  build: running step process duration 4.236952ms\\nINFO  build: running step assemble duration 13.684119ms\\nWARN  found no layout file for \\\"json\\\" for kind \\\"section\\\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination.\\nINFO  build: running step render duration 58.753135ms\\nINFO  build: running step postProcess duration 8.744Âµs\\n\\n                   | EN   \\n-------------------+------\\n  Pages            |  66  \\n  Paginator pages  |   7  \\n  Non-page files   |   0  \\n  Static files     | 541  \\n  Processed images |   0  \\n  Aliases          |   7  \\n  Sitemaps         |   1  \\n  Cleaned          |   0  \\n\\nBuilt in 579 ms\\nWatching for changes in /Users/mark/GitHub/static-cms-hugo-local-template/site/{archetypes,content,data,layouts,package.json,static,themes}\\nWatching for config changes in /Users/mark/GitHub/static-cms-hugo-local-template/site/config.toml, /Users/mark/GitHub/static-cms-hugo-local-template/site/config/_default\\nPress Ctrl+C to stop\\n<i> [webpack-dev-server] Project is running at:\\n<i> [webpack-dev-server] Loopback: http://localhost:3000/\\n<i> [webpack-dev-server] On Your Network (IPv4): http://192.168.0.183:3000/\\n<i> [webpack-dev-server] On Your Network (IPv6): http://[fe80::1]:3000/\\n<i> [webpack-dev-server] Content not from webpack is served from '/Users/mark/GitHub/static-cms-hugo-local-template/dist' directory\\n<i> [webpack-dev-server] 404s will fallback to '/index.html'\\n<i> [webpack-dev-middleware] wait until bundle finished: /\\nassets by path *.js 18.3 MiB\\n  asset cms.js 18 MiB [emitted] (name: cms)\\n  asset main.js 300 KiB [emitted] (name: main)\\nasset main.css 113 KiB [emitted] (name: main)\\nasset admin/index.html 521 bytes [emitted]\\nasset fonts/.keep 0 bytes [emitted] [from: src/fonts/.keep] [copied]\\nEntrypoint main 413 KiB = main.css 113 KiB main.js 300 KiB\\nEntrypoint cms 18 MiB = cms.js\\nruntime modules 72.3 KiB 38 modules\\nmodules by path ./node_modules/ 16.9 MiB 82 modules\\nmodules by path ./src/ 133 KiB (javascript) 113 KiB (css/mini-extract)\\n  modules by path ./src/js/ 15.2 KiB 9 modules\\n  modules by path ./src/css/*.scss 118 KiB (javascript) 113 KiB (css/mini-extract)\\n    ./src/css/main.scss 2.78 KiB [built] [code generated]\\n    ./node_modules/to-string-loader/src/to-string.js!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 429 bytes [built] [code generated]\\n    ./node_modules/mini-css-extract-plugin/dist/loader.js??ruleSet[1].rules[2].use[1]!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 332 bytes [built] [code generated]\\n    + 2 modules\\n  ./src/index.js 124 bytes [built] [code generated]\\nasset modules 5.46 KiB\\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.28 KiB [built] [code generated] [build time executed]\\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.33 KiB [built] [code generated] [build time executed]\\n  data:image/jpeg;base64,/9j/4QAYRXhpZgAA.. 1.55 KiB [built] [code generated] [build time executed]\\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.3 KiB [built] [code generated] [build time executed]\\nwebpack 5.89.0 compiled successfully in 5563 ms\\nINFO  Received System Events: [CHMOD         \\\"/Users/mark/GitHub/static-cms-hugo-local-template/site/data/webpack.json\\\" WRITE         \\\"/Users/mark/GitHub/static-cms-hugo-local-template/site/data/webpack.json\\\"]\\n\\nChange detected, rebuilding site.\\n2024-01-13 13:15:08.329 -0600\\nData changed WRITE         \\\"/Users/mark/GitHub/static-cms-hugo-local-template/site/data/webpack.json\\\"\\nINFO  build: running step process duration 186.604Âµs\\nINFO  build: running step assemble duration 244ns\\nWARN  found no layout file for \\\"json\\\" for kind \\\"section\\\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination.\\nINFO  build: running step render duration 31.514265ms\\nINFO  build: running step postProcess duration 7.661Âµs\\nTotal in 31 ms\\n^C<i> [webpack-dev-server] Gracefully shutting down. To force exit, press ^C again. Please wait...\\n```\\n\\n\\n\\n\"}],[\"markdown\",{\"markdown\":\"## Corrections Needed\\nSo, the first thing I see here is that the new `site` directory contains the template's `content/_index.md` file which naturally becomes the site's home page.  It contains only \\\"Kaldi\\\" content. So I tried removing that `_index.md` file and that changed the home page \\\"title\\\", but very little else.  \\n\\nI think returing to the `main` branch of this project and starting over again but using only the content of `wieting-ss` in the new `site/` directory might be wise.  I did it like this:  \\n\\n```zsh\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\\nâ•°â”€$ rm -fr static-cms-hugo-local-template\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\\nâ•°â”€$ git clone https://github.com/Summitt-Services/static-cms-hugo-local-template.git\\nCloning into 'static-cms-hugo-local-template'...\\nremote: Enumerating objects: 574, done.\\nremote: Counting objects: 100% (155/155), done.\\nremote: Compressing objects: 100% (50/50), done.\\nremote: Total 574 (delta 122), reused 125 (delta 102), pack-reused 419\\nReceiving objects: 100% (574/574), 22.14 MiB | 23.94 MiB/s, done.\\nResolving deltas: 100% (248/248), done.\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\\nâ•°â”€$ cd static-cms-hugo-local-template\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹mainâ€º\\nâ•°â”€$ cp -fr site/static/admin ~\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹mainâ€º\\nâ•°â”€$ rm -fr site\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º\\nâ•°â”€$ mkdir site\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º\\nâ•°â”€$ cp -fr ../wieting-ss/. site/.\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º\\nâ•°â”€$ cp -f ~/admin/config.yml site/static/admin/.\\n```  \\n\\nNext I launched the proxy server like so:\\n\\n```zsh\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º\\nâ•°â”€$ npx @staticcms/proxy-server\\ninfo: Static CMS File System Proxy Server configured with /Users/mark/GitHub/static-cms-hugo-local-template\\ninfo: Static CMS Proxy Server listening on port 8082\\n```\\n\\nThen in my _VSCode_ terminal this:\\n\\n```zsh\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º \\nâ•°â”€$ npm start\\n\\n> static-cms-hugo-netlify-template@1.0.0 start\\n> run-p start:**\\n\\n\\n> static-cms-hugo-netlify-template@1.0.0 start:webpack\\n> webpack-dev-server --config webpack.dev.js --hot --stats-error-details\\n\\n\\n> static-cms-hugo-netlify-template@1.0.0 start:hugo\\n> hugo -d ../dist -s site -vw\\n\\nWARN  --verbose was deprecated in Hugo v0.114.0 and will be removed in a future release. use --logLevel info\\nStart building sites â€¦ \\nhugo v0.120.1-16fb2cae88eb6add7d12e9fbfcf01d8670e60a35 darwin/amd64 BuildDate=2023-10-30T16:44:31Z VendorInfo=gohugoio\\n\\nINFO  copy static: syncing static files to /\\nINFO  build: running step process duration 3.193622ms\\nINFO  build: running step assemble duration 25.748629ms\\nWARN  found no layout file for \\\"json\\\" for kind \\\"section\\\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination.\\nINFO  build: running step render duration 70.992512ms\\nINFO  build: running step postProcess duration 9.94Âµs\\n<i> [webpack-dev-server] Project is running at:\\n<i> [webpack-dev-server] Loopback: http://localhost:3000/\\n<i> [webpack-dev-server] On Your Network (IPv4): http://192.168.0.183:3000/\\n<i> [webpack-dev-server] On Your Network (IPv6): http://[fe80::1]:3000/\\n<i> [webpack-dev-server] Content not from webpack is served from '/Users/mark/GitHub/static-cms-hugo-local-template/dist' directory\\n<i> [webpack-dev-server] 404s will fallback to '/index.html'\\n\\n                   | EN   \\n-------------------+------\\n  Pages            |  57  \\n  Paginator pages  |   0  \\n  Non-page files   |   0  \\n  Static files     | 499  \\n  Processed images |   0  \\n  Aliases          |   1  \\n  Sitemaps         |   1  \\n  Cleaned          |   0  \\n\\nBuilt in 1034 ms\\nWatching for changes in /Users/mark/GitHub/static-cms-hugo-local-template/site/{archetypes,content,layouts,package.json,static,themes}\\nWatching for config changes in /Users/mark/GitHub/static-cms-hugo-local-template/site/config/_default\\nPress Ctrl+C to stop\\n<i> [webpack-dev-middleware] wait until bundle finished: /\\nassets by path *.js 18.3 MiB\\n  asset cms.js 18 MiB [emitted] (name: cms)\\n  asset main.js 300 KiB [emitted] (name: main)\\nasset main.css 113 KiB [emitted] (name: main)\\nasset admin/index.html 521 bytes [emitted]\\nasset fonts/.keep 0 bytes [emitted] [from: src/fonts/.keep] [copied]\\nEntrypoint main 413 KiB = main.css 113 KiB main.js 300 KiB\\nEntrypoint cms 18 MiB = cms.js\\nruntime modules 72.3 KiB 38 modules\\nmodules by path ./node_modules/ 16.9 MiB 82 modules\\nmodules by path ./src/ 133 KiB (javascript) 113 KiB (css/mini-extract)\\n  modules by path ./src/js/ 15.2 KiB 9 modules\\n  modules by path ./src/css/*.scss 118 KiB (javascript) 113 KiB (css/mini-extract)\\n    ./src/css/main.scss 2.78 KiB [built] [code generated]\\n    ./node_modules/to-string-loader/src/to-string.js!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 429 bytes [built] [code generated]\\n    ./node_modules/mini-css-extract-plugin/dist/loader.js??ruleSet[1].rules[2].use[1]!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 332 bytes [built] [code generated]\\n    + 2 modules\\n  ./src/index.js 124 bytes [built] [code generated]\\nasset modules 5.46 KiB\\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.28 KiB [built] [code generated] [build time executed]\\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.33 KiB [built] [code generated] [build time executed]\\n  data:image/jpeg;base64,/9j/4QAYRXhpZgAA.. 1.55 KiB [built] [code generated] [build time executed]\\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.3 KiB [built] [code generated] [build time executed]\\nwebpack 5.89.0 compiled successfully in 6771 ms\\n```\\n\\nAgain, it works.  Only this time the Wieting website appears at http://localhost:3000 and http://localhost:3000/admin works too, but with the wrong configuration.  Still, that's a WIN!  \\n\"}],[\"markdown\",{\"markdown\":\"## Time To Save My Progress\\nI really don't want to dump 4000+ new files, many of them specific to the Wieting website, into my pristine (and working) [https://github.com/Summitt-Services/static-cms-hugo-local-template](https://github.com/Summitt-Services/static-cms-hugo-local-template) GitHub repository.  So, I'm going to clean up my local project by removing that which is no longer needed, and then I'm going to remove the `.git` directory and create/populate a new [wieting-staticCMS](https://github.com/SummittDweller/wieting-staticCMS) private repository.  After creating that empty repository the process looked like this:  \\n\\n```zsh\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º \\nâ•°â”€$ rm -fr site/.git \\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º \\nâ•°â”€$ rm -fr .git\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \\nâ•°â”€$ git init\\nInitialized empty Git repository in /Users/mark/GitHub/static-cms-hugo-local-template/.git/\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \\nâ•°â”€$ git add .\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \\nâ•°â”€$ git commit -m \\\"first commit\\\"\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \\nâ•°â”€$ git branch -M main\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \\nâ•°â”€$ git remote add origin https://github.com/SummittDweller/wieting-staticCMS.git\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \\nâ•°â”€$ git push -u origin main\\n...\\nEnumerating objects: 2979, done.\\nCounting objects: 100% (2979/2979), done.\\nDelta compression using up to 6 threads\\nCompressing objects: 100% (2855/2855), done.\\nWriting objects: 100% (2979/2979), 95.87 MiB | 2.65 MiB/s, done.\\nTotal 2979 (delta 638), reused 0 (delta 0), pack-reused 0\\nremote: Resolving deltas: 100% (638/638), done.\\nTo https://github.com/SummittDweller/wieting-staticCMS.git\\n * [new branch]      main -> main\\nbranch 'main' set up to track 'origin/main'.\\n```\\n\"}],[\"markdown\",{\"markdown\":\"# wieting-staticCMS\\nWith the new GitHub repo in place let's take it for a local spin.\\n\\n```zsh\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\\nâ•°â”€$ git clone https://github.com/SummittDweller/wieting-staticCMS.git\\nCloning into 'wieting-staticCMS'...\\nremote: Enumerating objects: 2979, done.\\nremote: Total 2979 (delta 0), reused 0 (delta 0), pack-reused 2979\\nReceiving objects: 100% (2979/2979), 95.87 MiB | 26.77 MiB/s, done.\\nResolving deltas: 100% (638/638), done.\\nUpdating files: 100% (4834/4834), done.\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\\nâ•°â”€$ cd wieting-staticCMS\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/wieting-staticCMS â€¹mainâ€º\\nâ•°â”€$ npm install\\nnpm WARN deprecated querystring@0.2.0: The querystring API is considered Legacy. new code should use the URLSearchParams API instead.\\n\\nadded 1567 packages, and audited 1568 packages in 1m\\n\\n426 packages are looking for funding\\n  run `npm fund` for details\\n\\n2 moderate severity vulnerabilities\\n\\nTo address all issues, run:\\n  npm audit fix\\n\\nRun `npm audit` for details.\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/wieting-staticCMS â€¹mainâ€º\\nâ•°â”€$ npx @staticcms/proxy-server\\ninfo: Static CMS File System Proxy Server configured with /Users/mark/GitHub/wieting-staticCMS\\ninfo: Static CMS Proxy Server listening on port 8082\\n```\\n\\nThen, in a differnt terminal window...  \\n```zsh\\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/wieting-staticCMS â€¹mainâ€º\\nâ•°â”€$ npm start\\n\\n> static-cms-hugo-netlify-template@1.0.0 start\\n> run-p start:**\\n\\n\\n> static-cms-hugo-netlify-template@1.0.0 start:hugo\\n> hugo -d ../dist -s site -vw\\n\\n\\n> static-cms-hugo-netlify-template@1.0.0 start:webpack\\n> webpack-dev-server --config webpack.dev.js --hot --stats-error-details\\n\\nWARN  --verbose was deprecated in Hugo v0.114.0 and will be removed in a future release. use --logLevel info\\nStart building sites â€¦\\nhugo v0.120.1-16fb2cae88eb6add7d12e9fbfcf01d8670e60a35 darwin/amd64 BuildDate=2023-10-30T16:44:31Z VendorInfo=gohugoio\\n\\nINFO  copy static: syncing static files to /\\nINFO  build: running step process duration 3.975463ms\\nINFO  build: running step assemble duration 19.211854ms\\nWARN  found no layout file for \\\"json\\\" for kind \\\"section\\\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination.\\nINFO  build: running step render duration 54.091014ms\\nINFO  build: running step postProcess duration 8.597Âµs\\n\\n                   | EN\\n-------------------+------\\n  Pages            |  57\\n  Paginator pages  |   0\\n  Non-page files   |   0\\n  Static files     | 499\\n  Processed images |   0\\n  Aliases          |   1\\n  Sitemaps         |   1\\n  Cleaned          |   0\\n\\nBuilt in 717 ms\\nWatching for changes in /Users/mark/GitHub/wieting-staticCMS/site/{archetypes,content,layouts,package.json,static,themes}\\nWatching for config changes in /Users/mark/GitHub/wieting-staticCMS/site/config/_default\\nPress Ctrl+C to stop\\n<i> [webpack-dev-server] Project is running at:\\n<i> [webpack-dev-server] Loopback: http://localhost:3000/\\n<i> [webpack-dev-server] On Your Network (IPv4): http://192.168.0.183:3000/\\n<i> [webpack-dev-server] On Your Network (IPv6): http://[fe80::1]:3000/\\n<i> [webpack-dev-server] Content not from webpack is served from '/Users/mark/GitHub/wieting-staticCMS/dist' directory\\n<i> [webpack-dev-server] 404s will fallback to '/index.html'\\n<i> [webpack-dev-middleware] wait until bundle finished: /\\nassets by path *.js 18.3 MiB\\n  asset cms.js 18 MiB [emitted] (name: cms)\\n  asset main.js 300 KiB [emitted] (name: main)\\nasset main.css 113 KiB [emitted] (name: main)\\nasset admin/index.html 521 bytes [emitted]\\nasset fonts/.keep 0 bytes [emitted] [from: src/fonts/.keep] [copied]\\nEntrypoint main 413 KiB = main.css 113 KiB main.js 300 KiB\\nEntrypoint cms 18 MiB = cms.js\\nruntime modules 72.3 KiB 38 modules\\nmodules by path ./node_modules/ 16.9 MiB 82 modules\\nmodules by path ./src/ 133 KiB (javascript) 113 KiB (css/mini-extract)\\n  modules by path ./src/js/ 15.2 KiB 9 modules\\n  modules by path ./src/css/*.scss 118 KiB (javascript) 113 KiB (css/mini-extract)\\n    ./src/css/main.scss 2.78 KiB [built] [code generated]\\n    ./node_modules/to-string-loader/src/to-string.js!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 429 bytes [built] [code generated]\\n    ./node_modules/mini-css-extract-plugin/dist/loader.js??ruleSet[1].rules[2].use[1]!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 332 bytes [built] [code generated]\\n    + 2 modules\\n  ./src/index.js 124 bytes [built] [code generated]\\nasset modules 5.46 KiB\\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.28 KiB [built] [code generated] [build time executed]\\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.33 KiB [built] [code generated] [build time executed]\\n  data:image/jpeg;base64,/9j/4QAYRXhpZgAA.. 1.55 KiB [built] [code generated] [build time executed]\\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.3 KiB [built] [code generated] [build time executed]\\nwebpack 5.89.0 compiled successfully in 6051 ms\\n```\\n\\nAnd again, **IT WORKS!**  \"}]],\"markups\":[[\"a\",[\"href\",\"https://www.staticcms.org/\"]],[\"a\",[\"href\",\"https://Wieting.TamaToledo.com\"]],[\"code\"]],\"sections\":[[1,\"p\",[[0,[],0,\"Today is Saturday, January 13, 2024, and I won't be able to watch the KC Chief's wildcard playoff game vs. the Miami Dolphins tonight because it is streaming ONLY on Peacock, and I refuse to pay them for the \\\"privilege\\\" to watch it live.  So, I'm going to do something productive instead.  Let's see if I can spin up an instance of \"],[0,[0],1,\"StaticCMS\"],[0,[],0,\" to provide an OPEN CMS for the content editor(s) behind the \"],[0,[1],1,\"Wieting Theatre website\"],[0,[],0,\".  \"]]],[10,0],[10,1],[10,2],[10,3],[1,\"p\",[[0,[],0,\"Time to merge the old CMS config from \"],[0,[2],1,\"site/static/.admin-netlify/config.yml\"],[0,[],0,\" into the new config at \"],[0,[2],1,\"site/static/admin/config.yml\"],[0,[],0,\".   Then a few changes will be needed since the site's content structure has changed somewhat from the old days.  \"]]],[1,\"p\",[]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Today is Saturday, January 13, 2024, and I won't be able to watch the KC Chief's wildcard playoff game vs. the Miami Dolphins tonight because it is streaming ONLY on Peacock, and I refuse to pay them for the \"privilege\" to watch it live. Â So, I'm going to do something productive instead. Â Let's see if I can spin up an instance of <a href=\"https://www.staticcms.org/\">StaticCMS</a> to provide an OPEN CMS for the content editor(s) behind the <a href=\"https://Wieting.TamaToledo.com\">Wieting Theatre website</a>. Â </p><!--kg-card-begin: markdown--><h2 id=\"the-plan\">The Plan</h2>\n<p>So, the plan here involves establishing a &quot;local-only&quot; CMS for the <a href=\"https://Wieting.TamaToledo.com\">Wieting Theatre website</a> and running it on the new Ubuntu server in the Wieting's projection booth.  Editors should will be given login credentials to that server where they can run a local copy of the website (it's a Hugo static site) AND a local copy of the CMS editor, make changes, preview them, and commit the changes to the project's GitHub repo.  The website, hosted with <em>AWS Amplify</em> is then automatically updated based on the updated content.</p>\n<h3 id=\"along-the-way\">Along the Way</h3>\n<p>It's worth noting that while looking at <a href=\"https://www.staticcms.org\">StaticCMS</a> I also stumbled upon <a href=\"https://mortenson.coffee/work/tabcms/\">tabcms - A CMS that runs in your browser tab</a> which might be of interest if &quot;The Plan&quot; doesn't work.</p>\n<h2 id=\"first-stepsstart-with-a-template\">First Steps - Start with a Template</h2>\n<p>I choose the guidance at <a href=\"https://www.staticcms.org/docs/start-with-a-template\">Start with a Template</a> to get started.  My aim is to clone that repo and build it locally &quot;as-is&quot;, then see if I can drop my existing <a href=\"https://github.com/SummittServices/wieting-ss\">wieting-ss</a> repo into the <code>site</code> directory and continue to make it work locally.</p>\n<p>If that works, I'll repeat the same on the Wieting's Ubuntu server and keep pushing forward.  Wish me luck?</p>\n<h3 id=\"getting-started\">Getting Started</h3>\n<p>Following the <a href=\"https://github.com/StaticJsCMS/static-cms-hugo-netlify-template#local-development\">Local Development</a> guidance found me cloning this <a href=\"https://github.com/StaticJsCMS/static-cms-hugo-netlify-template\">template</a> then...</p>\n<pre><code class=\"language-zsh\">â•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-netlify-template â€¹mainâ€º \nâ•°â”€$ npm install \nnpm WARN deprecated querystring@0.2.0: The querystring API is considered Legacy. new code should use the URLSearchParams API instead.\n\nadded 1567 packages, and audited 1568 packages in 2m\n\n426 packages are looking for funding\n  run `npm fund` for details\n\n2 moderate severity vulnerabilities\n\nTo address all issues, run:\n  npm audit fix\n\nRun `npm audit` for details.\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-netlify-template â€¹main*â€º \nâ•°â”€$ npm start\n\n&gt; static-cms-hugo-netlify-template@1.0.0 start\n&gt; run-p start:**\n\n\n&gt; static-cms-hugo-netlify-template@1.0.0 start:webpack\n&gt; webpack-dev-server --config webpack.dev.js --hot --stats-error-details\n\n\n&gt; static-cms-hugo-netlify-template@1.0.0 start:hugo\n&gt; hugo -d ../dist -s site -vw\n\nWARN  --verbose was deprecated in Hugo v0.114.0 and will be removed in a future release. use --logLevel info\nStart building sites â€¦ \nhugo v0.120.1-16fb2cae88eb6add7d12e9fbfcf01d8670e60a35 darwin/amd64 BuildDate=2023-10-30T16:44:31Z VendorInfo=gohugoio\n\nINFO  copy static: syncing static files to /\nINFO  build: running step process duration 962.376Âµs\nINFO  build: running step assemble duration 4.712758ms\nINFO  build: running step render duration 16.982673ms\nINFO  build: running step postProcess duration 8.3Âµs\n\n                   | EN  \n-------------------+-----\n  Pages            | 10  \n  Paginator pages  |  0  \n  Non-page files   |  0  \n  Static files     | 43  \n  Processed images |  0  \n  Aliases          |  1  \n  Sitemaps         |  1  \n  Cleaned          |  0  \n\nBuilt in 68 ms\nWatching for changes in /Users/mark/GitHub/static-cms-hugo-netlify-template/site/{content,data,layouts,static}\nWatching for config changes in /Users/mark/GitHub/static-cms-hugo-netlify-template/site/config.toml\nPress Ctrl+C to stop\n&lt;i&gt; [webpack-dev-server] Project is running at:\n&lt;i&gt; [webpack-dev-server] Loopback: http://localhost:3000/\n&lt;i&gt; [webpack-dev-server] On Your Network (IPv4): http://192.168.0.183:3000/\n&lt;i&gt; [webpack-dev-server] On Your Network (IPv6): http://[fe80::1]:3000/\n&lt;i&gt; [webpack-dev-server] Content not from webpack is served from '/Users/mark/GitHub/static-cms-hugo-netlify-template/dist' directory\n&lt;i&gt; [webpack-dev-server] 404s will fallback to '/index.html'\n&lt;i&gt; [webpack-dev-middleware] wait until bundle finished: /\nassets by path *.js 18.3 MiB\n  asset cms.js 18 MiB [emitted] (name: cms)\n  asset main.js 300 KiB [emitted] (name: main)\nasset main.css 113 KiB [emitted] (name: main)\nasset admin/index.html 521 bytes [emitted]\nasset fonts/.keep 0 bytes [emitted] [from: src/fonts/.keep] [copied]\nEntrypoint main 413 KiB = main.css 113 KiB main.js 300 KiB\nEntrypoint cms 18 MiB = cms.js\nruntime modules 72.3 KiB 38 modules\nmodules by path ./node_modules/ 16.9 MiB 82 modules\nmodules by path ./src/ 133 KiB (javascript) 113 KiB (css/mini-extract)\n  modules by path ./src/js/ 15.2 KiB 9 modules\n  modules by path ./src/css/*.scss 118 KiB (javascript) 113 KiB (css/mini-extract)\n    ./src/css/main.scss 2.78 KiB [built] [code generated]\n    ./node_modules/to-string-loader/src/to-string.js!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 429 bytes [built] [code generated]\n    ./node_modules/mini-css-extract-plugin/dist/loader.js??ruleSet[1].rules[2].use[1]!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 332 bytes [built] [code generated]\n    + 2 modules\n  ./src/index.js 124 bytes [built] [code generated]\nasset modules 5.46 KiB\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.28 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.33 KiB [built] [code generated] [build time executed]\n  data:image/jpeg;base64,/9j/4QAYRXhpZgAA.. 1.55 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.3 KiB [built] [code generated] [build time executed]\nwebpack 5.89.0 compiled successfully in 6191 ms\nINFO  Received System Events: [CREATE        &quot;/Users/mark/GitHub/static-cms-hugo-netlify-template/site/data/webpack.json&quot; WRITE         &quot;/Users/mark/GitHub/static-cms-hugo-netlify-template/site/data/webpack.json&quot;]\n\nChange detected, rebuilding site.\n2024-01-13 10:55:38.259 -0600\nData changed WRITE         &quot;/Users/mark/GitHub/static-cms-hugo-netlify-template/site/data/webpack.json&quot;\nData changed WRITE         &quot;/Users/mark/GitHub/static-cms-hugo-netlify-template/site/data/webpack.json&quot;\nINFO  build: running step process duration 114.033Âµs\nINFO  build: running step assemble duration 277ns\nINFO  build: running step render duration 6.244639ms\nINFO  build: running step postProcess duration 1.831Âµs\nTotal in 6 ms\n</code></pre>\n<p>The demo site is indeed working at <code>http://localhost:3000/</code> and a vist to <code>http://localhost:3000/admin</code> does indeed open a <em>StaticCMS</em> login that's prompting me with the following image.</p>\n<p><img src=\"__GHOST_URL__/content/images/2024/01/Screenshot-2024-01-13-at-11.00.45.png\" alt=\"Screenshot-2024-01-13-at-11.00.45\" loading=\"lazy\"></p>\n<h3 id=\"lets-go-local\">Let's Go Local!</h3>\n<p>Next, I'm going to try and switch what we have above to &quot;go local&quot; using <a href=\"https://www.staticcms.org/docs/local-backend\">this guidance</a> provided in the <em>StaticCMS</em> documenation.  Fingers crossed for good luck...</p>\n<h3 id=\"eureka-it-works\">Eureka! It Works!</h3>\n<p>So, I made the <code>local_backend</code> config changes as prescribed in <code>site/static/admin/config.yml</code> and that file now looks like this:</p>\n<pre><code>local_backend: \n  # when using a custom proxy server port\n  url: http://localhost:8082/api/v1\n  # when accessing the local site from a host other than 'localhost' or '127.0.0.1'\n  allowed_hosts: ['192.168.0.1']\n</code></pre>\n<p>I also added a new <code>.env</code> file in the project root directory with a single line reading <code>PORT=8082</code>, matching the port number specified in the <code>url:</code> value from <code>config.yml</code>.</p>\n<p>Now, with <code>npx @staticcms/proxy-server</code> running in a local terminal I'm able to run <code>npm start</code> (in my <em>VSCode</em> terminal) to launch the site at <code>localhost:3000</code>.  Having done that I'm able to visit <code>http://localhost:3000/admin</code> where I get a new <em>StaticCMS</em> splash screen with a simple <code>Login</code> button, not a <em>Netlify</em> button.  Yay!</p>\n<h3 id=\"even-better-news\">Even Better News?</h3>\n<p><em>StaticCMS</em> was built from <em>NetlifyCMS</em> so the <code>site/static/admin/config.yml</code>.  I think I'll be able to use the <code>collections:</code> portion of my old <code>admin/config.yml</code> file from <a href=\"https://github.com/SummittDweller/wieting-one-click-hugo-cms\">wieting-one-click-hugo-cms</a> to get a headstart on setting that up!</p>\n<p>Next step... let's see if I can drop the <code>site</code> directory from <a href=\"https://github.com/SummittServices/wieting-ss\">wieting-ss</a> into this local project and still have a functioning local site.  Again, fingers crossed for luck.</p>\n<h1 id=\"fresh-restart\">Fresh Restart</h1>\n<p>In order to start fresh I went back to the <a href=\"https://github.com/StaticJsCMS/static-cms-hugo-netlify-template\">StaticJsCMS/static-cms-hugo-netlify-template</a> repo and created a new fork (not a clone) in my <code>Summitt-Services</code> team space at <a href=\"https://github.com/Summitt-Services/static-cms-hugo-local-template\">https://github.com/Summitt-Services/static-cms-hugo-local-template</a>.  In the new fork I changed the <code>-netlify-</code> portion of the name to <code>-local-</code> as this new project is intended to have no <em>Netlify</em> association, only a &quot;local&quot; CMS will be supported.</p>\n<p>Next, I cloned the new fork to my workstation and got it working locally again using the same steps I had taken above.</p>\n<h2 id=\"copying-wieting-ss-to-static-cms-hugo-local-template\">Copying <code>wieting-ss</code> to <code>static-cms-hugo-local-template</code></h2>\n<p>For safe-keeping I created a new branch named <code>wieting</code> in <code>~/GitHub/static-cms-hugo-local-template</code> where I did this:</p>\n<pre><code class=\"language-zsh\">â•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹wieting*â€º \nâ•°â”€$ rsync -aruvi ../wieting-ss/. site/.\n...\n&gt;f++++++++++ themes/vanilla-bootstrap-hugo-theme/static/js/checkTweetDate.js\n&gt;f++++++++++ themes/vanilla-bootstrap-hugo-theme/static/js/feather.min.js\n&gt;f++++++++++ themes/vanilla-bootstrap-hugo-theme/static/js/jquery-3.3.1.slim.min.js\n\nsent 282,877,469 bytes  received 470,944 bytes  9,605,030.95 bytes/sec\ntotal size is 470,527,158  speedup is 1.66\n</code></pre>\n<p>Will it work?  Let's see... NOPE.  It does produce a site but the old &quot;Kaldi&quot; content is still all I see.  I even changed the <code>backend.branch:</code> value from <code>main</code> to <code>wieting</code>, but that did nothing.  So, I've captured the output here so that I can have a look at what's happening.</p>\n<pre><code class=\"language-zsh\">â•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹wieting*â€º \nâ•°â”€$ npm start                               \n\n&gt; static-cms-hugo-netlify-template@1.0.0 start\n&gt; run-p start:**\n\n\n&gt; static-cms-hugo-netlify-template@1.0.0 start:webpack\n&gt; webpack-dev-server --config webpack.dev.js --hot --stats-error-details\n\n\n&gt; static-cms-hugo-netlify-template@1.0.0 start:hugo\n&gt; hugo -d ../dist -s site -vw\n\nWARN  --verbose was deprecated in Hugo v0.114.0 and will be removed in a future release. use --logLevel info\nStart building sites â€¦ \nhugo v0.120.1-16fb2cae88eb6add7d12e9fbfcf01d8670e60a35 darwin/amd64 BuildDate=2023-10-30T16:44:31Z VendorInfo=gohugoio\n\nINFO  copy static: syncing static files to /\nINFO  build: running step process duration 4.236952ms\nINFO  build: running step assemble duration 13.684119ms\nWARN  found no layout file for &quot;json&quot; for kind &quot;section&quot;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination.\nINFO  build: running step render duration 58.753135ms\nINFO  build: running step postProcess duration 8.744Âµs\n\n                   | EN   \n-------------------+------\n  Pages            |  66  \n  Paginator pages  |   7  \n  Non-page files   |   0  \n  Static files     | 541  \n  Processed images |   0  \n  Aliases          |   7  \n  Sitemaps         |   1  \n  Cleaned          |   0  \n\nBuilt in 579 ms\nWatching for changes in /Users/mark/GitHub/static-cms-hugo-local-template/site/{archetypes,content,data,layouts,package.json,static,themes}\nWatching for config changes in /Users/mark/GitHub/static-cms-hugo-local-template/site/config.toml, /Users/mark/GitHub/static-cms-hugo-local-template/site/config/_default\nPress Ctrl+C to stop\n&lt;i&gt; [webpack-dev-server] Project is running at:\n&lt;i&gt; [webpack-dev-server] Loopback: http://localhost:3000/\n&lt;i&gt; [webpack-dev-server] On Your Network (IPv4): http://192.168.0.183:3000/\n&lt;i&gt; [webpack-dev-server] On Your Network (IPv6): http://[fe80::1]:3000/\n&lt;i&gt; [webpack-dev-server] Content not from webpack is served from '/Users/mark/GitHub/static-cms-hugo-local-template/dist' directory\n&lt;i&gt; [webpack-dev-server] 404s will fallback to '/index.html'\n&lt;i&gt; [webpack-dev-middleware] wait until bundle finished: /\nassets by path *.js 18.3 MiB\n  asset cms.js 18 MiB [emitted] (name: cms)\n  asset main.js 300 KiB [emitted] (name: main)\nasset main.css 113 KiB [emitted] (name: main)\nasset admin/index.html 521 bytes [emitted]\nasset fonts/.keep 0 bytes [emitted] [from: src/fonts/.keep] [copied]\nEntrypoint main 413 KiB = main.css 113 KiB main.js 300 KiB\nEntrypoint cms 18 MiB = cms.js\nruntime modules 72.3 KiB 38 modules\nmodules by path ./node_modules/ 16.9 MiB 82 modules\nmodules by path ./src/ 133 KiB (javascript) 113 KiB (css/mini-extract)\n  modules by path ./src/js/ 15.2 KiB 9 modules\n  modules by path ./src/css/*.scss 118 KiB (javascript) 113 KiB (css/mini-extract)\n    ./src/css/main.scss 2.78 KiB [built] [code generated]\n    ./node_modules/to-string-loader/src/to-string.js!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 429 bytes [built] [code generated]\n    ./node_modules/mini-css-extract-plugin/dist/loader.js??ruleSet[1].rules[2].use[1]!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 332 bytes [built] [code generated]\n    + 2 modules\n  ./src/index.js 124 bytes [built] [code generated]\nasset modules 5.46 KiB\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.28 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.33 KiB [built] [code generated] [build time executed]\n  data:image/jpeg;base64,/9j/4QAYRXhpZgAA.. 1.55 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.3 KiB [built] [code generated] [build time executed]\nwebpack 5.89.0 compiled successfully in 5563 ms\nINFO  Received System Events: [CHMOD         &quot;/Users/mark/GitHub/static-cms-hugo-local-template/site/data/webpack.json&quot; WRITE         &quot;/Users/mark/GitHub/static-cms-hugo-local-template/site/data/webpack.json&quot;]\n\nChange detected, rebuilding site.\n2024-01-13 13:15:08.329 -0600\nData changed WRITE         &quot;/Users/mark/GitHub/static-cms-hugo-local-template/site/data/webpack.json&quot;\nINFO  build: running step process duration 186.604Âµs\nINFO  build: running step assemble duration 244ns\nWARN  found no layout file for &quot;json&quot; for kind &quot;section&quot;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination.\nINFO  build: running step render duration 31.514265ms\nINFO  build: running step postProcess duration 7.661Âµs\nTotal in 31 ms\n^C&lt;i&gt; [webpack-dev-server] Gracefully shutting down. To force exit, press ^C again. Please wait...\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"corrections-needed\">Corrections Needed</h2>\n<p>So, the first thing I see here is that the new <code>site</code> directory contains the template's <code>content/_index.md</code> file which naturally becomes the site's home page.  It contains only &quot;Kaldi&quot; content. So I tried removing that <code>_index.md</code> file and that changed the home page &quot;title&quot;, but very little else.</p>\n<p>I think returing to the <code>main</code> branch of this project and starting over again but using only the content of <code>wieting-ss</code> in the new <code>site/</code> directory might be wise.  I did it like this:</p>\n<pre><code class=\"language-zsh\">â•­â”€mark@Marks-Mac-Mini ~/GitHub\nâ•°â”€$ rm -fr static-cms-hugo-local-template\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\nâ•°â”€$ git clone https://github.com/Summitt-Services/static-cms-hugo-local-template.git\nCloning into 'static-cms-hugo-local-template'...\nremote: Enumerating objects: 574, done.\nremote: Counting objects: 100% (155/155), done.\nremote: Compressing objects: 100% (50/50), done.\nremote: Total 574 (delta 122), reused 125 (delta 102), pack-reused 419\nReceiving objects: 100% (574/574), 22.14 MiB | 23.94 MiB/s, done.\nResolving deltas: 100% (248/248), done.\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\nâ•°â”€$ cd static-cms-hugo-local-template\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹mainâ€º\nâ•°â”€$ cp -fr site/static/admin ~\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹mainâ€º\nâ•°â”€$ rm -fr site\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º\nâ•°â”€$ mkdir site\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º\nâ•°â”€$ cp -fr ../wieting-ss/. site/.\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º\nâ•°â”€$ cp -f ~/admin/config.yml site/static/admin/.\n</code></pre>\n<p>Next I launched the proxy server like so:</p>\n<pre><code class=\"language-zsh\">â•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º\nâ•°â”€$ npx @staticcms/proxy-server\ninfo: Static CMS File System Proxy Server configured with /Users/mark/GitHub/static-cms-hugo-local-template\ninfo: Static CMS Proxy Server listening on port 8082\n</code></pre>\n<p>Then in my <em>VSCode</em> terminal this:</p>\n<pre><code class=\"language-zsh\">â•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º \nâ•°â”€$ npm start\n\n&gt; static-cms-hugo-netlify-template@1.0.0 start\n&gt; run-p start:**\n\n\n&gt; static-cms-hugo-netlify-template@1.0.0 start:webpack\n&gt; webpack-dev-server --config webpack.dev.js --hot --stats-error-details\n\n\n&gt; static-cms-hugo-netlify-template@1.0.0 start:hugo\n&gt; hugo -d ../dist -s site -vw\n\nWARN  --verbose was deprecated in Hugo v0.114.0 and will be removed in a future release. use --logLevel info\nStart building sites â€¦ \nhugo v0.120.1-16fb2cae88eb6add7d12e9fbfcf01d8670e60a35 darwin/amd64 BuildDate=2023-10-30T16:44:31Z VendorInfo=gohugoio\n\nINFO  copy static: syncing static files to /\nINFO  build: running step process duration 3.193622ms\nINFO  build: running step assemble duration 25.748629ms\nWARN  found no layout file for &quot;json&quot; for kind &quot;section&quot;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination.\nINFO  build: running step render duration 70.992512ms\nINFO  build: running step postProcess duration 9.94Âµs\n&lt;i&gt; [webpack-dev-server] Project is running at:\n&lt;i&gt; [webpack-dev-server] Loopback: http://localhost:3000/\n&lt;i&gt; [webpack-dev-server] On Your Network (IPv4): http://192.168.0.183:3000/\n&lt;i&gt; [webpack-dev-server] On Your Network (IPv6): http://[fe80::1]:3000/\n&lt;i&gt; [webpack-dev-server] Content not from webpack is served from '/Users/mark/GitHub/static-cms-hugo-local-template/dist' directory\n&lt;i&gt; [webpack-dev-server] 404s will fallback to '/index.html'\n\n                   | EN   \n-------------------+------\n  Pages            |  57  \n  Paginator pages  |   0  \n  Non-page files   |   0  \n  Static files     | 499  \n  Processed images |   0  \n  Aliases          |   1  \n  Sitemaps         |   1  \n  Cleaned          |   0  \n\nBuilt in 1034 ms\nWatching for changes in /Users/mark/GitHub/static-cms-hugo-local-template/site/{archetypes,content,layouts,package.json,static,themes}\nWatching for config changes in /Users/mark/GitHub/static-cms-hugo-local-template/site/config/_default\nPress Ctrl+C to stop\n&lt;i&gt; [webpack-dev-middleware] wait until bundle finished: /\nassets by path *.js 18.3 MiB\n  asset cms.js 18 MiB [emitted] (name: cms)\n  asset main.js 300 KiB [emitted] (name: main)\nasset main.css 113 KiB [emitted] (name: main)\nasset admin/index.html 521 bytes [emitted]\nasset fonts/.keep 0 bytes [emitted] [from: src/fonts/.keep] [copied]\nEntrypoint main 413 KiB = main.css 113 KiB main.js 300 KiB\nEntrypoint cms 18 MiB = cms.js\nruntime modules 72.3 KiB 38 modules\nmodules by path ./node_modules/ 16.9 MiB 82 modules\nmodules by path ./src/ 133 KiB (javascript) 113 KiB (css/mini-extract)\n  modules by path ./src/js/ 15.2 KiB 9 modules\n  modules by path ./src/css/*.scss 118 KiB (javascript) 113 KiB (css/mini-extract)\n    ./src/css/main.scss 2.78 KiB [built] [code generated]\n    ./node_modules/to-string-loader/src/to-string.js!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 429 bytes [built] [code generated]\n    ./node_modules/mini-css-extract-plugin/dist/loader.js??ruleSet[1].rules[2].use[1]!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 332 bytes [built] [code generated]\n    + 2 modules\n  ./src/index.js 124 bytes [built] [code generated]\nasset modules 5.46 KiB\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.28 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.33 KiB [built] [code generated] [build time executed]\n  data:image/jpeg;base64,/9j/4QAYRXhpZgAA.. 1.55 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.3 KiB [built] [code generated] [build time executed]\nwebpack 5.89.0 compiled successfully in 6771 ms\n</code></pre>\n<p>Again, it works.  Only this time the Wieting website appears at <a href=\"http://localhost:3000\">http://localhost:3000</a> and <a href=\"http://localhost:3000/admin\">http://localhost:3000/admin</a> works too, but with the wrong configuration.  Still, that's a WIN!</p>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h2 id=\"time-to-save-my-progress\">Time To Save My Progress</h2>\n<p>I really don't want to dump 4000+ new files, many of them specific to the Wieting website, into my pristine (and working) <a href=\"https://github.com/Summitt-Services/static-cms-hugo-local-template\">https://github.com/Summitt-Services/static-cms-hugo-local-template</a> GitHub repository.  So, I'm going to clean up my local project by removing that which is no longer needed, and then I'm going to remove the <code>.git</code> directory and create/populate a new <a href=\"https://github.com/SummittDweller/wieting-staticCMS\">wieting-staticCMS</a> private repository.  After creating that empty repository the process looked like this:</p>\n<pre><code class=\"language-zsh\">â•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º \nâ•°â”€$ rm -fr site/.git \nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º \nâ•°â”€$ rm -fr .git\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \nâ•°â”€$ git init\nInitialized empty Git repository in /Users/mark/GitHub/static-cms-hugo-local-template/.git/\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \nâ•°â”€$ git add .\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \nâ•°â”€$ git commit -m &quot;first commit&quot;\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \nâ•°â”€$ git branch -M main\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \nâ•°â”€$ git remote add origin https://github.com/SummittDweller/wieting-staticCMS.git\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \nâ•°â”€$ git push -u origin main\n...\nEnumerating objects: 2979, done.\nCounting objects: 100% (2979/2979), done.\nDelta compression using up to 6 threads\nCompressing objects: 100% (2855/2855), done.\nWriting objects: 100% (2979/2979), 95.87 MiB | 2.65 MiB/s, done.\nTotal 2979 (delta 638), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (638/638), done.\nTo https://github.com/SummittDweller/wieting-staticCMS.git\n * [new branch]      main -&gt; main\nbranch 'main' set up to track 'origin/main'.\n</code></pre>\n<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><h1 id=\"wieting-staticcms\">wieting-staticCMS</h1>\n<p>With the new GitHub repo in place let's take it for a local spin.</p>\n<pre><code class=\"language-zsh\">â•­â”€mark@Marks-Mac-Mini ~/GitHub\nâ•°â”€$ git clone https://github.com/SummittDweller/wieting-staticCMS.git\nCloning into 'wieting-staticCMS'...\nremote: Enumerating objects: 2979, done.\nremote: Total 2979 (delta 0), reused 0 (delta 0), pack-reused 2979\nReceiving objects: 100% (2979/2979), 95.87 MiB | 26.77 MiB/s, done.\nResolving deltas: 100% (638/638), done.\nUpdating files: 100% (4834/4834), done.\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\nâ•°â”€$ cd wieting-staticCMS\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/wieting-staticCMS â€¹mainâ€º\nâ•°â”€$ npm install\nnpm WARN deprecated querystring@0.2.0: The querystring API is considered Legacy. new code should use the URLSearchParams API instead.\n\nadded 1567 packages, and audited 1568 packages in 1m\n\n426 packages are looking for funding\n  run `npm fund` for details\n\n2 moderate severity vulnerabilities\n\nTo address all issues, run:\n  npm audit fix\n\nRun `npm audit` for details.\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/wieting-staticCMS â€¹mainâ€º\nâ•°â”€$ npx @staticcms/proxy-server\ninfo: Static CMS File System Proxy Server configured with /Users/mark/GitHub/wieting-staticCMS\ninfo: Static CMS Proxy Server listening on port 8082\n</code></pre>\n<p>Then, in a differnt terminal window...</p>\n<pre><code class=\"language-zsh\">â•­â”€mark@Marks-Mac-Mini ~/GitHub/wieting-staticCMS â€¹mainâ€º\nâ•°â”€$ npm start\n\n&gt; static-cms-hugo-netlify-template@1.0.0 start\n&gt; run-p start:**\n\n\n&gt; static-cms-hugo-netlify-template@1.0.0 start:hugo\n&gt; hugo -d ../dist -s site -vw\n\n\n&gt; static-cms-hugo-netlify-template@1.0.0 start:webpack\n&gt; webpack-dev-server --config webpack.dev.js --hot --stats-error-details\n\nWARN  --verbose was deprecated in Hugo v0.114.0 and will be removed in a future release. use --logLevel info\nStart building sites â€¦\nhugo v0.120.1-16fb2cae88eb6add7d12e9fbfcf01d8670e60a35 darwin/amd64 BuildDate=2023-10-30T16:44:31Z VendorInfo=gohugoio\n\nINFO  copy static: syncing static files to /\nINFO  build: running step process duration 3.975463ms\nINFO  build: running step assemble duration 19.211854ms\nWARN  found no layout file for &quot;json&quot; for kind &quot;section&quot;: You should create a template file which matches Hugo Layouts Lookup Rules for this combination.\nINFO  build: running step render duration 54.091014ms\nINFO  build: running step postProcess duration 8.597Âµs\n\n                   | EN\n-------------------+------\n  Pages            |  57\n  Paginator pages  |   0\n  Non-page files   |   0\n  Static files     | 499\n  Processed images |   0\n  Aliases          |   1\n  Sitemaps         |   1\n  Cleaned          |   0\n\nBuilt in 717 ms\nWatching for changes in /Users/mark/GitHub/wieting-staticCMS/site/{archetypes,content,layouts,package.json,static,themes}\nWatching for config changes in /Users/mark/GitHub/wieting-staticCMS/site/config/_default\nPress Ctrl+C to stop\n&lt;i&gt; [webpack-dev-server] Project is running at:\n&lt;i&gt; [webpack-dev-server] Loopback: http://localhost:3000/\n&lt;i&gt; [webpack-dev-server] On Your Network (IPv4): http://192.168.0.183:3000/\n&lt;i&gt; [webpack-dev-server] On Your Network (IPv6): http://[fe80::1]:3000/\n&lt;i&gt; [webpack-dev-server] Content not from webpack is served from '/Users/mark/GitHub/wieting-staticCMS/dist' directory\n&lt;i&gt; [webpack-dev-server] 404s will fallback to '/index.html'\n&lt;i&gt; [webpack-dev-middleware] wait until bundle finished: /\nassets by path *.js 18.3 MiB\n  asset cms.js 18 MiB [emitted] (name: cms)\n  asset main.js 300 KiB [emitted] (name: main)\nasset main.css 113 KiB [emitted] (name: main)\nasset admin/index.html 521 bytes [emitted]\nasset fonts/.keep 0 bytes [emitted] [from: src/fonts/.keep] [copied]\nEntrypoint main 413 KiB = main.css 113 KiB main.js 300 KiB\nEntrypoint cms 18 MiB = cms.js\nruntime modules 72.3 KiB 38 modules\nmodules by path ./node_modules/ 16.9 MiB 82 modules\nmodules by path ./src/ 133 KiB (javascript) 113 KiB (css/mini-extract)\n  modules by path ./src/js/ 15.2 KiB 9 modules\n  modules by path ./src/css/*.scss 118 KiB (javascript) 113 KiB (css/mini-extract)\n    ./src/css/main.scss 2.78 KiB [built] [code generated]\n    ./node_modules/to-string-loader/src/to-string.js!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 429 bytes [built] [code generated]\n    ./node_modules/mini-css-extract-plugin/dist/loader.js??ruleSet[1].rules[2].use[1]!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 332 bytes [built] [code generated]\n    + 2 modules\n  ./src/index.js 124 bytes [built] [code generated]\nasset modules 5.46 KiB\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.28 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.33 KiB [built] [code generated] [build time executed]\n  data:image/jpeg;base64,/9j/4QAYRXhpZgAA.. 1.55 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.3 KiB [built] [code generated] [build time executed]\nwebpack 5.89.0 compiled successfully in 6051 ms\n</code></pre>\n<p>And again, <strong>IT WORKS!</strong></p>\n<!--kg-card-end: markdown--><p>Time to merge the old CMS config from <code>site/static/.admin-netlify/config.yml</code> into the new config at <code>site/static/admin/config.yml</code>. Â  Then a few changes will be needed since the site's content structure has changed somewhat from the old days. Â </p>",
            "comment_id": "65a2adb6ddadd63e1863c691",
            "plaintext": "Today is Saturday, January 13, 2024, and I won't be able to watch the KC Chief's wildcard playoff game vs. the Miami Dolphins tonight because it is streaming ONLY on Peacock, and I refuse to pay them for the \"privilege\" to watch it live. Â So, I'm going to do something productive instead. Â Let's see if I can spin up an instance of StaticCMS to provide an OPEN CMS for the content editor(s) behind the Wieting Theatre website. Â \n\n\nThe Plan\n\n\nSo, the plan here involves establishing a \"local-only\" CMS for the Wieting Theatre website and running it on the new Ubuntu server in the Wieting's projection booth. Editors should will be given login credentials to that server where they can run a local copy of the website (it's a Hugo static site) AND a local copy of the CMS editor, make changes, preview them, and commit the changes to the project's GitHub repo. The website, hosted with AWS Amplify is then automatically updated based on the updated content.\n\n\n\nAlong the Way\n\n\nIt's worth noting that while looking at StaticCMS I also stumbled upon tabcms - A CMS that runs in your browser tab which might be of interest if \"The Plan\" doesn't work.\n\n\n\nFirst Steps - Start with a Template\n\n\nI choose the guidance at Start with a Template to get started. My aim is to clone that repo and build it locally \"as-is\", then see if I can drop my existing wieting-ss repo into the site directory and continue to make it work locally.\n\n\nIf that works, I'll repeat the same on the Wieting's Ubuntu server and keep pushing forward. Wish me luck?\n\n\n\nGetting Started\n\n\nFollowing the Local Development guidance found me cloning this template then...\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-netlify-template â€¹mainâ€º \nâ•°â”€$ npm install \nnpm WARN deprecated querystring@0.2.0: The querystring API is considered Legacy. new code should use the URLSearchParams API instead.\n\nadded 1567 packages, and audited 1568 packages in 2m\n\n426 packages are looking for funding\n  run `npm fund` for details\n\n2 moderate severity vulnerabilities\n\nTo address all issues, run:\n  npm audit fix\n\nRun `npm audit` for details.\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-netlify-template â€¹main*â€º \nâ•°â”€$ npm start\n\n> static-cms-hugo-netlify-template@1.0.0 start\n> run-p start:**\n\n\n> static-cms-hugo-netlify-template@1.0.0 start:webpack\n> webpack-dev-server --config webpack.dev.js --hot --stats-error-details\n\n\n> static-cms-hugo-netlify-template@1.0.0 start:hugo\n> hugo -d ../dist -s site -vw\n\nWARN  --verbose was deprecated in Hugo v0.114.0 and will be removed in a future release. use --logLevel info\nStart building sites â€¦ \nhugo v0.120.1-16fb2cae88eb6add7d12e9fbfcf01d8670e60a35 darwin/amd64 BuildDate=2023-10-30T16:44:31Z VendorInfo=gohugoio\n\nINFO  copy static: syncing static files to /\nINFO  build: running step process duration 962.376Âµs\nINFO  build: running step assemble duration 4.712758ms\nINFO  build: running step render duration 16.982673ms\nINFO  build: running step postProcess duration 8.3Âµs\n\n                   | EN  \n-------------------+-----\n  Pages            | 10  \n  Paginator pages  |  0  \n  Non-page files   |  0  \n  Static files     | 43  \n  Processed images |  0  \n  Aliases          |  1  \n  Sitemaps         |  1  \n  Cleaned          |  0  \n\nBuilt in 68 ms\nWatching for changes in /Users/mark/GitHub/static-cms-hugo-netlify-template/site/{content,data,layouts,static}\nWatching for config changes in /Users/mark/GitHub/static-cms-hugo-netlify-template/site/config.toml\nPress Ctrl+C to stop\n<i> [webpack-dev-server] Project is running at:\n<i> [webpack-dev-server] Loopback: http://localhost:3000/\n<i> [webpack-dev-server] On Your Network (IPv4): http://192.168.0.183:3000/\n<i> [webpack-dev-server] On Your Network (IPv6): http://[fe80::1]:3000/\n<i> [webpack-dev-server] Content not from webpack is served from '/Users/mark/GitHub/static-cms-hugo-netlify-template/dist' directory\n<i> [webpack-dev-server] 404s will fallback to '/index.html'\n<i> [webpack-dev-middleware] wait until bundle finished: /\nassets by path *.js 18.3 MiB\n  asset cms.js 18 MiB [emitted] (name: cms)\n  asset main.js 300 KiB [emitted] (name: main)\nasset main.css 113 KiB [emitted] (name: main)\nasset admin/index.html 521 bytes [emitted]\nasset fonts/.keep 0 bytes [emitted] [from: src/fonts/.keep] [copied]\nEntrypoint main 413 KiB = main.css 113 KiB main.js 300 KiB\nEntrypoint cms 18 MiB = cms.js\nruntime modules 72.3 KiB 38 modules\nmodules by path ./node_modules/ 16.9 MiB 82 modules\nmodules by path ./src/ 133 KiB (javascript) 113 KiB (css/mini-extract)\n  modules by path ./src/js/ 15.2 KiB 9 modules\n  modules by path ./src/css/*.scss 118 KiB (javascript) 113 KiB (css/mini-extract)\n    ./src/css/main.scss 2.78 KiB [built] [code generated]\n    ./node_modules/to-string-loader/src/to-string.js!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 429 bytes [built] [code generated]\n    ./node_modules/mini-css-extract-plugin/dist/loader.js??ruleSet[1].rules[2].use[1]!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 332 bytes [built] [code generated]\n    + 2 modules\n  ./src/index.js 124 bytes [built] [code generated]\nasset modules 5.46 KiB\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.28 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.33 KiB [built] [code generated] [build time executed]\n  data:image/jpeg;base64,/9j/4QAYRXhpZgAA.. 1.55 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.3 KiB [built] [code generated] [build time executed]\nwebpack 5.89.0 compiled successfully in 6191 ms\nINFO  Received System Events: [CREATE        \"/Users/mark/GitHub/static-cms-hugo-netlify-template/site/data/webpack.json\" WRITE         \"/Users/mark/GitHub/static-cms-hugo-netlify-template/site/data/webpack.json\"]\n\nChange detected, rebuilding site.\n2024-01-13 10:55:38.259 -0600\nData changed WRITE         \"/Users/mark/GitHub/static-cms-hugo-netlify-template/site/data/webpack.json\"\nData changed WRITE         \"/Users/mark/GitHub/static-cms-hugo-netlify-template/site/data/webpack.json\"\nINFO  build: running step process duration 114.033Âµs\nINFO  build: running step assemble duration 277ns\nINFO  build: running step render duration 6.244639ms\nINFO  build: running step postProcess duration 1.831Âµs\nTotal in 6 ms\n\n\n\nThe demo site is indeed working at http://localhost:3000/ and a vist to http://localhost:3000/admin does indeed open a StaticCMS login that's prompting me with the following image.\n\n\n\n\n\n\nLet's Go Local!\n\n\nNext, I'm going to try and switch what we have above to \"go local\" using this guidance provided in the StaticCMS documenation. Fingers crossed for good luck...\n\n\n\nEureka! It Works!\n\n\nSo, I made the local_backend config changes as prescribed in site/static/admin/config.yml and that file now looks like this:\n\n\nlocal_backend: \n  # when using a custom proxy server port\n  url: http://localhost:8082/api/v1\n  # when accessing the local site from a host other than 'localhost' or '127.0.0.1'\n  allowed_hosts: ['192.168.0.1']\n\n\n\nI also added a new .env file in the project root directory with a single line reading PORT=8082, matching the port number specified in the url: value from config.yml.\n\n\nNow, with npx @staticcms/proxy-server running in a local terminal I'm able to run npm start (in my VSCode terminal) to launch the site at localhost:3000. Having done that I'm able to visit http://localhost:3000/admin where I get a new StaticCMS splash screen with a simple Login button, not a Netlify button. Yay!\n\n\n\nEven Better News?\n\n\nStaticCMS was built from NetlifyCMS so the site/static/admin/config.yml. I think I'll be able to use the collections: portion of my old admin/config.yml file from wieting-one-click-hugo-cms to get a headstart on setting that up!\n\n\nNext step... let's see if I can drop the site directory from wieting-ss into this local project and still have a functioning local site. Again, fingers crossed for luck.\n\n\n\nFresh Restart\n\n\nIn order to start fresh I went back to the StaticJsCMS/static-cms-hugo-netlify-template repo and created a new fork (not a clone) in my Summitt-Services team space at https://github.com/Summitt-Services/static-cms-hugo-local-template. In the new fork I changed the -netlify- portion of the name to -local- as this new project is intended to have no Netlify association, only a \"local\" CMS will be supported.\n\n\nNext, I cloned the new fork to my workstation and got it working locally again using the same steps I had taken above.\n\n\n\nCopying wieting-ss to static-cms-hugo-local-template\n\n\nFor safe-keeping I created a new branch named wieting in ~/GitHub/static-cms-hugo-local-template where I did this:\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹wieting*â€º \nâ•°â”€$ rsync -aruvi ../wieting-ss/. site/.\n...\n>f++++++++++ themes/vanilla-bootstrap-hugo-theme/static/js/checkTweetDate.js\n>f++++++++++ themes/vanilla-bootstrap-hugo-theme/static/js/feather.min.js\n>f++++++++++ themes/vanilla-bootstrap-hugo-theme/static/js/jquery-3.3.1.slim.min.js\n\nsent 282,877,469 bytes  received 470,944 bytes  9,605,030.95 bytes/sec\ntotal size is 470,527,158  speedup is 1.66\n\n\n\nWill it work? Let's see... NOPE. It does produce a site but the old \"Kaldi\" content is still all I see. I even changed the backend.branch: value from main to wieting, but that did nothing. So, I've captured the output here so that I can have a look at what's happening.\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹wieting*â€º \nâ•°â”€$ npm start                               \n\n> static-cms-hugo-netlify-template@1.0.0 start\n> run-p start:**\n\n\n> static-cms-hugo-netlify-template@1.0.0 start:webpack\n> webpack-dev-server --config webpack.dev.js --hot --stats-error-details\n\n\n> static-cms-hugo-netlify-template@1.0.0 start:hugo\n> hugo -d ../dist -s site -vw\n\nWARN  --verbose was deprecated in Hugo v0.114.0 and will be removed in a future release. use --logLevel info\nStart building sites â€¦ \nhugo v0.120.1-16fb2cae88eb6add7d12e9fbfcf01d8670e60a35 darwin/amd64 BuildDate=2023-10-30T16:44:31Z VendorInfo=gohugoio\n\nINFO  copy static: syncing static files to /\nINFO  build: running step process duration 4.236952ms\nINFO  build: running step assemble duration 13.684119ms\nWARN  found no layout file for \"json\" for kind \"section\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination.\nINFO  build: running step render duration 58.753135ms\nINFO  build: running step postProcess duration 8.744Âµs\n\n                   | EN   \n-------------------+------\n  Pages            |  66  \n  Paginator pages  |   7  \n  Non-page files   |   0  \n  Static files     | 541  \n  Processed images |   0  \n  Aliases          |   7  \n  Sitemaps         |   1  \n  Cleaned          |   0  \n\nBuilt in 579 ms\nWatching for changes in /Users/mark/GitHub/static-cms-hugo-local-template/site/{archetypes,content,data,layouts,package.json,static,themes}\nWatching for config changes in /Users/mark/GitHub/static-cms-hugo-local-template/site/config.toml, /Users/mark/GitHub/static-cms-hugo-local-template/site/config/_default\nPress Ctrl+C to stop\n<i> [webpack-dev-server] Project is running at:\n<i> [webpack-dev-server] Loopback: http://localhost:3000/\n<i> [webpack-dev-server] On Your Network (IPv4): http://192.168.0.183:3000/\n<i> [webpack-dev-server] On Your Network (IPv6): http://[fe80::1]:3000/\n<i> [webpack-dev-server] Content not from webpack is served from '/Users/mark/GitHub/static-cms-hugo-local-template/dist' directory\n<i> [webpack-dev-server] 404s will fallback to '/index.html'\n<i> [webpack-dev-middleware] wait until bundle finished: /\nassets by path *.js 18.3 MiB\n  asset cms.js 18 MiB [emitted] (name: cms)\n  asset main.js 300 KiB [emitted] (name: main)\nasset main.css 113 KiB [emitted] (name: main)\nasset admin/index.html 521 bytes [emitted]\nasset fonts/.keep 0 bytes [emitted] [from: src/fonts/.keep] [copied]\nEntrypoint main 413 KiB = main.css 113 KiB main.js 300 KiB\nEntrypoint cms 18 MiB = cms.js\nruntime modules 72.3 KiB 38 modules\nmodules by path ./node_modules/ 16.9 MiB 82 modules\nmodules by path ./src/ 133 KiB (javascript) 113 KiB (css/mini-extract)\n  modules by path ./src/js/ 15.2 KiB 9 modules\n  modules by path ./src/css/*.scss 118 KiB (javascript) 113 KiB (css/mini-extract)\n    ./src/css/main.scss 2.78 KiB [built] [code generated]\n    ./node_modules/to-string-loader/src/to-string.js!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 429 bytes [built] [code generated]\n    ./node_modules/mini-css-extract-plugin/dist/loader.js??ruleSet[1].rules[2].use[1]!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 332 bytes [built] [code generated]\n    + 2 modules\n  ./src/index.js 124 bytes [built] [code generated]\nasset modules 5.46 KiB\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.28 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.33 KiB [built] [code generated] [build time executed]\n  data:image/jpeg;base64,/9j/4QAYRXhpZgAA.. 1.55 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.3 KiB [built] [code generated] [build time executed]\nwebpack 5.89.0 compiled successfully in 5563 ms\nINFO  Received System Events: [CHMOD         \"/Users/mark/GitHub/static-cms-hugo-local-template/site/data/webpack.json\" WRITE         \"/Users/mark/GitHub/static-cms-hugo-local-template/site/data/webpack.json\"]\n\nChange detected, rebuilding site.\n2024-01-13 13:15:08.329 -0600\nData changed WRITE         \"/Users/mark/GitHub/static-cms-hugo-local-template/site/data/webpack.json\"\nINFO  build: running step process duration 186.604Âµs\nINFO  build: running step assemble duration 244ns\nWARN  found no layout file for \"json\" for kind \"section\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination.\nINFO  build: running step render duration 31.514265ms\nINFO  build: running step postProcess duration 7.661Âµs\nTotal in 31 ms\n^C<i> [webpack-dev-server] Gracefully shutting down. To force exit, press ^C again. Please wait...\n\n\n\n\nCorrections Needed\n\n\nSo, the first thing I see here is that the new site directory contains the template's content/_index.md file which naturally becomes the site's home page. It contains only \"Kaldi\" content. So I tried removing that _index.md file and that changed the home page \"title\", but very little else.\n\n\nI think returing to the main branch of this project and starting over again but using only the content of wieting-ss in the new site/ directory might be wise. I did it like this:\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\nâ•°â”€$ rm -fr static-cms-hugo-local-template\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\nâ•°â”€$ git clone https://github.com/Summitt-Services/static-cms-hugo-local-template.git\nCloning into 'static-cms-hugo-local-template'...\nremote: Enumerating objects: 574, done.\nremote: Counting objects: 100% (155/155), done.\nremote: Compressing objects: 100% (50/50), done.\nremote: Total 574 (delta 122), reused 125 (delta 102), pack-reused 419\nReceiving objects: 100% (574/574), 22.14 MiB | 23.94 MiB/s, done.\nResolving deltas: 100% (248/248), done.\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\nâ•°â”€$ cd static-cms-hugo-local-template\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹mainâ€º\nâ•°â”€$ cp -fr site/static/admin ~\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹mainâ€º\nâ•°â”€$ rm -fr site\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º\nâ•°â”€$ mkdir site\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º\nâ•°â”€$ cp -fr ../wieting-ss/. site/.\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º\nâ•°â”€$ cp -f ~/admin/config.yml site/static/admin/.\n\n\n\nNext I launched the proxy server like so:\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º\nâ•°â”€$ npx @staticcms/proxy-server\ninfo: Static CMS File System Proxy Server configured with /Users/mark/GitHub/static-cms-hugo-local-template\ninfo: Static CMS Proxy Server listening on port 8082\n\n\n\nThen in my VSCode terminal this:\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º \nâ•°â”€$ npm start\n\n> static-cms-hugo-netlify-template@1.0.0 start\n> run-p start:**\n\n\n> static-cms-hugo-netlify-template@1.0.0 start:webpack\n> webpack-dev-server --config webpack.dev.js --hot --stats-error-details\n\n\n> static-cms-hugo-netlify-template@1.0.0 start:hugo\n> hugo -d ../dist -s site -vw\n\nWARN  --verbose was deprecated in Hugo v0.114.0 and will be removed in a future release. use --logLevel info\nStart building sites â€¦ \nhugo v0.120.1-16fb2cae88eb6add7d12e9fbfcf01d8670e60a35 darwin/amd64 BuildDate=2023-10-30T16:44:31Z VendorInfo=gohugoio\n\nINFO  copy static: syncing static files to /\nINFO  build: running step process duration 3.193622ms\nINFO  build: running step assemble duration 25.748629ms\nWARN  found no layout file for \"json\" for kind \"section\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination.\nINFO  build: running step render duration 70.992512ms\nINFO  build: running step postProcess duration 9.94Âµs\n<i> [webpack-dev-server] Project is running at:\n<i> [webpack-dev-server] Loopback: http://localhost:3000/\n<i> [webpack-dev-server] On Your Network (IPv4): http://192.168.0.183:3000/\n<i> [webpack-dev-server] On Your Network (IPv6): http://[fe80::1]:3000/\n<i> [webpack-dev-server] Content not from webpack is served from '/Users/mark/GitHub/static-cms-hugo-local-template/dist' directory\n<i> [webpack-dev-server] 404s will fallback to '/index.html'\n\n                   | EN   \n-------------------+------\n  Pages            |  57  \n  Paginator pages  |   0  \n  Non-page files   |   0  \n  Static files     | 499  \n  Processed images |   0  \n  Aliases          |   1  \n  Sitemaps         |   1  \n  Cleaned          |   0  \n\nBuilt in 1034 ms\nWatching for changes in /Users/mark/GitHub/static-cms-hugo-local-template/site/{archetypes,content,layouts,package.json,static,themes}\nWatching for config changes in /Users/mark/GitHub/static-cms-hugo-local-template/site/config/_default\nPress Ctrl+C to stop\n<i> [webpack-dev-middleware] wait until bundle finished: /\nassets by path *.js 18.3 MiB\n  asset cms.js 18 MiB [emitted] (name: cms)\n  asset main.js 300 KiB [emitted] (name: main)\nasset main.css 113 KiB [emitted] (name: main)\nasset admin/index.html 521 bytes [emitted]\nasset fonts/.keep 0 bytes [emitted] [from: src/fonts/.keep] [copied]\nEntrypoint main 413 KiB = main.css 113 KiB main.js 300 KiB\nEntrypoint cms 18 MiB = cms.js\nruntime modules 72.3 KiB 38 modules\nmodules by path ./node_modules/ 16.9 MiB 82 modules\nmodules by path ./src/ 133 KiB (javascript) 113 KiB (css/mini-extract)\n  modules by path ./src/js/ 15.2 KiB 9 modules\n  modules by path ./src/css/*.scss 118 KiB (javascript) 113 KiB (css/mini-extract)\n    ./src/css/main.scss 2.78 KiB [built] [code generated]\n    ./node_modules/to-string-loader/src/to-string.js!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 429 bytes [built] [code generated]\n    ./node_modules/mini-css-extract-plugin/dist/loader.js??ruleSet[1].rules[2].use[1]!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 332 bytes [built] [code generated]\n    + 2 modules\n  ./src/index.js 124 bytes [built] [code generated]\nasset modules 5.46 KiB\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.28 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.33 KiB [built] [code generated] [build time executed]\n  data:image/jpeg;base64,/9j/4QAYRXhpZgAA.. 1.55 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.3 KiB [built] [code generated] [build time executed]\nwebpack 5.89.0 compiled successfully in 6771 ms\n\n\n\nAgain, it works. Only this time the Wieting website appears at http://localhost:3000 and http://localhost:3000/admin works too, but with the wrong configuration. Still, that's a WIN!\n\n\n\nTime To Save My Progress\n\n\nI really don't want to dump 4000+ new files, many of them specific to the Wieting website, into my pristine (and working) https://github.com/Summitt-Services/static-cms-hugo-local-template GitHub repository. So, I'm going to clean up my local project by removing that which is no longer needed, and then I'm going to remove the .git directory and create/populate a new wieting-staticCMS private repository. After creating that empty repository the process looked like this:\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º \nâ•°â”€$ rm -fr site/.git \nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template â€¹main*â€º \nâ•°â”€$ rm -fr .git\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \nâ•°â”€$ git init\nInitialized empty Git repository in /Users/mark/GitHub/static-cms-hugo-local-template/.git/\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \nâ•°â”€$ git add .\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \nâ•°â”€$ git commit -m \"first commit\"\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \nâ•°â”€$ git branch -M main\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \nâ•°â”€$ git remote add origin https://github.com/SummittDweller/wieting-staticCMS.git\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/static-cms-hugo-local-template \nâ•°â”€$ git push -u origin main\n...\nEnumerating objects: 2979, done.\nCounting objects: 100% (2979/2979), done.\nDelta compression using up to 6 threads\nCompressing objects: 100% (2855/2855), done.\nWriting objects: 100% (2979/2979), 95.87 MiB | 2.65 MiB/s, done.\nTotal 2979 (delta 638), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (638/638), done.\nTo https://github.com/SummittDweller/wieting-staticCMS.git\n * [new branch]      main -> main\nbranch 'main' set up to track 'origin/main'.\n\n\n\n\nwieting-staticCMS\n\n\nWith the new GitHub repo in place let's take it for a local spin.\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\nâ•°â”€$ git clone https://github.com/SummittDweller/wieting-staticCMS.git\nCloning into 'wieting-staticCMS'...\nremote: Enumerating objects: 2979, done.\nremote: Total 2979 (delta 0), reused 0 (delta 0), pack-reused 2979\nReceiving objects: 100% (2979/2979), 95.87 MiB | 26.77 MiB/s, done.\nResolving deltas: 100% (638/638), done.\nUpdating files: 100% (4834/4834), done.\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub\nâ•°â”€$ cd wieting-staticCMS\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/wieting-staticCMS â€¹mainâ€º\nâ•°â”€$ npm install\nnpm WARN deprecated querystring@0.2.0: The querystring API is considered Legacy. new code should use the URLSearchParams API instead.\n\nadded 1567 packages, and audited 1568 packages in 1m\n\n426 packages are looking for funding\n  run `npm fund` for details\n\n2 moderate severity vulnerabilities\n\nTo address all issues, run:\n  npm audit fix\n\nRun `npm audit` for details.\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/wieting-staticCMS â€¹mainâ€º\nâ•°â”€$ npx @staticcms/proxy-server\ninfo: Static CMS File System Proxy Server configured with /Users/mark/GitHub/wieting-staticCMS\ninfo: Static CMS Proxy Server listening on port 8082\n\n\n\nThen, in a differnt terminal window...\n\n\nâ•­â”€mark@Marks-Mac-Mini ~/GitHub/wieting-staticCMS â€¹mainâ€º\nâ•°â”€$ npm start\n\n> static-cms-hugo-netlify-template@1.0.0 start\n> run-p start:**\n\n\n> static-cms-hugo-netlify-template@1.0.0 start:hugo\n> hugo -d ../dist -s site -vw\n\n\n> static-cms-hugo-netlify-template@1.0.0 start:webpack\n> webpack-dev-server --config webpack.dev.js --hot --stats-error-details\n\nWARN  --verbose was deprecated in Hugo v0.114.0 and will be removed in a future release. use --logLevel info\nStart building sites â€¦\nhugo v0.120.1-16fb2cae88eb6add7d12e9fbfcf01d8670e60a35 darwin/amd64 BuildDate=2023-10-30T16:44:31Z VendorInfo=gohugoio\n\nINFO  copy static: syncing static files to /\nINFO  build: running step process duration 3.975463ms\nINFO  build: running step assemble duration 19.211854ms\nWARN  found no layout file for \"json\" for kind \"section\": You should create a template file which matches Hugo Layouts Lookup Rules for this combination.\nINFO  build: running step render duration 54.091014ms\nINFO  build: running step postProcess duration 8.597Âµs\n\n                   | EN\n-------------------+------\n  Pages            |  57\n  Paginator pages  |   0\n  Non-page files   |   0\n  Static files     | 499\n  Processed images |   0\n  Aliases          |   1\n  Sitemaps         |   1\n  Cleaned          |   0\n\nBuilt in 717 ms\nWatching for changes in /Users/mark/GitHub/wieting-staticCMS/site/{archetypes,content,layouts,package.json,static,themes}\nWatching for config changes in /Users/mark/GitHub/wieting-staticCMS/site/config/_default\nPress Ctrl+C to stop\n<i> [webpack-dev-server] Project is running at:\n<i> [webpack-dev-server] Loopback: http://localhost:3000/\n<i> [webpack-dev-server] On Your Network (IPv4): http://192.168.0.183:3000/\n<i> [webpack-dev-server] On Your Network (IPv6): http://[fe80::1]:3000/\n<i> [webpack-dev-server] Content not from webpack is served from '/Users/mark/GitHub/wieting-staticCMS/dist' directory\n<i> [webpack-dev-server] 404s will fallback to '/index.html'\n<i> [webpack-dev-middleware] wait until bundle finished: /\nassets by path *.js 18.3 MiB\n  asset cms.js 18 MiB [emitted] (name: cms)\n  asset main.js 300 KiB [emitted] (name: main)\nasset main.css 113 KiB [emitted] (name: main)\nasset admin/index.html 521 bytes [emitted]\nasset fonts/.keep 0 bytes [emitted] [from: src/fonts/.keep] [copied]\nEntrypoint main 413 KiB = main.css 113 KiB main.js 300 KiB\nEntrypoint cms 18 MiB = cms.js\nruntime modules 72.3 KiB 38 modules\nmodules by path ./node_modules/ 16.9 MiB 82 modules\nmodules by path ./src/ 133 KiB (javascript) 113 KiB (css/mini-extract)\n  modules by path ./src/js/ 15.2 KiB 9 modules\n  modules by path ./src/css/*.scss 118 KiB (javascript) 113 KiB (css/mini-extract)\n    ./src/css/main.scss 2.78 KiB [built] [code generated]\n    ./node_modules/to-string-loader/src/to-string.js!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 429 bytes [built] [code generated]\n    ./node_modules/mini-css-extract-plugin/dist/loader.js??ruleSet[1].rules[2].use[1]!./node_modules/css-loader/dist/cjs.js!./node_modules/postcss-loader/dist/cjs.js!./node_modules/sass-loader/dist/cjs.js!./src/css/main.scss 332 bytes [built] [code generated]\n    + 2 modules\n  ./src/index.js 124 bytes [built] [code generated]\nasset modules 5.46 KiB\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.28 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.33 KiB [built] [code generated] [build time executed]\n  data:image/jpeg;base64,/9j/4QAYRXhpZgAA.. 1.55 KiB [built] [code generated] [build time executed]\n  data:image/png;base64,iVBORw0KGgoAAAAN.. 1.3 KiB [built] [code generated] [build time executed]\nwebpack 5.89.0 compiled successfully in 6051 ms\n\n\n\nAnd again, IT WORKS!\n\n\nTime to merge the old CMS config from site/static/.admin-netlify/config.yml into the new config at site/static/admin/config.yml. Â  Then a few changes will be needed since the site's content structure has changed somewhat from the old days. Â ",
            "feature_image": "__GHOST_URL__/content/images/2024/01/Screenshot-2024-01-13-at-09.34.52.png",
            "featured": 1,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2024-01-13T15:35:18.000Z",
            "updated_at": "2024-01-14T03:53:56.000Z",
            "published_at": "2024-01-13T15:40:23.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          },
          {
            "id": "670983acddadd63e1863c6d9",
            "uuid": "c5a83a00-dbca-4d55-b64a-00f3e095760c",
            "title": "NOT Like a Rolling Stone",
            "slug": "not-like-a-rolling-stone",
            "mobiledoc": "{\"version\":\"0.3.1\",\"atoms\":[],\"cards\":[],\"markups\":[],\"sections\":[[1,\"p\",[[0,[],0,\"Where has the last year gone?  While life (metaphorically the stream in the hero image) rolls on, this blog (any of the moss covered rocks in the image) has not. \"]]],[1,\"p\",[[0,[],0,\"This blog was born of good intentions, but frankly it's too hard for an old fart like me to remember how to maintain it and make contributions.  Having not posted here in many months, I had to consult my \\\"documentation\\\", and ultimately my retired password manager, to get back in and post this.  That's unacceptable, and it won't happen again.  \"]]],[1,\"p\",[[0,[],0,\"So, I'm going to replace this Ghost-driven \\\"semi-static\\\" blog with something more familiar and less costly/complex to operate.  Probably a Hugo static site that is truly \\\"static\\\", but not stagnant!   There will be no more blog-moss grown here! \"]]],[1,\"p\",[[0,[],0,\"Famous last words?\"]]],[1,\"p\",[[0,[],0,\"See you on the flip-side.  Soon.\"]]]],\"ghostVersion\":\"4.0\"}",
            "lexical": null,
            "html": "<p>Where has the last year gone? Â While life (metaphorically the stream in the hero image) rolls on, this blog (any of the moss covered rocks in the image) has not. </p><p>This blog was born of good intentions, but frankly it's too hard for an old fart like me to remember how to maintain it and make contributions. Â Having not posted here in many months, I had to consult my \"documentation\", and ultimately my retired password manager, to get back in and post this. Â That's unacceptable, and it won't happen again. Â </p><p>So, I'm going to replace this Ghost-driven \"semi-static\" blog with something more familiar and less costly/complex to operate. Â Probably a Hugo static site that is truly \"static\", but not stagnant! Â  There will be no more blog-moss grown here! </p><p>Famous last words?</p><p>See you on the flip-side. Â Soon.</p>",
            "comment_id": "670983acddadd63e1863c6d9",
            "plaintext": "Where has the last year gone? Â While life (metaphorically the stream in the hero image) rolls on, this blog (any of the moss covered rocks in the image) has not.\n\nThis blog was born of good intentions, but frankly it's too hard for an old fart like me to remember how to maintain it and make contributions. Â Having not posted here in many months, I had to consult my \"documentation\", and ultimately my retired password manager, to get back in and post this. Â That's unacceptable, and it won't happen again. Â \n\nSo, I'm going to replace this Ghost-driven \"semi-static\" blog with something more familiar and less costly/complex to operate. Â Probably a Hugo static site that is truly \"static\", but not stagnant! Â  There will be no more blog-moss grown here!\n\nFamous last words?\n\nSee you on the flip-side. Â Soon.",
            "feature_image": "https://images.unsplash.com/photo-1438006864692-327506ca1997?crop=entropy&cs=tinysrgb&fit=max&fm=jpg&ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fG1vc3N8ZW58MHx8fHwxNzI4Njc2Njk3fDA&ixlib=rb-4.0.3&q=80&w=2000",
            "featured": 1,
            "type": "post",
            "status": "published",
            "locale": null,
            "visibility": "public",
            "email_recipient_filter": "all",
            "created_at": "2024-10-11T19:59:40.000Z",
            "updated_at": "2024-10-11T20:17:41.000Z",
            "published_at": "2024-10-11T20:09:55.000Z",
            "custom_excerpt": null,
            "codeinjection_head": null,
            "codeinjection_foot": null,
            "custom_template": null,
            "canonical_url": null,
            "newsletter_id": null
          }
        ]
}